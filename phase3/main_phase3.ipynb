{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***\n",
    "### <span style='color:green'> ME Algorithm  &emsp;&emsp; Feb, 2024 </span>\n",
    "### <span style='color:Blue'> Phase 3 </span>\n",
    "### <p> Yan-Bin Chen (陳彥賓) &emsp; yanbin@stat.sinica.edu.tw </p>\n",
    "### <p> Institute of Statistical Science, Academia Sinica, Taipei, Taiwan.</p>  \n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Input"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "import numpy as np\n",
    "import collections\n",
    "import pandas\n",
    "import itertools\n",
    "from itertools import chain\n",
    "import random \n",
    "import time\n",
    "import datetime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "region: [15  9 11  6  7  8 10 20 14 12 19  1 13 18  4]\n",
      "region amount: 15\n"
     ]
    }
   ],
   "source": [
    "# Input\n",
    "MNIST     = True\n",
    "TRIALS    = 1\n",
    "timestr   = ''\n",
    "#NUM_NEI  = 4 # Others is 4\n",
    "#NUM_NEI   = 2 # MNIST is 5\n",
    "#Region_Index_loc = 6 # column location; Others is 6\n",
    "REGION_INDEX_LOC = 4 # column location; MNIST is 4\n",
    "\n",
    "PATH1='../phase3_data/MNIST_seedinds.txt'\n",
    "PATH2='../phase3_data/MNIST_bilabels.txt'\n",
    "PATH3='../phase3_data/MNIST_seedinds_neighborregions.txt'\n",
    "PATH4='../phase3_data/MNIST_Labels_Spec20.csv'\n",
    "PATH5='../phase3_data/Small_MNIST_tSNE_embeddings.pickle'\n",
    "#PATH5='../phase3_data/MNIST_Labels_5000.csv'\n",
    "#=================================================================\n",
    "\n",
    "# (1)PATH1\n",
    "df = pandas.read_csv(PATH1, header=None, delimiter = \"\\t\")\n",
    "region = df.to_numpy().T[0]\n",
    "NUM_region = len(region)\n",
    "\n",
    "# (2)PATH2\n",
    "df = pandas.read_csv(PATH2, header=None, delimiter = \"\\t\")\n",
    "cen = df.to_numpy()\n",
    "\n",
    "print('region:', region)\n",
    "print('region amount:', len(region))\n",
    "\n",
    "\n",
    "# (4)PATH4. Have to be here. The following neighboring process needs this information\n",
    "df = pandas.read_csv(PATH4)\n",
    "#1213 add auto judge\n",
    "all_region_index = df.to_numpy().T[REGION_INDEX_LOC].astype(int)"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "# (5)PATH5     conver the embedded data into the pickle file\n",
    "df1 = pandas.read_csv(PATH5)\n",
    "test_array        = df1.iloc[:,:3].to_numpy().copy()\n",
    "test_label_answer = df1.iloc[:,3].to_numpy().copy()\n",
    "\n",
    "#save\n",
    "with open('../phase3_data/Small_MNIST_tSNE_embeddings.pickle', 'wb') as f:\n",
    "    pickle.dump([test_array, test_label_answer], f)\n",
    "print (test_label_answer, test_array)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Get neighbors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "neighbor amount:  15\n",
      "[[ 9]\n",
      " [15]\n",
      " [16]\n",
      " [ 7]\n",
      " [ 6]\n",
      " [ 8]\n",
      " [20]\n",
      " [10]\n",
      " [ 5]\n",
      " [ 6]\n",
      " [ 1]\n",
      " [19]\n",
      " [13]\n",
      " [ 4]\n",
      " [18]]\n",
      "neighbor amount:  14\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[[9],\n",
       " [15],\n",
       " [16],\n",
       " [7],\n",
       " [6],\n",
       " [8],\n",
       " [20],\n",
       " [10],\n",
       " [5],\n",
       " [],\n",
       " [1],\n",
       " [19],\n",
       " [13],\n",
       " [4],\n",
       " [18]]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "if (PATH3):\n",
    "    df = pandas.read_csv(PATH3, delim_whitespace=' ', header=None,  index_col=0)\n",
    "    neighbors = df.to_numpy()\n",
    "    NUM_NEI=df.shape[1]\n",
    "    \n",
    "    print('neighbor amount: ',len(list(chain.from_iterable(neighbors))))\n",
    "    print(neighbors)\n",
    "\n",
    "# filter out duplicated ones\n",
    "    test_list=list(chain.from_iterable(neighbors))\n",
    "    res2=[]\n",
    "    [res2.append(n) for n, i in enumerate(test_list) if i in test_list[:n]]\n",
    "\n",
    "    res2.reverse()\n",
    "    neighbors=neighbors.tolist()\n",
    "    [neighbors[x//NUM_NEI].pop(x%NUM_NEI) for x in res2]\n",
    "    print('neighbor amount: ',len(list(chain.from_iterable(neighbors))))\n",
    "    display(neighbors)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[15, 9],\n",
       " [9, 15],\n",
       " [11, 16],\n",
       " [6, 7],\n",
       " [7, 6],\n",
       " [8, 8],\n",
       " [10, 20],\n",
       " [20, 10],\n",
       " [14, 5],\n",
       " [12],\n",
       " [19, 1],\n",
       " [1, 19],\n",
       " [13, 13],\n",
       " [18, 4],\n",
       " [4, 18]]"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# combine seed regions and neighbors\n",
    "if (PATH3):\n",
    "    reg_nei=[]\n",
    "    for i in range(len(neighbors)):\n",
    "        a=[region[i]]\n",
    "        b=neighbors[i]\n",
    "        if len(b):\n",
    "            c=list(np.concatenate((a,b),axis=0))\n",
    "        else:\n",
    "            c=a.copy()\n",
    "        reg_nei.append(c)\n",
    "else:\n",
    "    reg_nei=region.copy()\n",
    "\n",
    "reg_nei"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "** original duplicate at i= 5 ;region 8 ;duplicate size 491\n",
      "** same duplicate situation\n",
      "** original duplicate at i= 12 ;region 13 ;duplicate size 460\n",
      "** same duplicate situation\n"
     ]
    }
   ],
   "source": [
    "# collect images from target region and neighboring regions\n",
    "# input : region, NUM_region, cen, all_region_index, neighbors\n",
    "# output: region_image: to save image indices corresponding to seed regions.\n",
    "#         region_answer: to save answer\n",
    "\n",
    "region_image_before=[]\n",
    "region_image=[]\n",
    "region_image_pure=[]\n",
    "for i in range(NUM_region):\n",
    "    \n",
    "    \n",
    "    #(1)neighbor  nei\n",
    "    if (PATH3):\n",
    "        addr_nei=[]\n",
    "        for j in range(len(neighbors[i])):\n",
    "            addr_nei=addr_nei+list(np.where(all_region_index==neighbors[i][j])[0])\n",
    "            #check whether it has duplicates\n",
    "            if (len(addr_nei) != len(set(addr_nei))):\n",
    "                print(\"neighbor duplicate at i=\",i,\"j=\",j)\n",
    "                addr_nei=list(set(addr_nei))\n",
    "\n",
    "    #(2)original\n",
    "    addr=list(np.where(  (all_region_index==region[i])  &  (cen.T[1]==1)  )[0])\n",
    "    if (PATH3):\n",
    "        addr=addr+addr_nei\n",
    "    #check whether it has duplicates\n",
    "    if (len(addr) != len(set(addr))):\n",
    "        print(\"** original duplicate at i=\",i,\";region\",region[i],\";duplicate size\",len(addr)-len(set(addr)))\n",
    "        addr=list(set(addr))\n",
    "    region_image.append(addr)\n",
    "\n",
    "    #(3)original before centroid (this is only for check, rather than for main codes)\n",
    "    addr_before=list(np.where(all_region_index==region[i])[0])\n",
    "    if (PATH3):\n",
    "        addr_before=addr_before+addr_nei\n",
    "    #check whether it has duplicates\n",
    "    if (len(addr_before) != len(set(addr_before))):\n",
    "        print(\"** same duplicate situation\")\n",
    "        addr_before=list(set(addr_before))\n",
    "    region_image_before.append(addr_before)\n",
    "\n",
    "    #(4)pure\n",
    "    addr_pure=list(np.where(  (all_region_index==region[i])  &  (cen.T[1]==1)  )[0])\n",
    "    region_image_pure.append(addr_pure)\n",
    "\n",
    "\n",
    "with open('../phase3_data/' + timestr + 'region_for_phase5.pickle', 'wb') as f:\n",
    "    pickle.dump([region, reg_nei, region_image_pure, region_image,], f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test_array: (5000, 3)\n",
      "training size: 7151\n"
     ]
    }
   ],
   "source": [
    "# ==== test_array ====\n",
    "with open(PATH5, 'rb') as f:\n",
    "    test_array, test_label_answer = pickle.load(f)\n",
    "print(\"test_array:\",np.shape(test_array))\n",
    "\n",
    "\n",
    "# 1213 add auto judge /255\n",
    "test_array = np.expand_dims(test_array, axis = -1)\n",
    "test_array /= 255\n",
    "print(\"training size:\",len(np.array(list(chain.from_iterable(region_image)))))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# CNN original"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "n, p1, p2 0 0 0\n",
      "Model: \"sequential_3\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv1d_7 (Conv1D)            (None, 3, 6)              12        \n",
      "_________________________________________________________________\n",
      "average_pooling1d_5 (Average (None, 1, 6)              0         \n",
      "_________________________________________________________________\n",
      "conv1d_8 (Conv1D)            (None, 1, 16)             112       \n",
      "_________________________________________________________________\n",
      "average_pooling1d_6 (Average (None, 1, 16)             0         \n",
      "_________________________________________________________________\n",
      "conv1d_9 (Conv1D)            (None, 1, 120)            2040      \n",
      "_________________________________________________________________\n",
      "flatten_3 (Flatten)          (None, 120)               0         \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (None, 84)                10164     \n",
      "_________________________________________________________________\n",
      "preds (Dense)                (None, 15)                1275      \n",
      "=================================================================\n",
      "Total params: 13,603\n",
      "Trainable params: 13,603\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Train on 6435 samples, validate on 716 samples\n",
      "Epoch 1/80\n",
      "6435/6435 [==============================] - 1s 82us/step - loss: 2.6667 - accuracy: 0.1753 - val_loss: 2.5668 - val_accuracy: 0.1885\n",
      "Epoch 2/80\n",
      "6435/6435 [==============================] - 0s 39us/step - loss: 2.3448 - accuracy: 0.2023 - val_loss: 2.1390 - val_accuracy: 0.2207\n",
      "Epoch 3/80\n",
      "6435/6435 [==============================] - 0s 38us/step - loss: 2.0361 - accuracy: 0.2505 - val_loss: 1.9727 - val_accuracy: 0.2486\n",
      "Epoch 4/80\n",
      "6435/6435 [==============================] - 0s 38us/step - loss: 1.9013 - accuracy: 0.2738 - val_loss: 1.8676 - val_accuracy: 0.2612\n",
      "Epoch 5/80\n",
      "6435/6435 [==============================] - 0s 42us/step - loss: 1.7996 - accuracy: 0.2962 - val_loss: 1.7860 - val_accuracy: 0.2751\n",
      "Epoch 6/80\n",
      "6435/6435 [==============================] - 0s 43us/step - loss: 1.7183 - accuracy: 0.2917 - val_loss: 1.6972 - val_accuracy: 0.2626\n",
      "Epoch 7/80\n",
      "6435/6435 [==============================] - 0s 38us/step - loss: 1.6675 - accuracy: 0.2956 - val_loss: 1.6753 - val_accuracy: 0.2682\n",
      "Epoch 8/80\n",
      "6435/6435 [==============================] - 0s 37us/step - loss: 1.6353 - accuracy: 0.3012 - val_loss: 1.6182 - val_accuracy: 0.3087\n",
      "Epoch 9/80\n",
      "6435/6435 [==============================] - 0s 38us/step - loss: 1.6032 - accuracy: 0.3013 - val_loss: 1.5911 - val_accuracy: 0.3045\n",
      "Epoch 10/80\n",
      "6435/6435 [==============================] - 0s 38us/step - loss: 1.5784 - accuracy: 0.3009 - val_loss: 1.5694 - val_accuracy: 0.3031\n",
      "Epoch 11/80\n",
      "6435/6435 [==============================] - 0s 42us/step - loss: 1.5502 - accuracy: 0.3147 - val_loss: 1.5588 - val_accuracy: 0.3240\n",
      "Epoch 12/80\n",
      "6435/6435 [==============================] - 0s 41us/step - loss: 1.5408 - accuracy: 0.3147 - val_loss: 1.5424 - val_accuracy: 0.3087\n",
      "Epoch 13/80\n",
      "6435/6435 [==============================] - 0s 37us/step - loss: 1.5337 - accuracy: 0.3111 - val_loss: 1.5325 - val_accuracy: 0.3226\n",
      "Epoch 14/80\n",
      "6435/6435 [==============================] - 0s 36us/step - loss: 1.5278 - accuracy: 0.3088 - val_loss: 1.5409 - val_accuracy: 0.3059\n",
      "Epoch 15/80\n",
      "6435/6435 [==============================] - 0s 42us/step - loss: 1.5286 - accuracy: 0.3091 - val_loss: 1.5743 - val_accuracy: 0.2961\n",
      "Epoch 16/80\n",
      "6435/6435 [==============================] - 0s 37us/step - loss: 1.5284 - accuracy: 0.3002 - val_loss: 1.5415 - val_accuracy: 0.2933\n",
      "Epoch 17/80\n",
      "6435/6435 [==============================] - 0s 42us/step - loss: 1.5243 - accuracy: 0.3141 - val_loss: 1.5380 - val_accuracy: 0.3059\n",
      "Epoch 18/80\n",
      "6435/6435 [==============================] - 0s 40us/step - loss: 1.5108 - accuracy: 0.3086 - val_loss: 1.5270 - val_accuracy: 0.2961\n",
      "Epoch 19/80\n",
      "6435/6435 [==============================] - 0s 38us/step - loss: 1.5170 - accuracy: 0.3040 - val_loss: 1.5128 - val_accuracy: 0.3059\n",
      "Epoch 20/80\n",
      "6435/6435 [==============================] - 0s 37us/step - loss: 1.5042 - accuracy: 0.3037 - val_loss: 1.5259 - val_accuracy: 0.2849\n",
      "Epoch 21/80\n",
      "6435/6435 [==============================] - 0s 38us/step - loss: 1.5030 - accuracy: 0.3155 - val_loss: 1.5175 - val_accuracy: 0.2975\n",
      "Epoch 22/80\n",
      "6435/6435 [==============================] - 0s 37us/step - loss: 1.4960 - accuracy: 0.3117 - val_loss: 1.5185 - val_accuracy: 0.2709\n",
      "Epoch 23/80\n",
      "6435/6435 [==============================] - 0s 46us/step - loss: 1.4975 - accuracy: 0.3094 - val_loss: 1.5116 - val_accuracy: 0.3059\n",
      "Epoch 24/80\n",
      "6435/6435 [==============================] - 0s 37us/step - loss: 1.4943 - accuracy: 0.3136 - val_loss: 1.5052 - val_accuracy: 0.3073\n",
      "Epoch 25/80\n",
      "6435/6435 [==============================] - 0s 41us/step - loss: 1.4928 - accuracy: 0.3246 - val_loss: 1.4998 - val_accuracy: 0.3087\n",
      "Epoch 26/80\n",
      "6435/6435 [==============================] - 0s 37us/step - loss: 1.4880 - accuracy: 0.3183 - val_loss: 1.5173 - val_accuracy: 0.2709\n",
      "Epoch 27/80\n",
      "6435/6435 [==============================] - 0s 41us/step - loss: 1.4882 - accuracy: 0.3178 - val_loss: 1.5086 - val_accuracy: 0.2933\n",
      "Epoch 28/80\n",
      "6435/6435 [==============================] - 0s 40us/step - loss: 1.4884 - accuracy: 0.3106 - val_loss: 1.5373 - val_accuracy: 0.2947\n",
      "Epoch 29/80\n",
      "6435/6435 [==============================] - 0s 41us/step - loss: 1.4872 - accuracy: 0.3127 - val_loss: 1.5041 - val_accuracy: 0.2877\n",
      "Epoch 30/80\n",
      "6435/6435 [==============================] - 0s 38us/step - loss: 1.4904 - accuracy: 0.3167 - val_loss: 1.5090 - val_accuracy: 0.2723\n",
      "Epoch 31/80\n",
      "6435/6435 [==============================] - 0s 38us/step - loss: 1.4822 - accuracy: 0.3181 - val_loss: 1.4810 - val_accuracy: 0.3087\n",
      "Epoch 32/80\n",
      "6435/6435 [==============================] - 0s 34us/step - loss: 1.4817 - accuracy: 0.3068 - val_loss: 1.4922 - val_accuracy: 0.3073\n",
      "Epoch 33/80\n",
      "6435/6435 [==============================] - 0s 39us/step - loss: 1.4758 - accuracy: 0.3235 - val_loss: 1.4962 - val_accuracy: 0.2891\n",
      "Epoch 34/80\n",
      "6435/6435 [==============================] - 0s 36us/step - loss: 1.4765 - accuracy: 0.3232 - val_loss: 1.5101 - val_accuracy: 0.2933\n",
      "Epoch 35/80\n",
      "6435/6435 [==============================] - 0s 41us/step - loss: 1.4822 - accuracy: 0.3183 - val_loss: 1.4869 - val_accuracy: 0.3128\n",
      "Epoch 36/80\n",
      "6435/6435 [==============================] - 0s 39us/step - loss: 1.4851 - accuracy: 0.3114 - val_loss: 1.5094 - val_accuracy: 0.3045\n",
      "Epoch 37/80\n",
      "6435/6435 [==============================] - 0s 36us/step - loss: 1.4738 - accuracy: 0.3189 - val_loss: 1.4775 - val_accuracy: 0.3268\n",
      "Epoch 38/80\n",
      "6435/6435 [==============================] - 0s 34us/step - loss: 1.4700 - accuracy: 0.3221 - val_loss: 1.5173 - val_accuracy: 0.2751\n",
      "Epoch 39/80\n",
      "6435/6435 [==============================] - 0s 41us/step - loss: 1.4768 - accuracy: 0.3077 - val_loss: 1.4912 - val_accuracy: 0.2989\n",
      "Epoch 40/80\n",
      "6435/6435 [==============================] - 0s 37us/step - loss: 1.4707 - accuracy: 0.3142 - val_loss: 1.4898 - val_accuracy: 0.2989\n",
      "Epoch 41/80\n",
      "6435/6435 [==============================] - 0s 41us/step - loss: 1.4714 - accuracy: 0.3124 - val_loss: 1.4745 - val_accuracy: 0.3031\n",
      "Epoch 42/80\n",
      "6435/6435 [==============================] - 0s 39us/step - loss: 1.4804 - accuracy: 0.3189 - val_loss: 1.4713 - val_accuracy: 0.3059\n",
      "Epoch 43/80\n",
      "6435/6435 [==============================] - 0s 40us/step - loss: 1.4680 - accuracy: 0.3147 - val_loss: 1.4806 - val_accuracy: 0.2961\n",
      "Epoch 44/80\n",
      "6435/6435 [==============================] - 0s 36us/step - loss: 1.4709 - accuracy: 0.3122 - val_loss: 1.4678 - val_accuracy: 0.3226\n",
      "Epoch 45/80\n",
      "6435/6435 [==============================] - 0s 36us/step - loss: 1.4691 - accuracy: 0.3209 - val_loss: 1.4887 - val_accuracy: 0.3017\n",
      "Epoch 46/80\n",
      "6435/6435 [==============================] - 0s 36us/step - loss: 1.4659 - accuracy: 0.3156 - val_loss: 1.4706 - val_accuracy: 0.2933\n",
      "Epoch 47/80\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6435/6435 [==============================] - 0s 35us/step - loss: 1.4622 - accuracy: 0.3228 - val_loss: 1.4661 - val_accuracy: 0.2877\n",
      "Epoch 48/80\n",
      "6435/6435 [==============================] - 0s 35us/step - loss: 1.4644 - accuracy: 0.3203 - val_loss: 1.4889 - val_accuracy: 0.3073\n",
      "Epoch 49/80\n",
      "6435/6435 [==============================] - 0s 37us/step - loss: 1.4626 - accuracy: 0.3305 - val_loss: 1.4841 - val_accuracy: 0.3254\n",
      "Epoch 50/80\n",
      "6435/6435 [==============================] - 0s 40us/step - loss: 1.4593 - accuracy: 0.3235 - val_loss: 1.4837 - val_accuracy: 0.2919\n",
      "Epoch 51/80\n",
      "6435/6435 [==============================] - 0s 42us/step - loss: 1.4596 - accuracy: 0.3267 - val_loss: 1.4780 - val_accuracy: 0.3115\n",
      "Epoch 52/80\n",
      "6435/6435 [==============================] - 0s 37us/step - loss: 1.4652 - accuracy: 0.3200 - val_loss: 1.4823 - val_accuracy: 0.3115\n",
      "Epoch 53/80\n",
      "6435/6435 [==============================] - 0s 36us/step - loss: 1.4573 - accuracy: 0.3294 - val_loss: 1.4810 - val_accuracy: 0.3128\n",
      "Epoch 54/80\n",
      "6435/6435 [==============================] - 0s 40us/step - loss: 1.4588 - accuracy: 0.3327 - val_loss: 1.4687 - val_accuracy: 0.3282\n",
      "Epoch 55/80\n",
      "6435/6435 [==============================] - 0s 38us/step - loss: 1.4531 - accuracy: 0.3221 - val_loss: 1.4816 - val_accuracy: 0.2961\n",
      "Epoch 56/80\n",
      "6435/6435 [==============================] - 0s 36us/step - loss: 1.4512 - accuracy: 0.3280 - val_loss: 1.4634 - val_accuracy: 0.3003\n",
      "Epoch 57/80\n",
      "6435/6435 [==============================] - 0s 38us/step - loss: 1.4487 - accuracy: 0.3308 - val_loss: 1.4698 - val_accuracy: 0.2905\n",
      "Epoch 58/80\n",
      "6435/6435 [==============================] - 0s 38us/step - loss: 1.4479 - accuracy: 0.3414 - val_loss: 1.4577 - val_accuracy: 0.3296\n",
      "Epoch 59/80\n",
      "6435/6435 [==============================] - 0s 36us/step - loss: 1.4444 - accuracy: 0.3402 - val_loss: 1.4636 - val_accuracy: 0.2905\n",
      "Epoch 60/80\n",
      "6435/6435 [==============================] - 0s 36us/step - loss: 1.4463 - accuracy: 0.3355 - val_loss: 1.4584 - val_accuracy: 0.3198\n",
      "Epoch 61/80\n",
      "6435/6435 [==============================] - 0s 38us/step - loss: 1.4422 - accuracy: 0.3442 - val_loss: 1.4551 - val_accuracy: 0.3478\n",
      "Epoch 62/80\n",
      "6435/6435 [==============================] - 0s 35us/step - loss: 1.4361 - accuracy: 0.3436 - val_loss: 1.4661 - val_accuracy: 0.3198\n",
      "Epoch 63/80\n",
      "6435/6435 [==============================] - 0s 35us/step - loss: 1.4338 - accuracy: 0.3521 - val_loss: 1.4616 - val_accuracy: 0.3156\n",
      "Epoch 64/80\n",
      "6435/6435 [==============================] - 0s 36us/step - loss: 1.4345 - accuracy: 0.3445 - val_loss: 1.4413 - val_accuracy: 0.3408\n",
      "Epoch 65/80\n",
      "6435/6435 [==============================] - 0s 37us/step - loss: 1.4263 - accuracy: 0.3556 - val_loss: 1.4444 - val_accuracy: 0.2975\n",
      "Epoch 66/80\n",
      "6435/6435 [==============================] - 0s 36us/step - loss: 1.4252 - accuracy: 0.3506 - val_loss: 1.4401 - val_accuracy: 0.3310\n",
      "Epoch 67/80\n",
      "6435/6435 [==============================] - 0s 37us/step - loss: 1.4139 - accuracy: 0.3681 - val_loss: 1.4060 - val_accuracy: 0.3520\n",
      "Epoch 68/80\n",
      "6435/6435 [==============================] - 0s 38us/step - loss: 1.4029 - accuracy: 0.3705 - val_loss: 1.4138 - val_accuracy: 0.3324\n",
      "Epoch 69/80\n",
      "6435/6435 [==============================] - 0s 40us/step - loss: 1.3901 - accuracy: 0.3806 - val_loss: 1.4201 - val_accuracy: 0.3436\n",
      "Epoch 70/80\n",
      "6435/6435 [==============================] - 0s 40us/step - loss: 1.3806 - accuracy: 0.3744 - val_loss: 1.3817 - val_accuracy: 0.3520\n",
      "Epoch 71/80\n",
      "6435/6435 [==============================] - 0s 35us/step - loss: 1.3672 - accuracy: 0.3795 - val_loss: 1.3908 - val_accuracy: 0.3534\n",
      "Epoch 72/80\n",
      "6435/6435 [==============================] - 0s 38us/step - loss: 1.3478 - accuracy: 0.3775 - val_loss: 1.3524 - val_accuracy: 0.3506\n",
      "Epoch 73/80\n",
      "6435/6435 [==============================] - 0s 37us/step - loss: 1.3392 - accuracy: 0.3795 - val_loss: 1.3509 - val_accuracy: 0.3757\n",
      "Epoch 74/80\n",
      "6435/6435 [==============================] - 0s 38us/step - loss: 1.3235 - accuracy: 0.3902 - val_loss: 1.3383 - val_accuracy: 0.3506\n",
      "Epoch 75/80\n",
      "6435/6435 [==============================] - 0s 36us/step - loss: 1.3192 - accuracy: 0.3921 - val_loss: 1.3413 - val_accuracy: 0.3589\n",
      "Epoch 76/80\n",
      "6435/6435 [==============================] - 0s 40us/step - loss: 1.3114 - accuracy: 0.3933 - val_loss: 1.3376 - val_accuracy: 0.3520\n",
      "Epoch 77/80\n",
      "6435/6435 [==============================] - 0s 39us/step - loss: 1.3158 - accuracy: 0.3877 - val_loss: 1.3230 - val_accuracy: 0.3561\n",
      "Epoch 78/80\n",
      "6435/6435 [==============================] - 0s 41us/step - loss: 1.2952 - accuracy: 0.3960 - val_loss: 1.3276 - val_accuracy: 0.3589\n",
      "Epoch 79/80\n",
      "6435/6435 [==============================] - 0s 39us/step - loss: 1.2997 - accuracy: 0.3893 - val_loss: 1.3235 - val_accuracy: 0.3645\n",
      "Epoch 80/80\n",
      "6435/6435 [==============================] - 0s 39us/step - loss: 1.2871 - accuracy: 0.3941 - val_loss: 1.3053 - val_accuracy: 0.3785\n",
      "[[1.01619266e-01 9.40350816e-02 5.00818701e-12 ... 3.01050961e-01\n",
      "  2.35033393e-01 2.44355455e-01]\n",
      " [3.44042219e-02 3.27563174e-02 3.91484831e-17 ... 9.21557285e-03\n",
      "  1.66895352e-02 1.32444734e-02]\n",
      " [2.07546964e-01 2.02554345e-01 4.46838780e-14 ... 1.02911986e-01\n",
      "  2.40944117e-01 2.39607096e-01]\n",
      " ...\n",
      " [2.59732157e-01 2.75691628e-01 7.75497796e-15 ... 2.98236050e-02\n",
      "  2.17270717e-01 2.15470120e-01]\n",
      " [1.01716042e-01 1.06529206e-01 3.39657955e-11 ... 1.79180413e-01\n",
      "  2.78876930e-01 2.85734773e-01]\n",
      " [1.14070788e-01 1.15609467e-01 1.22019513e-11 ... 1.87715113e-01\n",
      "  2.71628141e-01 2.80438036e-01]]\n",
      "[12  5 13 ...  1 14 14]\n",
      "<class 'numpy.ndarray'>\n",
      "One CNN, r:  0\n",
      "Computing Time:  0:00:21.707857\n",
      "n, p1, p2 1 0 0\n",
      "Model: \"sequential_1\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv1d_1 (Conv1D)            (None, 3, 6)              12        \n",
      "_________________________________________________________________\n",
      "average_pooling1d_1 (Average (None, 1, 6)              0         \n",
      "_________________________________________________________________\n",
      "conv1d_2 (Conv1D)            (None, 1, 16)             112       \n",
      "_________________________________________________________________\n",
      "average_pooling1d_2 (Average (None, 1, 16)             0         \n",
      "_________________________________________________________________\n",
      "conv1d_3 (Conv1D)            (None, 1, 120)            2040      \n",
      "_________________________________________________________________\n",
      "flatten_1 (Flatten)          (None, 120)               0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 84)                10164     \n",
      "_________________________________________________________________\n",
      "preds (Dense)                (None, 15)                1275      \n",
      "=================================================================\n",
      "Total params: 13,603\n",
      "Trainable params: 13,603\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Train on 6435 samples, validate on 716 samples\n",
      "Epoch 1/80\n",
      "6435/6435 [==============================] - 0s 75us/step - loss: 2.6751 - accuracy: 0.0761 - val_loss: 2.5855 - val_accuracy: 0.0922\n",
      "Epoch 2/80\n",
      "6435/6435 [==============================] - 0s 43us/step - loss: 2.3972 - accuracy: 0.1706 - val_loss: 2.1588 - val_accuracy: 0.2249\n",
      "Epoch 3/80\n",
      "6435/6435 [==============================] - 0s 40us/step - loss: 2.0697 - accuracy: 0.2460 - val_loss: 1.9442 - val_accuracy: 0.2919\n",
      "Epoch 4/80\n",
      "6435/6435 [==============================] - 0s 38us/step - loss: 1.9107 - accuracy: 0.2752 - val_loss: 1.8112 - val_accuracy: 0.2961\n",
      "Epoch 5/80\n",
      "6435/6435 [==============================] - 0s 38us/step - loss: 1.8081 - accuracy: 0.2880 - val_loss: 1.7335 - val_accuracy: 0.2821\n",
      "Epoch 6/80\n",
      "6435/6435 [==============================] - 0s 37us/step - loss: 1.7396 - accuracy: 0.2914 - val_loss: 1.6673 - val_accuracy: 0.2989\n",
      "Epoch 7/80\n",
      "6435/6435 [==============================] - 0s 36us/step - loss: 1.6828 - accuracy: 0.2957 - val_loss: 1.6162 - val_accuracy: 0.3087\n",
      "Epoch 8/80\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6435/6435 [==============================] - 0s 37us/step - loss: 1.6424 - accuracy: 0.3001 - val_loss: 1.5913 - val_accuracy: 0.3212\n",
      "Epoch 9/80\n",
      "6435/6435 [==============================] - 0s 39us/step - loss: 1.6257 - accuracy: 0.3032 - val_loss: 1.5725 - val_accuracy: 0.3115\n",
      "Epoch 10/80\n",
      "6435/6435 [==============================] - 0s 37us/step - loss: 1.6043 - accuracy: 0.2974 - val_loss: 1.5548 - val_accuracy: 0.3017\n",
      "Epoch 11/80\n",
      "6435/6435 [==============================] - 0s 40us/step - loss: 1.5903 - accuracy: 0.3072 - val_loss: 1.5424 - val_accuracy: 0.3226\n",
      "Epoch 12/80\n",
      "6435/6435 [==============================] - 0s 39us/step - loss: 1.5781 - accuracy: 0.3077 - val_loss: 1.5303 - val_accuracy: 0.3282\n",
      "Epoch 13/80\n",
      "6435/6435 [==============================] - 0s 39us/step - loss: 1.5711 - accuracy: 0.3040 - val_loss: 1.5176 - val_accuracy: 0.3394\n",
      "Epoch 14/80\n",
      "6435/6435 [==============================] - 0s 37us/step - loss: 1.5580 - accuracy: 0.3083 - val_loss: 1.5393 - val_accuracy: 0.3031\n",
      "Epoch 15/80\n",
      "6435/6435 [==============================] - 0s 39us/step - loss: 1.5592 - accuracy: 0.3106 - val_loss: 1.5062 - val_accuracy: 0.3268\n",
      "Epoch 16/80\n",
      "6435/6435 [==============================] - 0s 35us/step - loss: 1.5443 - accuracy: 0.3144 - val_loss: 1.5095 - val_accuracy: 0.3142\n",
      "Epoch 17/80\n",
      "6435/6435 [==============================] - 0s 37us/step - loss: 1.5381 - accuracy: 0.3077 - val_loss: 1.4957 - val_accuracy: 0.3198\n",
      "Epoch 18/80\n",
      "6435/6435 [==============================] - 0s 35us/step - loss: 1.5319 - accuracy: 0.3147 - val_loss: 1.4993 - val_accuracy: 0.3310\n",
      "Epoch 19/80\n",
      "6435/6435 [==============================] - 0s 37us/step - loss: 1.5307 - accuracy: 0.3131 - val_loss: 1.4992 - val_accuracy: 0.3128\n",
      "Epoch 20/80\n",
      "6435/6435 [==============================] - 0s 35us/step - loss: 1.5289 - accuracy: 0.3096 - val_loss: 1.4893 - val_accuracy: 0.3380\n",
      "Epoch 21/80\n",
      "6435/6435 [==============================] - 0s 37us/step - loss: 1.5244 - accuracy: 0.3130 - val_loss: 1.4823 - val_accuracy: 0.3254\n",
      "Epoch 22/80\n",
      "6435/6435 [==============================] - 0s 37us/step - loss: 1.5135 - accuracy: 0.3159 - val_loss: 1.4963 - val_accuracy: 0.3450\n",
      "Epoch 23/80\n",
      "6435/6435 [==============================] - 0s 40us/step - loss: 1.5093 - accuracy: 0.3183 - val_loss: 1.4856 - val_accuracy: 0.3017\n",
      "Epoch 24/80\n",
      "6435/6435 [==============================] - 0s 38us/step - loss: 1.5041 - accuracy: 0.3193 - val_loss: 1.4728 - val_accuracy: 0.3087\n",
      "Epoch 25/80\n",
      "6435/6435 [==============================] - 0s 37us/step - loss: 1.5004 - accuracy: 0.3175 - val_loss: 1.4662 - val_accuracy: 0.3506\n",
      "Epoch 26/80\n",
      "6435/6435 [==============================] - 0s 36us/step - loss: 1.5006 - accuracy: 0.3215 - val_loss: 1.4834 - val_accuracy: 0.2933\n",
      "Epoch 27/80\n",
      "6435/6435 [==============================] - 0s 36us/step - loss: 1.4953 - accuracy: 0.3207 - val_loss: 1.4768 - val_accuracy: 0.3128\n",
      "Epoch 28/80\n",
      "6435/6435 [==============================] - 0s 37us/step - loss: 1.4956 - accuracy: 0.3134 - val_loss: 1.4480 - val_accuracy: 0.3338\n",
      "Epoch 29/80\n",
      "6435/6435 [==============================] - 0s 35us/step - loss: 1.4857 - accuracy: 0.3147 - val_loss: 1.4602 - val_accuracy: 0.3268\n",
      "Epoch 30/80\n",
      "6435/6435 [==============================] - 0s 35us/step - loss: 1.4889 - accuracy: 0.3200 - val_loss: 1.4635 - val_accuracy: 0.3101\n",
      "Epoch 31/80\n",
      "6435/6435 [==============================] - 0s 37us/step - loss: 1.4824 - accuracy: 0.3207 - val_loss: 1.4545 - val_accuracy: 0.3268\n",
      "Epoch 32/80\n",
      "6435/6435 [==============================] - 0s 37us/step - loss: 1.4770 - accuracy: 0.3235 - val_loss: 1.4535 - val_accuracy: 0.3408\n",
      "Epoch 33/80\n",
      "6435/6435 [==============================] - 0s 35us/step - loss: 1.4755 - accuracy: 0.3234 - val_loss: 1.4485 - val_accuracy: 0.3450\n",
      "Epoch 34/80\n",
      "6435/6435 [==============================] - 0s 35us/step - loss: 1.4730 - accuracy: 0.3148 - val_loss: 1.4509 - val_accuracy: 0.3226\n",
      "Epoch 35/80\n",
      "6435/6435 [==============================] - 0s 37us/step - loss: 1.4737 - accuracy: 0.3117 - val_loss: 1.4378 - val_accuracy: 0.3464\n",
      "Epoch 36/80\n",
      "6435/6435 [==============================] - 0s 35us/step - loss: 1.4711 - accuracy: 0.3232 - val_loss: 1.4468 - val_accuracy: 0.3170\n",
      "Epoch 37/80\n",
      "6435/6435 [==============================] - 0s 36us/step - loss: 1.4677 - accuracy: 0.3085 - val_loss: 1.4285 - val_accuracy: 0.3478\n",
      "Epoch 38/80\n",
      "6435/6435 [==============================] - 0s 37us/step - loss: 1.4591 - accuracy: 0.3302 - val_loss: 1.4333 - val_accuracy: 0.3701\n",
      "Epoch 39/80\n",
      "6435/6435 [==============================] - 0s 39us/step - loss: 1.4606 - accuracy: 0.3217 - val_loss: 1.4320 - val_accuracy: 0.3268\n",
      "Epoch 40/80\n",
      "6435/6435 [==============================] - 0s 38us/step - loss: 1.4631 - accuracy: 0.3209 - val_loss: 1.4293 - val_accuracy: 0.3128\n",
      "Epoch 41/80\n",
      "6435/6435 [==============================] - 0s 37us/step - loss: 1.4558 - accuracy: 0.3274 - val_loss: 1.4285 - val_accuracy: 0.3352\n",
      "Epoch 42/80\n",
      "6435/6435 [==============================] - 0s 35us/step - loss: 1.4492 - accuracy: 0.3262 - val_loss: 1.4215 - val_accuracy: 0.3184\n",
      "Epoch 43/80\n",
      "6435/6435 [==============================] - 0s 38us/step - loss: 1.4479 - accuracy: 0.3327 - val_loss: 1.4260 - val_accuracy: 0.3296\n",
      "Epoch 44/80\n",
      "6435/6435 [==============================] - 0s 40us/step - loss: 1.4414 - accuracy: 0.3419 - val_loss: 1.4099 - val_accuracy: 0.3715\n",
      "Epoch 45/80\n",
      "6435/6435 [==============================] - 0s 38us/step - loss: 1.4315 - accuracy: 0.3565 - val_loss: 1.4002 - val_accuracy: 0.3813\n",
      "Epoch 46/80\n",
      "6435/6435 [==============================] - 0s 40us/step - loss: 1.4302 - accuracy: 0.3472 - val_loss: 1.3878 - val_accuracy: 0.3673\n",
      "Epoch 47/80\n",
      "6435/6435 [==============================] - 0s 39us/step - loss: 1.4155 - accuracy: 0.3537 - val_loss: 1.3764 - val_accuracy: 0.3757\n",
      "Epoch 48/80\n",
      "6435/6435 [==============================] - 0s 39us/step - loss: 1.4087 - accuracy: 0.3587 - val_loss: 1.3869 - val_accuracy: 0.3617\n",
      "Epoch 49/80\n",
      "6435/6435 [==============================] - 0s 39us/step - loss: 1.3945 - accuracy: 0.3672 - val_loss: 1.3595 - val_accuracy: 0.4050\n",
      "Epoch 50/80\n",
      "6435/6435 [==============================] - 0s 42us/step - loss: 1.3806 - accuracy: 0.3717 - val_loss: 1.3496 - val_accuracy: 0.3715\n",
      "Epoch 51/80\n",
      "6435/6435 [==============================] - 0s 36us/step - loss: 1.3659 - accuracy: 0.3722 - val_loss: 1.3270 - val_accuracy: 0.3994\n",
      "Epoch 52/80\n",
      "6435/6435 [==============================] - 0s 36us/step - loss: 1.3539 - accuracy: 0.3812 - val_loss: 1.3091 - val_accuracy: 0.4078\n",
      "Epoch 53/80\n",
      "6435/6435 [==============================] - 0s 39us/step - loss: 1.3406 - accuracy: 0.3770 - val_loss: 1.3019 - val_accuracy: 0.3966\n",
      "Epoch 54/80\n",
      "6435/6435 [==============================] - 0s 39us/step - loss: 1.3424 - accuracy: 0.3818 - val_loss: 1.3043 - val_accuracy: 0.3799\n",
      "Epoch 55/80\n",
      "6435/6435 [==============================] - 0s 39us/step - loss: 1.3257 - accuracy: 0.3807 - val_loss: 1.2842 - val_accuracy: 0.4064\n",
      "Epoch 56/80\n",
      "6435/6435 [==============================] - 0s 37us/step - loss: 1.3164 - accuracy: 0.3837 - val_loss: 1.2790 - val_accuracy: 0.4134\n",
      "Epoch 57/80\n",
      "6435/6435 [==============================] - 0s 38us/step - loss: 1.3131 - accuracy: 0.3801 - val_loss: 1.2670 - val_accuracy: 0.4204\n",
      "Epoch 58/80\n",
      "6435/6435 [==============================] - 0s 37us/step - loss: 1.3013 - accuracy: 0.3868 - val_loss: 1.2734 - val_accuracy: 0.4064\n",
      "Epoch 59/80\n",
      "6435/6435 [==============================] - 0s 40us/step - loss: 1.2985 - accuracy: 0.3765 - val_loss: 1.2632 - val_accuracy: 0.3911\n",
      "Epoch 60/80\n",
      "6435/6435 [==============================] - 0s 38us/step - loss: 1.2982 - accuracy: 0.3916 - val_loss: 1.2670 - val_accuracy: 0.3855\n",
      "Epoch 61/80\n",
      "6435/6435 [==============================] - 0s 37us/step - loss: 1.2946 - accuracy: 0.3860 - val_loss: 1.2644 - val_accuracy: 0.4036\n",
      "Epoch 62/80\n",
      "6435/6435 [==============================] - 0s 38us/step - loss: 1.2874 - accuracy: 0.3911 - val_loss: 1.2550 - val_accuracy: 0.4176\n",
      "Epoch 63/80\n",
      "6435/6435 [==============================] - 0s 39us/step - loss: 1.2872 - accuracy: 0.3843 - val_loss: 1.2563 - val_accuracy: 0.3980\n",
      "Epoch 64/80\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6435/6435 [==============================] - 0s 38us/step - loss: 1.2811 - accuracy: 0.3994 - val_loss: 1.2552 - val_accuracy: 0.4092\n",
      "Epoch 65/80\n",
      "6435/6435 [==============================] - 0s 37us/step - loss: 1.2844 - accuracy: 0.3949 - val_loss: 1.2670 - val_accuracy: 0.3980\n",
      "Epoch 66/80\n",
      "6435/6435 [==============================] - 0s 35us/step - loss: 1.2869 - accuracy: 0.3855 - val_loss: 1.2412 - val_accuracy: 0.4022\n",
      "Epoch 67/80\n",
      "6435/6435 [==============================] - 0s 33us/step - loss: 1.2768 - accuracy: 0.3911 - val_loss: 1.2390 - val_accuracy: 0.4050\n",
      "Epoch 68/80\n",
      "6435/6435 [==============================] - 0s 37us/step - loss: 1.2737 - accuracy: 0.4045 - val_loss: 1.2463 - val_accuracy: 0.4022\n",
      "Epoch 69/80\n",
      "6435/6435 [==============================] - 0s 37us/step - loss: 1.2751 - accuracy: 0.3946 - val_loss: 1.2440 - val_accuracy: 0.4106\n",
      "Epoch 70/80\n",
      "6435/6435 [==============================] - 0s 39us/step - loss: 1.2747 - accuracy: 0.3977 - val_loss: 1.2431 - val_accuracy: 0.4022\n",
      "Epoch 71/80\n",
      "6435/6435 [==============================] - 0s 41us/step - loss: 1.2687 - accuracy: 0.3995 - val_loss: 1.2563 - val_accuracy: 0.3939\n",
      "Epoch 72/80\n",
      "6435/6435 [==============================] - 0s 36us/step - loss: 1.2684 - accuracy: 0.3873 - val_loss: 1.2404 - val_accuracy: 0.3939\n",
      "Epoch 73/80\n",
      "6435/6435 [==============================] - 0s 39us/step - loss: 1.2606 - accuracy: 0.3907 - val_loss: 1.2355 - val_accuracy: 0.4190\n",
      "Epoch 74/80\n",
      "6435/6435 [==============================] - 0s 38us/step - loss: 1.2625 - accuracy: 0.4028 - val_loss: 1.2387 - val_accuracy: 0.4064\n",
      "Epoch 75/80\n",
      "6435/6435 [==============================] - 0s 39us/step - loss: 1.2579 - accuracy: 0.3978 - val_loss: 1.2393 - val_accuracy: 0.4162\n",
      "Epoch 76/80\n",
      "6435/6435 [==============================] - 0s 35us/step - loss: 1.2583 - accuracy: 0.3938 - val_loss: 1.2210 - val_accuracy: 0.4330\n",
      "Epoch 77/80\n",
      "6435/6435 [==============================] - 0s 36us/step - loss: 1.2635 - accuracy: 0.3964 - val_loss: 1.2355 - val_accuracy: 0.4218\n",
      "Epoch 78/80\n",
      "6435/6435 [==============================] - 0s 37us/step - loss: 1.2523 - accuracy: 0.3967 - val_loss: 1.2210 - val_accuracy: 0.4344\n",
      "Epoch 79/80\n",
      "6435/6435 [==============================] - 0s 37us/step - loss: 1.2478 - accuracy: 0.4026 - val_loss: 1.2505 - val_accuracy: 0.4022\n",
      "Epoch 80/80\n",
      "6435/6435 [==============================] - 0s 38us/step - loss: 1.2516 - accuracy: 0.4030 - val_loss: 1.2196 - val_accuracy: 0.4260\n",
      "[[1.3030355e-01 1.0730026e-01 1.6378487e-16 ... 2.8621167e-01\n",
      "  2.1059248e-01 2.4675784e-01]\n",
      " [5.6502864e-02 4.3390453e-02 3.3263020e-25 ... 4.0034121e-03\n",
      "  9.9017853e-03 1.3778073e-02]\n",
      " [1.8464512e-01 1.5384848e-01 2.9551472e-19 ... 4.7226813e-02\n",
      "  2.6647195e-01 3.4597230e-01]\n",
      " ...\n",
      " [2.1925925e-01 1.7072989e-01 1.2773822e-19 ... 6.6914833e-03\n",
      "  2.7695575e-01 3.2587183e-01]\n",
      " [9.1372035e-02 7.2394013e-02 3.0981632e-15 ... 1.2879212e-01\n",
      "  3.0425262e-01 3.8413957e-01]\n",
      " [1.0428287e-01 8.3470426e-02 8.1165079e-16 ... 1.3544874e-01\n",
      "  2.9500657e-01 3.6895382e-01]]\n",
      "[12 10 14 ... 14 14 14]\n",
      "<class 'numpy.ndarray'>\n",
      "One CNN, r:  0\n",
      "Computing Time:  0:00:42.779064\n",
      "n, p1, p2 2 0 0\n",
      "Model: \"sequential_1\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv1d_1 (Conv1D)            (None, 3, 6)              12        \n",
      "_________________________________________________________________\n",
      "average_pooling1d_1 (Average (None, 1, 6)              0         \n",
      "_________________________________________________________________\n",
      "conv1d_2 (Conv1D)            (None, 1, 16)             112       \n",
      "_________________________________________________________________\n",
      "average_pooling1d_2 (Average (None, 1, 16)             0         \n",
      "_________________________________________________________________\n",
      "conv1d_3 (Conv1D)            (None, 1, 120)            2040      \n",
      "_________________________________________________________________\n",
      "flatten_1 (Flatten)          (None, 120)               0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 84)                10164     \n",
      "_________________________________________________________________\n",
      "preds (Dense)                (None, 15)                1275      \n",
      "=================================================================\n",
      "Total params: 13,603\n",
      "Trainable params: 13,603\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Train on 6435 samples, validate on 716 samples\n",
      "Epoch 1/80\n",
      "6435/6435 [==============================] - 1s 85us/step - loss: 2.6649 - accuracy: 0.1437 - val_loss: 2.5384 - val_accuracy: 0.1941\n",
      "Epoch 2/80\n",
      "6435/6435 [==============================] - 0s 41us/step - loss: 2.3164 - accuracy: 0.1821 - val_loss: 2.0799 - val_accuracy: 0.2570\n",
      "Epoch 3/80\n",
      "6435/6435 [==============================] - 0s 40us/step - loss: 1.9954 - accuracy: 0.2485 - val_loss: 1.8765 - val_accuracy: 0.2975\n",
      "Epoch 4/80\n",
      "6435/6435 [==============================] - 0s 43us/step - loss: 1.8376 - accuracy: 0.2898 - val_loss: 1.7594 - val_accuracy: 0.3017\n",
      "Epoch 5/80\n",
      "6435/6435 [==============================] - 0s 39us/step - loss: 1.7341 - accuracy: 0.2956 - val_loss: 1.6732 - val_accuracy: 0.3059\n",
      "Epoch 6/80\n",
      "6435/6435 [==============================] - 0s 41us/step - loss: 1.6585 - accuracy: 0.2953 - val_loss: 1.5947 - val_accuracy: 0.3268\n",
      "Epoch 7/80\n",
      "6435/6435 [==============================] - 0s 41us/step - loss: 1.6076 - accuracy: 0.3010 - val_loss: 1.5572 - val_accuracy: 0.3226\n",
      "Epoch 8/80\n",
      "6435/6435 [==============================] - 0s 38us/step - loss: 1.5726 - accuracy: 0.3069 - val_loss: 1.5343 - val_accuracy: 0.3198\n",
      "Epoch 9/80\n",
      "6435/6435 [==============================] - 0s 37us/step - loss: 1.5503 - accuracy: 0.3057 - val_loss: 1.5159 - val_accuracy: 0.3268\n",
      "Epoch 10/80\n",
      "6435/6435 [==============================] - 0s 41us/step - loss: 1.5376 - accuracy: 0.3111 - val_loss: 1.5172 - val_accuracy: 0.3212\n",
      "Epoch 11/80\n",
      "6435/6435 [==============================] - 0s 38us/step - loss: 1.5229 - accuracy: 0.3080 - val_loss: 1.5165 - val_accuracy: 0.3366\n",
      "Epoch 12/80\n",
      "6435/6435 [==============================] - 0s 37us/step - loss: 1.5201 - accuracy: 0.3055 - val_loss: 1.5109 - val_accuracy: 0.2905\n",
      "Epoch 13/80\n",
      "6435/6435 [==============================] - 0s 36us/step - loss: 1.5158 - accuracy: 0.3091 - val_loss: 1.5017 - val_accuracy: 0.3380\n",
      "Epoch 14/80\n",
      "6435/6435 [==============================] - 0s 36us/step - loss: 1.5048 - accuracy: 0.3094 - val_loss: 1.4987 - val_accuracy: 0.3324\n",
      "Epoch 15/80\n",
      "6435/6435 [==============================] - 0s 36us/step - loss: 1.5047 - accuracy: 0.3141 - val_loss: 1.4966 - val_accuracy: 0.3464\n",
      "Epoch 16/80\n",
      "6435/6435 [==============================] - 0s 37us/step - loss: 1.5016 - accuracy: 0.3141 - val_loss: 1.4802 - val_accuracy: 0.3170\n",
      "Epoch 17/80\n",
      "6435/6435 [==============================] - 0s 37us/step - loss: 1.4982 - accuracy: 0.3096 - val_loss: 1.4935 - val_accuracy: 0.3017\n",
      "Epoch 18/80\n",
      "6435/6435 [==============================] - 0s 41us/step - loss: 1.4991 - accuracy: 0.3075 - val_loss: 1.4755 - val_accuracy: 0.3380\n",
      "Epoch 19/80\n",
      "6435/6435 [==============================] - 0s 40us/step - loss: 1.4905 - accuracy: 0.3055 - val_loss: 1.4828 - val_accuracy: 0.3422\n",
      "Epoch 20/80\n",
      "6435/6435 [==============================] - 0s 35us/step - loss: 1.4966 - accuracy: 0.3010 - val_loss: 1.4805 - val_accuracy: 0.3422\n",
      "Epoch 21/80\n",
      "6435/6435 [==============================] - 0s 35us/step - loss: 1.4959 - accuracy: 0.3086 - val_loss: 1.4989 - val_accuracy: 0.3017\n",
      "Epoch 22/80\n",
      "6435/6435 [==============================] - 0s 37us/step - loss: 1.4880 - accuracy: 0.3148 - val_loss: 1.4794 - val_accuracy: 0.3478\n",
      "Epoch 23/80\n",
      "6435/6435 [==============================] - 0s 37us/step - loss: 1.4839 - accuracy: 0.3117 - val_loss: 1.4773 - val_accuracy: 0.3436\n",
      "Epoch 24/80\n",
      "6435/6435 [==============================] - 0s 36us/step - loss: 1.4937 - accuracy: 0.2998 - val_loss: 1.4765 - val_accuracy: 0.3198\n",
      "Epoch 25/80\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6435/6435 [==============================] - 0s 34us/step - loss: 1.4805 - accuracy: 0.3082 - val_loss: 1.4886 - val_accuracy: 0.2919\n",
      "Epoch 26/80\n",
      "6435/6435 [==============================] - 0s 37us/step - loss: 1.4781 - accuracy: 0.3226 - val_loss: 1.4694 - val_accuracy: 0.3380\n",
      "Epoch 27/80\n",
      "6435/6435 [==============================] - 0s 37us/step - loss: 1.4752 - accuracy: 0.3144 - val_loss: 1.4650 - val_accuracy: 0.3310\n",
      "Epoch 28/80\n",
      "6435/6435 [==============================] - 0s 36us/step - loss: 1.4831 - accuracy: 0.3158 - val_loss: 1.4698 - val_accuracy: 0.3561\n",
      "Epoch 29/80\n",
      "6435/6435 [==============================] - 0s 37us/step - loss: 1.4774 - accuracy: 0.3172 - val_loss: 1.4865 - val_accuracy: 0.3198\n",
      "Epoch 30/80\n",
      "6435/6435 [==============================] - 0s 39us/step - loss: 1.4823 - accuracy: 0.3197 - val_loss: 1.4669 - val_accuracy: 0.3547\n",
      "Epoch 31/80\n",
      "6435/6435 [==============================] - 0s 37us/step - loss: 1.4766 - accuracy: 0.3119 - val_loss: 1.4692 - val_accuracy: 0.3156\n",
      "Epoch 32/80\n",
      "6435/6435 [==============================] - 0s 36us/step - loss: 1.4746 - accuracy: 0.3089 - val_loss: 1.4804 - val_accuracy: 0.3142\n",
      "Epoch 33/80\n",
      "6435/6435 [==============================] - 0s 36us/step - loss: 1.4764 - accuracy: 0.3133 - val_loss: 1.4694 - val_accuracy: 0.3073\n",
      "Epoch 34/80\n",
      "6435/6435 [==============================] - 0s 39us/step - loss: 1.4707 - accuracy: 0.3138 - val_loss: 1.4578 - val_accuracy: 0.3338\n",
      "Epoch 35/80\n",
      "6435/6435 [==============================] - 0s 34us/step - loss: 1.4646 - accuracy: 0.3173 - val_loss: 1.4644 - val_accuracy: 0.3408\n",
      "Epoch 36/80\n",
      "6435/6435 [==============================] - 0s 36us/step - loss: 1.4661 - accuracy: 0.3172 - val_loss: 1.4569 - val_accuracy: 0.3561\n",
      "Epoch 37/80\n",
      "6435/6435 [==============================] - 0s 37us/step - loss: 1.4662 - accuracy: 0.3162 - val_loss: 1.4533 - val_accuracy: 0.3701\n",
      "Epoch 38/80\n",
      "6435/6435 [==============================] - 0s 35us/step - loss: 1.4611 - accuracy: 0.3279 - val_loss: 1.4546 - val_accuracy: 0.3408\n",
      "Epoch 39/80\n",
      "6435/6435 [==============================] - 0s 39us/step - loss: 1.4693 - accuracy: 0.3270 - val_loss: 1.4701 - val_accuracy: 0.3422\n",
      "Epoch 40/80\n",
      "6435/6435 [==============================] - 0s 36us/step - loss: 1.4617 - accuracy: 0.3282 - val_loss: 1.4544 - val_accuracy: 0.3520\n",
      "Epoch 41/80\n",
      "6435/6435 [==============================] - 0s 37us/step - loss: 1.4601 - accuracy: 0.3338 - val_loss: 1.4586 - val_accuracy: 0.3324\n",
      "Epoch 42/80\n",
      "6435/6435 [==============================] - 0s 36us/step - loss: 1.4567 - accuracy: 0.3259 - val_loss: 1.4421 - val_accuracy: 0.3743\n",
      "Epoch 43/80\n",
      "6435/6435 [==============================] - 0s 37us/step - loss: 1.4542 - accuracy: 0.3294 - val_loss: 1.4484 - val_accuracy: 0.3617\n",
      "Epoch 44/80\n",
      "6435/6435 [==============================] - 0s 35us/step - loss: 1.4529 - accuracy: 0.3284 - val_loss: 1.4607 - val_accuracy: 0.3282\n",
      "Epoch 45/80\n",
      "6435/6435 [==============================] - 0s 36us/step - loss: 1.4535 - accuracy: 0.3313 - val_loss: 1.4447 - val_accuracy: 0.3506\n",
      "Epoch 46/80\n",
      "6435/6435 [==============================] - 0s 35us/step - loss: 1.4446 - accuracy: 0.3436 - val_loss: 1.4419 - val_accuracy: 0.3659\n",
      "Epoch 47/80\n",
      "6435/6435 [==============================] - 0s 37us/step - loss: 1.4403 - accuracy: 0.3453 - val_loss: 1.4423 - val_accuracy: 0.3729\n",
      "Epoch 48/80\n",
      "6435/6435 [==============================] - 0s 37us/step - loss: 1.4370 - accuracy: 0.3484 - val_loss: 1.4310 - val_accuracy: 0.3464\n",
      "Epoch 49/80\n",
      "6435/6435 [==============================] - 0s 37us/step - loss: 1.4265 - accuracy: 0.3478 - val_loss: 1.4155 - val_accuracy: 0.3911\n",
      "Epoch 50/80\n",
      "6435/6435 [==============================] - 0s 34us/step - loss: 1.4212 - accuracy: 0.3548 - val_loss: 1.4184 - val_accuracy: 0.3450\n",
      "Epoch 51/80\n",
      "6435/6435 [==============================] - 0s 35us/step - loss: 1.4144 - accuracy: 0.3641 - val_loss: 1.3980 - val_accuracy: 0.4036\n",
      "Epoch 52/80\n",
      "6435/6435 [==============================] - 0s 35us/step - loss: 1.4021 - accuracy: 0.3630 - val_loss: 1.4060 - val_accuracy: 0.3799\n",
      "Epoch 53/80\n",
      "6435/6435 [==============================] - 0s 38us/step - loss: 1.3941 - accuracy: 0.3733 - val_loss: 1.3883 - val_accuracy: 0.3603\n",
      "Epoch 54/80\n",
      "6435/6435 [==============================] - 0s 40us/step - loss: 1.3886 - accuracy: 0.3716 - val_loss: 1.4186 - val_accuracy: 0.3813\n",
      "Epoch 55/80\n",
      "6435/6435 [==============================] - ETA: 0s - loss: 1.3905 - accuracy: 0.37 - 0s 37us/step - loss: 1.3894 - accuracy: 0.3734 - val_loss: 1.3720 - val_accuracy: 0.3785\n",
      "Epoch 56/80\n",
      "6435/6435 [==============================] - 0s 38us/step - loss: 1.3676 - accuracy: 0.3817 - val_loss: 1.3795 - val_accuracy: 0.3743\n",
      "Epoch 57/80\n",
      "6435/6435 [==============================] - 0s 37us/step - loss: 1.3564 - accuracy: 0.3817 - val_loss: 1.3539 - val_accuracy: 0.4218\n",
      "Epoch 58/80\n",
      "6435/6435 [==============================] - 0s 38us/step - loss: 1.3477 - accuracy: 0.3874 - val_loss: 1.3488 - val_accuracy: 0.4204\n",
      "Epoch 59/80\n",
      "6435/6435 [==============================] - 0s 36us/step - loss: 1.3413 - accuracy: 0.3798 - val_loss: 1.3420 - val_accuracy: 0.3939\n",
      "Epoch 60/80\n",
      "6435/6435 [==============================] - 0s 35us/step - loss: 1.3300 - accuracy: 0.3803 - val_loss: 1.3466 - val_accuracy: 0.3939\n",
      "Epoch 61/80\n",
      "6435/6435 [==============================] - 0s 40us/step - loss: 1.3299 - accuracy: 0.3854 - val_loss: 1.3424 - val_accuracy: 0.3575\n",
      "Epoch 62/80\n",
      "6435/6435 [==============================] - 0s 37us/step - loss: 1.3304 - accuracy: 0.3890 - val_loss: 1.3459 - val_accuracy: 0.4036\n",
      "Epoch 63/80\n",
      "6435/6435 [==============================] - 0s 35us/step - loss: 1.3251 - accuracy: 0.3879 - val_loss: 1.3383 - val_accuracy: 0.3520\n",
      "Epoch 64/80\n",
      "6435/6435 [==============================] - 0s 35us/step - loss: 1.3111 - accuracy: 0.3828 - val_loss: 1.3274 - val_accuracy: 0.3911\n",
      "Epoch 65/80\n",
      "6435/6435 [==============================] - 0s 37us/step - loss: 1.3094 - accuracy: 0.3888 - val_loss: 1.3541 - val_accuracy: 0.3743\n",
      "Epoch 66/80\n",
      "6435/6435 [==============================] - 0s 35us/step - loss: 1.3081 - accuracy: 0.3859 - val_loss: 1.3173 - val_accuracy: 0.4050\n",
      "Epoch 67/80\n",
      "6435/6435 [==============================] - 0s 37us/step - loss: 1.3037 - accuracy: 0.3854 - val_loss: 1.3231 - val_accuracy: 0.3771\n",
      "Epoch 68/80\n",
      "6435/6435 [==============================] - 0s 37us/step - loss: 1.3058 - accuracy: 0.3846 - val_loss: 1.3400 - val_accuracy: 0.4218\n",
      "Epoch 69/80\n",
      "6435/6435 [==============================] - 0s 36us/step - loss: 1.3033 - accuracy: 0.3924 - val_loss: 1.3406 - val_accuracy: 0.3911\n",
      "Epoch 70/80\n",
      "6435/6435 [==============================] - 0s 38us/step - loss: 1.2936 - accuracy: 0.3910 - val_loss: 1.3241 - val_accuracy: 0.3883\n",
      "Epoch 71/80\n",
      "6435/6435 [==============================] - 0s 36us/step - loss: 1.2916 - accuracy: 0.3888 - val_loss: 1.3265 - val_accuracy: 0.3855\n",
      "Epoch 72/80\n",
      "6435/6435 [==============================] - 0s 34us/step - loss: 1.2855 - accuracy: 0.4002 - val_loss: 1.3160 - val_accuracy: 0.3841\n",
      "Epoch 73/80\n",
      "6435/6435 [==============================] - 0s 36us/step - loss: 1.2948 - accuracy: 0.3876 - val_loss: 1.3132 - val_accuracy: 0.3813\n",
      "Epoch 74/80\n",
      "6435/6435 [==============================] - 0s 40us/step - loss: 1.2818 - accuracy: 0.3939 - val_loss: 1.3046 - val_accuracy: 0.3827\n",
      "Epoch 75/80\n",
      "6435/6435 [==============================] - 0s 38us/step - loss: 1.2758 - accuracy: 0.3832 - val_loss: 1.3175 - val_accuracy: 0.3743\n",
      "Epoch 76/80\n",
      "6435/6435 [==============================] - 0s 38us/step - loss: 1.2754 - accuracy: 0.3868 - val_loss: 1.2978 - val_accuracy: 0.4176\n",
      "Epoch 77/80\n",
      "6435/6435 [==============================] - 0s 34us/step - loss: 1.2728 - accuracy: 0.3949 - val_loss: 1.2955 - val_accuracy: 0.3841\n",
      "Epoch 78/80\n",
      "6435/6435 [==============================] - 0s 41us/step - loss: 1.2752 - accuracy: 0.3927 - val_loss: 1.3003 - val_accuracy: 0.3953\n",
      "Epoch 79/80\n",
      "6435/6435 [==============================] - 0s 37us/step - loss: 1.2721 - accuracy: 0.3916 - val_loss: 1.3000 - val_accuracy: 0.3980\n",
      "Epoch 80/80\n",
      "6435/6435 [==============================] - 0s 37us/step - loss: 1.2715 - accuracy: 0.3854 - val_loss: 1.3075 - val_accuracy: 0.3827\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[1.0936469e-01 1.2382034e-01 2.3591762e-13 ... 3.9329389e-01\n",
      "  1.4913493e-01 1.9631407e-01]\n",
      " [3.7018657e-02 3.4828149e-02 1.5820419e-19 ... 8.9257339e-04\n",
      "  5.0201081e-03 4.0380638e-03]\n",
      " [2.1925037e-01 2.4744773e-01 1.1435459e-15 ... 7.8666329e-02\n",
      "  2.0135823e-01 2.4868277e-01]\n",
      " ...\n",
      " [2.4656411e-01 2.5993302e-01 1.1577379e-16 ... 9.5530525e-03\n",
      "  2.1019526e-01 2.7273774e-01]\n",
      " [1.3392623e-01 1.3965544e-01 1.8493547e-12 ... 1.7892893e-01\n",
      "  2.1927890e-01 2.9470643e-01]\n",
      " [1.3327296e-01 1.4606556e-01 5.7430796e-13 ... 2.0061362e-01\n",
      "  2.1480753e-01 2.8158915e-01]]\n",
      "[12 10 14 ... 14 14 14]\n",
      "<class 'numpy.ndarray'>\n",
      "One CNN, r:  0\n",
      "Computing Time:  0:01:03.803814\n",
      "n, p1, p2 3 0 0\n",
      "Model: \"sequential_1\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv1d_1 (Conv1D)            (None, 3, 6)              12        \n",
      "_________________________________________________________________\n",
      "average_pooling1d_1 (Average (None, 1, 6)              0         \n",
      "_________________________________________________________________\n",
      "conv1d_2 (Conv1D)            (None, 1, 16)             112       \n",
      "_________________________________________________________________\n",
      "average_pooling1d_2 (Average (None, 1, 16)             0         \n",
      "_________________________________________________________________\n",
      "conv1d_3 (Conv1D)            (None, 1, 120)            2040      \n",
      "_________________________________________________________________\n",
      "flatten_1 (Flatten)          (None, 120)               0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 84)                10164     \n",
      "_________________________________________________________________\n",
      "preds (Dense)                (None, 15)                1275      \n",
      "=================================================================\n",
      "Total params: 13,603\n",
      "Trainable params: 13,603\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Train on 6435 samples, validate on 716 samples\n",
      "Epoch 1/80\n",
      "6435/6435 [==============================] - 0s 71us/step - loss: 2.6824 - accuracy: 0.1243 - val_loss: 2.6251 - val_accuracy: 0.1159\n",
      "Epoch 2/80\n",
      "6435/6435 [==============================] - 0s 43us/step - loss: 2.4236 - accuracy: 0.1403 - val_loss: 2.2690 - val_accuracy: 0.1760\n",
      "Epoch 3/80\n",
      "6435/6435 [==============================] - 0s 38us/step - loss: 2.0641 - accuracy: 0.2584 - val_loss: 2.0397 - val_accuracy: 0.2709\n",
      "Epoch 4/80\n",
      "6435/6435 [==============================] - 0s 40us/step - loss: 1.8881 - accuracy: 0.2729 - val_loss: 1.9366 - val_accuracy: 0.2598\n",
      "Epoch 5/80\n",
      "6435/6435 [==============================] - 0s 39us/step - loss: 1.7872 - accuracy: 0.2942 - val_loss: 1.8235 - val_accuracy: 0.2947\n",
      "Epoch 6/80\n",
      "6435/6435 [==============================] - 0s 39us/step - loss: 1.7058 - accuracy: 0.2987 - val_loss: 1.7372 - val_accuracy: 0.3045\n",
      "Epoch 7/80\n",
      "6435/6435 [==============================] - 0s 39us/step - loss: 1.6451 - accuracy: 0.3085 - val_loss: 1.7170 - val_accuracy: 0.2933\n",
      "Epoch 8/80\n",
      "6435/6435 [==============================] - 0s 38us/step - loss: 1.6128 - accuracy: 0.3047 - val_loss: 1.6618 - val_accuracy: 0.2751\n",
      "Epoch 9/80\n",
      "6435/6435 [==============================] - 0s 38us/step - loss: 1.5783 - accuracy: 0.3103 - val_loss: 1.6336 - val_accuracy: 0.2723\n",
      "Epoch 10/80\n",
      "6435/6435 [==============================] - 0s 37us/step - loss: 1.5607 - accuracy: 0.3145 - val_loss: 1.5935 - val_accuracy: 0.2877\n",
      "Epoch 11/80\n",
      "6435/6435 [==============================] - 0s 35us/step - loss: 1.5450 - accuracy: 0.3108 - val_loss: 1.5794 - val_accuracy: 0.2891\n",
      "Epoch 12/80\n",
      "6435/6435 [==============================] - 0s 37us/step - loss: 1.5272 - accuracy: 0.3138 - val_loss: 1.5607 - val_accuracy: 0.2835\n",
      "Epoch 13/80\n",
      "6435/6435 [==============================] - 0s 36us/step - loss: 1.5159 - accuracy: 0.3124 - val_loss: 1.5372 - val_accuracy: 0.3184\n",
      "Epoch 14/80\n",
      "6435/6435 [==============================] - 0s 36us/step - loss: 1.5070 - accuracy: 0.3189 - val_loss: 1.5472 - val_accuracy: 0.2933\n",
      "Epoch 15/80\n",
      "6435/6435 [==============================] - 0s 38us/step - loss: 1.5034 - accuracy: 0.3097 - val_loss: 1.5312 - val_accuracy: 0.3073\n",
      "Epoch 16/80\n",
      "6435/6435 [==============================] - 0s 39us/step - loss: 1.4995 - accuracy: 0.3169 - val_loss: 1.5273 - val_accuracy: 0.3115\n",
      "Epoch 17/80\n",
      "6435/6435 [==============================] - 0s 39us/step - loss: 1.5012 - accuracy: 0.3150 - val_loss: 1.5264 - val_accuracy: 0.2877\n",
      "Epoch 18/80\n",
      "6435/6435 [==============================] - 0s 39us/step - loss: 1.4919 - accuracy: 0.3203 - val_loss: 1.5215 - val_accuracy: 0.2933\n",
      "Epoch 19/80\n",
      "6435/6435 [==============================] - 0s 41us/step - loss: 1.4832 - accuracy: 0.3195 - val_loss: 1.5131 - val_accuracy: 0.2849\n",
      "Epoch 20/80\n",
      "6435/6435 [==============================] - 0s 43us/step - loss: 1.4855 - accuracy: 0.3184 - val_loss: 1.5170 - val_accuracy: 0.2877\n",
      "Epoch 21/80\n",
      "6435/6435 [==============================] - 0s 39us/step - loss: 1.4781 - accuracy: 0.3229 - val_loss: 1.5059 - val_accuracy: 0.2779\n",
      "Epoch 22/80\n",
      "6435/6435 [==============================] - 0s 38us/step - loss: 1.4734 - accuracy: 0.3267 - val_loss: 1.5101 - val_accuracy: 0.3142\n",
      "Epoch 23/80\n",
      "6435/6435 [==============================] - 0s 41us/step - loss: 1.4677 - accuracy: 0.3270 - val_loss: 1.5063 - val_accuracy: 0.2905\n",
      "Epoch 24/80\n",
      "6435/6435 [==============================] - 0s 37us/step - loss: 1.4655 - accuracy: 0.3277 - val_loss: 1.5024 - val_accuracy: 0.2947\n",
      "Epoch 25/80\n",
      "6435/6435 [==============================] - 0s 44us/step - loss: 1.4657 - accuracy: 0.3249 - val_loss: 1.4960 - val_accuracy: 0.2891\n",
      "Epoch 26/80\n",
      "6435/6435 [==============================] - 0s 40us/step - loss: 1.4626 - accuracy: 0.3217 - val_loss: 1.4856 - val_accuracy: 0.3017\n",
      "Epoch 27/80\n",
      "6435/6435 [==============================] - 0s 38us/step - loss: 1.4595 - accuracy: 0.3231 - val_loss: 1.4835 - val_accuracy: 0.3282\n",
      "Epoch 28/80\n",
      "6435/6435 [==============================] - 0s 38us/step - loss: 1.4588 - accuracy: 0.3318 - val_loss: 1.4880 - val_accuracy: 0.2821\n",
      "Epoch 29/80\n",
      "6435/6435 [==============================] - 0s 43us/step - loss: 1.4634 - accuracy: 0.3369 - val_loss: 1.4861 - val_accuracy: 0.3156\n",
      "Epoch 30/80\n",
      "6435/6435 [==============================] - 0s 37us/step - loss: 1.4526 - accuracy: 0.3355 - val_loss: 1.4823 - val_accuracy: 0.2975\n",
      "Epoch 31/80\n",
      "6435/6435 [==============================] - 0s 37us/step - loss: 1.4448 - accuracy: 0.3352 - val_loss: 1.4734 - val_accuracy: 0.2961\n",
      "Epoch 32/80\n",
      "6435/6435 [==============================] - 0s 38us/step - loss: 1.4430 - accuracy: 0.3388 - val_loss: 1.4822 - val_accuracy: 0.3073\n",
      "Epoch 33/80\n",
      "6435/6435 [==============================] - 0s 38us/step - loss: 1.4319 - accuracy: 0.3458 - val_loss: 1.4531 - val_accuracy: 0.3422\n",
      "Epoch 34/80\n",
      "6435/6435 [==============================] - 0s 38us/step - loss: 1.4188 - accuracy: 0.3556 - val_loss: 1.4440 - val_accuracy: 0.3254\n",
      "Epoch 35/80\n",
      "6435/6435 [==============================] - 0s 40us/step - loss: 1.4124 - accuracy: 0.3608 - val_loss: 1.4340 - val_accuracy: 0.3492\n",
      "Epoch 36/80\n",
      "6435/6435 [==============================] - 0s 36us/step - loss: 1.3940 - accuracy: 0.3697 - val_loss: 1.4086 - val_accuracy: 0.3617\n",
      "Epoch 37/80\n",
      "6435/6435 [==============================] - 0s 36us/step - loss: 1.3769 - accuracy: 0.3611 - val_loss: 1.3798 - val_accuracy: 0.3561\n",
      "Epoch 38/80\n",
      "6435/6435 [==============================] - 0s 39us/step - loss: 1.3549 - accuracy: 0.3772 - val_loss: 1.3553 - val_accuracy: 0.3520\n",
      "Epoch 39/80\n",
      "6435/6435 [==============================] - 0s 38us/step - loss: 1.3331 - accuracy: 0.3796 - val_loss: 1.3557 - val_accuracy: 0.3589\n",
      "Epoch 40/80\n",
      "6435/6435 [==============================] - 0s 36us/step - loss: 1.3294 - accuracy: 0.3803 - val_loss: 1.3348 - val_accuracy: 0.3743\n",
      "Epoch 41/80\n",
      "6435/6435 [==============================] - 0s 37us/step - loss: 1.3114 - accuracy: 0.3857 - val_loss: 1.3299 - val_accuracy: 0.3547\n",
      "Epoch 42/80\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6435/6435 [==============================] - 0s 37us/step - loss: 1.3031 - accuracy: 0.3868 - val_loss: 1.3218 - val_accuracy: 0.3813\n",
      "Epoch 43/80\n",
      "6435/6435 [==============================] - 0s 36us/step - loss: 1.2989 - accuracy: 0.3854 - val_loss: 1.3180 - val_accuracy: 0.3603\n",
      "Epoch 44/80\n",
      "6435/6435 [==============================] - 0s 48us/step - loss: 1.3065 - accuracy: 0.3860 - val_loss: 1.3175 - val_accuracy: 0.3478\n",
      "Epoch 45/80\n",
      "6435/6435 [==============================] - 0s 40us/step - loss: 1.2963 - accuracy: 0.3877 - val_loss: 1.3112 - val_accuracy: 0.3561\n",
      "Epoch 46/80\n",
      "6435/6435 [==============================] - 0s 39us/step - loss: 1.2854 - accuracy: 0.3879 - val_loss: 1.3064 - val_accuracy: 0.3883\n",
      "Epoch 47/80\n",
      "6435/6435 [==============================] - 0s 40us/step - loss: 1.2812 - accuracy: 0.3913 - val_loss: 1.3109 - val_accuracy: 0.3687\n",
      "Epoch 48/80\n",
      "6435/6435 [==============================] - 0s 39us/step - loss: 1.2834 - accuracy: 0.3983 - val_loss: 1.3055 - val_accuracy: 0.3743\n",
      "Epoch 49/80\n",
      "6435/6435 [==============================] - 0s 36us/step - loss: 1.2763 - accuracy: 0.3994 - val_loss: 1.3049 - val_accuracy: 0.3589\n",
      "Epoch 50/80\n",
      "6435/6435 [==============================] - 0s 40us/step - loss: 1.2810 - accuracy: 0.3904 - val_loss: 1.2984 - val_accuracy: 0.3771\n",
      "Epoch 51/80\n",
      "6435/6435 [==============================] - 0s 35us/step - loss: 1.2771 - accuracy: 0.3961 - val_loss: 1.2959 - val_accuracy: 0.3715\n",
      "Epoch 52/80\n",
      "6435/6435 [==============================] - 0s 37us/step - loss: 1.2729 - accuracy: 0.3882 - val_loss: 1.2837 - val_accuracy: 0.3883\n",
      "Epoch 53/80\n",
      "6435/6435 [==============================] - 0s 42us/step - loss: 1.2718 - accuracy: 0.3866 - val_loss: 1.2814 - val_accuracy: 0.4022\n",
      "Epoch 54/80\n",
      "6435/6435 [==============================] - 0s 38us/step - loss: 1.2652 - accuracy: 0.3941 - val_loss: 1.2917 - val_accuracy: 0.3939\n",
      "Epoch 55/80\n",
      "6435/6435 [==============================] - 0s 39us/step - loss: 1.2657 - accuracy: 0.3913 - val_loss: 1.2856 - val_accuracy: 0.3715\n",
      "Epoch 56/80\n",
      "6435/6435 [==============================] - 0s 37us/step - loss: 1.2581 - accuracy: 0.3989 - val_loss: 1.3063 - val_accuracy: 0.3743\n",
      "Epoch 57/80\n",
      "6435/6435 [==============================] - 0s 36us/step - loss: 1.2668 - accuracy: 0.3953 - val_loss: 1.2772 - val_accuracy: 0.3925\n",
      "Epoch 58/80\n",
      "6435/6435 [==============================] - 0s 37us/step - loss: 1.2720 - accuracy: 0.3967 - val_loss: 1.2969 - val_accuracy: 0.3757\n",
      "Epoch 59/80\n",
      "6435/6435 [==============================] - 0s 35us/step - loss: 1.2583 - accuracy: 0.3984 - val_loss: 1.2704 - val_accuracy: 0.3897\n",
      "Epoch 60/80\n",
      "6435/6435 [==============================] - 0s 37us/step - loss: 1.2598 - accuracy: 0.3997 - val_loss: 1.2754 - val_accuracy: 0.3617\n",
      "Epoch 61/80\n",
      "6435/6435 [==============================] - 0s 38us/step - loss: 1.2527 - accuracy: 0.3992 - val_loss: 1.2720 - val_accuracy: 0.4106\n",
      "Epoch 62/80\n",
      "6435/6435 [==============================] - 0s 34us/step - loss: 1.2469 - accuracy: 0.4033 - val_loss: 1.2822 - val_accuracy: 0.3827\n",
      "Epoch 63/80\n",
      "6435/6435 [==============================] - 0s 39us/step - loss: 1.2536 - accuracy: 0.4036 - val_loss: 1.2717 - val_accuracy: 0.3785\n",
      "Epoch 64/80\n",
      "6435/6435 [==============================] - 0s 40us/step - loss: 1.2520 - accuracy: 0.3991 - val_loss: 1.2760 - val_accuracy: 0.3953\n",
      "Epoch 65/80\n",
      "6435/6435 [==============================] - 0s 35us/step - loss: 1.2553 - accuracy: 0.3950 - val_loss: 1.2586 - val_accuracy: 0.3827\n",
      "Epoch 66/80\n",
      "6435/6435 [==============================] - 0s 38us/step - loss: 1.2438 - accuracy: 0.4009 - val_loss: 1.2665 - val_accuracy: 0.4008\n",
      "Epoch 67/80\n",
      "6435/6435 [==============================] - 0s 37us/step - loss: 1.2441 - accuracy: 0.4044 - val_loss: 1.2730 - val_accuracy: 0.3799\n",
      "Epoch 68/80\n",
      "6435/6435 [==============================] - 0s 41us/step - loss: 1.2392 - accuracy: 0.4023 - val_loss: 1.2582 - val_accuracy: 0.3799\n",
      "Epoch 69/80\n",
      "6435/6435 [==============================] - 0s 37us/step - loss: 1.2358 - accuracy: 0.4050 - val_loss: 1.2619 - val_accuracy: 0.3869\n",
      "Epoch 70/80\n",
      "6435/6435 [==============================] - 0s 38us/step - loss: 1.2330 - accuracy: 0.3946 - val_loss: 1.2556 - val_accuracy: 0.3757\n",
      "Epoch 71/80\n",
      "6435/6435 [==============================] - 0s 39us/step - loss: 1.2293 - accuracy: 0.4065 - val_loss: 1.2545 - val_accuracy: 0.3855\n",
      "Epoch 72/80\n",
      "6435/6435 [==============================] - 0s 37us/step - loss: 1.2301 - accuracy: 0.4070 - val_loss: 1.2590 - val_accuracy: 0.3869\n",
      "Epoch 73/80\n",
      "6435/6435 [==============================] - 0s 36us/step - loss: 1.2303 - accuracy: 0.4084 - val_loss: 1.2451 - val_accuracy: 0.3925\n",
      "Epoch 74/80\n",
      "6435/6435 [==============================] - 0s 41us/step - loss: 1.2328 - accuracy: 0.3991 - val_loss: 1.2605 - val_accuracy: 0.3687\n",
      "Epoch 75/80\n",
      "6435/6435 [==============================] - 0s 39us/step - loss: 1.2224 - accuracy: 0.4104 - val_loss: 1.2489 - val_accuracy: 0.3827\n",
      "Epoch 76/80\n",
      "6435/6435 [==============================] - 0s 43us/step - loss: 1.2271 - accuracy: 0.4093 - val_loss: 1.2414 - val_accuracy: 0.4022\n",
      "Epoch 77/80\n",
      "6435/6435 [==============================] - 0s 38us/step - loss: 1.2286 - accuracy: 0.4036 - val_loss: 1.2511 - val_accuracy: 0.3966\n",
      "Epoch 78/80\n",
      "6435/6435 [==============================] - 0s 39us/step - loss: 1.2251 - accuracy: 0.4044 - val_loss: 1.2393 - val_accuracy: 0.3925\n",
      "Epoch 79/80\n",
      "6435/6435 [==============================] - 0s 35us/step - loss: 1.2211 - accuracy: 0.4028 - val_loss: 1.2496 - val_accuracy: 0.3715\n",
      "Epoch 80/80\n",
      "6435/6435 [==============================] - 0s 39us/step - loss: 1.2196 - accuracy: 0.4095 - val_loss: 1.2352 - val_accuracy: 0.4106\n",
      "[[1.18026175e-01 1.04963064e-01 9.86792245e-13 ... 2.61366308e-01\n",
      "  2.49387249e-01 2.41281897e-01]\n",
      " [6.08317964e-02 4.97956313e-02 3.54433889e-17 ... 4.68781451e-03\n",
      "  6.18639309e-03 5.41257160e-03]\n",
      " [1.66911542e-01 1.53077275e-01 5.01340268e-14 ... 5.45653217e-02\n",
      "  3.25994164e-01 2.97396928e-01]\n",
      " ...\n",
      " [2.37159684e-01 2.13824823e-01 1.06451902e-13 ... 7.40092341e-03\n",
      "  2.90397525e-01 2.50437319e-01]\n",
      " [9.82687101e-02 8.78393948e-02 5.51630616e-12 ... 1.30411953e-01\n",
      "  3.43469679e-01 3.19675893e-01]\n",
      " [1.08179294e-01 9.67629999e-02 2.43728475e-12 ... 1.41735584e-01\n",
      "  3.27745467e-01 3.08814228e-01]]\n",
      "[12  5 13 ... 13 13 13]\n",
      "<class 'numpy.ndarray'>\n",
      "One CNN, r:  0\n",
      "Computing Time:  0:01:25.285592\n",
      "n, p1, p2 4 0 0\n",
      "Model: \"sequential_1\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv1d_1 (Conv1D)            (None, 3, 6)              12        \n",
      "_________________________________________________________________\n",
      "average_pooling1d_1 (Average (None, 1, 6)              0         \n",
      "_________________________________________________________________\n",
      "conv1d_2 (Conv1D)            (None, 1, 16)             112       \n",
      "_________________________________________________________________\n",
      "average_pooling1d_2 (Average (None, 1, 16)             0         \n",
      "_________________________________________________________________\n",
      "conv1d_3 (Conv1D)            (None, 1, 120)            2040      \n",
      "_________________________________________________________________\n",
      "flatten_1 (Flatten)          (None, 120)               0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 84)                10164     \n",
      "_________________________________________________________________\n",
      "preds (Dense)                (None, 15)                1275      \n",
      "=================================================================\n",
      "Total params: 13,603\n",
      "Trainable params: 13,603\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Train on 6435 samples, validate on 716 samples\n",
      "Epoch 1/80\n",
      "6435/6435 [==============================] - 0s 77us/step - loss: 2.6712 - accuracy: 0.1685 - val_loss: 2.5778 - val_accuracy: 0.1620\n",
      "Epoch 2/80\n",
      "6435/6435 [==============================] - 0s 38us/step - loss: 2.3478 - accuracy: 0.1933 - val_loss: 2.1744 - val_accuracy: 0.2067\n",
      "Epoch 3/80\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6435/6435 [==============================] - 0s 41us/step - loss: 2.0335 - accuracy: 0.2493 - val_loss: 2.0285 - val_accuracy: 0.2821\n",
      "Epoch 4/80\n",
      "6435/6435 [==============================] - 0s 40us/step - loss: 1.9094 - accuracy: 0.2721 - val_loss: 1.9438 - val_accuracy: 0.2891\n",
      "Epoch 5/80\n",
      "6435/6435 [==============================] - 0s 39us/step - loss: 1.8283 - accuracy: 0.2831 - val_loss: 1.8668 - val_accuracy: 0.2570\n",
      "Epoch 6/80\n",
      "6435/6435 [==============================] - 0s 35us/step - loss: 1.7571 - accuracy: 0.2945 - val_loss: 1.7986 - val_accuracy: 0.2765\n",
      "Epoch 7/80\n",
      "6435/6435 [==============================] - 0s 34us/step - loss: 1.7082 - accuracy: 0.2948 - val_loss: 1.7332 - val_accuracy: 0.2779\n",
      "Epoch 8/80\n",
      "6435/6435 [==============================] - 0s 42us/step - loss: 1.6676 - accuracy: 0.3082 - val_loss: 1.6966 - val_accuracy: 0.2696\n",
      "Epoch 9/80\n",
      "6435/6435 [==============================] - 0s 43us/step - loss: 1.6434 - accuracy: 0.3030 - val_loss: 1.6912 - val_accuracy: 0.2584\n",
      "Epoch 10/80\n",
      "6435/6435 [==============================] - 0s 40us/step - loss: 1.6183 - accuracy: 0.3033 - val_loss: 1.6514 - val_accuracy: 0.2779\n",
      "Epoch 11/80\n",
      "6435/6435 [==============================] - 0s 40us/step - loss: 1.5955 - accuracy: 0.3030 - val_loss: 1.6281 - val_accuracy: 0.2779\n",
      "Epoch 12/80\n",
      "6435/6435 [==============================] - 0s 39us/step - loss: 1.5774 - accuracy: 0.3141 - val_loss: 1.6148 - val_accuracy: 0.2989\n",
      "Epoch 13/80\n",
      "6435/6435 [==============================] - 0s 40us/step - loss: 1.5626 - accuracy: 0.3103 - val_loss: 1.5995 - val_accuracy: 0.2709\n",
      "Epoch 14/80\n",
      "6435/6435 [==============================] - 0s 40us/step - loss: 1.5497 - accuracy: 0.3215 - val_loss: 1.5901 - val_accuracy: 0.2905\n",
      "Epoch 15/80\n",
      "6435/6435 [==============================] - 0s 41us/step - loss: 1.5472 - accuracy: 0.3091 - val_loss: 1.5885 - val_accuracy: 0.2765\n",
      "Epoch 16/80\n",
      "6435/6435 [==============================] - 0s 44us/step - loss: 1.5341 - accuracy: 0.3172 - val_loss: 1.5767 - val_accuracy: 0.2793\n",
      "Epoch 17/80\n",
      "6435/6435 [==============================] - 0s 39us/step - loss: 1.5209 - accuracy: 0.3201 - val_loss: 1.5570 - val_accuracy: 0.3115\n",
      "Epoch 18/80\n",
      "6435/6435 [==============================] - 0s 36us/step - loss: 1.5196 - accuracy: 0.3144 - val_loss: 1.5707 - val_accuracy: 0.2933\n",
      "Epoch 19/80\n",
      "6435/6435 [==============================] - 0s 37us/step - loss: 1.5129 - accuracy: 0.3249 - val_loss: 1.5578 - val_accuracy: 0.2668\n",
      "Epoch 20/80\n",
      "6435/6435 [==============================] - 0s 34us/step - loss: 1.5093 - accuracy: 0.3242 - val_loss: 1.5436 - val_accuracy: 0.2891\n",
      "Epoch 21/80\n",
      "6435/6435 [==============================] - 0s 36us/step - loss: 1.5099 - accuracy: 0.3178 - val_loss: 1.5558 - val_accuracy: 0.2793\n",
      "Epoch 22/80\n",
      "6435/6435 [==============================] - 0s 41us/step - loss: 1.5044 - accuracy: 0.3232 - val_loss: 1.5559 - val_accuracy: 0.2849\n",
      "Epoch 23/80\n",
      "6435/6435 [==============================] - 0s 37us/step - loss: 1.5054 - accuracy: 0.3193 - val_loss: 1.5270 - val_accuracy: 0.2961\n",
      "Epoch 24/80\n",
      "6435/6435 [==============================] - 0s 39us/step - loss: 1.4938 - accuracy: 0.3248 - val_loss: 1.5484 - val_accuracy: 0.2989\n",
      "Epoch 25/80\n",
      "6435/6435 [==============================] - 0s 38us/step - loss: 1.4946 - accuracy: 0.3223 - val_loss: 1.5433 - val_accuracy: 0.2737\n",
      "Epoch 26/80\n",
      "6435/6435 [==============================] - 0s 40us/step - loss: 1.4895 - accuracy: 0.3223 - val_loss: 1.5219 - val_accuracy: 0.3115\n",
      "Epoch 27/80\n",
      "6435/6435 [==============================] - 0s 39us/step - loss: 1.4869 - accuracy: 0.3211 - val_loss: 1.5450 - val_accuracy: 0.3115\n",
      "Epoch 28/80\n",
      "6435/6435 [==============================] - 0s 36us/step - loss: 1.4845 - accuracy: 0.3260 - val_loss: 1.5298 - val_accuracy: 0.2863\n",
      "Epoch 29/80\n",
      "6435/6435 [==============================] - 0s 39us/step - loss: 1.4825 - accuracy: 0.3267 - val_loss: 1.5188 - val_accuracy: 0.2891\n",
      "Epoch 30/80\n",
      "6435/6435 [==============================] - 0s 38us/step - loss: 1.4800 - accuracy: 0.3225 - val_loss: 1.5356 - val_accuracy: 0.2849\n",
      "Epoch 31/80\n",
      "6435/6435 [==============================] - 0s 38us/step - loss: 1.4766 - accuracy: 0.3294 - val_loss: 1.5092 - val_accuracy: 0.3017\n",
      "Epoch 32/80\n",
      "6435/6435 [==============================] - 0s 39us/step - loss: 1.4787 - accuracy: 0.3270 - val_loss: 1.5015 - val_accuracy: 0.3240\n",
      "Epoch 33/80\n",
      "6435/6435 [==============================] - 0s 39us/step - loss: 1.4695 - accuracy: 0.3246 - val_loss: 1.5200 - val_accuracy: 0.3059\n",
      "Epoch 34/80\n",
      "6435/6435 [==============================] - 0s 39us/step - loss: 1.4693 - accuracy: 0.3206 - val_loss: 1.5101 - val_accuracy: 0.2877\n",
      "Epoch 35/80\n",
      "6435/6435 [==============================] - 0s 36us/step - loss: 1.4667 - accuracy: 0.3296 - val_loss: 1.4989 - val_accuracy: 0.2905\n",
      "Epoch 36/80\n",
      "6435/6435 [==============================] - 0s 38us/step - loss: 1.4620 - accuracy: 0.3358 - val_loss: 1.5193 - val_accuracy: 0.3087\n",
      "Epoch 37/80\n",
      "6435/6435 [==============================] - 0s 39us/step - loss: 1.4564 - accuracy: 0.3391 - val_loss: 1.5114 - val_accuracy: 0.2737\n",
      "Epoch 38/80\n",
      "6435/6435 [==============================] - 0s 40us/step - loss: 1.4647 - accuracy: 0.3298 - val_loss: 1.4871 - val_accuracy: 0.3142\n",
      "Epoch 39/80\n",
      "6435/6435 [==============================] - 0s 38us/step - loss: 1.4681 - accuracy: 0.3338 - val_loss: 1.4990 - val_accuracy: 0.3017\n",
      "Epoch 40/80\n",
      "6435/6435 [==============================] - 0s 44us/step - loss: 1.4597 - accuracy: 0.3316 - val_loss: 1.4936 - val_accuracy: 0.2877\n",
      "Epoch 41/80\n",
      "6435/6435 [==============================] - 0s 41us/step - loss: 1.4552 - accuracy: 0.3391 - val_loss: 1.5076 - val_accuracy: 0.2863\n",
      "Epoch 42/80\n",
      "6435/6435 [==============================] - 0s 39us/step - loss: 1.4498 - accuracy: 0.3409 - val_loss: 1.4851 - val_accuracy: 0.3184\n",
      "Epoch 43/80\n",
      "6435/6435 [==============================] - 0s 34us/step - loss: 1.4511 - accuracy: 0.3392 - val_loss: 1.5021 - val_accuracy: 0.2835\n",
      "Epoch 44/80\n",
      "6435/6435 [==============================] - 0s 44us/step - loss: 1.4431 - accuracy: 0.3411 - val_loss: 1.4886 - val_accuracy: 0.2947\n",
      "Epoch 45/80\n",
      "6435/6435 [==============================] - 0s 38us/step - loss: 1.4411 - accuracy: 0.3304 - val_loss: 1.5060 - val_accuracy: 0.3087\n",
      "Epoch 46/80\n",
      "6435/6435 [==============================] - 0s 39us/step - loss: 1.4470 - accuracy: 0.3397 - val_loss: 1.4771 - val_accuracy: 0.3170\n",
      "Epoch 47/80\n",
      "6435/6435 [==============================] - 0s 41us/step - loss: 1.4347 - accuracy: 0.3456 - val_loss: 1.4806 - val_accuracy: 0.3059\n",
      "Epoch 48/80\n",
      "6435/6435 [==============================] - 0s 38us/step - loss: 1.4368 - accuracy: 0.3400 - val_loss: 1.5000 - val_accuracy: 0.2737\n",
      "Epoch 49/80\n",
      "6435/6435 [==============================] - 0s 34us/step - loss: 1.4390 - accuracy: 0.3416 - val_loss: 1.4682 - val_accuracy: 0.3184\n",
      "Epoch 50/80\n",
      "6435/6435 [==============================] - 0s 38us/step - loss: 1.4411 - accuracy: 0.3419 - val_loss: 1.4866 - val_accuracy: 0.3003\n",
      "Epoch 51/80\n",
      "6435/6435 [==============================] - 0s 37us/step - loss: 1.4311 - accuracy: 0.3484 - val_loss: 1.4667 - val_accuracy: 0.3031\n",
      "Epoch 52/80\n",
      "6435/6435 [==============================] - 0s 38us/step - loss: 1.4252 - accuracy: 0.3450 - val_loss: 1.4703 - val_accuracy: 0.3254\n",
      "Epoch 53/80\n",
      "6435/6435 [==============================] - 0s 37us/step - loss: 1.4256 - accuracy: 0.3490 - val_loss: 1.4626 - val_accuracy: 0.3352\n",
      "Epoch 54/80\n",
      "6435/6435 [==============================] - 0s 41us/step - loss: 1.4250 - accuracy: 0.3425 - val_loss: 1.4838 - val_accuracy: 0.3101\n",
      "Epoch 55/80\n",
      "6435/6435 [==============================] - 0s 39us/step - loss: 1.4205 - accuracy: 0.3464 - val_loss: 1.4581 - val_accuracy: 0.2961\n",
      "Epoch 56/80\n",
      "6435/6435 [==============================] - 0s 38us/step - loss: 1.4185 - accuracy: 0.3458 - val_loss: 1.4818 - val_accuracy: 0.3045\n",
      "Epoch 57/80\n",
      "6435/6435 [==============================] - 0s 37us/step - loss: 1.4173 - accuracy: 0.3469 - val_loss: 1.4724 - val_accuracy: 0.3170\n",
      "Epoch 58/80\n",
      "6435/6435 [==============================] - 0s 39us/step - loss: 1.4231 - accuracy: 0.3448 - val_loss: 1.4539 - val_accuracy: 0.3045\n",
      "Epoch 59/80\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6435/6435 [==============================] - 0s 38us/step - loss: 1.4117 - accuracy: 0.3472 - val_loss: 1.4429 - val_accuracy: 0.3254\n",
      "Epoch 60/80\n",
      "6435/6435 [==============================] - 0s 38us/step - loss: 1.4040 - accuracy: 0.3576 - val_loss: 1.4518 - val_accuracy: 0.3128\n",
      "Epoch 61/80\n",
      "6435/6435 [==============================] - 0s 37us/step - loss: 1.3986 - accuracy: 0.3605 - val_loss: 1.4345 - val_accuracy: 0.3282\n",
      "Epoch 62/80\n",
      "6435/6435 [==============================] - 0s 35us/step - loss: 1.3917 - accuracy: 0.3579 - val_loss: 1.4296 - val_accuracy: 0.3212\n",
      "Epoch 63/80\n",
      "6435/6435 [==============================] - 0s 39us/step - loss: 1.3890 - accuracy: 0.3699 - val_loss: 1.4193 - val_accuracy: 0.3436\n",
      "Epoch 64/80\n",
      "6435/6435 [==============================] - 0s 36us/step - loss: 1.3844 - accuracy: 0.3812 - val_loss: 1.4129 - val_accuracy: 0.3701\n",
      "Epoch 65/80\n",
      "6435/6435 [==============================] - 0s 35us/step - loss: 1.3717 - accuracy: 0.3700 - val_loss: 1.4179 - val_accuracy: 0.3506\n",
      "Epoch 66/80\n",
      "6435/6435 [==============================] - 0s 37us/step - loss: 1.3709 - accuracy: 0.3737 - val_loss: 1.4200 - val_accuracy: 0.3156\n",
      "Epoch 67/80\n",
      "6435/6435 [==============================] - 0s 37us/step - loss: 1.3625 - accuracy: 0.3778 - val_loss: 1.3840 - val_accuracy: 0.3422\n",
      "Epoch 68/80\n",
      "6435/6435 [==============================] - 0s 37us/step - loss: 1.3518 - accuracy: 0.3814 - val_loss: 1.3813 - val_accuracy: 0.3589\n",
      "Epoch 69/80\n",
      "6435/6435 [==============================] - 0s 37us/step - loss: 1.3471 - accuracy: 0.3817 - val_loss: 1.3789 - val_accuracy: 0.3478\n",
      "Epoch 70/80\n",
      "6435/6435 [==============================] - 0s 36us/step - loss: 1.3469 - accuracy: 0.3782 - val_loss: 1.3799 - val_accuracy: 0.3338\n",
      "Epoch 71/80\n",
      "6435/6435 [==============================] - 0s 38us/step - loss: 1.3350 - accuracy: 0.3838 - val_loss: 1.3937 - val_accuracy: 0.3478\n",
      "Epoch 72/80\n",
      "6435/6435 [==============================] - 0s 35us/step - loss: 1.3389 - accuracy: 0.3876 - val_loss: 1.3888 - val_accuracy: 0.3408\n",
      "Epoch 73/80\n",
      "6435/6435 [==============================] - 0s 38us/step - loss: 1.3295 - accuracy: 0.3857 - val_loss: 1.3496 - val_accuracy: 0.3450\n",
      "Epoch 74/80\n",
      "6435/6435 [==============================] - 0s 36us/step - loss: 1.3341 - accuracy: 0.3770 - val_loss: 1.3512 - val_accuracy: 0.3366\n",
      "Epoch 75/80\n",
      "6435/6435 [==============================] - 0s 38us/step - loss: 1.3198 - accuracy: 0.3812 - val_loss: 1.3582 - val_accuracy: 0.3771\n",
      "Epoch 76/80\n",
      "6435/6435 [==============================] - 0s 38us/step - loss: 1.3062 - accuracy: 0.3891 - val_loss: 1.3274 - val_accuracy: 0.3506\n",
      "Epoch 77/80\n",
      "6435/6435 [==============================] - 0s 35us/step - loss: 1.3049 - accuracy: 0.3795 - val_loss: 1.3320 - val_accuracy: 0.3478\n",
      "Epoch 78/80\n",
      "6435/6435 [==============================] - 0s 37us/step - loss: 1.3032 - accuracy: 0.3800 - val_loss: 1.3339 - val_accuracy: 0.3422\n",
      "Epoch 79/80\n",
      "6435/6435 [==============================] - 0s 39us/step - loss: 1.2949 - accuracy: 0.3972 - val_loss: 1.3221 - val_accuracy: 0.3855\n",
      "Epoch 80/80\n",
      "6435/6435 [==============================] - 0s 35us/step - loss: 1.2913 - accuracy: 0.3814 - val_loss: 1.3291 - val_accuracy: 0.3464\n",
      "[[9.4956286e-02 1.4553569e-01 7.2171622e-16 ... 3.0006981e-01\n",
      "  2.3716341e-01 1.7982386e-01]\n",
      " [2.2346793e-02 3.4677930e-02 1.2273226e-23 ... 6.5702596e-03\n",
      "  5.9899599e-03 4.6264003e-03]\n",
      " [1.6721192e-01 2.6891690e-01 6.5999285e-17 ... 8.4801011e-02\n",
      "  2.6880395e-01 2.0389327e-01]\n",
      " ...\n",
      " [1.8053877e-01 3.0750096e-01 1.8626000e-15 ... 2.0663744e-02\n",
      "  2.7875185e-01 2.1093960e-01]\n",
      " [9.6371256e-02 1.5074949e-01 7.8311001e-14 ... 1.7325839e-01\n",
      "  3.0350444e-01 2.2137377e-01]\n",
      " [1.0528338e-01 1.6462791e-01 1.9050549e-14 ... 1.8609332e-01\n",
      "  2.8993565e-01 2.1439835e-01]]\n",
      "[12  5  1 ...  1 13 13]\n",
      "<class 'numpy.ndarray'>\n",
      "One CNN, r:  0\n",
      "Computing Time:  0:01:46.749588\n"
     ]
    }
   ],
   "source": [
    "#======================================================\n",
    "\n",
    "#1213 add auto judge\n",
    "from CNN_Modules_1D import ME_CNN\n",
    "\n",
    "# ==== CNN Original =====\n",
    "ROUND_start = time.time()\n",
    "\n",
    "for n in range(5):\n",
    "    region=region_image.copy()\n",
    "    region=list(region)\n",
    "    selected_region = list(range(NUM_region))\n",
    "\n",
    "    p1=0\n",
    "    p2=0\n",
    "\n",
    "    print(\"n, p1, p2\", n, p1, p2)\n",
    "\n",
    "\n",
    "    # ===== one CNN =============\n",
    "    NUM_CLASSES = len(selected_region)\n",
    "\n",
    "    # input image and label\n",
    "    Input_img     = []\n",
    "    Input_img_len = []\n",
    "    for c,sel in enumerate(selected_region, start=0):\n",
    "        Input_img = Input_img + list(region[sel])\n",
    "        Input_img_len.append(len(region[sel]))\n",
    "\n",
    "    # 1213\n",
    "    # fill up training array\n",
    "    W           = np.shape(test_array[0])[0]\n",
    "    train_array = np.zeros((len(Input_img), W), dtype=float)\n",
    "    for i in range (len(Input_img)):\n",
    "        train_array[i] = test_array[Input_img[i]].reshape(W)\n",
    "\n",
    "    train_array = np.expand_dims(train_array, axis = -1)\n",
    "\n",
    "\n",
    "    # fill up the training label to each training image\n",
    "    current_train_label = np.zeros(len(train_array), dtype=int)\n",
    "    accum_base=0\n",
    "    for label in range(1,NUM_CLASSES):\n",
    "        pre_cursor = Input_img_len[label-1]\n",
    "        accum_base = accum_base + pre_cursor\n",
    "        current_train_label[accum_base:] = label\n",
    "\n",
    "    # CNN\n",
    "    #===============================================\n",
    "    one_predicted_results  = np.zeros((TRIALS, len(test_label_answer)), dtype=int)\n",
    "    one_predict_percentage = np.zeros((TRIALS, len(test_label_answer), NUM_CLASSES), dtype=float)    \n",
    "    model_history = np.zeros(TRIALS, dtype=list)\n",
    "\n",
    "    for r in range(TRIALS):\n",
    "        one_predicted_results[r], one_predict_percentage[r], model_history[r] = ME_CNN(\n",
    "                x_train     = train_array,\n",
    "                train_label = current_train_label,\n",
    "                test_array  = test_array,\n",
    "                true_answer = test_label_answer,\n",
    "                Num_Classes = NUM_CLASSES\n",
    "                )\n",
    "        print(type(model_history))\n",
    "\n",
    "\n",
    "        # ===== delete CNN tensors =====\n",
    "        from keras import backend as K\n",
    "        K.clear_session()\n",
    "        import gc\n",
    "        gc.collect()\n",
    "\n",
    "        print(\"One CNN, r: \",r)\n",
    "        ROUND_duration = time.time() - ROUND_start\n",
    "        print(\"Computing Time: \", str(datetime.timedelta(seconds=ROUND_duration)))\n",
    "\n",
    "    # === save to file ===\n",
    "    savefile_path = './' + str(timestr) + '(classes=' + str(NUM_CLASSES)+')_n0_R' + str(p1) + '+R'+ str(p2) +'_trial' + str(n)+'.pickle'  #extra_original\n",
    "    with open(savefile_path, 'wb') as f:\n",
    "        pickle.dump([Input_img, Input_img_len, one_predicted_results, one_predict_percentage, model_history], f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(5, 5000) (5, 5000, 15)\n"
     ]
    }
   ],
   "source": [
    "#==== shift label =======\n",
    "N=5\n",
    "Original_result=[]\n",
    "Original_prob=[]\n",
    "for i in range(N):\n",
    "    with open('./' + timestr + '(classes=' + str(NUM_region) + ')_n0_R0+R0_trial' + str(i)+ '.pickle', 'rb') as f:\n",
    "        Input_img, Input_img_len, one_predicted_results, one_predict_percentage, model_history = pickle.load(f)\n",
    "    label_B = one_predicted_results[0].copy()\n",
    "    label_B_prob = one_predict_percentage[0].copy()\n",
    "\n",
    "    #(1)\n",
    "    Original_result.append(label_B)\n",
    "\n",
    "    #(2)\n",
    "    Original_prob.append(label_B_prob)\n",
    "print(np.shape(Original_result), np.shape(Original_prob))\n",
    "\n",
    "# save pickle\n",
    "with open('./' + timestr + 'results_of_original.pickle', 'wb') as f:\n",
    "    pickle.dump([Original_result, Original_prob], f)\n",
    "    \n",
    "# save mat\n",
    "from scipy.io import savemat\n",
    "savemat('./' + timestr + 'results_of_original.mat', {'result_for_original':Original_result, 'prob_for_original':Original_prob})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# CNN combination and removal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "105"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "n, p1, p2 0 0 0\n",
      "Model: \"sequential_1\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv1d_1 (Conv1D)            (None, 3, 6)              12        \n",
      "_________________________________________________________________\n",
      "average_pooling1d_1 (Average (None, 1, 6)              0         \n",
      "_________________________________________________________________\n",
      "conv1d_2 (Conv1D)            (None, 1, 16)             112       \n",
      "_________________________________________________________________\n",
      "average_pooling1d_2 (Average (None, 1, 16)             0         \n",
      "_________________________________________________________________\n",
      "conv1d_3 (Conv1D)            (None, 1, 120)            2040      \n",
      "_________________________________________________________________\n",
      "flatten_1 (Flatten)          (None, 120)               0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 84)                10164     \n",
      "_________________________________________________________________\n",
      "preds (Dense)                (None, 15)                1275      \n",
      "=================================================================\n",
      "Total params: 13,603\n",
      "Trainable params: 13,603\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Train on 6435 samples, validate on 716 samples\n",
      "Epoch 1/80\n",
      "6435/6435 [==============================] - 0s 73us/step - loss: 2.6846 - accuracy: 0.1484 - val_loss: 2.6197 - val_accuracy: 0.1662\n",
      "Epoch 2/80\n",
      "6435/6435 [==============================] - 0s 38us/step - loss: 2.4121 - accuracy: 0.2362 - val_loss: 2.1886 - val_accuracy: 0.2067\n",
      "Epoch 3/80\n",
      "6435/6435 [==============================] - 0s 37us/step - loss: 2.0704 - accuracy: 0.2513 - val_loss: 1.9943 - val_accuracy: 0.2626\n",
      "Epoch 4/80\n",
      "6435/6435 [==============================] - 0s 37us/step - loss: 1.9453 - accuracy: 0.2685 - val_loss: 1.9131 - val_accuracy: 0.2919\n",
      "Epoch 5/80\n",
      "6435/6435 [==============================] - 0s 37us/step - loss: 1.8734 - accuracy: 0.2855 - val_loss: 1.8564 - val_accuracy: 0.2905\n",
      "Epoch 6/80\n",
      "6435/6435 [==============================] - 0s 37us/step - loss: 1.8138 - accuracy: 0.2828 - val_loss: 1.8043 - val_accuracy: 0.2835\n",
      "Epoch 7/80\n",
      "6435/6435 [==============================] - 0s 36us/step - loss: 1.7468 - accuracy: 0.2946 - val_loss: 1.7455 - val_accuracy: 0.2989\n",
      "Epoch 8/80\n",
      "6435/6435 [==============================] - 0s 39us/step - loss: 1.6967 - accuracy: 0.2934 - val_loss: 1.6956 - val_accuracy: 0.3031\n",
      "Epoch 9/80\n",
      "6435/6435 [==============================] - 0s 36us/step - loss: 1.6671 - accuracy: 0.3019 - val_loss: 1.6625 - val_accuracy: 0.3156\n",
      "Epoch 10/80\n",
      "6435/6435 [==============================] - 0s 38us/step - loss: 1.6409 - accuracy: 0.2886 - val_loss: 1.6479 - val_accuracy: 0.3170\n",
      "Epoch 11/80\n",
      "6435/6435 [==============================] - 0s 36us/step - loss: 1.6248 - accuracy: 0.3061 - val_loss: 1.6328 - val_accuracy: 0.3142\n",
      "Epoch 12/80\n",
      "6435/6435 [==============================] - 0s 35us/step - loss: 1.6094 - accuracy: 0.3044 - val_loss: 1.6311 - val_accuracy: 0.3115\n",
      "Epoch 13/80\n",
      "6435/6435 [==============================] - 0s 37us/step - loss: 1.5982 - accuracy: 0.3041 - val_loss: 1.6125 - val_accuracy: 0.2975\n",
      "Epoch 14/80\n",
      "6435/6435 [==============================] - 0s 41us/step - loss: 1.5925 - accuracy: 0.3088 - val_loss: 1.6004 - val_accuracy: 0.3003\n",
      "Epoch 15/80\n",
      "6435/6435 [==============================] - 0s 39us/step - loss: 1.5906 - accuracy: 0.3108 - val_loss: 1.6212 - val_accuracy: 0.3184\n",
      "Epoch 16/80\n",
      "6435/6435 [==============================] - 0s 35us/step - loss: 1.5845 - accuracy: 0.3078 - val_loss: 1.5938 - val_accuracy: 0.2961\n",
      "Epoch 17/80\n",
      "6435/6435 [==============================] - 0s 42us/step - loss: 1.5652 - accuracy: 0.3144 - val_loss: 1.5811 - val_accuracy: 0.3073\n",
      "Epoch 18/80\n",
      "6435/6435 [==============================] - 0s 38us/step - loss: 1.5729 - accuracy: 0.3072 - val_loss: 1.5771 - val_accuracy: 0.3184\n",
      "Epoch 19/80\n",
      "6435/6435 [==============================] - 0s 47us/step - loss: 1.5552 - accuracy: 0.3049 - val_loss: 1.5699 - val_accuracy: 0.2961\n",
      "Epoch 20/80\n",
      "6435/6435 [==============================] - 0s 40us/step - loss: 1.5510 - accuracy: 0.3075 - val_loss: 1.5898 - val_accuracy: 0.2933\n",
      "Epoch 21/80\n",
      "6435/6435 [==============================] - 0s 37us/step - loss: 1.5524 - accuracy: 0.3052 - val_loss: 1.5833 - val_accuracy: 0.3282\n",
      "Epoch 22/80\n",
      "6435/6435 [==============================] - 0s 40us/step - loss: 1.5444 - accuracy: 0.3085 - val_loss: 1.5742 - val_accuracy: 0.2612\n",
      "Epoch 23/80\n",
      "6435/6435 [==============================] - 0s 39us/step - loss: 1.5359 - accuracy: 0.3071 - val_loss: 1.5586 - val_accuracy: 0.3101\n",
      "Epoch 24/80\n",
      "6435/6435 [==============================] - 0s 38us/step - loss: 1.5326 - accuracy: 0.3122 - val_loss: 1.5587 - val_accuracy: 0.3101\n",
      "Epoch 25/80\n",
      "6435/6435 [==============================] - 0s 36us/step - loss: 1.5289 - accuracy: 0.3159 - val_loss: 1.5688 - val_accuracy: 0.2947\n",
      "Epoch 26/80\n",
      "6435/6435 [==============================] - 0s 38us/step - loss: 1.5235 - accuracy: 0.3147 - val_loss: 1.5508 - val_accuracy: 0.3059\n",
      "Epoch 27/80\n",
      "6435/6435 [==============================] - 0s 39us/step - loss: 1.5163 - accuracy: 0.3136 - val_loss: 1.5442 - val_accuracy: 0.3212\n",
      "Epoch 28/80\n",
      "6435/6435 [==============================] - 0s 40us/step - loss: 1.5136 - accuracy: 0.3251 - val_loss: 1.5393 - val_accuracy: 0.3031\n",
      "Epoch 29/80\n",
      "6435/6435 [==============================] - 0s 40us/step - loss: 1.5141 - accuracy: 0.3075 - val_loss: 1.5512 - val_accuracy: 0.3073\n",
      "Epoch 30/80\n",
      "6435/6435 [==============================] - 0s 36us/step - loss: 1.5124 - accuracy: 0.3162 - val_loss: 1.5515 - val_accuracy: 0.3059\n",
      "Epoch 31/80\n",
      "6435/6435 [==============================] - 0s 40us/step - loss: 1.5052 - accuracy: 0.3249 - val_loss: 1.5272 - val_accuracy: 0.3254\n",
      "Epoch 32/80\n",
      "6435/6435 [==============================] - 0s 38us/step - loss: 1.5014 - accuracy: 0.3239 - val_loss: 1.5434 - val_accuracy: 0.2905\n",
      "Epoch 33/80\n",
      "6435/6435 [==============================] - 0s 34us/step - loss: 1.5010 - accuracy: 0.3245 - val_loss: 1.5228 - val_accuracy: 0.3212\n",
      "Epoch 34/80\n",
      "6435/6435 [==============================] - 0s 33us/step - loss: 1.4969 - accuracy: 0.3166 - val_loss: 1.5242 - val_accuracy: 0.3436\n",
      "Epoch 35/80\n",
      "6435/6435 [==============================] - 0s 38us/step - loss: 1.4934 - accuracy: 0.3234 - val_loss: 1.5192 - val_accuracy: 0.3170\n",
      "Epoch 36/80\n",
      "6435/6435 [==============================] - 0s 45us/step - loss: 1.4933 - accuracy: 0.3170 - val_loss: 1.5262 - val_accuracy: 0.3101\n",
      "Epoch 37/80\n",
      "6435/6435 [==============================] - 0s 39us/step - loss: 1.4875 - accuracy: 0.3235 - val_loss: 1.5110 - val_accuracy: 0.3240\n",
      "Epoch 38/80\n",
      "6435/6435 [==============================] - 0s 40us/step - loss: 1.4833 - accuracy: 0.3229 - val_loss: 1.5263 - val_accuracy: 0.3324\n",
      "Epoch 39/80\n",
      "6435/6435 [==============================] - 0s 43us/step - loss: 1.4873 - accuracy: 0.3271 - val_loss: 1.5032 - val_accuracy: 0.3240\n",
      "Epoch 40/80\n",
      "6435/6435 [==============================] - 0s 42us/step - loss: 1.4765 - accuracy: 0.3302 - val_loss: 1.5126 - val_accuracy: 0.3017\n",
      "Epoch 41/80\n",
      "6435/6435 [==============================] - 0s 41us/step - loss: 1.4768 - accuracy: 0.3336 - val_loss: 1.4994 - val_accuracy: 0.3338\n",
      "Epoch 42/80\n",
      "6435/6435 [==============================] - 0s 41us/step - loss: 1.4694 - accuracy: 0.3372 - val_loss: 1.4952 - val_accuracy: 0.3212\n",
      "Epoch 43/80\n",
      "6435/6435 [==============================] - 0s 40us/step - loss: 1.4668 - accuracy: 0.3372 - val_loss: 1.5054 - val_accuracy: 0.3073\n",
      "Epoch 44/80\n",
      "6435/6435 [==============================] - 0s 38us/step - loss: 1.4541 - accuracy: 0.3327 - val_loss: 1.4889 - val_accuracy: 0.3520\n",
      "Epoch 45/80\n",
      "6435/6435 [==============================] - 0s 41us/step - loss: 1.4466 - accuracy: 0.3473 - val_loss: 1.4729 - val_accuracy: 0.3170\n",
      "Epoch 46/80\n",
      "6435/6435 [==============================] - 0s 38us/step - loss: 1.4392 - accuracy: 0.3498 - val_loss: 1.4495 - val_accuracy: 0.3547\n",
      "Epoch 47/80\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6435/6435 [==============================] - 0s 40us/step - loss: 1.4164 - accuracy: 0.3653 - val_loss: 1.4330 - val_accuracy: 0.3771\n",
      "Epoch 48/80\n",
      "6435/6435 [==============================] - 0s 40us/step - loss: 1.3970 - accuracy: 0.3706 - val_loss: 1.4057 - val_accuracy: 0.3645\n",
      "Epoch 49/80\n",
      "6435/6435 [==============================] - 0s 37us/step - loss: 1.3718 - accuracy: 0.3796 - val_loss: 1.3664 - val_accuracy: 0.3841\n",
      "Epoch 50/80\n",
      "6435/6435 [==============================] - 0s 39us/step - loss: 1.3432 - accuracy: 0.3828 - val_loss: 1.3723 - val_accuracy: 0.3855\n",
      "Epoch 51/80\n",
      "6435/6435 [==============================] - 0s 39us/step - loss: 1.3303 - accuracy: 0.3792 - val_loss: 1.3353 - val_accuracy: 0.3953\n",
      "Epoch 52/80\n",
      "6435/6435 [==============================] - 0s 41us/step - loss: 1.3151 - accuracy: 0.3817 - val_loss: 1.3207 - val_accuracy: 0.3939\n",
      "Epoch 53/80\n",
      "6435/6435 [==============================] - 0s 40us/step - loss: 1.3065 - accuracy: 0.3843 - val_loss: 1.3329 - val_accuracy: 0.3980\n",
      "Epoch 54/80\n",
      "6435/6435 [==============================] - 0s 37us/step - loss: 1.2986 - accuracy: 0.3905 - val_loss: 1.3183 - val_accuracy: 0.4050\n",
      "Epoch 55/80\n",
      "6435/6435 [==============================] - 0s 37us/step - loss: 1.2924 - accuracy: 0.3936 - val_loss: 1.2981 - val_accuracy: 0.3994\n",
      "Epoch 56/80\n",
      "6435/6435 [==============================] - 0s 37us/step - loss: 1.2878 - accuracy: 0.3913 - val_loss: 1.2987 - val_accuracy: 0.4022\n",
      "Epoch 57/80\n",
      "6435/6435 [==============================] - 0s 36us/step - loss: 1.2843 - accuracy: 0.3854 - val_loss: 1.2940 - val_accuracy: 0.3953\n",
      "Epoch 58/80\n",
      "6435/6435 [==============================] - 0s 38us/step - loss: 1.2820 - accuracy: 0.3925 - val_loss: 1.3072 - val_accuracy: 0.3939\n",
      "Epoch 59/80\n",
      "6435/6435 [==============================] - 0s 39us/step - loss: 1.2837 - accuracy: 0.3865 - val_loss: 1.2962 - val_accuracy: 0.4148\n",
      "Epoch 60/80\n",
      "6435/6435 [==============================] - 0s 41us/step - loss: 1.2764 - accuracy: 0.3879 - val_loss: 1.2943 - val_accuracy: 0.3980\n",
      "Epoch 61/80\n",
      "6435/6435 [==============================] - 0s 40us/step - loss: 1.2710 - accuracy: 0.3983 - val_loss: 1.2879 - val_accuracy: 0.3925\n",
      "Epoch 62/80\n",
      "6435/6435 [==============================] - 0s 39us/step - loss: 1.2680 - accuracy: 0.3995 - val_loss: 1.2855 - val_accuracy: 0.4092\n",
      "Epoch 63/80\n",
      "6435/6435 [==============================] - 0s 40us/step - loss: 1.2650 - accuracy: 0.4099 - val_loss: 1.2882 - val_accuracy: 0.4064\n",
      "Epoch 64/80\n",
      "6435/6435 [==============================] - 0s 38us/step - loss: 1.2654 - accuracy: 0.3994 - val_loss: 1.2947 - val_accuracy: 0.4008\n",
      "Epoch 65/80\n",
      "6435/6435 [==============================] - 0s 38us/step - loss: 1.2653 - accuracy: 0.3975 - val_loss: 1.2818 - val_accuracy: 0.4106\n",
      "Epoch 66/80\n",
      "6435/6435 [==============================] - 0s 38us/step - loss: 1.2646 - accuracy: 0.4044 - val_loss: 1.2741 - val_accuracy: 0.4008\n",
      "Epoch 67/80\n",
      "6435/6435 [==============================] - 0s 40us/step - loss: 1.2586 - accuracy: 0.4079 - val_loss: 1.2798 - val_accuracy: 0.3939\n",
      "Epoch 68/80\n",
      "6435/6435 [==============================] - 0s 38us/step - loss: 1.2551 - accuracy: 0.3956 - val_loss: 1.2747 - val_accuracy: 0.4092\n",
      "Epoch 69/80\n",
      "6435/6435 [==============================] - 0s 39us/step - loss: 1.2548 - accuracy: 0.4003 - val_loss: 1.2708 - val_accuracy: 0.4092\n",
      "Epoch 70/80\n",
      "6435/6435 [==============================] - 0s 37us/step - loss: 1.2523 - accuracy: 0.4062 - val_loss: 1.2784 - val_accuracy: 0.4008\n",
      "Epoch 71/80\n",
      "6435/6435 [==============================] - 0s 38us/step - loss: 1.2519 - accuracy: 0.4048 - val_loss: 1.2867 - val_accuracy: 0.4064\n",
      "Epoch 72/80\n",
      "6435/6435 [==============================] - 0s 37us/step - loss: 1.2526 - accuracy: 0.3972 - val_loss: 1.2680 - val_accuracy: 0.3966\n",
      "Epoch 73/80\n",
      "6435/6435 [==============================] - 0s 37us/step - loss: 1.2465 - accuracy: 0.3997 - val_loss: 1.2707 - val_accuracy: 0.3994\n",
      "Epoch 74/80\n",
      "6435/6435 [==============================] - 0s 38us/step - loss: 1.2436 - accuracy: 0.4078 - val_loss: 1.2704 - val_accuracy: 0.4106\n",
      "Epoch 75/80\n",
      "6435/6435 [==============================] - 0s 38us/step - loss: 1.2438 - accuracy: 0.3970 - val_loss: 1.2757 - val_accuracy: 0.4022\n",
      "Epoch 76/80\n",
      "6435/6435 [==============================] - 0s 36us/step - loss: 1.2438 - accuracy: 0.3972 - val_loss: 1.2560 - val_accuracy: 0.3994\n",
      "Epoch 77/80\n",
      "6435/6435 [==============================] - ETA: 0s - loss: 1.2391 - accuracy: 0.40 - 0s 37us/step - loss: 1.2368 - accuracy: 0.4054 - val_loss: 1.2643 - val_accuracy: 0.4078\n",
      "Epoch 78/80\n",
      "6435/6435 [==============================] - 0s 39us/step - loss: 1.2413 - accuracy: 0.4026 - val_loss: 1.2670 - val_accuracy: 0.3827\n",
      "Epoch 79/80\n",
      "6435/6435 [==============================] - 0s 38us/step - loss: 1.2435 - accuracy: 0.3932 - val_loss: 1.2578 - val_accuracy: 0.4148\n",
      "Epoch 80/80\n",
      "6435/6435 [==============================] - 0s 37us/step - loss: 1.2344 - accuracy: 0.3938 - val_loss: 1.2591 - val_accuracy: 0.3966\n",
      "[[1.50485054e-01 1.26612395e-01 2.10394183e-17 ... 2.42501646e-01\n",
      "  2.30654299e-01 2.38326490e-01]\n",
      " [6.36745542e-02 5.98260649e-02 3.87113983e-26 ... 1.37891585e-03\n",
      "  1.29313255e-02 1.20882746e-02]\n",
      " [1.95881322e-01 1.56033546e-01 1.90490870e-21 ... 3.16320360e-02\n",
      "  3.03568393e-01 3.12066793e-01]\n",
      " ...\n",
      " [2.67655343e-01 2.02134266e-01 1.58860986e-22 ... 3.53716011e-03\n",
      "  2.70631731e-01 2.55899042e-01]\n",
      " [1.03274360e-01 8.89894739e-02 6.65878699e-16 ... 1.12187535e-01\n",
      "  3.32899511e-01 3.50198090e-01]\n",
      " [1.10986777e-01 9.50063318e-02 1.04713085e-16 ... 1.12885773e-01\n",
      "  3.26214194e-01 3.47954482e-01]]\n",
      "[12 11 14 ... 13 14 14]\n",
      "<class 'numpy.ndarray'>\n",
      "One CNN, r:  0\n",
      "Computing Time:  0:02:15.130615\n",
      "n, p1, p2 1 0 1\n",
      "Model: \"sequential_1\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv1d_1 (Conv1D)            (None, 3, 6)              12        \n",
      "_________________________________________________________________\n",
      "average_pooling1d_1 (Average (None, 1, 6)              0         \n",
      "_________________________________________________________________\n",
      "conv1d_2 (Conv1D)            (None, 1, 16)             112       \n",
      "_________________________________________________________________\n",
      "average_pooling1d_2 (Average (None, 1, 16)             0         \n",
      "_________________________________________________________________\n",
      "conv1d_3 (Conv1D)            (None, 1, 120)            2040      \n",
      "_________________________________________________________________\n",
      "flatten_1 (Flatten)          (None, 120)               0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 84)                10164     \n",
      "_________________________________________________________________\n",
      "preds (Dense)                (None, 14)                1190      \n",
      "=================================================================\n",
      "Total params: 13,518\n",
      "Trainable params: 13,518\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Train on 6435 samples, validate on 716 samples\n",
      "Epoch 1/80\n",
      "6435/6435 [==============================] - 0s 74us/step - loss: 2.5845 - accuracy: 0.1717 - val_loss: 2.4446 - val_accuracy: 0.2053\n",
      "Epoch 2/80\n",
      "6435/6435 [==============================] - 0s 42us/step - loss: 2.1895 - accuracy: 0.2650 - val_loss: 1.9709 - val_accuracy: 0.2751\n",
      "Epoch 3/80\n",
      "6435/6435 [==============================] - 0s 43us/step - loss: 1.8408 - accuracy: 0.3156 - val_loss: 1.7616 - val_accuracy: 0.3450\n",
      "Epoch 4/80\n",
      "6435/6435 [==============================] - 0s 38us/step - loss: 1.6813 - accuracy: 0.3406 - val_loss: 1.6334 - val_accuracy: 0.3589\n",
      "Epoch 5/80\n",
      "6435/6435 [==============================] - 0s 36us/step - loss: 1.5834 - accuracy: 0.3439 - val_loss: 1.5461 - val_accuracy: 0.3645\n",
      "Epoch 6/80\n",
      "6435/6435 [==============================] - 0s 40us/step - loss: 1.5152 - accuracy: 0.3531 - val_loss: 1.5093 - val_accuracy: 0.3547\n",
      "Epoch 7/80\n",
      "6435/6435 [==============================] - 0s 38us/step - loss: 1.4839 - accuracy: 0.3408 - val_loss: 1.4917 - val_accuracy: 0.3520\n",
      "Epoch 8/80\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6435/6435 [==============================] - 0s 39us/step - loss: 1.4558 - accuracy: 0.3497 - val_loss: 1.4576 - val_accuracy: 0.3589\n",
      "Epoch 9/80\n",
      "6435/6435 [==============================] - 0s 38us/step - loss: 1.4395 - accuracy: 0.3493 - val_loss: 1.4416 - val_accuracy: 0.3645\n",
      "Epoch 10/80\n",
      "6435/6435 [==============================] - 0s 38us/step - loss: 1.4301 - accuracy: 0.3506 - val_loss: 1.4360 - val_accuracy: 0.3659\n",
      "Epoch 11/80\n",
      "6435/6435 [==============================] - 0s 41us/step - loss: 1.4238 - accuracy: 0.3500 - val_loss: 1.4317 - val_accuracy: 0.3589\n",
      "Epoch 12/80\n",
      "6435/6435 [==============================] - 0s 40us/step - loss: 1.4157 - accuracy: 0.3556 - val_loss: 1.4274 - val_accuracy: 0.3603\n",
      "Epoch 13/80\n",
      "6435/6435 [==============================] - 0s 39us/step - loss: 1.4118 - accuracy: 0.3538 - val_loss: 1.4246 - val_accuracy: 0.3743\n",
      "Epoch 14/80\n",
      "6435/6435 [==============================] - 0s 38us/step - loss: 1.4060 - accuracy: 0.3521 - val_loss: 1.4063 - val_accuracy: 0.3980\n",
      "Epoch 15/80\n",
      "6435/6435 [==============================] - 0s 39us/step - loss: 1.4043 - accuracy: 0.3573 - val_loss: 1.4001 - val_accuracy: 0.3953\n",
      "Epoch 16/80\n",
      "6435/6435 [==============================] - 0s 39us/step - loss: 1.3974 - accuracy: 0.3521 - val_loss: 1.3886 - val_accuracy: 0.3715\n",
      "Epoch 17/80\n",
      "6435/6435 [==============================] - 0s 38us/step - loss: 1.4029 - accuracy: 0.3534 - val_loss: 1.4408 - val_accuracy: 0.3743\n",
      "Epoch 18/80\n",
      "6435/6435 [==============================] - 0s 37us/step - loss: 1.3917 - accuracy: 0.3563 - val_loss: 1.3894 - val_accuracy: 0.3785\n",
      "Epoch 19/80\n",
      "6435/6435 [==============================] - 0s 40us/step - loss: 1.3940 - accuracy: 0.3540 - val_loss: 1.3946 - val_accuracy: 0.3953\n",
      "Epoch 20/80\n",
      "6435/6435 [==============================] - 0s 38us/step - loss: 1.3867 - accuracy: 0.3523 - val_loss: 1.3960 - val_accuracy: 0.3911\n",
      "Epoch 21/80\n",
      "6435/6435 [==============================] - 0s 37us/step - loss: 1.3892 - accuracy: 0.3461 - val_loss: 1.3823 - val_accuracy: 0.4078\n",
      "Epoch 22/80\n",
      "6435/6435 [==============================] - 0s 38us/step - loss: 1.3834 - accuracy: 0.3579 - val_loss: 1.3818 - val_accuracy: 0.3855\n",
      "Epoch 23/80\n",
      "6435/6435 [==============================] - 0s 40us/step - loss: 1.3841 - accuracy: 0.3529 - val_loss: 1.3834 - val_accuracy: 0.3785\n",
      "Epoch 24/80\n",
      "6435/6435 [==============================] - 0s 38us/step - loss: 1.3821 - accuracy: 0.3568 - val_loss: 1.3935 - val_accuracy: 0.3869\n",
      "Epoch 25/80\n",
      "6435/6435 [==============================] - 0s 39us/step - loss: 1.3836 - accuracy: 0.3574 - val_loss: 1.3995 - val_accuracy: 0.3785\n",
      "Epoch 26/80\n",
      "6435/6435 [==============================] - 0s 40us/step - loss: 1.3811 - accuracy: 0.3497 - val_loss: 1.3885 - val_accuracy: 0.4022\n",
      "Epoch 27/80\n",
      "6435/6435 [==============================] - 0s 40us/step - loss: 1.3813 - accuracy: 0.3557 - val_loss: 1.3778 - val_accuracy: 0.3841\n",
      "Epoch 28/80\n",
      "6435/6435 [==============================] - 0s 37us/step - loss: 1.3727 - accuracy: 0.3624 - val_loss: 1.3734 - val_accuracy: 0.4120\n",
      "Epoch 29/80\n",
      "6435/6435 [==============================] - 0s 37us/step - loss: 1.3761 - accuracy: 0.3618 - val_loss: 1.3735 - val_accuracy: 0.3701\n",
      "Epoch 30/80\n",
      "6435/6435 [==============================] - 0s 36us/step - loss: 1.3734 - accuracy: 0.3456 - val_loss: 1.3769 - val_accuracy: 0.3841\n",
      "Epoch 31/80\n",
      "6435/6435 [==============================] - 0s 36us/step - loss: 1.3674 - accuracy: 0.3644 - val_loss: 1.3740 - val_accuracy: 0.3673\n",
      "Epoch 32/80\n",
      "6435/6435 [==============================] - 0s 39us/step - loss: 1.3727 - accuracy: 0.3500 - val_loss: 1.3614 - val_accuracy: 0.3897\n",
      "Epoch 33/80\n",
      "6435/6435 [==============================] - 0s 40us/step - loss: 1.3632 - accuracy: 0.3683 - val_loss: 1.3688 - val_accuracy: 0.4106\n",
      "Epoch 34/80\n",
      "6435/6435 [==============================] - 0s 37us/step - loss: 1.3642 - accuracy: 0.3677 - val_loss: 1.3616 - val_accuracy: 0.3799\n",
      "Epoch 35/80\n",
      "6435/6435 [==============================] - 0s 37us/step - loss: 1.3637 - accuracy: 0.3559 - val_loss: 1.3587 - val_accuracy: 0.3925\n",
      "Epoch 36/80\n",
      "6435/6435 [==============================] - 0s 39us/step - loss: 1.3635 - accuracy: 0.3587 - val_loss: 1.3612 - val_accuracy: 0.4022\n",
      "Epoch 37/80\n",
      "6435/6435 [==============================] - 0s 42us/step - loss: 1.3579 - accuracy: 0.3677 - val_loss: 1.3531 - val_accuracy: 0.3701\n",
      "Epoch 38/80\n",
      "6435/6435 [==============================] - 0s 43us/step - loss: 1.3631 - accuracy: 0.3671 - val_loss: 1.3596 - val_accuracy: 0.3911\n",
      "Epoch 39/80\n",
      "6435/6435 [==============================] - 0s 40us/step - loss: 1.3628 - accuracy: 0.3714 - val_loss: 1.3687 - val_accuracy: 0.3980\n",
      "Epoch 40/80\n",
      "6435/6435 [==============================] - 0s 36us/step - loss: 1.3580 - accuracy: 0.3716 - val_loss: 1.3483 - val_accuracy: 0.4148\n",
      "Epoch 41/80\n",
      "6435/6435 [==============================] - 0s 37us/step - loss: 1.3497 - accuracy: 0.3734 - val_loss: 1.3538 - val_accuracy: 0.4022\n",
      "Epoch 42/80\n",
      "6435/6435 [==============================] - 0s 38us/step - loss: 1.3484 - accuracy: 0.3762 - val_loss: 1.3694 - val_accuracy: 0.3911\n",
      "Epoch 43/80\n",
      "6435/6435 [==============================] - 0s 39us/step - loss: 1.3493 - accuracy: 0.3708 - val_loss: 1.3517 - val_accuracy: 0.4162\n",
      "Epoch 44/80\n",
      "6435/6435 [==============================] - 0s 41us/step - loss: 1.3461 - accuracy: 0.3688 - val_loss: 1.3352 - val_accuracy: 0.4162\n",
      "Epoch 45/80\n",
      "6435/6435 [==============================] - 0s 40us/step - loss: 1.3394 - accuracy: 0.3778 - val_loss: 1.3494 - val_accuracy: 0.3994\n",
      "Epoch 46/80\n",
      "6435/6435 [==============================] - 0s 39us/step - loss: 1.3412 - accuracy: 0.3835 - val_loss: 1.3271 - val_accuracy: 0.4162\n",
      "Epoch 47/80\n",
      "6435/6435 [==============================] - 0s 38us/step - loss: 1.3347 - accuracy: 0.3812 - val_loss: 1.3346 - val_accuracy: 0.3827\n",
      "Epoch 48/80\n",
      "6435/6435 [==============================] - 0s 38us/step - loss: 1.3270 - accuracy: 0.3956 - val_loss: 1.3248 - val_accuracy: 0.3841\n",
      "Epoch 49/80\n",
      "6435/6435 [==============================] - 0s 38us/step - loss: 1.3238 - accuracy: 0.3974 - val_loss: 1.3066 - val_accuracy: 0.3883\n",
      "Epoch 50/80\n",
      "6435/6435 [==============================] - 0s 37us/step - loss: 1.3143 - accuracy: 0.3958 - val_loss: 1.3158 - val_accuracy: 0.4204\n",
      "Epoch 51/80\n",
      "6435/6435 [==============================] - 0s 37us/step - loss: 1.3056 - accuracy: 0.4092 - val_loss: 1.2964 - val_accuracy: 0.4218\n",
      "Epoch 52/80\n",
      "6435/6435 [==============================] - 0s 38us/step - loss: 1.3028 - accuracy: 0.4053 - val_loss: 1.3256 - val_accuracy: 0.4232\n",
      "Epoch 53/80\n",
      "6435/6435 [==============================] - 0s 37us/step - loss: 1.2927 - accuracy: 0.4126 - val_loss: 1.2838 - val_accuracy: 0.4232\n",
      "Epoch 54/80\n",
      "6435/6435 [==============================] - 0s 40us/step - loss: 1.2800 - accuracy: 0.4135 - val_loss: 1.2638 - val_accuracy: 0.4427\n",
      "Epoch 55/80\n",
      "6435/6435 [==============================] - 0s 38us/step - loss: 1.2677 - accuracy: 0.4256 - val_loss: 1.2688 - val_accuracy: 0.4469\n",
      "Epoch 56/80\n",
      "6435/6435 [==============================] - 0s 38us/step - loss: 1.2594 - accuracy: 0.4222 - val_loss: 1.2521 - val_accuracy: 0.4469\n",
      "Epoch 57/80\n",
      "6435/6435 [==============================] - 0s 37us/step - loss: 1.2469 - accuracy: 0.4186 - val_loss: 1.2519 - val_accuracy: 0.4441\n",
      "Epoch 58/80\n",
      "6435/6435 [==============================] - 0s 37us/step - loss: 1.2418 - accuracy: 0.4186 - val_loss: 1.2658 - val_accuracy: 0.4064\n",
      "Epoch 59/80\n",
      "6435/6435 [==============================] - 0s 37us/step - loss: 1.2327 - accuracy: 0.4236 - val_loss: 1.2270 - val_accuracy: 0.4399\n",
      "Epoch 60/80\n",
      "6435/6435 [==============================] - 0s 38us/step - loss: 1.2159 - accuracy: 0.4235 - val_loss: 1.2214 - val_accuracy: 0.4539\n",
      "Epoch 61/80\n",
      "6435/6435 [==============================] - 0s 36us/step - loss: 1.2176 - accuracy: 0.4199 - val_loss: 1.2051 - val_accuracy: 0.4581\n",
      "Epoch 62/80\n",
      "6435/6435 [==============================] - 0s 36us/step - loss: 1.2132 - accuracy: 0.4200 - val_loss: 1.1998 - val_accuracy: 0.4581\n",
      "Epoch 63/80\n",
      "6435/6435 [==============================] - 0s 39us/step - loss: 1.2031 - accuracy: 0.4232 - val_loss: 1.2140 - val_accuracy: 0.4399\n",
      "Epoch 64/80\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6435/6435 [==============================] - 0s 38us/step - loss: 1.2046 - accuracy: 0.4180 - val_loss: 1.2228 - val_accuracy: 0.4511\n",
      "Epoch 65/80\n",
      "6435/6435 [==============================] - 0s 38us/step - loss: 1.2098 - accuracy: 0.4180 - val_loss: 1.2086 - val_accuracy: 0.4274\n",
      "Epoch 66/80\n",
      "6435/6435 [==============================] - 0s 41us/step - loss: 1.1981 - accuracy: 0.4266 - val_loss: 1.1987 - val_accuracy: 0.4372\n",
      "Epoch 67/80\n",
      "6435/6435 [==============================] - 0s 40us/step - loss: 1.1953 - accuracy: 0.4185 - val_loss: 1.2044 - val_accuracy: 0.4162\n",
      "Epoch 68/80\n",
      "6435/6435 [==============================] - 0s 40us/step - loss: 1.1925 - accuracy: 0.4183 - val_loss: 1.1863 - val_accuracy: 0.4385\n",
      "Epoch 69/80\n",
      "6435/6435 [==============================] - 0s 38us/step - loss: 1.1885 - accuracy: 0.4219 - val_loss: 1.2094 - val_accuracy: 0.4176\n",
      "Epoch 70/80\n",
      "6435/6435 [==============================] - 0s 41us/step - loss: 1.1889 - accuracy: 0.4159 - val_loss: 1.1987 - val_accuracy: 0.4455\n",
      "Epoch 71/80\n",
      "6435/6435 [==============================] - 0s 37us/step - loss: 1.1895 - accuracy: 0.4233 - val_loss: 1.1853 - val_accuracy: 0.4525\n",
      "Epoch 72/80\n",
      "6435/6435 [==============================] - 0s 41us/step - loss: 1.1787 - accuracy: 0.4214 - val_loss: 1.1799 - val_accuracy: 0.4553\n",
      "Epoch 73/80\n",
      "6435/6435 [==============================] - 0s 37us/step - loss: 1.1825 - accuracy: 0.4233 - val_loss: 1.1793 - val_accuracy: 0.4637\n",
      "Epoch 74/80\n",
      "6435/6435 [==============================] - 0s 39us/step - loss: 1.1818 - accuracy: 0.4284 - val_loss: 1.1937 - val_accuracy: 0.4274\n",
      "Epoch 75/80\n",
      "6435/6435 [==============================] - 0s 47us/step - loss: 1.1765 - accuracy: 0.4311 - val_loss: 1.1808 - val_accuracy: 0.4288\n",
      "Epoch 76/80\n",
      "6435/6435 [==============================] - 0s 41us/step - loss: 1.1760 - accuracy: 0.4249 - val_loss: 1.1898 - val_accuracy: 0.4204\n",
      "Epoch 77/80\n",
      "6435/6435 [==============================] - 0s 39us/step - loss: 1.1726 - accuracy: 0.4249 - val_loss: 1.1846 - val_accuracy: 0.4246\n",
      "Epoch 78/80\n",
      "6435/6435 [==============================] - 0s 38us/step - loss: 1.1785 - accuracy: 0.4219 - val_loss: 1.1666 - val_accuracy: 0.4623\n",
      "Epoch 79/80\n",
      "6435/6435 [==============================] - 0s 38us/step - loss: 1.1683 - accuracy: 0.4306 - val_loss: 1.1764 - val_accuracy: 0.4539\n",
      "Epoch 80/80\n",
      "6435/6435 [==============================] - 0s 38us/step - loss: 1.1676 - accuracy: 0.4286 - val_loss: 1.1749 - val_accuracy: 0.4288\n",
      "[[1.96966738e-01 2.57393255e-14 1.79490307e-04 ... 3.97297025e-01\n",
      "  1.69492602e-01 2.04460666e-01]\n",
      " [8.46227929e-02 2.22075780e-21 1.40102790e-03 ... 5.93154784e-03\n",
      "  1.05595952e-02 1.36797102e-02]\n",
      " [3.95699471e-01 6.05851036e-17 6.00033345e-05 ... 1.52650982e-01\n",
      "  2.09090874e-01 2.39248350e-01]\n",
      " ...\n",
      " [4.89510149e-01 4.98928297e-18 8.35902665e-06 ... 2.82628685e-02\n",
      "  2.22356543e-01 2.59346277e-01]\n",
      " [2.17146903e-01 3.11791066e-13 1.19767246e-04 ... 1.95054114e-01\n",
      "  2.58735299e-01 2.99061894e-01]\n",
      " [2.43882805e-01 7.43710242e-14 9.02226529e-05 ... 2.26459444e-01\n",
      "  2.31855199e-01 2.76104391e-01]]\n",
      "[11  4  0 ...  0 13 13]\n",
      "<class 'numpy.ndarray'>\n",
      "One CNN, r:  0\n",
      "Computing Time:  0:02:36.943073\n",
      "n, p1, p2 2 0 2\n",
      "Model: \"sequential_1\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv1d_1 (Conv1D)            (None, 3, 6)              12        \n",
      "_________________________________________________________________\n",
      "average_pooling1d_1 (Average (None, 1, 6)              0         \n",
      "_________________________________________________________________\n",
      "conv1d_2 (Conv1D)            (None, 1, 16)             112       \n",
      "_________________________________________________________________\n",
      "average_pooling1d_2 (Average (None, 1, 16)             0         \n",
      "_________________________________________________________________\n",
      "conv1d_3 (Conv1D)            (None, 1, 120)            2040      \n",
      "_________________________________________________________________\n",
      "flatten_1 (Flatten)          (None, 120)               0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 84)                10164     \n",
      "_________________________________________________________________\n",
      "preds (Dense)                (None, 14)                1190      \n",
      "=================================================================\n",
      "Total params: 13,518\n",
      "Trainable params: 13,518\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Train on 6435 samples, validate on 716 samples\n",
      "Epoch 1/80\n",
      "6435/6435 [==============================] - 1s 82us/step - loss: 2.6016 - accuracy: 0.1414 - val_loss: 2.4941 - val_accuracy: 0.1620\n",
      "Epoch 2/80\n",
      "6435/6435 [==============================] - 0s 41us/step - loss: 2.2892 - accuracy: 0.1622 - val_loss: 2.0794 - val_accuracy: 0.1816\n",
      "Epoch 3/80\n",
      "6435/6435 [==============================] - 0s 39us/step - loss: 2.0126 - accuracy: 0.2305 - val_loss: 1.9398 - val_accuracy: 0.2556\n",
      "Epoch 4/80\n",
      "6435/6435 [==============================] - 0s 41us/step - loss: 1.9128 - accuracy: 0.2573 - val_loss: 1.8478 - val_accuracy: 0.2877\n",
      "Epoch 5/80\n",
      "6435/6435 [==============================] - 0s 37us/step - loss: 1.8402 - accuracy: 0.2758 - val_loss: 1.7974 - val_accuracy: 0.2723\n",
      "Epoch 6/80\n",
      "6435/6435 [==============================] - 0s 37us/step - loss: 1.7754 - accuracy: 0.2911 - val_loss: 1.7137 - val_accuracy: 0.2821\n",
      "Epoch 7/80\n",
      "6435/6435 [==============================] - 0s 37us/step - loss: 1.7139 - accuracy: 0.2904 - val_loss: 1.6460 - val_accuracy: 0.2570\n",
      "Epoch 8/80\n",
      "6435/6435 [==============================] - 0s 40us/step - loss: 1.6692 - accuracy: 0.2900 - val_loss: 1.6008 - val_accuracy: 0.3296\n",
      "Epoch 9/80\n",
      "6435/6435 [==============================] - 0s 37us/step - loss: 1.6342 - accuracy: 0.2945 - val_loss: 1.5729 - val_accuracy: 0.3450\n",
      "Epoch 10/80\n",
      "6435/6435 [==============================] - 0s 38us/step - loss: 1.6086 - accuracy: 0.3077 - val_loss: 1.5675 - val_accuracy: 0.3198\n",
      "Epoch 11/80\n",
      "6435/6435 [==============================] - 0s 38us/step - loss: 1.5885 - accuracy: 0.3027 - val_loss: 1.5293 - val_accuracy: 0.3310\n",
      "Epoch 12/80\n",
      "6435/6435 [==============================] - 0s 37us/step - loss: 1.5695 - accuracy: 0.3078 - val_loss: 1.5225 - val_accuracy: 0.3101\n",
      "Epoch 13/80\n",
      "6435/6435 [==============================] - 0s 35us/step - loss: 1.5543 - accuracy: 0.3083 - val_loss: 1.5190 - val_accuracy: 0.3338\n",
      "Epoch 14/80\n",
      "6435/6435 [==============================] - 0s 40us/step - loss: 1.5430 - accuracy: 0.3150 - val_loss: 1.5051 - val_accuracy: 0.3170\n",
      "Epoch 15/80\n",
      "6435/6435 [==============================] - 0s 38us/step - loss: 1.5334 - accuracy: 0.3099 - val_loss: 1.4958 - val_accuracy: 0.3324\n",
      "Epoch 16/80\n",
      "6435/6435 [==============================] - 0s 37us/step - loss: 1.5351 - accuracy: 0.3176 - val_loss: 1.4795 - val_accuracy: 0.3715\n",
      "Epoch 17/80\n",
      "6435/6435 [==============================] - 0s 37us/step - loss: 1.5192 - accuracy: 0.3159 - val_loss: 1.4833 - val_accuracy: 0.3254\n",
      "Epoch 18/80\n",
      "6435/6435 [==============================] - 0s 39us/step - loss: 1.5134 - accuracy: 0.3159 - val_loss: 1.4936 - val_accuracy: 0.3352\n",
      "Epoch 19/80\n",
      "6435/6435 [==============================] - 0s 38us/step - loss: 1.5028 - accuracy: 0.3111 - val_loss: 1.4732 - val_accuracy: 0.3254\n",
      "Epoch 20/80\n",
      "6435/6435 [==============================] - 0s 35us/step - loss: 1.4966 - accuracy: 0.3201 - val_loss: 1.4451 - val_accuracy: 0.3757\n",
      "Epoch 21/80\n",
      "6435/6435 [==============================] - 0s 40us/step - loss: 1.4890 - accuracy: 0.3246 - val_loss: 1.4439 - val_accuracy: 0.3324\n",
      "Epoch 22/80\n",
      "6435/6435 [==============================] - 0s 37us/step - loss: 1.4840 - accuracy: 0.3350 - val_loss: 1.4312 - val_accuracy: 0.3757\n",
      "Epoch 23/80\n",
      "6435/6435 [==============================] - 0s 37us/step - loss: 1.4814 - accuracy: 0.3318 - val_loss: 1.4267 - val_accuracy: 0.3631\n",
      "Epoch 24/80\n",
      "6435/6435 [==============================] - 0s 38us/step - loss: 1.4791 - accuracy: 0.3246 - val_loss: 1.4239 - val_accuracy: 0.3673\n",
      "Epoch 25/80\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6435/6435 [==============================] - 0s 37us/step - loss: 1.4674 - accuracy: 0.3455 - val_loss: 1.4274 - val_accuracy: 0.3296\n",
      "Epoch 26/80\n",
      "6435/6435 [==============================] - 0s 39us/step - loss: 1.4607 - accuracy: 0.3402 - val_loss: 1.4197 - val_accuracy: 0.3631\n",
      "Epoch 27/80\n",
      "6435/6435 [==============================] - 0s 36us/step - loss: 1.4564 - accuracy: 0.3445 - val_loss: 1.4047 - val_accuracy: 0.3659\n",
      "Epoch 28/80\n",
      "6435/6435 [==============================] - 0s 36us/step - loss: 1.4529 - accuracy: 0.3545 - val_loss: 1.4234 - val_accuracy: 0.3492\n",
      "Epoch 29/80\n",
      "6435/6435 [==============================] - 0s 37us/step - loss: 1.4492 - accuracy: 0.3591 - val_loss: 1.4076 - val_accuracy: 0.3478\n",
      "Epoch 30/80\n",
      "6435/6435 [==============================] - 0s 37us/step - loss: 1.4372 - accuracy: 0.3672 - val_loss: 1.3872 - val_accuracy: 0.3743\n",
      "Epoch 31/80\n",
      "6435/6435 [==============================] - 0s 37us/step - loss: 1.4272 - accuracy: 0.3733 - val_loss: 1.4024 - val_accuracy: 0.3603\n",
      "Epoch 32/80\n",
      "6435/6435 [==============================] - 0s 38us/step - loss: 1.4239 - accuracy: 0.3650 - val_loss: 1.3784 - val_accuracy: 0.3603\n",
      "Epoch 33/80\n",
      "6435/6435 [==============================] - 0s 35us/step - loss: 1.4069 - accuracy: 0.3695 - val_loss: 1.3947 - val_accuracy: 0.3799\n",
      "Epoch 34/80\n",
      "6435/6435 [==============================] - 0s 36us/step - loss: 1.3968 - accuracy: 0.3800 - val_loss: 1.3590 - val_accuracy: 0.3813\n",
      "Epoch 35/80\n",
      "6435/6435 [==============================] - 0s 38us/step - loss: 1.3778 - accuracy: 0.3852 - val_loss: 1.3734 - val_accuracy: 0.3869\n",
      "Epoch 36/80\n",
      "6435/6435 [==============================] - 0s 37us/step - loss: 1.3705 - accuracy: 0.3789 - val_loss: 1.3525 - val_accuracy: 0.3603\n",
      "Epoch 37/80\n",
      "6435/6435 [==============================] - 0s 35us/step - loss: 1.3559 - accuracy: 0.3711 - val_loss: 1.3197 - val_accuracy: 0.4050\n",
      "Epoch 38/80\n",
      "6435/6435 [==============================] - 0s 35us/step - loss: 1.3407 - accuracy: 0.3865 - val_loss: 1.3197 - val_accuracy: 0.4134\n",
      "Epoch 39/80\n",
      "6435/6435 [==============================] - 0s 35us/step - loss: 1.3328 - accuracy: 0.3930 - val_loss: 1.3121 - val_accuracy: 0.3757\n",
      "Epoch 40/80\n",
      "6435/6435 [==============================] - 0s 36us/step - loss: 1.3282 - accuracy: 0.3845 - val_loss: 1.3033 - val_accuracy: 0.3659\n",
      "Epoch 41/80\n",
      "6435/6435 [==============================] - 0s 40us/step - loss: 1.3224 - accuracy: 0.3789 - val_loss: 1.2930 - val_accuracy: 0.4302\n",
      "Epoch 42/80\n",
      "6435/6435 [==============================] - 0s 37us/step - loss: 1.3162 - accuracy: 0.3798 - val_loss: 1.2897 - val_accuracy: 0.3827\n",
      "Epoch 43/80\n",
      "6435/6435 [==============================] - 0s 34us/step - loss: 1.3085 - accuracy: 0.3899 - val_loss: 1.2917 - val_accuracy: 0.4022\n",
      "Epoch 44/80\n",
      "6435/6435 [==============================] - 0s 36us/step - loss: 1.2966 - accuracy: 0.3863 - val_loss: 1.2880 - val_accuracy: 0.4162\n",
      "Epoch 45/80\n",
      "6435/6435 [==============================] - 0s 38us/step - loss: 1.2965 - accuracy: 0.3941 - val_loss: 1.2985 - val_accuracy: 0.3966\n",
      "Epoch 46/80\n",
      "6435/6435 [==============================] - 0s 42us/step - loss: 1.3012 - accuracy: 0.3860 - val_loss: 1.2745 - val_accuracy: 0.3925\n",
      "Epoch 47/80\n",
      "6435/6435 [==============================] - 0s 35us/step - loss: 1.2949 - accuracy: 0.3935 - val_loss: 1.2856 - val_accuracy: 0.4190\n",
      "Epoch 48/80\n",
      "6435/6435 [==============================] - 0s 40us/step - loss: 1.2944 - accuracy: 0.3809 - val_loss: 1.2910 - val_accuracy: 0.3883\n",
      "Epoch 49/80\n",
      "6435/6435 [==============================] - 0s 39us/step - loss: 1.2866 - accuracy: 0.3932 - val_loss: 1.2715 - val_accuracy: 0.4190\n",
      "Epoch 50/80\n",
      "6435/6435 [==============================] - 0s 36us/step - loss: 1.2868 - accuracy: 0.3952 - val_loss: 1.2707 - val_accuracy: 0.3911\n",
      "Epoch 51/80\n",
      "6435/6435 [==============================] - 0s 38us/step - loss: 1.2781 - accuracy: 0.3941 - val_loss: 1.2829 - val_accuracy: 0.3715\n",
      "Epoch 52/80\n",
      "6435/6435 [==============================] - 0s 37us/step - loss: 1.2817 - accuracy: 0.3960 - val_loss: 1.2712 - val_accuracy: 0.4092\n",
      "Epoch 53/80\n",
      "6435/6435 [==============================] - 0s 37us/step - loss: 1.2706 - accuracy: 0.3977 - val_loss: 1.2701 - val_accuracy: 0.3897\n",
      "Epoch 54/80\n",
      "6435/6435 [==============================] - 0s 41us/step - loss: 1.2664 - accuracy: 0.3952 - val_loss: 1.2589 - val_accuracy: 0.4050\n",
      "Epoch 55/80\n",
      "6435/6435 [==============================] - 0s 37us/step - loss: 1.2667 - accuracy: 0.3859 - val_loss: 1.2595 - val_accuracy: 0.4218\n",
      "Epoch 56/80\n",
      "6435/6435 [==============================] - 0s 38us/step - loss: 1.2643 - accuracy: 0.4016 - val_loss: 1.2910 - val_accuracy: 0.3897\n",
      "Epoch 57/80\n",
      "6435/6435 [==============================] - 0s 37us/step - loss: 1.2708 - accuracy: 0.3955 - val_loss: 1.2847 - val_accuracy: 0.4036\n",
      "Epoch 58/80\n",
      "6435/6435 [==============================] - 0s 40us/step - loss: 1.2658 - accuracy: 0.3927 - val_loss: 1.2578 - val_accuracy: 0.4036\n",
      "Epoch 59/80\n",
      "6435/6435 [==============================] - 0s 37us/step - loss: 1.2591 - accuracy: 0.3932 - val_loss: 1.2471 - val_accuracy: 0.4176\n",
      "Epoch 60/80\n",
      "6435/6435 [==============================] - 0s 38us/step - loss: 1.2529 - accuracy: 0.4093 - val_loss: 1.2724 - val_accuracy: 0.4008\n",
      "Epoch 61/80\n",
      "6435/6435 [==============================] - 0s 37us/step - loss: 1.2513 - accuracy: 0.3974 - val_loss: 1.2497 - val_accuracy: 0.4190\n",
      "Epoch 62/80\n",
      "6435/6435 [==============================] - 0s 38us/step - loss: 1.2530 - accuracy: 0.4023 - val_loss: 1.2573 - val_accuracy: 0.4050\n",
      "Epoch 63/80\n",
      "6435/6435 [==============================] - 0s 37us/step - loss: 1.2547 - accuracy: 0.4012 - val_loss: 1.2533 - val_accuracy: 0.4302\n",
      "Epoch 64/80\n",
      "6435/6435 [==============================] - 0s 35us/step - loss: 1.2441 - accuracy: 0.4071 - val_loss: 1.2431 - val_accuracy: 0.4106\n",
      "Epoch 65/80\n",
      "6435/6435 [==============================] - 0s 38us/step - loss: 1.2409 - accuracy: 0.4123 - val_loss: 1.2605 - val_accuracy: 0.4120\n",
      "Epoch 66/80\n",
      "6435/6435 [==============================] - 0s 37us/step - loss: 1.2443 - accuracy: 0.4012 - val_loss: 1.2362 - val_accuracy: 0.4302\n",
      "Epoch 67/80\n",
      "6435/6435 [==============================] - 0s 38us/step - loss: 1.2403 - accuracy: 0.4026 - val_loss: 1.2295 - val_accuracy: 0.4232\n",
      "Epoch 68/80\n",
      "6435/6435 [==============================] - 0s 39us/step - loss: 1.2399 - accuracy: 0.3956 - val_loss: 1.2524 - val_accuracy: 0.3701\n",
      "Epoch 69/80\n",
      "6435/6435 [==============================] - 0s 37us/step - loss: 1.2353 - accuracy: 0.4028 - val_loss: 1.2359 - val_accuracy: 0.4134\n",
      "Epoch 70/80\n",
      "6435/6435 [==============================] - 0s 37us/step - loss: 1.2397 - accuracy: 0.4051 - val_loss: 1.2313 - val_accuracy: 0.4204\n",
      "Epoch 71/80\n",
      "6435/6435 [==============================] - 0s 40us/step - loss: 1.2418 - accuracy: 0.3992 - val_loss: 1.2364 - val_accuracy: 0.3939\n",
      "Epoch 72/80\n",
      "6435/6435 [==============================] - 0s 39us/step - loss: 1.2389 - accuracy: 0.4023 - val_loss: 1.2535 - val_accuracy: 0.4162\n",
      "Epoch 73/80\n",
      "6435/6435 [==============================] - 0s 35us/step - loss: 1.2311 - accuracy: 0.4076 - val_loss: 1.2516 - val_accuracy: 0.4218\n",
      "Epoch 74/80\n",
      "6435/6435 [==============================] - 0s 38us/step - loss: 1.2356 - accuracy: 0.4062 - val_loss: 1.2515 - val_accuracy: 0.4120\n",
      "Epoch 75/80\n",
      "6435/6435 [==============================] - 0s 42us/step - loss: 1.2354 - accuracy: 0.4057 - val_loss: 1.2683 - val_accuracy: 0.3827\n",
      "Epoch 76/80\n",
      "6435/6435 [==============================] - 0s 44us/step - loss: 1.2277 - accuracy: 0.4014 - val_loss: 1.2404 - val_accuracy: 0.4022\n",
      "Epoch 77/80\n",
      "6435/6435 [==============================] - 0s 36us/step - loss: 1.2297 - accuracy: 0.4177 - val_loss: 1.2494 - val_accuracy: 0.3827\n",
      "Epoch 00077: early stopping\n",
      "[[1.42952263e-01 8.88229832e-02 1.15842544e-04 ... 3.66177827e-01\n",
      "  2.03918144e-01 1.84164360e-01]\n",
      " [4.55862358e-02 3.38474140e-02 1.14380312e-03 ... 2.55809841e-03\n",
      "  5.66977123e-03 4.52019554e-03]\n",
      " [2.14808881e-01 1.42512202e-01 2.77473519e-05 ... 4.45360616e-02\n",
      "  3.19644928e-01 2.77049482e-01]\n",
      " ...\n",
      " [2.67225981e-01 1.66040137e-01 1.81746345e-05 ... 3.48430732e-03\n",
      "  2.93469965e-01 2.69309461e-01]\n",
      " [1.19440496e-01 7.05357790e-02 9.58420715e-05 ... 1.85703799e-01\n",
      "  3.17624003e-01 2.94922709e-01]\n",
      " [1.37571231e-01 8.17650184e-02 8.25212046e-05 ... 2.29093149e-01\n",
      "  2.81178564e-01 2.60720223e-01]]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[11 10 12 ... 12 12 12]\n",
      "<class 'numpy.ndarray'>\n",
      "One CNN, r:  0\n",
      "Computing Time:  0:02:57.336475\n",
      "n, p1, p2 3 0 3\n",
      "Model: \"sequential_1\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv1d_1 (Conv1D)            (None, 3, 6)              12        \n",
      "_________________________________________________________________\n",
      "average_pooling1d_1 (Average (None, 1, 6)              0         \n",
      "_________________________________________________________________\n",
      "conv1d_2 (Conv1D)            (None, 1, 16)             112       \n",
      "_________________________________________________________________\n",
      "average_pooling1d_2 (Average (None, 1, 16)             0         \n",
      "_________________________________________________________________\n",
      "conv1d_3 (Conv1D)            (None, 1, 120)            2040      \n",
      "_________________________________________________________________\n",
      "flatten_1 (Flatten)          (None, 120)               0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 84)                10164     \n",
      "_________________________________________________________________\n",
      "preds (Dense)                (None, 14)                1190      \n",
      "=================================================================\n",
      "Total params: 13,518\n",
      "Trainable params: 13,518\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Train on 6435 samples, validate on 716 samples\n",
      "Epoch 1/80\n",
      "6435/6435 [==============================] - 0s 72us/step - loss: 2.6002 - accuracy: 0.1455 - val_loss: 2.5243 - val_accuracy: 0.1480\n",
      "Epoch 2/80\n",
      "6435/6435 [==============================] - 0s 42us/step - loss: 2.3257 - accuracy: 0.1925 - val_loss: 2.1530 - val_accuracy: 0.2025\n",
      "Epoch 3/80\n",
      "6435/6435 [==============================] - 0s 38us/step - loss: 2.0149 - accuracy: 0.2320 - val_loss: 1.9891 - val_accuracy: 0.1885\n",
      "Epoch 4/80\n",
      "6435/6435 [==============================] - 0s 37us/step - loss: 1.8836 - accuracy: 0.2375 - val_loss: 1.8758 - val_accuracy: 0.2277\n",
      "Epoch 5/80\n",
      "6435/6435 [==============================] - 0s 37us/step - loss: 1.7952 - accuracy: 0.2598 - val_loss: 1.7810 - val_accuracy: 0.3059\n",
      "Epoch 6/80\n",
      "6435/6435 [==============================] - 0s 38us/step - loss: 1.7360 - accuracy: 0.2715 - val_loss: 1.7285 - val_accuracy: 0.2989\n",
      "Epoch 7/80\n",
      "6435/6435 [==============================] - 0s 34us/step - loss: 1.7042 - accuracy: 0.2831 - val_loss: 1.6921 - val_accuracy: 0.2919\n",
      "Epoch 8/80\n",
      "6435/6435 [==============================] - 0s 36us/step - loss: 1.6692 - accuracy: 0.2957 - val_loss: 1.6802 - val_accuracy: 0.2947\n",
      "Epoch 9/80\n",
      "6435/6435 [==============================] - 0s 37us/step - loss: 1.6527 - accuracy: 0.2931 - val_loss: 1.6319 - val_accuracy: 0.3296\n",
      "Epoch 10/80\n",
      "6435/6435 [==============================] - 0s 37us/step - loss: 1.6355 - accuracy: 0.2993 - val_loss: 1.6345 - val_accuracy: 0.3017\n",
      "Epoch 11/80\n",
      "6435/6435 [==============================] - 0s 37us/step - loss: 1.6238 - accuracy: 0.2953 - val_loss: 1.6209 - val_accuracy: 0.3087\n",
      "Epoch 12/80\n",
      "6435/6435 [==============================] - 0s 38us/step - loss: 1.5989 - accuracy: 0.3015 - val_loss: 1.5831 - val_accuracy: 0.2975\n",
      "Epoch 13/80\n",
      "6435/6435 [==============================] - 0s 37us/step - loss: 1.5760 - accuracy: 0.3033 - val_loss: 1.5809 - val_accuracy: 0.3003\n",
      "Epoch 14/80\n",
      "6435/6435 [==============================] - 0s 34us/step - loss: 1.5555 - accuracy: 0.3043 - val_loss: 1.5657 - val_accuracy: 0.3031\n",
      "Epoch 15/80\n",
      "6435/6435 [==============================] - 0s 34us/step - loss: 1.5458 - accuracy: 0.3069 - val_loss: 1.5455 - val_accuracy: 0.3352\n",
      "Epoch 16/80\n",
      "6435/6435 [==============================] - 0s 37us/step - loss: 1.5372 - accuracy: 0.3027 - val_loss: 1.5425 - val_accuracy: 0.2849\n",
      "Epoch 17/80\n",
      "6435/6435 [==============================] - 0s 36us/step - loss: 1.5300 - accuracy: 0.3138 - val_loss: 1.5399 - val_accuracy: 0.3073\n",
      "Epoch 18/80\n",
      "6435/6435 [==============================] - 0s 36us/step - loss: 1.5258 - accuracy: 0.2987 - val_loss: 1.5238 - val_accuracy: 0.3059\n",
      "Epoch 19/80\n",
      "6435/6435 [==============================] - 0s 39us/step - loss: 1.5218 - accuracy: 0.3074 - val_loss: 1.5128 - val_accuracy: 0.3073\n",
      "Epoch 20/80\n",
      "6435/6435 [==============================] - 0s 38us/step - loss: 1.5169 - accuracy: 0.3080 - val_loss: 1.5103 - val_accuracy: 0.3142\n",
      "Epoch 21/80\n",
      "6435/6435 [==============================] - 0s 38us/step - loss: 1.5092 - accuracy: 0.3113 - val_loss: 1.5372 - val_accuracy: 0.3282\n",
      "Epoch 22/80\n",
      "6435/6435 [==============================] - 0s 39us/step - loss: 1.5044 - accuracy: 0.3086 - val_loss: 1.5136 - val_accuracy: 0.3059\n",
      "Epoch 23/80\n",
      "6435/6435 [==============================] - 0s 38us/step - loss: 1.4972 - accuracy: 0.3096 - val_loss: 1.5151 - val_accuracy: 0.3422\n",
      "Epoch 24/80\n",
      "6435/6435 [==============================] - 0s 34us/step - loss: 1.4969 - accuracy: 0.3134 - val_loss: 1.4914 - val_accuracy: 0.3366\n",
      "Epoch 25/80\n",
      "6435/6435 [==============================] - 0s 33us/step - loss: 1.4993 - accuracy: 0.3069 - val_loss: 1.4916 - val_accuracy: 0.3296\n",
      "Epoch 26/80\n",
      "6435/6435 [==============================] - 0s 34us/step - loss: 1.4871 - accuracy: 0.3192 - val_loss: 1.4962 - val_accuracy: 0.2891\n",
      "Epoch 27/80\n",
      "6435/6435 [==============================] - 0s 39us/step - loss: 1.4910 - accuracy: 0.3141 - val_loss: 1.4813 - val_accuracy: 0.3422\n",
      "Epoch 28/80\n",
      "6435/6435 [==============================] - 0s 34us/step - loss: 1.4801 - accuracy: 0.3302 - val_loss: 1.5032 - val_accuracy: 0.3115\n",
      "Epoch 29/80\n",
      "6435/6435 [==============================] - 0s 36us/step - loss: 1.4819 - accuracy: 0.3139 - val_loss: 1.4896 - val_accuracy: 0.2933\n",
      "Epoch 30/80\n",
      "6435/6435 [==============================] - 0s 37us/step - loss: 1.4726 - accuracy: 0.3277 - val_loss: 1.4872 - val_accuracy: 0.3045\n",
      "Epoch 31/80\n",
      "6435/6435 [==============================] - 0s 35us/step - loss: 1.4752 - accuracy: 0.3150 - val_loss: 1.4938 - val_accuracy: 0.3045\n",
      "Epoch 32/80\n",
      "6435/6435 [==============================] - 0s 35us/step - loss: 1.4751 - accuracy: 0.3195 - val_loss: 1.4693 - val_accuracy: 0.3478\n",
      "Epoch 33/80\n",
      "6435/6435 [==============================] - 0s 34us/step - loss: 1.4671 - accuracy: 0.3296 - val_loss: 1.4851 - val_accuracy: 0.2891\n",
      "Epoch 34/80\n",
      "6435/6435 [==============================] - 0s 35us/step - loss: 1.4686 - accuracy: 0.3231 - val_loss: 1.4693 - val_accuracy: 0.3561\n",
      "Epoch 35/80\n",
      "6435/6435 [==============================] - 0s 34us/step - loss: 1.4618 - accuracy: 0.3237 - val_loss: 1.4623 - val_accuracy: 0.3170\n",
      "Epoch 36/80\n",
      "6435/6435 [==============================] - 0s 35us/step - loss: 1.4587 - accuracy: 0.3240 - val_loss: 1.4786 - val_accuracy: 0.3087\n",
      "Epoch 37/80\n",
      "6435/6435 [==============================] - 0s 35us/step - loss: 1.4537 - accuracy: 0.3391 - val_loss: 1.4529 - val_accuracy: 0.3422\n",
      "Epoch 38/80\n",
      "6435/6435 [==============================] - 0s 37us/step - loss: 1.4501 - accuracy: 0.3478 - val_loss: 1.4791 - val_accuracy: 0.3226\n",
      "Epoch 39/80\n",
      "6435/6435 [==============================] - 0s 37us/step - loss: 1.4502 - accuracy: 0.3427 - val_loss: 1.4505 - val_accuracy: 0.3436\n",
      "Epoch 40/80\n",
      "6435/6435 [==============================] - 0s 36us/step - loss: 1.4465 - accuracy: 0.3428 - val_loss: 1.4203 - val_accuracy: 0.3785\n",
      "Epoch 41/80\n",
      "6435/6435 [==============================] - 0s 35us/step - loss: 1.4319 - accuracy: 0.3510 - val_loss: 1.4479 - val_accuracy: 0.3450\n",
      "Epoch 42/80\n",
      "6435/6435 [==============================] - 0s 36us/step - loss: 1.4236 - accuracy: 0.3627 - val_loss: 1.4181 - val_accuracy: 0.3883\n",
      "Epoch 43/80\n",
      "6435/6435 [==============================] - 0s 36us/step - loss: 1.4145 - accuracy: 0.3680 - val_loss: 1.4236 - val_accuracy: 0.3659\n",
      "Epoch 44/80\n",
      "6435/6435 [==============================] - 0s 35us/step - loss: 1.4026 - accuracy: 0.3650 - val_loss: 1.4072 - val_accuracy: 0.3673\n",
      "Epoch 45/80\n",
      "6435/6435 [==============================] - 0s 33us/step - loss: 1.3928 - accuracy: 0.3747 - val_loss: 1.4032 - val_accuracy: 0.3520\n",
      "Epoch 46/80\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6435/6435 [==============================] - 0s 35us/step - loss: 1.3847 - accuracy: 0.3694 - val_loss: 1.3623 - val_accuracy: 0.3771\n",
      "Epoch 47/80\n",
      "6435/6435 [==============================] - 0s 34us/step - loss: 1.3799 - accuracy: 0.3703 - val_loss: 1.3641 - val_accuracy: 0.3911\n",
      "Epoch 48/80\n",
      "6435/6435 [==============================] - 0s 36us/step - loss: 1.3614 - accuracy: 0.3736 - val_loss: 1.3447 - val_accuracy: 0.3897\n",
      "Epoch 49/80\n",
      "6435/6435 [==============================] - 0s 34us/step - loss: 1.3529 - accuracy: 0.3782 - val_loss: 1.3372 - val_accuracy: 0.4050\n",
      "Epoch 50/80\n",
      "6435/6435 [==============================] - 0s 37us/step - loss: 1.3434 - accuracy: 0.3817 - val_loss: 1.3410 - val_accuracy: 0.3785\n",
      "Epoch 51/80\n",
      "6435/6435 [==============================] - 0s 34us/step - loss: 1.3378 - accuracy: 0.3824 - val_loss: 1.3189 - val_accuracy: 0.3617\n",
      "Epoch 52/80\n",
      "6435/6435 [==============================] - 0s 35us/step - loss: 1.3232 - accuracy: 0.3890 - val_loss: 1.3210 - val_accuracy: 0.3785\n",
      "Epoch 53/80\n",
      "6435/6435 [==============================] - 0s 35us/step - loss: 1.3214 - accuracy: 0.3880 - val_loss: 1.3050 - val_accuracy: 0.3743\n",
      "Epoch 54/80\n",
      "6435/6435 [==============================] - 0s 35us/step - loss: 1.3166 - accuracy: 0.3885 - val_loss: 1.2996 - val_accuracy: 0.3715\n",
      "Epoch 55/80\n",
      "6435/6435 [==============================] - 0s 36us/step - loss: 1.3092 - accuracy: 0.3949 - val_loss: 1.2934 - val_accuracy: 0.3883\n",
      "Epoch 56/80\n",
      "6435/6435 [==============================] - 0s 34us/step - loss: 1.3046 - accuracy: 0.3841 - val_loss: 1.3114 - val_accuracy: 0.4050\n",
      "Epoch 57/80\n",
      "6435/6435 [==============================] - 0s 36us/step - loss: 1.3036 - accuracy: 0.3910 - val_loss: 1.2884 - val_accuracy: 0.3966\n",
      "Epoch 58/80\n",
      "6435/6435 [==============================] - 0s 39us/step - loss: 1.2938 - accuracy: 0.3956 - val_loss: 1.2800 - val_accuracy: 0.3617\n",
      "Epoch 59/80\n",
      "6435/6435 [==============================] - 0s 34us/step - loss: 1.2920 - accuracy: 0.3911 - val_loss: 1.2762 - val_accuracy: 0.3799\n",
      "Epoch 60/80\n",
      "6435/6435 [==============================] - 0s 34us/step - loss: 1.2934 - accuracy: 0.3911 - val_loss: 1.2899 - val_accuracy: 0.3925\n",
      "Epoch 61/80\n",
      "6435/6435 [==============================] - 0s 43us/step - loss: 1.2958 - accuracy: 0.3963 - val_loss: 1.2841 - val_accuracy: 0.3785\n",
      "Epoch 62/80\n",
      "6435/6435 [==============================] - 0s 35us/step - loss: 1.2945 - accuracy: 0.3938 - val_loss: 1.2707 - val_accuracy: 0.3897\n",
      "Epoch 63/80\n",
      "6435/6435 [==============================] - 0s 35us/step - loss: 1.2821 - accuracy: 0.3955 - val_loss: 1.2867 - val_accuracy: 0.3911\n",
      "Epoch 64/80\n",
      "6435/6435 [==============================] - 0s 34us/step - loss: 1.2851 - accuracy: 0.3897 - val_loss: 1.2731 - val_accuracy: 0.4218\n",
      "Epoch 65/80\n",
      "6435/6435 [==============================] - 0s 36us/step - loss: 1.2887 - accuracy: 0.3935 - val_loss: 1.2668 - val_accuracy: 0.3953\n",
      "Epoch 66/80\n",
      "6435/6435 [==============================] - 0s 34us/step - loss: 1.2822 - accuracy: 0.3994 - val_loss: 1.2713 - val_accuracy: 0.4176\n",
      "Epoch 67/80\n",
      "6435/6435 [==============================] - 0s 35us/step - loss: 1.2746 - accuracy: 0.3901 - val_loss: 1.2623 - val_accuracy: 0.4092\n",
      "Epoch 68/80\n",
      "6435/6435 [==============================] - 0s 36us/step - loss: 1.2724 - accuracy: 0.3992 - val_loss: 1.2615 - val_accuracy: 0.3813\n",
      "Epoch 69/80\n",
      "6435/6435 [==============================] - 0s 35us/step - loss: 1.2737 - accuracy: 0.3929 - val_loss: 1.2633 - val_accuracy: 0.3925\n",
      "Epoch 70/80\n",
      "6435/6435 [==============================] - 0s 36us/step - loss: 1.2691 - accuracy: 0.4026 - val_loss: 1.2420 - val_accuracy: 0.4078\n",
      "Epoch 71/80\n",
      "6435/6435 [==============================] - 0s 35us/step - loss: 1.2710 - accuracy: 0.4002 - val_loss: 1.2656 - val_accuracy: 0.3757\n",
      "Epoch 72/80\n",
      "6435/6435 [==============================] - 0s 33us/step - loss: 1.2650 - accuracy: 0.4030 - val_loss: 1.2562 - val_accuracy: 0.3617\n",
      "Epoch 73/80\n",
      "6435/6435 [==============================] - 0s 35us/step - loss: 1.2665 - accuracy: 0.4009 - val_loss: 1.2500 - val_accuracy: 0.3953\n",
      "Epoch 74/80\n",
      "6435/6435 [==============================] - 0s 35us/step - loss: 1.2661 - accuracy: 0.3989 - val_loss: 1.2312 - val_accuracy: 0.4106\n",
      "Epoch 75/80\n",
      "6435/6435 [==============================] - 0s 34us/step - loss: 1.2539 - accuracy: 0.4090 - val_loss: 1.2326 - val_accuracy: 0.3939\n",
      "Epoch 76/80\n",
      "6435/6435 [==============================] - 0s 34us/step - loss: 1.2548 - accuracy: 0.4026 - val_loss: 1.2363 - val_accuracy: 0.3827\n",
      "Epoch 77/80\n",
      "6435/6435 [==============================] - 0s 35us/step - loss: 1.2578 - accuracy: 0.3997 - val_loss: 1.2308 - val_accuracy: 0.4050\n",
      "Epoch 78/80\n",
      "6435/6435 [==============================] - 0s 34us/step - loss: 1.2517 - accuracy: 0.4050 - val_loss: 1.2456 - val_accuracy: 0.3953\n",
      "Epoch 79/80\n",
      "6435/6435 [==============================] - 0s 39us/step - loss: 1.2506 - accuracy: 0.4028 - val_loss: 1.2456 - val_accuracy: 0.4120\n",
      "Epoch 80/80\n",
      "6435/6435 [==============================] - 0s 34us/step - loss: 1.2471 - accuracy: 0.4053 - val_loss: 1.2188 - val_accuracy: 0.4050\n",
      "[[1.0162682e-01 1.2199091e-01 5.9990356e-14 ... 3.6225924e-01\n",
      "  1.8070677e-01 2.1906251e-01]\n",
      " [4.7668979e-02 4.4296712e-02 1.2857268e-21 ... 2.6468688e-03\n",
      "  1.1750247e-02 1.4785081e-02]\n",
      " [1.6663097e-01 1.9135199e-01 1.3973428e-16 ... 6.8852693e-02\n",
      "  2.6187602e-01 3.0817938e-01]\n",
      " ...\n",
      " [2.5284219e-01 2.6172793e-01 5.9976398e-17 ... 8.6183390e-03\n",
      "  2.1874657e-01 2.5693989e-01]\n",
      " [8.7526388e-02 9.8874025e-02 7.9380919e-13 ... 1.9535431e-01\n",
      "  2.7354822e-01 3.2702637e-01]\n",
      " [9.8224409e-02 1.1513728e-01 1.8254450e-13 ... 2.1895482e-01\n",
      "  2.5285268e-01 3.0294406e-01]]\n",
      "[11  9 13 ...  1 13 13]\n",
      "<class 'numpy.ndarray'>\n",
      "One CNN, r:  0\n",
      "Computing Time:  0:03:17.472434\n",
      "n, p1, p2 4 0 4\n",
      "Model: \"sequential_1\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv1d_1 (Conv1D)            (None, 3, 6)              12        \n",
      "_________________________________________________________________\n",
      "average_pooling1d_1 (Average (None, 1, 6)              0         \n",
      "_________________________________________________________________\n",
      "conv1d_2 (Conv1D)            (None, 1, 16)             112       \n",
      "_________________________________________________________________\n",
      "average_pooling1d_2 (Average (None, 1, 16)             0         \n",
      "_________________________________________________________________\n",
      "conv1d_3 (Conv1D)            (None, 1, 120)            2040      \n",
      "_________________________________________________________________\n",
      "flatten_1 (Flatten)          (None, 120)               0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 84)                10164     \n",
      "_________________________________________________________________\n",
      "preds (Dense)                (None, 14)                1190      \n",
      "=================================================================\n",
      "Total params: 13,518\n",
      "Trainable params: 13,518\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Train on 6435 samples, validate on 716 samples\n",
      "Epoch 1/80\n",
      "6435/6435 [==============================] - 1s 82us/step - loss: 2.5849 - accuracy: 0.1461 - val_loss: 2.4891 - val_accuracy: 0.1453\n",
      "Epoch 2/80\n",
      "6435/6435 [==============================] - 0s 44us/step - loss: 2.2897 - accuracy: 0.2117 - val_loss: 2.1140 - val_accuracy: 0.2193\n",
      "Epoch 3/80\n",
      "6435/6435 [==============================] - 0s 39us/step - loss: 2.0033 - accuracy: 0.2311 - val_loss: 1.9366 - val_accuracy: 0.2444\n",
      "Epoch 4/80\n",
      "6435/6435 [==============================] - 0s 41us/step - loss: 1.8740 - accuracy: 0.2488 - val_loss: 1.8331 - val_accuracy: 0.2304\n",
      "Epoch 5/80\n",
      "6435/6435 [==============================] - 0s 39us/step - loss: 1.7905 - accuracy: 0.2629 - val_loss: 1.7616 - val_accuracy: 0.2709\n",
      "Epoch 6/80\n",
      "6435/6435 [==============================] - 0s 37us/step - loss: 1.7190 - accuracy: 0.2852 - val_loss: 1.6908 - val_accuracy: 0.3198\n",
      "Epoch 7/80\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6435/6435 [==============================] - 0s 35us/step - loss: 1.6651 - accuracy: 0.2996 - val_loss: 1.6415 - val_accuracy: 0.3240\n",
      "Epoch 8/80\n",
      "6435/6435 [==============================] - 0s 34us/step - loss: 1.6208 - accuracy: 0.3051 - val_loss: 1.6058 - val_accuracy: 0.3296\n",
      "Epoch 9/80\n",
      "6435/6435 [==============================] - 0s 35us/step - loss: 1.5921 - accuracy: 0.2990 - val_loss: 1.5791 - val_accuracy: 0.3254\n",
      "Epoch 10/80\n",
      "6435/6435 [==============================] - 0s 37us/step - loss: 1.5764 - accuracy: 0.3064 - val_loss: 1.5643 - val_accuracy: 0.3310\n",
      "Epoch 11/80\n",
      "6435/6435 [==============================] - 0s 34us/step - loss: 1.5534 - accuracy: 0.3116 - val_loss: 1.5573 - val_accuracy: 0.3296\n",
      "Epoch 12/80\n",
      "6435/6435 [==============================] - 0s 40us/step - loss: 1.5418 - accuracy: 0.3072 - val_loss: 1.5406 - val_accuracy: 0.3324\n",
      "Epoch 13/80\n",
      "6435/6435 [==============================] - 0s 37us/step - loss: 1.5303 - accuracy: 0.3077 - val_loss: 1.5403 - val_accuracy: 0.3254\n",
      "Epoch 14/80\n",
      "6435/6435 [==============================] - 0s 38us/step - loss: 1.5275 - accuracy: 0.3041 - val_loss: 1.5222 - val_accuracy: 0.3059\n",
      "Epoch 15/80\n",
      "6435/6435 [==============================] - 0s 35us/step - loss: 1.5171 - accuracy: 0.3159 - val_loss: 1.5051 - val_accuracy: 0.3422\n",
      "Epoch 16/80\n",
      "6435/6435 [==============================] - 0s 38us/step - loss: 1.5142 - accuracy: 0.3043 - val_loss: 1.5051 - val_accuracy: 0.3520\n",
      "Epoch 17/80\n",
      "6435/6435 [==============================] - 0s 35us/step - loss: 1.5066 - accuracy: 0.3120 - val_loss: 1.5013 - val_accuracy: 0.2989\n",
      "Epoch 18/80\n",
      "6435/6435 [==============================] - 0s 35us/step - loss: 1.4985 - accuracy: 0.3169 - val_loss: 1.4946 - val_accuracy: 0.3296\n",
      "Epoch 19/80\n",
      "6435/6435 [==============================] - 0s 39us/step - loss: 1.5018 - accuracy: 0.3136 - val_loss: 1.4938 - val_accuracy: 0.3282\n",
      "Epoch 20/80\n",
      "6435/6435 [==============================] - 0s 38us/step - loss: 1.4976 - accuracy: 0.3074 - val_loss: 1.4918 - val_accuracy: 0.3101\n",
      "Epoch 21/80\n",
      "6435/6435 [==============================] - 0s 37us/step - loss: 1.4881 - accuracy: 0.3169 - val_loss: 1.5018 - val_accuracy: 0.2989\n",
      "Epoch 22/80\n",
      "6435/6435 [==============================] - 0s 37us/step - loss: 1.4910 - accuracy: 0.3148 - val_loss: 1.4916 - val_accuracy: 0.3142\n",
      "Epoch 23/80\n",
      "6435/6435 [==============================] - 0s 38us/step - loss: 1.4811 - accuracy: 0.3150 - val_loss: 1.4786 - val_accuracy: 0.2975\n",
      "Epoch 24/80\n",
      "6435/6435 [==============================] - 0s 37us/step - loss: 1.4791 - accuracy: 0.3197 - val_loss: 1.4737 - val_accuracy: 0.3338\n",
      "Epoch 25/80\n",
      "6435/6435 [==============================] - 0s 36us/step - loss: 1.4799 - accuracy: 0.3134 - val_loss: 1.4817 - val_accuracy: 0.3380\n",
      "Epoch 26/80\n",
      "6435/6435 [==============================] - 0s 38us/step - loss: 1.4726 - accuracy: 0.3226 - val_loss: 1.4721 - val_accuracy: 0.3380\n",
      "Epoch 27/80\n",
      "6435/6435 [==============================] - 0s 40us/step - loss: 1.4692 - accuracy: 0.3294 - val_loss: 1.4680 - val_accuracy: 0.3492\n",
      "Epoch 28/80\n",
      "6435/6435 [==============================] - 0s 38us/step - loss: 1.4691 - accuracy: 0.3249 - val_loss: 1.4723 - val_accuracy: 0.3268\n",
      "Epoch 29/80\n",
      "6435/6435 [==============================] - 0s 39us/step - loss: 1.4645 - accuracy: 0.3235 - val_loss: 1.4612 - val_accuracy: 0.3436\n",
      "Epoch 30/80\n",
      "6435/6435 [==============================] - 0s 36us/step - loss: 1.4812 - accuracy: 0.3254 - val_loss: 1.4753 - val_accuracy: 0.3687\n",
      "Epoch 31/80\n",
      "6435/6435 [==============================] - 0s 34us/step - loss: 1.4618 - accuracy: 0.3270 - val_loss: 1.4713 - val_accuracy: 0.3338\n",
      "Epoch 32/80\n",
      "6435/6435 [==============================] - 0s 33us/step - loss: 1.4608 - accuracy: 0.3246 - val_loss: 1.4620 - val_accuracy: 0.3673\n",
      "Epoch 33/80\n",
      "6435/6435 [==============================] - 0s 36us/step - loss: 1.4600 - accuracy: 0.3319 - val_loss: 1.4819 - val_accuracy: 0.3352\n",
      "Epoch 34/80\n",
      "6435/6435 [==============================] - 0s 35us/step - loss: 1.4513 - accuracy: 0.3355 - val_loss: 1.4586 - val_accuracy: 0.3478\n",
      "Epoch 35/80\n",
      "6435/6435 [==============================] - 0s 38us/step - loss: 1.4532 - accuracy: 0.3408 - val_loss: 1.4623 - val_accuracy: 0.3394\n",
      "Epoch 36/80\n",
      "6435/6435 [==============================] - 0s 37us/step - loss: 1.4520 - accuracy: 0.3341 - val_loss: 1.4549 - val_accuracy: 0.3240\n",
      "Epoch 37/80\n",
      "6435/6435 [==============================] - 0s 34us/step - loss: 1.4431 - accuracy: 0.3319 - val_loss: 1.4501 - val_accuracy: 0.3603\n",
      "Epoch 38/80\n",
      "6435/6435 [==============================] - 0s 36us/step - loss: 1.4402 - accuracy: 0.3451 - val_loss: 1.4447 - val_accuracy: 0.3338\n",
      "Epoch 39/80\n",
      "6435/6435 [==============================] - 0s 34us/step - loss: 1.4291 - accuracy: 0.3549 - val_loss: 1.4524 - val_accuracy: 0.3575\n",
      "Epoch 40/80\n",
      "6435/6435 [==============================] - 0s 35us/step - loss: 1.4222 - accuracy: 0.3629 - val_loss: 1.4443 - val_accuracy: 0.3268\n",
      "Epoch 41/80\n",
      "6435/6435 [==============================] - 0s 39us/step - loss: 1.4143 - accuracy: 0.3593 - val_loss: 1.4336 - val_accuracy: 0.3841\n",
      "Epoch 42/80\n",
      "6435/6435 [==============================] - 0s 36us/step - loss: 1.4044 - accuracy: 0.3695 - val_loss: 1.4144 - val_accuracy: 0.3645\n",
      "Epoch 43/80\n",
      "6435/6435 [==============================] - 0s 37us/step - loss: 1.3986 - accuracy: 0.3557 - val_loss: 1.4083 - val_accuracy: 0.3659\n",
      "Epoch 44/80\n",
      "6435/6435 [==============================] - 0s 34us/step - loss: 1.3878 - accuracy: 0.3689 - val_loss: 1.3882 - val_accuracy: 0.3813\n",
      "Epoch 45/80\n",
      "6435/6435 [==============================] - 0s 34us/step - loss: 1.3807 - accuracy: 0.3759 - val_loss: 1.3806 - val_accuracy: 0.3827\n",
      "Epoch 46/80\n",
      "6435/6435 [==============================] - 0s 35us/step - loss: 1.3609 - accuracy: 0.3714 - val_loss: 1.3816 - val_accuracy: 0.3785\n",
      "Epoch 47/80\n",
      "6435/6435 [==============================] - 0s 35us/step - loss: 1.3429 - accuracy: 0.3803 - val_loss: 1.3657 - val_accuracy: 0.3799\n",
      "Epoch 48/80\n",
      "6435/6435 [==============================] - 0s 37us/step - loss: 1.3385 - accuracy: 0.3661 - val_loss: 1.3490 - val_accuracy: 0.3883\n",
      "Epoch 49/80\n",
      "6435/6435 [==============================] - 0s 40us/step - loss: 1.3267 - accuracy: 0.3754 - val_loss: 1.3570 - val_accuracy: 0.3785\n",
      "Epoch 50/80\n",
      "6435/6435 [==============================] - 0s 39us/step - loss: 1.3186 - accuracy: 0.3901 - val_loss: 1.3582 - val_accuracy: 0.3827\n",
      "Epoch 51/80\n",
      "6435/6435 [==============================] - 0s 38us/step - loss: 1.3099 - accuracy: 0.3834 - val_loss: 1.3569 - val_accuracy: 0.3687\n",
      "Epoch 52/80\n",
      "6435/6435 [==============================] - 0s 35us/step - loss: 1.3132 - accuracy: 0.3843 - val_loss: 1.3441 - val_accuracy: 0.3841\n",
      "Epoch 53/80\n",
      "6435/6435 [==============================] - 0s 37us/step - loss: 1.3057 - accuracy: 0.3851 - val_loss: 1.3463 - val_accuracy: 0.3715\n",
      "Epoch 54/80\n",
      "6435/6435 [==============================] - 0s 33us/step - loss: 1.2997 - accuracy: 0.3772 - val_loss: 1.3457 - val_accuracy: 0.3673\n",
      "Epoch 55/80\n",
      "6435/6435 [==============================] - 0s 37us/step - loss: 1.3049 - accuracy: 0.3888 - val_loss: 1.3482 - val_accuracy: 0.3869\n",
      "Epoch 56/80\n",
      "6435/6435 [==============================] - 0s 36us/step - loss: 1.2941 - accuracy: 0.3944 - val_loss: 1.3317 - val_accuracy: 0.3813\n",
      "Epoch 57/80\n",
      "6435/6435 [==============================] - 0s 39us/step - loss: 1.2904 - accuracy: 0.3894 - val_loss: 1.3296 - val_accuracy: 0.3799\n",
      "Epoch 58/80\n",
      "6435/6435 [==============================] - 0s 35us/step - loss: 1.2903 - accuracy: 0.3902 - val_loss: 1.3326 - val_accuracy: 0.3883\n",
      "Epoch 59/80\n",
      "6435/6435 [==============================] - 0s 35us/step - loss: 1.2863 - accuracy: 0.3911 - val_loss: 1.3409 - val_accuracy: 0.3855\n",
      "Epoch 60/80\n",
      "6435/6435 [==============================] - 0s 40us/step - loss: 1.2825 - accuracy: 0.3840 - val_loss: 1.3267 - val_accuracy: 0.3980\n",
      "Epoch 61/80\n",
      "6435/6435 [==============================] - 0s 37us/step - loss: 1.2800 - accuracy: 0.3883 - val_loss: 1.3230 - val_accuracy: 0.3980\n",
      "Epoch 62/80\n",
      "6435/6435 [==============================] - 0s 37us/step - loss: 1.2814 - accuracy: 0.3854 - val_loss: 1.3212 - val_accuracy: 0.3966\n",
      "Epoch 63/80\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6435/6435 [==============================] - 0s 40us/step - loss: 1.2731 - accuracy: 0.4017 - val_loss: 1.3226 - val_accuracy: 0.3645\n",
      "Epoch 64/80\n",
      "6435/6435 [==============================] - 0s 40us/step - loss: 1.2699 - accuracy: 0.3970 - val_loss: 1.3197 - val_accuracy: 0.3994\n",
      "Epoch 65/80\n",
      "6435/6435 [==============================] - 0s 33us/step - loss: 1.2797 - accuracy: 0.4023 - val_loss: 1.3335 - val_accuracy: 0.3939\n",
      "Epoch 66/80\n",
      "6435/6435 [==============================] - 0s 35us/step - loss: 1.2684 - accuracy: 0.3984 - val_loss: 1.3240 - val_accuracy: 0.3966\n",
      "Epoch 67/80\n",
      "6435/6435 [==============================] - 0s 37us/step - loss: 1.2657 - accuracy: 0.4002 - val_loss: 1.3167 - val_accuracy: 0.4036\n",
      "Epoch 68/80\n",
      "6435/6435 [==============================] - 0s 37us/step - loss: 1.2643 - accuracy: 0.3958 - val_loss: 1.3223 - val_accuracy: 0.3939\n",
      "Epoch 69/80\n",
      "6435/6435 [==============================] - 0s 37us/step - loss: 1.2616 - accuracy: 0.3966 - val_loss: 1.2999 - val_accuracy: 0.3966\n",
      "Epoch 70/80\n",
      "6435/6435 [==============================] - 0s 36us/step - loss: 1.2632 - accuracy: 0.3941 - val_loss: 1.3085 - val_accuracy: 0.3841\n",
      "Epoch 71/80\n",
      "6435/6435 [==============================] - 0s 36us/step - loss: 1.2576 - accuracy: 0.4030 - val_loss: 1.2999 - val_accuracy: 0.4036\n",
      "Epoch 72/80\n",
      "6435/6435 [==============================] - 0s 38us/step - loss: 1.2543 - accuracy: 0.4034 - val_loss: 1.3040 - val_accuracy: 0.3855\n",
      "Epoch 73/80\n",
      "6435/6435 [==============================] - 0s 38us/step - loss: 1.2553 - accuracy: 0.4031 - val_loss: 1.3165 - val_accuracy: 0.3715\n",
      "Epoch 74/80\n",
      "6435/6435 [==============================] - 0s 36us/step - loss: 1.2568 - accuracy: 0.3905 - val_loss: 1.2953 - val_accuracy: 0.3869\n",
      "Epoch 75/80\n",
      "6435/6435 [==============================] - 0s 36us/step - loss: 1.2525 - accuracy: 0.4081 - val_loss: 1.3060 - val_accuracy: 0.3897\n",
      "Epoch 76/80\n",
      "6435/6435 [==============================] - 0s 37us/step - loss: 1.2443 - accuracy: 0.4033 - val_loss: 1.3045 - val_accuracy: 0.3841\n",
      "Epoch 77/80\n",
      "6435/6435 [==============================] - 0s 37us/step - loss: 1.2419 - accuracy: 0.3998 - val_loss: 1.2981 - val_accuracy: 0.3827\n",
      "Epoch 78/80\n",
      "6435/6435 [==============================] - 0s 37us/step - loss: 1.2446 - accuracy: 0.3983 - val_loss: 1.2872 - val_accuracy: 0.4050\n",
      "Epoch 79/80\n",
      "6435/6435 [==============================] - 0s 38us/step - loss: 1.2441 - accuracy: 0.3984 - val_loss: 1.2862 - val_accuracy: 0.4092\n",
      "Epoch 80/80\n",
      "6435/6435 [==============================] - 0s 35us/step - loss: 1.2378 - accuracy: 0.4082 - val_loss: 1.2908 - val_accuracy: 0.3953\n",
      "[[1.17742635e-01 1.21582486e-01 6.34625138e-14 ... 2.92402476e-01\n",
      "  2.10068002e-01 2.46044219e-01]\n",
      " [3.74908298e-02 3.75034511e-02 3.32429444e-22 ... 2.51931080e-04\n",
      "  1.08846165e-02 1.24667957e-02]\n",
      " [1.80050999e-01 1.93765238e-01 3.80904331e-17 ... 3.04182041e-02\n",
      "  2.74805844e-01 3.18598986e-01]\n",
      " ...\n",
      " [2.41909489e-01 2.24410787e-01 2.53967547e-18 ... 1.17900036e-03\n",
      "  2.52007961e-01 2.80002594e-01]\n",
      " [9.86636505e-02 9.05472636e-02 5.49716631e-13 ... 1.40904784e-01\n",
      "  2.95427024e-01 3.60266358e-01]\n",
      " [1.11647531e-01 1.09161623e-01 1.55465606e-13 ... 1.59158632e-01\n",
      "  2.75667161e-01 3.35332483e-01]]\n",
      "[11 10 13 ... 13 13 13]\n",
      "<class 'numpy.ndarray'>\n",
      "One CNN, r:  0\n",
      "Computing Time:  0:03:38.270762\n",
      "n, p1, p2 5 0 5\n",
      "Model: \"sequential_1\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv1d_1 (Conv1D)            (None, 3, 6)              12        \n",
      "_________________________________________________________________\n",
      "average_pooling1d_1 (Average (None, 1, 6)              0         \n",
      "_________________________________________________________________\n",
      "conv1d_2 (Conv1D)            (None, 1, 16)             112       \n",
      "_________________________________________________________________\n",
      "average_pooling1d_2 (Average (None, 1, 16)             0         \n",
      "_________________________________________________________________\n",
      "conv1d_3 (Conv1D)            (None, 1, 120)            2040      \n",
      "_________________________________________________________________\n",
      "flatten_1 (Flatten)          (None, 120)               0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 84)                10164     \n",
      "_________________________________________________________________\n",
      "preds (Dense)                (None, 14)                1190      \n",
      "=================================================================\n",
      "Total params: 13,518\n",
      "Trainable params: 13,518\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Train on 6435 samples, validate on 716 samples\n",
      "Epoch 1/80\n",
      "6435/6435 [==============================] - 0s 73us/step - loss: 2.5983 - accuracy: 0.1357 - val_loss: 2.5186 - val_accuracy: 0.1592\n",
      "Epoch 2/80\n",
      "6435/6435 [==============================] - 0s 37us/step - loss: 2.3059 - accuracy: 0.2109 - val_loss: 2.0903 - val_accuracy: 0.2765\n",
      "Epoch 3/80\n",
      "6435/6435 [==============================] - 0s 37us/step - loss: 1.9737 - accuracy: 0.3001 - val_loss: 1.8756 - val_accuracy: 0.3017\n",
      "Epoch 4/80\n",
      "6435/6435 [==============================] - 0s 36us/step - loss: 1.8393 - accuracy: 0.3122 - val_loss: 1.7827 - val_accuracy: 0.3128\n",
      "Epoch 5/80\n",
      "6435/6435 [==============================] - 0s 35us/step - loss: 1.7663 - accuracy: 0.3088 - val_loss: 1.7174 - val_accuracy: 0.3101\n",
      "Epoch 6/80\n",
      "6435/6435 [==============================] - 0s 34us/step - loss: 1.6991 - accuracy: 0.3183 - val_loss: 1.6709 - val_accuracy: 0.3059\n",
      "Epoch 7/80\n",
      "6435/6435 [==============================] - 0s 35us/step - loss: 1.6550 - accuracy: 0.3172 - val_loss: 1.6304 - val_accuracy: 0.3142\n",
      "Epoch 8/80\n",
      "6435/6435 [==============================] - 0s 36us/step - loss: 1.6213 - accuracy: 0.3290 - val_loss: 1.5939 - val_accuracy: 0.3212\n",
      "Epoch 9/80\n",
      "6435/6435 [==============================] - 0s 36us/step - loss: 1.5902 - accuracy: 0.3243 - val_loss: 1.5834 - val_accuracy: 0.3059\n",
      "Epoch 10/80\n",
      "6435/6435 [==============================] - 0s 35us/step - loss: 1.5669 - accuracy: 0.3248 - val_loss: 1.5467 - val_accuracy: 0.3226\n",
      "Epoch 11/80\n",
      "6435/6435 [==============================] - 0s 37us/step - loss: 1.5495 - accuracy: 0.3237 - val_loss: 1.5415 - val_accuracy: 0.3128\n",
      "Epoch 12/80\n",
      "6435/6435 [==============================] - 0s 37us/step - loss: 1.5339 - accuracy: 0.3312 - val_loss: 1.5262 - val_accuracy: 0.3240\n",
      "Epoch 13/80\n",
      "6435/6435 [==============================] - 0s 35us/step - loss: 1.5299 - accuracy: 0.3263 - val_loss: 1.5103 - val_accuracy: 0.3198\n",
      "Epoch 14/80\n",
      "6435/6435 [==============================] - 0s 36us/step - loss: 1.5244 - accuracy: 0.3304 - val_loss: 1.5177 - val_accuracy: 0.3198\n",
      "Epoch 15/80\n",
      "6435/6435 [==============================] - 0s 35us/step - loss: 1.5159 - accuracy: 0.3280 - val_loss: 1.5084 - val_accuracy: 0.3212\n",
      "Epoch 16/80\n",
      "6435/6435 [==============================] - 0s 40us/step - loss: 1.5116 - accuracy: 0.3273 - val_loss: 1.5182 - val_accuracy: 0.3156\n",
      "Epoch 17/80\n",
      "6435/6435 [==============================] - 0s 37us/step - loss: 1.5053 - accuracy: 0.3338 - val_loss: 1.5022 - val_accuracy: 0.3170\n",
      "Epoch 18/80\n",
      "6435/6435 [==============================] - 0s 34us/step - loss: 1.5006 - accuracy: 0.3324 - val_loss: 1.4935 - val_accuracy: 0.2989\n",
      "Epoch 19/80\n",
      "6435/6435 [==============================] - 0s 36us/step - loss: 1.4967 - accuracy: 0.3184 - val_loss: 1.4965 - val_accuracy: 0.3268\n",
      "Epoch 20/80\n",
      "6435/6435 [==============================] - 0s 35us/step - loss: 1.4994 - accuracy: 0.3335 - val_loss: 1.4953 - val_accuracy: 0.3212\n",
      "Epoch 21/80\n",
      "6435/6435 [==============================] - 0s 38us/step - loss: 1.4929 - accuracy: 0.3340 - val_loss: 1.4772 - val_accuracy: 0.3142\n",
      "Epoch 22/80\n",
      "6435/6435 [==============================] - 0s 42us/step - loss: 1.4933 - accuracy: 0.3326 - val_loss: 1.4834 - val_accuracy: 0.3366\n",
      "Epoch 23/80\n",
      "6435/6435 [==============================] - 0s 35us/step - loss: 1.4877 - accuracy: 0.3288 - val_loss: 1.4961 - val_accuracy: 0.3045\n",
      "Epoch 24/80\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6435/6435 [==============================] - 0s 38us/step - loss: 1.4863 - accuracy: 0.3321 - val_loss: 1.4849 - val_accuracy: 0.3115\n",
      "Epoch 25/80\n",
      "6435/6435 [==============================] - 0s 37us/step - loss: 1.4895 - accuracy: 0.3197 - val_loss: 1.4832 - val_accuracy: 0.3240\n",
      "Epoch 26/80\n",
      "6435/6435 [==============================] - 0s 37us/step - loss: 1.4797 - accuracy: 0.3310 - val_loss: 1.5035 - val_accuracy: 0.3031\n",
      "Epoch 27/80\n",
      "6435/6435 [==============================] - 0s 35us/step - loss: 1.4838 - accuracy: 0.3284 - val_loss: 1.4637 - val_accuracy: 0.3268\n",
      "Epoch 28/80\n",
      "6435/6435 [==============================] - 0s 38us/step - loss: 1.4765 - accuracy: 0.3276 - val_loss: 1.4856 - val_accuracy: 0.3087\n",
      "Epoch 29/80\n",
      "6435/6435 [==============================] - 0s 35us/step - loss: 1.4733 - accuracy: 0.3335 - val_loss: 1.5004 - val_accuracy: 0.3338\n",
      "Epoch 30/80\n",
      "6435/6435 [==============================] - 0s 35us/step - loss: 1.4779 - accuracy: 0.3257 - val_loss: 1.4588 - val_accuracy: 0.2961\n",
      "Epoch 31/80\n",
      "6435/6435 [==============================] - 0s 38us/step - loss: 1.4758 - accuracy: 0.3276 - val_loss: 1.4717 - val_accuracy: 0.3170\n",
      "Epoch 32/80\n",
      "6435/6435 [==============================] - 0s 36us/step - loss: 1.4710 - accuracy: 0.3315 - val_loss: 1.4642 - val_accuracy: 0.3170\n",
      "Epoch 33/80\n",
      "6435/6435 [==============================] - 0s 34us/step - loss: 1.4713 - accuracy: 0.3318 - val_loss: 1.4720 - val_accuracy: 0.3017\n",
      "Epoch 34/80\n",
      "6435/6435 [==============================] - 0s 33us/step - loss: 1.4665 - accuracy: 0.3245 - val_loss: 1.4508 - val_accuracy: 0.3436\n",
      "Epoch 35/80\n",
      "6435/6435 [==============================] - 0s 38us/step - loss: 1.4648 - accuracy: 0.3369 - val_loss: 1.4759 - val_accuracy: 0.3198\n",
      "Epoch 36/80\n",
      "6435/6435 [==============================] - 0s 36us/step - loss: 1.4692 - accuracy: 0.3366 - val_loss: 1.4690 - val_accuracy: 0.3128\n",
      "Epoch 37/80\n",
      "6435/6435 [==============================] - 0s 35us/step - loss: 1.4610 - accuracy: 0.3312 - val_loss: 1.4448 - val_accuracy: 0.3128\n",
      "Epoch 38/80\n",
      "6435/6435 [==============================] - 0s 36us/step - loss: 1.4646 - accuracy: 0.3285 - val_loss: 1.4542 - val_accuracy: 0.3101\n",
      "Epoch 39/80\n",
      "6435/6435 [==============================] - 0s 37us/step - loss: 1.4602 - accuracy: 0.3260 - val_loss: 1.4583 - val_accuracy: 0.3073\n",
      "Epoch 40/80\n",
      "6435/6435 [==============================] - 0s 37us/step - loss: 1.4533 - accuracy: 0.3377 - val_loss: 1.4456 - val_accuracy: 0.3338\n",
      "Epoch 41/80\n",
      "6435/6435 [==============================] - 0s 38us/step - loss: 1.4576 - accuracy: 0.3363 - val_loss: 1.4269 - val_accuracy: 0.3408\n",
      "Epoch 42/80\n",
      "6435/6435 [==============================] - 0s 35us/step - loss: 1.4519 - accuracy: 0.3361 - val_loss: 1.4363 - val_accuracy: 0.3450\n",
      "Epoch 43/80\n",
      "6435/6435 [==============================] - 0s 36us/step - loss: 1.4513 - accuracy: 0.3366 - val_loss: 1.4686 - val_accuracy: 0.3128\n",
      "Epoch 44/80\n",
      "6435/6435 [==============================] - 0s 35us/step - loss: 1.4496 - accuracy: 0.3420 - val_loss: 1.4541 - val_accuracy: 0.3268\n",
      "Epoch 45/80\n",
      "6435/6435 [==============================] - 0s 39us/step - loss: 1.4465 - accuracy: 0.3371 - val_loss: 1.4345 - val_accuracy: 0.3212\n",
      "Epoch 46/80\n",
      "6435/6435 [==============================] - 0s 38us/step - loss: 1.4373 - accuracy: 0.3472 - val_loss: 1.4296 - val_accuracy: 0.3352\n",
      "Epoch 47/80\n",
      "6435/6435 [==============================] - 0s 38us/step - loss: 1.4351 - accuracy: 0.3526 - val_loss: 1.4332 - val_accuracy: 0.3254\n",
      "Epoch 48/80\n",
      "6435/6435 [==============================] - 0s 37us/step - loss: 1.4360 - accuracy: 0.3456 - val_loss: 1.4233 - val_accuracy: 0.3366\n",
      "Epoch 49/80\n",
      "6435/6435 [==============================] - 0s 35us/step - loss: 1.4257 - accuracy: 0.3473 - val_loss: 1.4204 - val_accuracy: 0.3073\n",
      "Epoch 50/80\n",
      "6435/6435 [==============================] - 0s 39us/step - loss: 1.4181 - accuracy: 0.3565 - val_loss: 1.4049 - val_accuracy: 0.3506\n",
      "Epoch 51/80\n",
      "6435/6435 [==============================] - 0s 36us/step - loss: 1.4150 - accuracy: 0.3532 - val_loss: 1.4004 - val_accuracy: 0.3352\n",
      "Epoch 52/80\n",
      "6435/6435 [==============================] - 0s 40us/step - loss: 1.4061 - accuracy: 0.3708 - val_loss: 1.3987 - val_accuracy: 0.3561\n",
      "Epoch 53/80\n",
      "6435/6435 [==============================] - 0s 36us/step - loss: 1.4001 - accuracy: 0.3677 - val_loss: 1.3815 - val_accuracy: 0.3534\n",
      "Epoch 54/80\n",
      "6435/6435 [==============================] - 0s 34us/step - loss: 1.3933 - accuracy: 0.3709 - val_loss: 1.3607 - val_accuracy: 0.3687\n",
      "Epoch 55/80\n",
      "6435/6435 [==============================] - 0s 37us/step - loss: 1.3833 - accuracy: 0.3742 - val_loss: 1.3546 - val_accuracy: 0.3366\n",
      "Epoch 56/80\n",
      "6435/6435 [==============================] - 0s 36us/step - loss: 1.3696 - accuracy: 0.3709 - val_loss: 1.3459 - val_accuracy: 0.3561\n",
      "Epoch 57/80\n",
      "6435/6435 [==============================] - 0s 37us/step - loss: 1.3554 - accuracy: 0.3747 - val_loss: 1.3404 - val_accuracy: 0.3729\n",
      "Epoch 58/80\n",
      "6435/6435 [==============================] - 0s 37us/step - loss: 1.3496 - accuracy: 0.3778 - val_loss: 1.3318 - val_accuracy: 0.3701\n",
      "Epoch 59/80\n",
      "6435/6435 [==============================] - 0s 37us/step - loss: 1.3400 - accuracy: 0.3901 - val_loss: 1.3211 - val_accuracy: 0.3701\n",
      "Epoch 60/80\n",
      "6435/6435 [==============================] - 0s 34us/step - loss: 1.3314 - accuracy: 0.3740 - val_loss: 1.2953 - val_accuracy: 0.3966\n",
      "Epoch 61/80\n",
      "6435/6435 [==============================] - 0s 34us/step - loss: 1.3169 - accuracy: 0.3831 - val_loss: 1.2919 - val_accuracy: 0.4036\n",
      "Epoch 62/80\n",
      "6435/6435 [==============================] - 0s 36us/step - loss: 1.3114 - accuracy: 0.3779 - val_loss: 1.2830 - val_accuracy: 0.3813\n",
      "Epoch 63/80\n",
      "6435/6435 [==============================] - 0s 35us/step - loss: 1.3090 - accuracy: 0.3841 - val_loss: 1.2757 - val_accuracy: 0.3785\n",
      "Epoch 64/80\n",
      "6435/6435 [==============================] - 0s 33us/step - loss: 1.3048 - accuracy: 0.3904 - val_loss: 1.2789 - val_accuracy: 0.3729\n",
      "Epoch 65/80\n",
      "6435/6435 [==============================] - 0s 36us/step - loss: 1.2987 - accuracy: 0.3871 - val_loss: 1.2883 - val_accuracy: 0.3589\n",
      "Epoch 66/80\n",
      "6435/6435 [==============================] - 0s 38us/step - loss: 1.2938 - accuracy: 0.3866 - val_loss: 1.2683 - val_accuracy: 0.3687\n",
      "Epoch 67/80\n",
      "6435/6435 [==============================] - 0s 35us/step - loss: 1.2935 - accuracy: 0.3855 - val_loss: 1.2528 - val_accuracy: 0.4064\n",
      "Epoch 68/80\n",
      "6435/6435 [==============================] - 0s 36us/step - loss: 1.2896 - accuracy: 0.3857 - val_loss: 1.2457 - val_accuracy: 0.3799\n",
      "Epoch 69/80\n",
      "6435/6435 [==============================] - 0s 36us/step - loss: 1.2851 - accuracy: 0.3865 - val_loss: 1.2610 - val_accuracy: 0.3883\n",
      "Epoch 70/80\n",
      "6435/6435 [==============================] - 0s 34us/step - loss: 1.2807 - accuracy: 0.3966 - val_loss: 1.2448 - val_accuracy: 0.3841\n",
      "Epoch 71/80\n",
      "6435/6435 [==============================] - 0s 36us/step - loss: 1.2810 - accuracy: 0.3919 - val_loss: 1.2317 - val_accuracy: 0.4064\n",
      "Epoch 72/80\n",
      "6435/6435 [==============================] - 0s 36us/step - loss: 1.2779 - accuracy: 0.3918 - val_loss: 1.2518 - val_accuracy: 0.3757\n",
      "Epoch 73/80\n",
      "6435/6435 [==============================] - 0s 35us/step - loss: 1.2743 - accuracy: 0.3981 - val_loss: 1.2334 - val_accuracy: 0.3966\n",
      "Epoch 74/80\n",
      "6435/6435 [==============================] - 0s 35us/step - loss: 1.2733 - accuracy: 0.3946 - val_loss: 1.2536 - val_accuracy: 0.3701\n",
      "Epoch 75/80\n",
      "6435/6435 [==============================] - 0s 38us/step - loss: 1.2685 - accuracy: 0.3984 - val_loss: 1.2228 - val_accuracy: 0.3925\n",
      "Epoch 76/80\n",
      "6435/6435 [==============================] - 0s 35us/step - loss: 1.2641 - accuracy: 0.3978 - val_loss: 1.2324 - val_accuracy: 0.3771\n",
      "Epoch 77/80\n",
      "6435/6435 [==============================] - 0s 36us/step - loss: 1.2607 - accuracy: 0.4020 - val_loss: 1.2204 - val_accuracy: 0.3841\n",
      "Epoch 78/80\n",
      "6435/6435 [==============================] - 0s 36us/step - loss: 1.2647 - accuracy: 0.3981 - val_loss: 1.2155 - val_accuracy: 0.4302\n",
      "Epoch 79/80\n",
      "6435/6435 [==============================] - 0s 38us/step - loss: 1.2603 - accuracy: 0.3983 - val_loss: 1.2268 - val_accuracy: 0.3897\n",
      "Epoch 80/80\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6435/6435 [==============================] - 0s 37us/step - loss: 1.2553 - accuracy: 0.4028 - val_loss: 1.2413 - val_accuracy: 0.3883\n",
      "[[1.08977817e-01 1.02719545e-01 3.16487017e-14 ... 3.53829563e-01\n",
      "  1.84540495e-01 2.28878751e-01]\n",
      " [2.98069149e-01 2.31824312e-02 5.38353094e-21 ... 2.07779394e-03\n",
      "  8.99070594e-03 1.01107657e-02]\n",
      " [1.90090284e-01 1.78023562e-01 7.05967021e-17 ... 5.38830310e-02\n",
      "  2.60305613e-01 3.12461942e-01]\n",
      " ...\n",
      " [1.51413381e-01 2.00254217e-01 1.28639084e-17 ... 6.17745612e-03\n",
      "  3.05867523e-01 3.34528655e-01]\n",
      " [1.03940465e-01 1.13667093e-01 3.86285838e-13 ... 2.12898552e-01\n",
      "  2.37727910e-01 2.97092885e-01]\n",
      " [1.14262775e-01 1.21294297e-01 1.14145266e-13 ... 2.24466503e-01\n",
      "  2.28679389e-01 2.87281096e-01]]\n",
      "[11  9 13 ... 13 13 13]\n",
      "<class 'numpy.ndarray'>\n",
      "One CNN, r:  0\n",
      "Computing Time:  0:03:58.612150\n",
      "n, p1, p2 6 0 6\n",
      "Model: \"sequential_1\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv1d_1 (Conv1D)            (None, 3, 6)              12        \n",
      "_________________________________________________________________\n",
      "average_pooling1d_1 (Average (None, 1, 6)              0         \n",
      "_________________________________________________________________\n",
      "conv1d_2 (Conv1D)            (None, 1, 16)             112       \n",
      "_________________________________________________________________\n",
      "average_pooling1d_2 (Average (None, 1, 16)             0         \n",
      "_________________________________________________________________\n",
      "conv1d_3 (Conv1D)            (None, 1, 120)            2040      \n",
      "_________________________________________________________________\n",
      "flatten_1 (Flatten)          (None, 120)               0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 84)                10164     \n",
      "_________________________________________________________________\n",
      "preds (Dense)                (None, 14)                1190      \n",
      "=================================================================\n",
      "Total params: 13,518\n",
      "Trainable params: 13,518\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Train on 6435 samples, validate on 716 samples\n",
      "Epoch 1/80\n",
      "6435/6435 [==============================] - 0s 73us/step - loss: 2.6024 - accuracy: 0.1312 - val_loss: 2.5277 - val_accuracy: 0.1285\n",
      "Epoch 2/80\n",
      "6435/6435 [==============================] - 0s 39us/step - loss: 2.3246 - accuracy: 0.2071 - val_loss: 2.1141 - val_accuracy: 0.2458\n",
      "Epoch 3/80\n",
      "6435/6435 [==============================] - 0s 38us/step - loss: 1.9934 - accuracy: 0.2664 - val_loss: 1.9029 - val_accuracy: 0.3059\n",
      "Epoch 4/80\n",
      "6435/6435 [==============================] - 0s 39us/step - loss: 1.8474 - accuracy: 0.3052 - val_loss: 1.7735 - val_accuracy: 0.3101\n",
      "Epoch 5/80\n",
      "6435/6435 [==============================] - 0s 38us/step - loss: 1.7601 - accuracy: 0.3116 - val_loss: 1.6939 - val_accuracy: 0.3506\n",
      "Epoch 6/80\n",
      "6435/6435 [==============================] - 0s 37us/step - loss: 1.6857 - accuracy: 0.3113 - val_loss: 1.6560 - val_accuracy: 0.2933\n",
      "Epoch 7/80\n",
      "6435/6435 [==============================] - 0s 39us/step - loss: 1.6260 - accuracy: 0.3148 - val_loss: 1.5854 - val_accuracy: 0.3184\n",
      "Epoch 8/80\n",
      "6435/6435 [==============================] - 0s 39us/step - loss: 1.5754 - accuracy: 0.3268 - val_loss: 1.5424 - val_accuracy: 0.3380\n",
      "Epoch 9/80\n",
      "6435/6435 [==============================] - 0s 37us/step - loss: 1.5456 - accuracy: 0.3262 - val_loss: 1.5192 - val_accuracy: 0.3380\n",
      "Epoch 10/80\n",
      "6435/6435 [==============================] - 0s 37us/step - loss: 1.5204 - accuracy: 0.3240 - val_loss: 1.4926 - val_accuracy: 0.3324\n",
      "Epoch 11/80\n",
      "6435/6435 [==============================] - 0s 35us/step - loss: 1.5022 - accuracy: 0.3354 - val_loss: 1.4850 - val_accuracy: 0.3561\n",
      "Epoch 12/80\n",
      "6435/6435 [==============================] - 0s 38us/step - loss: 1.4935 - accuracy: 0.3310 - val_loss: 1.4848 - val_accuracy: 0.3422\n",
      "Epoch 13/80\n",
      "6435/6435 [==============================] - 0s 39us/step - loss: 1.4850 - accuracy: 0.3277 - val_loss: 1.4732 - val_accuracy: 0.3184\n",
      "Epoch 14/80\n",
      "6435/6435 [==============================] - 0s 37us/step - loss: 1.4807 - accuracy: 0.3267 - val_loss: 1.4589 - val_accuracy: 0.3338\n",
      "Epoch 15/80\n",
      "6435/6435 [==============================] - 0s 37us/step - loss: 1.4732 - accuracy: 0.3423 - val_loss: 1.4630 - val_accuracy: 0.3492\n",
      "Epoch 16/80\n",
      "6435/6435 [==============================] - 0s 37us/step - loss: 1.4636 - accuracy: 0.3358 - val_loss: 1.4414 - val_accuracy: 0.3673\n",
      "Epoch 17/80\n",
      "6435/6435 [==============================] - 0s 37us/step - loss: 1.4663 - accuracy: 0.3371 - val_loss: 1.4308 - val_accuracy: 0.3603\n",
      "Epoch 18/80\n",
      "6435/6435 [==============================] - 0s 37us/step - loss: 1.4585 - accuracy: 0.3368 - val_loss: 1.4394 - val_accuracy: 0.3296\n",
      "Epoch 19/80\n",
      "6435/6435 [==============================] - 0s 35us/step - loss: 1.4584 - accuracy: 0.3308 - val_loss: 1.4496 - val_accuracy: 0.3534\n",
      "Epoch 20/80\n",
      "6435/6435 [==============================] - 0s 34us/step - loss: 1.4535 - accuracy: 0.3394 - val_loss: 1.4347 - val_accuracy: 0.3282\n",
      "Epoch 21/80\n",
      "6435/6435 [==============================] - 0s 37us/step - loss: 1.4463 - accuracy: 0.3319 - val_loss: 1.4311 - val_accuracy: 0.3575\n",
      "Epoch 22/80\n",
      "6435/6435 [==============================] - 0s 37us/step - loss: 1.4532 - accuracy: 0.3456 - val_loss: 1.4170 - val_accuracy: 0.3603\n",
      "Epoch 23/80\n",
      "6435/6435 [==============================] - 0s 35us/step - loss: 1.4369 - accuracy: 0.3375 - val_loss: 1.4219 - val_accuracy: 0.3352\n",
      "Epoch 24/80\n",
      "6435/6435 [==============================] - 0s 37us/step - loss: 1.4343 - accuracy: 0.3389 - val_loss: 1.4191 - val_accuracy: 0.3520\n",
      "Epoch 25/80\n",
      "6435/6435 [==============================] - 0s 34us/step - loss: 1.4326 - accuracy: 0.3416 - val_loss: 1.4217 - val_accuracy: 0.3436\n",
      "Epoch 26/80\n",
      "6435/6435 [==============================] - 0s 36us/step - loss: 1.4361 - accuracy: 0.3430 - val_loss: 1.4163 - val_accuracy: 0.3715\n",
      "Epoch 27/80\n",
      "6435/6435 [==============================] - 0s 36us/step - loss: 1.4275 - accuracy: 0.3518 - val_loss: 1.4268 - val_accuracy: 0.3492\n",
      "Epoch 28/80\n",
      "6435/6435 [==============================] - 0s 37us/step - loss: 1.4206 - accuracy: 0.3481 - val_loss: 1.3924 - val_accuracy: 0.3841\n",
      "Epoch 29/80\n",
      "6435/6435 [==============================] - 0s 38us/step - loss: 1.4153 - accuracy: 0.3556 - val_loss: 1.3996 - val_accuracy: 0.3492\n",
      "Epoch 30/80\n",
      "6435/6435 [==============================] - 0s 37us/step - loss: 1.4107 - accuracy: 0.3545 - val_loss: 1.3869 - val_accuracy: 0.3617\n",
      "Epoch 31/80\n",
      "6435/6435 [==============================] - 0s 38us/step - loss: 1.4145 - accuracy: 0.3585 - val_loss: 1.3929 - val_accuracy: 0.3506\n",
      "Epoch 32/80\n",
      "6435/6435 [==============================] - 0s 36us/step - loss: 1.4012 - accuracy: 0.3650 - val_loss: 1.3842 - val_accuracy: 0.3855\n",
      "Epoch 33/80\n",
      "6435/6435 [==============================] - 0s 33us/step - loss: 1.3959 - accuracy: 0.3722 - val_loss: 1.3645 - val_accuracy: 0.4050\n",
      "Epoch 34/80\n",
      "6435/6435 [==============================] - 0s 37us/step - loss: 1.3826 - accuracy: 0.3719 - val_loss: 1.3500 - val_accuracy: 0.4330\n",
      "Epoch 35/80\n",
      "6435/6435 [==============================] - 0s 36us/step - loss: 1.3718 - accuracy: 0.3798 - val_loss: 1.3411 - val_accuracy: 0.4330\n",
      "Epoch 36/80\n",
      "6435/6435 [==============================] - 0s 35us/step - loss: 1.3636 - accuracy: 0.3915 - val_loss: 1.3286 - val_accuracy: 0.4246\n",
      "Epoch 37/80\n",
      "6435/6435 [==============================] - 0s 37us/step - loss: 1.3512 - accuracy: 0.3994 - val_loss: 1.3169 - val_accuracy: 0.4511\n",
      "Epoch 38/80\n",
      "6435/6435 [==============================] - 0s 38us/step - loss: 1.3334 - accuracy: 0.4047 - val_loss: 1.3109 - val_accuracy: 0.4218\n",
      "Epoch 39/80\n",
      "6435/6435 [==============================] - 0s 36us/step - loss: 1.3225 - accuracy: 0.4106 - val_loss: 1.3006 - val_accuracy: 0.4134\n",
      "Epoch 40/80\n",
      "6435/6435 [==============================] - 0s 36us/step - loss: 1.3123 - accuracy: 0.3986 - val_loss: 1.2874 - val_accuracy: 0.3994\n",
      "Epoch 41/80\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6435/6435 [==============================] - 0s 37us/step - loss: 1.3014 - accuracy: 0.4025 - val_loss: 1.2812 - val_accuracy: 0.4232\n",
      "Epoch 42/80\n",
      "6435/6435 [==============================] - 0s 37us/step - loss: 1.2952 - accuracy: 0.4057 - val_loss: 1.2714 - val_accuracy: 0.3994\n",
      "Epoch 43/80\n",
      "6435/6435 [==============================] - 0s 38us/step - loss: 1.2903 - accuracy: 0.4000 - val_loss: 1.2499 - val_accuracy: 0.4497\n",
      "Epoch 44/80\n",
      "6435/6435 [==============================] - 0s 37us/step - loss: 1.2821 - accuracy: 0.4087 - val_loss: 1.2792 - val_accuracy: 0.4232\n",
      "Epoch 45/80\n",
      "6435/6435 [==============================] - 0s 37us/step - loss: 1.2765 - accuracy: 0.4124 - val_loss: 1.2484 - val_accuracy: 0.4232\n",
      "Epoch 46/80\n",
      "6435/6435 [==============================] - 0s 36us/step - loss: 1.2765 - accuracy: 0.4070 - val_loss: 1.2369 - val_accuracy: 0.4344\n",
      "Epoch 47/80\n",
      "6435/6435 [==============================] - 0s 38us/step - loss: 1.2691 - accuracy: 0.4081 - val_loss: 1.2405 - val_accuracy: 0.4232\n",
      "Epoch 48/80\n",
      "6435/6435 [==============================] - 0s 37us/step - loss: 1.2663 - accuracy: 0.4054 - val_loss: 1.2297 - val_accuracy: 0.4372\n",
      "Epoch 49/80\n",
      "6435/6435 [==============================] - 0s 41us/step - loss: 1.2652 - accuracy: 0.4152 - val_loss: 1.2353 - val_accuracy: 0.4232\n",
      "Epoch 50/80\n",
      "6435/6435 [==============================] - 0s 37us/step - loss: 1.2607 - accuracy: 0.4132 - val_loss: 1.2355 - val_accuracy: 0.4050\n",
      "Epoch 51/80\n",
      "6435/6435 [==============================] - 0s 33us/step - loss: 1.2716 - accuracy: 0.4056 - val_loss: 1.2398 - val_accuracy: 0.4022\n",
      "Epoch 52/80\n",
      "6435/6435 [==============================] - 0s 34us/step - loss: 1.2573 - accuracy: 0.4057 - val_loss: 1.2234 - val_accuracy: 0.4385\n",
      "Epoch 53/80\n",
      "6435/6435 [==============================] - 0s 35us/step - loss: 1.2569 - accuracy: 0.4045 - val_loss: 1.2194 - val_accuracy: 0.4204\n",
      "Epoch 54/80\n",
      "6435/6435 [==============================] - 0s 35us/step - loss: 1.2517 - accuracy: 0.4118 - val_loss: 1.2206 - val_accuracy: 0.4372\n",
      "Epoch 55/80\n",
      "6435/6435 [==============================] - 0s 36us/step - loss: 1.2526 - accuracy: 0.4081 - val_loss: 1.2176 - val_accuracy: 0.4553\n",
      "Epoch 56/80\n",
      "6435/6435 [==============================] - 0s 35us/step - loss: 1.2447 - accuracy: 0.4131 - val_loss: 1.2190 - val_accuracy: 0.4260\n",
      "Epoch 57/80\n",
      "6435/6435 [==============================] - 0s 34us/step - loss: 1.2515 - accuracy: 0.4045 - val_loss: 1.2167 - val_accuracy: 0.4511\n",
      "Epoch 58/80\n",
      "6435/6435 [==============================] - 0s 38us/step - loss: 1.2452 - accuracy: 0.4186 - val_loss: 1.1975 - val_accuracy: 0.4539\n",
      "Epoch 59/80\n",
      "6435/6435 [==============================] - 0s 35us/step - loss: 1.2371 - accuracy: 0.4200 - val_loss: 1.2239 - val_accuracy: 0.4399\n",
      "Epoch 60/80\n",
      "6435/6435 [==============================] - 0s 38us/step - loss: 1.2395 - accuracy: 0.4120 - val_loss: 1.2028 - val_accuracy: 0.4218\n",
      "Epoch 61/80\n",
      "6435/6435 [==============================] - 0s 37us/step - loss: 1.2349 - accuracy: 0.4092 - val_loss: 1.2050 - val_accuracy: 0.4260\n",
      "Epoch 62/80\n",
      "6435/6435 [==============================] - 0s 37us/step - loss: 1.2304 - accuracy: 0.4238 - val_loss: 1.2013 - val_accuracy: 0.4120\n",
      "Epoch 63/80\n",
      "6435/6435 [==============================] - 0s 35us/step - loss: 1.2296 - accuracy: 0.4236 - val_loss: 1.2079 - val_accuracy: 0.4441\n",
      "Epoch 64/80\n",
      "6435/6435 [==============================] - 0s 36us/step - loss: 1.2306 - accuracy: 0.4081 - val_loss: 1.1930 - val_accuracy: 0.4553\n",
      "Epoch 65/80\n",
      "6435/6435 [==============================] - 0s 34us/step - loss: 1.2259 - accuracy: 0.4250 - val_loss: 1.2003 - val_accuracy: 0.4120\n",
      "Epoch 66/80\n",
      "6435/6435 [==============================] - 0s 34us/step - loss: 1.2225 - accuracy: 0.4186 - val_loss: 1.1943 - val_accuracy: 0.4330\n",
      "Epoch 67/80\n",
      "6435/6435 [==============================] - 0s 38us/step - loss: 1.2174 - accuracy: 0.4218 - val_loss: 1.1932 - val_accuracy: 0.4260\n",
      "Epoch 68/80\n",
      "6435/6435 [==============================] - 0s 38us/step - loss: 1.2176 - accuracy: 0.4121 - val_loss: 1.1939 - val_accuracy: 0.4092\n",
      "Epoch 69/80\n",
      "6435/6435 [==============================] - 0s 36us/step - loss: 1.2193 - accuracy: 0.4213 - val_loss: 1.2045 - val_accuracy: 0.4567\n",
      "Epoch 70/80\n",
      "6435/6435 [==============================] - 0s 36us/step - loss: 1.2166 - accuracy: 0.4141 - val_loss: 1.2069 - val_accuracy: 0.4399\n",
      "Epoch 71/80\n",
      "6435/6435 [==============================] - 0s 36us/step - loss: 1.2169 - accuracy: 0.4182 - val_loss: 1.1764 - val_accuracy: 0.4372\n",
      "Epoch 72/80\n",
      "6435/6435 [==============================] - 0s 40us/step - loss: 1.2073 - accuracy: 0.4241 - val_loss: 1.1829 - val_accuracy: 0.4385\n",
      "Epoch 73/80\n",
      "6435/6435 [==============================] - 0s 35us/step - loss: 1.2060 - accuracy: 0.4230 - val_loss: 1.1839 - val_accuracy: 0.4358\n",
      "Epoch 74/80\n",
      "6435/6435 [==============================] - 0s 36us/step - loss: 1.2037 - accuracy: 0.4221 - val_loss: 1.1719 - val_accuracy: 0.4260\n",
      "Epoch 75/80\n",
      "6435/6435 [==============================] - 0s 36us/step - loss: 1.2042 - accuracy: 0.4186 - val_loss: 1.1799 - val_accuracy: 0.4372\n",
      "Epoch 76/80\n",
      "6435/6435 [==============================] - 0s 34us/step - loss: 1.2022 - accuracy: 0.4197 - val_loss: 1.1751 - val_accuracy: 0.4344\n",
      "Epoch 77/80\n",
      "6435/6435 [==============================] - 0s 35us/step - loss: 1.1966 - accuracy: 0.4233 - val_loss: 1.1624 - val_accuracy: 0.4539\n",
      "Epoch 78/80\n",
      "6435/6435 [==============================] - 0s 37us/step - loss: 1.1985 - accuracy: 0.4221 - val_loss: 1.1830 - val_accuracy: 0.4204\n",
      "Epoch 79/80\n",
      "6435/6435 [==============================] - 0s 35us/step - loss: 1.1957 - accuracy: 0.4294 - val_loss: 1.1723 - val_accuracy: 0.4469\n",
      "Epoch 80/80\n",
      "6435/6435 [==============================] - 0s 36us/step - loss: 1.2027 - accuracy: 0.4224 - val_loss: 1.1805 - val_accuracy: 0.4372\n",
      "[[1.07891582e-01 1.25308976e-01 3.27090887e-14 ... 3.29761595e-01\n",
      "  2.32689887e-01 1.78448409e-01]\n",
      " [6.77206665e-02 8.62287208e-02 4.71209590e-23 ... 2.01068725e-03\n",
      "  1.51610505e-02 1.13445688e-02]\n",
      " [1.76959097e-01 1.83827162e-01 1.18088770e-18 ... 8.67235661e-02\n",
      "  3.21821600e-01 2.29696438e-01]\n",
      " ...\n",
      " [2.16256589e-01 2.30398953e-01 2.21400352e-20 ... 9.39336699e-03\n",
      "  3.09546143e-01 2.34294072e-01]\n",
      " [6.89563155e-02 8.39646384e-02 1.79090575e-13 ... 1.29070312e-01\n",
      "  3.87307942e-01 3.10034335e-01]\n",
      " [8.28215256e-02 9.80750099e-02 4.14437399e-14 ... 1.48090184e-01\n",
      "  3.68464470e-01 2.88027465e-01]]\n",
      "[11 10 12 ... 12 12 12]\n",
      "<class 'numpy.ndarray'>\n",
      "One CNN, r:  0\n",
      "Computing Time:  0:04:19.061667\n",
      "n, p1, p2 7 0 7\n",
      "Model: \"sequential_1\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv1d_1 (Conv1D)            (None, 3, 6)              12        \n",
      "_________________________________________________________________\n",
      "average_pooling1d_1 (Average (None, 1, 6)              0         \n",
      "_________________________________________________________________\n",
      "conv1d_2 (Conv1D)            (None, 1, 16)             112       \n",
      "_________________________________________________________________\n",
      "average_pooling1d_2 (Average (None, 1, 16)             0         \n",
      "_________________________________________________________________\n",
      "conv1d_3 (Conv1D)            (None, 1, 120)            2040      \n",
      "_________________________________________________________________\n",
      "flatten_1 (Flatten)          (None, 120)               0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 84)                10164     \n",
      "_________________________________________________________________\n",
      "preds (Dense)                (None, 14)                1190      \n",
      "=================================================================\n",
      "Total params: 13,518\n",
      "Trainable params: 13,518\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Train on 6435 samples, validate on 716 samples\n",
      "Epoch 1/80\n",
      "6435/6435 [==============================] - 0s 74us/step - loss: 2.6112 - accuracy: 0.1313 - val_loss: 2.5538 - val_accuracy: 0.1425\n",
      "Epoch 2/80\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6435/6435 [==============================] - 0s 40us/step - loss: 2.3967 - accuracy: 0.1992 - val_loss: 2.2083 - val_accuracy: 0.2291\n",
      "Epoch 3/80\n",
      "6435/6435 [==============================] - 0s 39us/step - loss: 2.0562 - accuracy: 0.2561 - val_loss: 1.9703 - val_accuracy: 0.2500\n",
      "Epoch 4/80\n",
      "6435/6435 [==============================] - 0s 37us/step - loss: 1.9076 - accuracy: 0.2873 - val_loss: 1.8808 - val_accuracy: 0.2779\n",
      "Epoch 5/80\n",
      "6435/6435 [==============================] - 0s 38us/step - loss: 1.8346 - accuracy: 0.2948 - val_loss: 1.8085 - val_accuracy: 0.2975\n",
      "Epoch 6/80\n",
      "6435/6435 [==============================] - 0s 37us/step - loss: 1.7745 - accuracy: 0.3032 - val_loss: 1.7607 - val_accuracy: 0.2947\n",
      "Epoch 7/80\n",
      "6435/6435 [==============================] - 0s 40us/step - loss: 1.7305 - accuracy: 0.3032 - val_loss: 1.7161 - val_accuracy: 0.2989\n",
      "Epoch 8/80\n",
      "6435/6435 [==============================] - 0s 47us/step - loss: 1.6908 - accuracy: 0.3108 - val_loss: 1.6675 - val_accuracy: 0.3142\n",
      "Epoch 9/80\n",
      "6435/6435 [==============================] - 0s 36us/step - loss: 1.6563 - accuracy: 0.3141 - val_loss: 1.6385 - val_accuracy: 0.3268\n",
      "Epoch 10/80\n",
      "6435/6435 [==============================] - 0s 36us/step - loss: 1.6371 - accuracy: 0.3179 - val_loss: 1.6161 - val_accuracy: 0.2961\n",
      "Epoch 11/80\n",
      "6435/6435 [==============================] - 0s 38us/step - loss: 1.6284 - accuracy: 0.3134 - val_loss: 1.6167 - val_accuracy: 0.3087\n",
      "Epoch 12/80\n",
      "6435/6435 [==============================] - 0s 37us/step - loss: 1.6153 - accuracy: 0.3152 - val_loss: 1.6025 - val_accuracy: 0.3128\n",
      "Epoch 13/80\n",
      "6435/6435 [==============================] - 0s 37us/step - loss: 1.6008 - accuracy: 0.3200 - val_loss: 1.5806 - val_accuracy: 0.3003\n",
      "Epoch 14/80\n",
      "6435/6435 [==============================] - 0s 36us/step - loss: 1.5786 - accuracy: 0.3225 - val_loss: 1.5670 - val_accuracy: 0.3296\n",
      "Epoch 15/80\n",
      "6435/6435 [==============================] - 0s 36us/step - loss: 1.5585 - accuracy: 0.3329 - val_loss: 1.5454 - val_accuracy: 0.3394\n",
      "Epoch 16/80\n",
      "6435/6435 [==============================] - 0s 39us/step - loss: 1.5496 - accuracy: 0.3282 - val_loss: 1.5368 - val_accuracy: 0.3366\n",
      "Epoch 17/80\n",
      "6435/6435 [==============================] - 0s 37us/step - loss: 1.5412 - accuracy: 0.3294 - val_loss: 1.5360 - val_accuracy: 0.3240\n",
      "Epoch 18/80\n",
      "6435/6435 [==============================] - 0s 34us/step - loss: 1.5338 - accuracy: 0.3391 - val_loss: 1.5349 - val_accuracy: 0.3352\n",
      "Epoch 19/80\n",
      "6435/6435 [==============================] - 0s 38us/step - loss: 1.5291 - accuracy: 0.3298 - val_loss: 1.5135 - val_accuracy: 0.3310\n",
      "Epoch 20/80\n",
      "6435/6435 [==============================] - 0s 37us/step - loss: 1.5215 - accuracy: 0.3336 - val_loss: 1.5188 - val_accuracy: 0.3142\n",
      "Epoch 21/80\n",
      "6435/6435 [==============================] - 0s 35us/step - loss: 1.5176 - accuracy: 0.3375 - val_loss: 1.5205 - val_accuracy: 0.3352\n",
      "Epoch 22/80\n",
      "6435/6435 [==============================] - 0s 38us/step - loss: 1.5160 - accuracy: 0.3231 - val_loss: 1.5192 - val_accuracy: 0.3128\n",
      "Epoch 23/80\n",
      "6435/6435 [==============================] - 0s 38us/step - loss: 1.5110 - accuracy: 0.3310 - val_loss: 1.5203 - val_accuracy: 0.3142\n",
      "Epoch 24/80\n",
      "6435/6435 [==============================] - 0s 39us/step - loss: 1.5074 - accuracy: 0.3333 - val_loss: 1.5207 - val_accuracy: 0.3478\n",
      "Epoch 25/80\n",
      "6435/6435 [==============================] - 0s 38us/step - loss: 1.5093 - accuracy: 0.3280 - val_loss: 1.4859 - val_accuracy: 0.3436\n",
      "Epoch 26/80\n",
      "6435/6435 [==============================] - 0s 35us/step - loss: 1.4950 - accuracy: 0.3371 - val_loss: 1.4964 - val_accuracy: 0.3254\n",
      "Epoch 27/80\n",
      "6435/6435 [==============================] - 0s 38us/step - loss: 1.4856 - accuracy: 0.3428 - val_loss: 1.4890 - val_accuracy: 0.3254\n",
      "Epoch 28/80\n",
      "6435/6435 [==============================] - 0s 37us/step - loss: 1.4865 - accuracy: 0.3388 - val_loss: 1.4983 - val_accuracy: 0.3087\n",
      "Epoch 29/80\n",
      "6435/6435 [==============================] - 0s 35us/step - loss: 1.4814 - accuracy: 0.3377 - val_loss: 1.4822 - val_accuracy: 0.3310\n",
      "Epoch 30/80\n",
      "6435/6435 [==============================] - 0s 36us/step - loss: 1.4736 - accuracy: 0.3414 - val_loss: 1.5067 - val_accuracy: 0.3184\n",
      "Epoch 31/80\n",
      "6435/6435 [==============================] - 0s 37us/step - loss: 1.4772 - accuracy: 0.3453 - val_loss: 1.4897 - val_accuracy: 0.3324\n",
      "Epoch 32/80\n",
      "6435/6435 [==============================] - 0s 36us/step - loss: 1.4683 - accuracy: 0.3423 - val_loss: 1.4754 - val_accuracy: 0.3338\n",
      "Epoch 33/80\n",
      "6435/6435 [==============================] - 0s 36us/step - loss: 1.4695 - accuracy: 0.3422 - val_loss: 1.4806 - val_accuracy: 0.3268\n",
      "Epoch 34/80\n",
      "6435/6435 [==============================] - 0s 36us/step - loss: 1.4669 - accuracy: 0.3322 - val_loss: 1.4662 - val_accuracy: 0.3729\n",
      "Epoch 35/80\n",
      "6435/6435 [==============================] - 0s 37us/step - loss: 1.4656 - accuracy: 0.3332 - val_loss: 1.4707 - val_accuracy: 0.3478\n",
      "Epoch 36/80\n",
      "6435/6435 [==============================] - 0s 34us/step - loss: 1.4595 - accuracy: 0.3324 - val_loss: 1.4622 - val_accuracy: 0.3338\n",
      "Epoch 37/80\n",
      "6435/6435 [==============================] - 0s 39us/step - loss: 1.4598 - accuracy: 0.3408 - val_loss: 1.4832 - val_accuracy: 0.3268\n",
      "Epoch 38/80\n",
      "6435/6435 [==============================] - 0s 35us/step - loss: 1.4562 - accuracy: 0.3414 - val_loss: 1.4682 - val_accuracy: 0.3534\n",
      "Epoch 39/80\n",
      "6435/6435 [==============================] - 0s 36us/step - loss: 1.4552 - accuracy: 0.3383 - val_loss: 1.4545 - val_accuracy: 0.3366\n",
      "Epoch 40/80\n",
      "6435/6435 [==============================] - 0s 39us/step - loss: 1.4497 - accuracy: 0.3448 - val_loss: 1.4582 - val_accuracy: 0.3561\n",
      "Epoch 41/80\n",
      "6435/6435 [==============================] - 0s 39us/step - loss: 1.4528 - accuracy: 0.3352 - val_loss: 1.4632 - val_accuracy: 0.3310\n",
      "Epoch 42/80\n",
      "6435/6435 [==============================] - 0s 40us/step - loss: 1.4446 - accuracy: 0.3400 - val_loss: 1.4770 - val_accuracy: 0.3268\n",
      "Epoch 43/80\n",
      "6435/6435 [==============================] - 0s 39us/step - loss: 1.4446 - accuracy: 0.3436 - val_loss: 1.4533 - val_accuracy: 0.3380\n",
      "Epoch 44/80\n",
      "6435/6435 [==============================] - 0s 38us/step - loss: 1.4419 - accuracy: 0.3420 - val_loss: 1.4501 - val_accuracy: 0.3380\n",
      "Epoch 45/80\n",
      "6435/6435 [==============================] - 0s 41us/step - loss: 1.4386 - accuracy: 0.3397 - val_loss: 1.4522 - val_accuracy: 0.3547\n",
      "Epoch 46/80\n",
      "6435/6435 [==============================] - 0s 38us/step - loss: 1.4358 - accuracy: 0.3453 - val_loss: 1.4462 - val_accuracy: 0.3380\n",
      "Epoch 47/80\n",
      "6435/6435 [==============================] - 0s 37us/step - loss: 1.4307 - accuracy: 0.3445 - val_loss: 1.4384 - val_accuracy: 0.3450\n",
      "Epoch 48/80\n",
      "6435/6435 [==============================] - 0s 37us/step - loss: 1.4293 - accuracy: 0.3479 - val_loss: 1.4395 - val_accuracy: 0.3338\n",
      "Epoch 49/80\n",
      "6435/6435 [==============================] - 0s 36us/step - loss: 1.4265 - accuracy: 0.3493 - val_loss: 1.4591 - val_accuracy: 0.3450\n",
      "Epoch 50/80\n",
      "6435/6435 [==============================] - 0s 35us/step - loss: 1.4292 - accuracy: 0.3372 - val_loss: 1.4435 - val_accuracy: 0.3436\n",
      "Epoch 51/80\n",
      "6435/6435 [==============================] - 0s 36us/step - loss: 1.4241 - accuracy: 0.3470 - val_loss: 1.4407 - val_accuracy: 0.3212\n",
      "Epoch 52/80\n",
      "6435/6435 [==============================] - 0s 42us/step - loss: 1.4201 - accuracy: 0.3489 - val_loss: 1.4242 - val_accuracy: 0.3492\n",
      "Epoch 53/80\n",
      "6435/6435 [==============================] - 0s 35us/step - loss: 1.4128 - accuracy: 0.3568 - val_loss: 1.4271 - val_accuracy: 0.3743\n",
      "Epoch 54/80\n",
      "6435/6435 [==============================] - 0s 36us/step - loss: 1.4185 - accuracy: 0.3532 - val_loss: 1.4182 - val_accuracy: 0.3645\n",
      "Epoch 55/80\n",
      "6435/6435 [==============================] - 0s 40us/step - loss: 1.4099 - accuracy: 0.3493 - val_loss: 1.4131 - val_accuracy: 0.3450\n",
      "Epoch 56/80\n",
      "6435/6435 [==============================] - 0s 39us/step - loss: 1.3990 - accuracy: 0.3590 - val_loss: 1.4100 - val_accuracy: 0.3743\n",
      "Epoch 57/80\n",
      "6435/6435 [==============================] - 0s 37us/step - loss: 1.3958 - accuracy: 0.3736 - val_loss: 1.4001 - val_accuracy: 0.3757\n",
      "Epoch 58/80\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6435/6435 [==============================] - 0s 36us/step - loss: 1.3918 - accuracy: 0.3737 - val_loss: 1.3925 - val_accuracy: 0.3645\n",
      "Epoch 59/80\n",
      "6435/6435 [==============================] - 0s 34us/step - loss: 1.3872 - accuracy: 0.3826 - val_loss: 1.3935 - val_accuracy: 0.3994\n",
      "Epoch 60/80\n",
      "6435/6435 [==============================] - 0s 38us/step - loss: 1.3735 - accuracy: 0.3972 - val_loss: 1.3868 - val_accuracy: 0.3953\n",
      "Epoch 61/80\n",
      "6435/6435 [==============================] - 0s 40us/step - loss: 1.3663 - accuracy: 0.3902 - val_loss: 1.3653 - val_accuracy: 0.4218\n",
      "Epoch 62/80\n",
      "6435/6435 [==============================] - 0s 34us/step - loss: 1.3524 - accuracy: 0.3921 - val_loss: 1.3643 - val_accuracy: 0.3785\n",
      "Epoch 63/80\n",
      "6435/6435 [==============================] - 0s 37us/step - loss: 1.3358 - accuracy: 0.3958 - val_loss: 1.3367 - val_accuracy: 0.3897\n",
      "Epoch 64/80\n",
      "6435/6435 [==============================] - 0s 37us/step - loss: 1.3271 - accuracy: 0.4051 - val_loss: 1.3201 - val_accuracy: 0.4246\n",
      "Epoch 65/80\n",
      "6435/6435 [==============================] - 0s 39us/step - loss: 1.3096 - accuracy: 0.4005 - val_loss: 1.3031 - val_accuracy: 0.4106\n",
      "Epoch 66/80\n",
      "6435/6435 [==============================] - 0s 40us/step - loss: 1.2976 - accuracy: 0.3989 - val_loss: 1.3046 - val_accuracy: 0.4022\n",
      "Epoch 67/80\n",
      "6435/6435 [==============================] - 0s 39us/step - loss: 1.2869 - accuracy: 0.4006 - val_loss: 1.2767 - val_accuracy: 0.4148\n",
      "Epoch 68/80\n",
      "6435/6435 [==============================] - 0s 34us/step - loss: 1.2756 - accuracy: 0.4085 - val_loss: 1.2781 - val_accuracy: 0.4134\n",
      "Epoch 69/80\n",
      "6435/6435 [==============================] - 0s 37us/step - loss: 1.2736 - accuracy: 0.4121 - val_loss: 1.2648 - val_accuracy: 0.3939\n",
      "Epoch 70/80\n",
      "6435/6435 [==============================] - 0s 38us/step - loss: 1.2625 - accuracy: 0.4056 - val_loss: 1.2627 - val_accuracy: 0.4344\n",
      "Epoch 71/80\n",
      "6435/6435 [==============================] - 0s 36us/step - loss: 1.2652 - accuracy: 0.3947 - val_loss: 1.2815 - val_accuracy: 0.4148\n",
      "Epoch 72/80\n",
      "6435/6435 [==============================] - 0s 36us/step - loss: 1.2603 - accuracy: 0.4082 - val_loss: 1.2551 - val_accuracy: 0.4106\n",
      "Epoch 73/80\n",
      "6435/6435 [==============================] - 0s 37us/step - loss: 1.2644 - accuracy: 0.4177 - val_loss: 1.2525 - val_accuracy: 0.4064\n",
      "Epoch 74/80\n",
      "6435/6435 [==============================] - 0s 45us/step - loss: 1.2593 - accuracy: 0.4059 - val_loss: 1.2539 - val_accuracy: 0.3925\n",
      "Epoch 75/80\n",
      "6435/6435 [==============================] - 0s 37us/step - loss: 1.2555 - accuracy: 0.4064 - val_loss: 1.2429 - val_accuracy: 0.4441\n",
      "Epoch 76/80\n",
      "6435/6435 [==============================] - 0s 37us/step - loss: 1.2439 - accuracy: 0.4151 - val_loss: 1.2595 - val_accuracy: 0.4399\n",
      "Epoch 77/80\n",
      "6435/6435 [==============================] - 0s 33us/step - loss: 1.2485 - accuracy: 0.4154 - val_loss: 1.2375 - val_accuracy: 0.4106\n",
      "Epoch 78/80\n",
      "6435/6435 [==============================] - 0s 36us/step - loss: 1.2441 - accuracy: 0.4070 - val_loss: 1.2244 - val_accuracy: 0.4595\n",
      "Epoch 79/80\n",
      "6435/6435 [==============================] - 0s 35us/step - loss: 1.2421 - accuracy: 0.4106 - val_loss: 1.2511 - val_accuracy: 0.4162\n",
      "Epoch 80/80\n",
      "6435/6435 [==============================] - 0s 36us/step - loss: 1.2432 - accuracy: 0.4129 - val_loss: 1.2291 - val_accuracy: 0.4316\n",
      "[[9.57660750e-02 1.21101812e-01 1.13435110e-14 ... 2.42904142e-01\n",
      "  3.05892706e-01 2.16792211e-01]\n",
      " [3.70173901e-02 4.83003333e-02 9.14402123e-22 ... 2.67083244e-03\n",
      "  4.86146212e-02 3.36874053e-02]\n",
      " [2.04588711e-01 2.20682040e-01 3.57746351e-18 ... 4.27596793e-02\n",
      "  3.11615914e-01 2.17503950e-01]\n",
      " ...\n",
      " [2.42144570e-01 2.45189294e-01 1.02985162e-19 ... 5.82104037e-03\n",
      "  2.83724248e-01 2.22543985e-01]\n",
      " [9.91074070e-02 1.20559469e-01 6.50623354e-14 ... 1.15002245e-01\n",
      "  3.67925555e-01 2.59608060e-01]\n",
      " [1.06660664e-01 1.30246341e-01 1.70376713e-14 ... 1.33438662e-01\n",
      "  3.53164792e-01 2.50316501e-01]]\n",
      "[12 10 12 ... 12 12 12]\n",
      "<class 'numpy.ndarray'>\n",
      "One CNN, r:  0\n",
      "Computing Time:  0:04:40.030478\n",
      "n, p1, p2 8 0 8\n",
      "Model: \"sequential_1\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv1d_1 (Conv1D)            (None, 3, 6)              12        \n",
      "_________________________________________________________________\n",
      "average_pooling1d_1 (Average (None, 1, 6)              0         \n",
      "_________________________________________________________________\n",
      "conv1d_2 (Conv1D)            (None, 1, 16)             112       \n",
      "_________________________________________________________________\n",
      "average_pooling1d_2 (Average (None, 1, 16)             0         \n",
      "_________________________________________________________________\n",
      "conv1d_3 (Conv1D)            (None, 1, 120)            2040      \n",
      "_________________________________________________________________\n",
      "flatten_1 (Flatten)          (None, 120)               0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 84)                10164     \n",
      "_________________________________________________________________\n",
      "preds (Dense)                (None, 14)                1190      \n",
      "=================================================================\n",
      "Total params: 13,518\n",
      "Trainable params: 13,518\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Train on 6435 samples, validate on 716 samples\n",
      "Epoch 1/80\n",
      "6435/6435 [==============================] - 0s 69us/step - loss: 2.6002 - accuracy: 0.1413 - val_loss: 2.5272 - val_accuracy: 0.1355\n",
      "Epoch 2/80\n",
      "6435/6435 [==============================] - 0s 41us/step - loss: 2.3509 - accuracy: 0.2090 - val_loss: 2.1046 - val_accuracy: 0.2570\n",
      "Epoch 3/80\n",
      "6435/6435 [==============================] - 0s 36us/step - loss: 2.0004 - accuracy: 0.2772 - val_loss: 1.8654 - val_accuracy: 0.2905\n",
      "Epoch 4/80\n",
      "6435/6435 [==============================] - 0s 38us/step - loss: 1.8656 - accuracy: 0.2814 - val_loss: 1.7739 - val_accuracy: 0.3184\n",
      "Epoch 5/80\n",
      "6435/6435 [==============================] - 0s 34us/step - loss: 1.7974 - accuracy: 0.2884 - val_loss: 1.7137 - val_accuracy: 0.3142\n",
      "Epoch 6/80\n",
      "6435/6435 [==============================] - 0s 35us/step - loss: 1.7374 - accuracy: 0.2853 - val_loss: 1.6678 - val_accuracy: 0.3324\n",
      "Epoch 7/80\n",
      "6435/6435 [==============================] - 0s 36us/step - loss: 1.7013 - accuracy: 0.2971 - val_loss: 1.6205 - val_accuracy: 0.3436\n",
      "Epoch 8/80\n",
      "6435/6435 [==============================] - 0s 35us/step - loss: 1.6772 - accuracy: 0.3040 - val_loss: 1.6101 - val_accuracy: 0.3366\n",
      "Epoch 9/80\n",
      "6435/6435 [==============================] - 0s 36us/step - loss: 1.6568 - accuracy: 0.3061 - val_loss: 1.5937 - val_accuracy: 0.3478\n",
      "Epoch 10/80\n",
      "6435/6435 [==============================] - 0s 40us/step - loss: 1.6465 - accuracy: 0.3124 - val_loss: 1.5834 - val_accuracy: 0.3450\n",
      "Epoch 11/80\n",
      "6435/6435 [==============================] - 0s 35us/step - loss: 1.6394 - accuracy: 0.3184 - val_loss: 1.5776 - val_accuracy: 0.3324\n",
      "Epoch 12/80\n",
      "6435/6435 [==============================] - 0s 37us/step - loss: 1.6374 - accuracy: 0.3102 - val_loss: 1.5746 - val_accuracy: 0.3380\n",
      "Epoch 13/80\n",
      "6435/6435 [==============================] - 0s 40us/step - loss: 1.6318 - accuracy: 0.3124 - val_loss: 1.5680 - val_accuracy: 0.3520\n",
      "Epoch 14/80\n",
      "6435/6435 [==============================] - 0s 36us/step - loss: 1.6304 - accuracy: 0.3167 - val_loss: 1.5634 - val_accuracy: 0.3450\n",
      "Epoch 15/80\n",
      "6435/6435 [==============================] - 0s 36us/step - loss: 1.6230 - accuracy: 0.3124 - val_loss: 1.6044 - val_accuracy: 0.3268\n",
      "Epoch 16/80\n",
      "6435/6435 [==============================] - 0s 36us/step - loss: 1.6324 - accuracy: 0.3128 - val_loss: 1.5721 - val_accuracy: 0.3506\n",
      "Epoch 17/80\n",
      "6435/6435 [==============================] - 0s 40us/step - loss: 1.6296 - accuracy: 0.3094 - val_loss: 1.5855 - val_accuracy: 0.3198\n",
      "Epoch 18/80\n",
      "6435/6435 [==============================] - 0s 41us/step - loss: 1.6246 - accuracy: 0.3061 - val_loss: 1.5629 - val_accuracy: 0.3520\n",
      "Epoch 19/80\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6435/6435 [==============================] - 0s 39us/step - loss: 1.6199 - accuracy: 0.3125 - val_loss: 1.5576 - val_accuracy: 0.3561\n",
      "Epoch 20/80\n",
      "6435/6435 [==============================] - 0s 39us/step - loss: 1.6243 - accuracy: 0.3119 - val_loss: 1.5708 - val_accuracy: 0.3324\n",
      "Epoch 21/80\n",
      "6435/6435 [==============================] - 0s 39us/step - loss: 1.6172 - accuracy: 0.3195 - val_loss: 1.5607 - val_accuracy: 0.3394\n",
      "Epoch 22/80\n",
      "6435/6435 [==============================] - 0s 37us/step - loss: 1.6175 - accuracy: 0.3128 - val_loss: 1.5576 - val_accuracy: 0.3394\n",
      "Epoch 23/80\n",
      "6435/6435 [==============================] - 0s 34us/step - loss: 1.6193 - accuracy: 0.3181 - val_loss: 1.5640 - val_accuracy: 0.3478\n",
      "Epoch 24/80\n",
      "6435/6435 [==============================] - 0s 35us/step - loss: 1.6163 - accuracy: 0.3152 - val_loss: 1.5493 - val_accuracy: 0.3436\n",
      "Epoch 25/80\n",
      "6435/6435 [==============================] - 0s 38us/step - loss: 1.6141 - accuracy: 0.3125 - val_loss: 1.5526 - val_accuracy: 0.3338\n",
      "Epoch 26/80\n",
      "6435/6435 [==============================] - 0s 39us/step - loss: 1.6163 - accuracy: 0.3100 - val_loss: 1.5720 - val_accuracy: 0.3408\n",
      "Epoch 27/80\n",
      "6435/6435 [==============================] - 0s 36us/step - loss: 1.6153 - accuracy: 0.3120 - val_loss: 1.5530 - val_accuracy: 0.3352\n",
      "Epoch 28/80\n",
      "6435/6435 [==============================] - 0s 36us/step - loss: 1.6142 - accuracy: 0.3124 - val_loss: 1.5606 - val_accuracy: 0.3422\n",
      "Epoch 29/80\n",
      "6435/6435 [==============================] - 0s 36us/step - loss: 1.6152 - accuracy: 0.3119 - val_loss: 1.5616 - val_accuracy: 0.3380\n",
      "Epoch 30/80\n",
      "6435/6435 [==============================] - 0s 39us/step - loss: 1.6144 - accuracy: 0.3173 - val_loss: 1.5683 - val_accuracy: 0.3268\n",
      "Epoch 31/80\n",
      "6435/6435 [==============================] - 0s 39us/step - loss: 1.6147 - accuracy: 0.3161 - val_loss: 1.5580 - val_accuracy: 0.3352\n",
      "Epoch 32/80\n",
      "6435/6435 [==============================] - 0s 44us/step - loss: 1.6138 - accuracy: 0.3155 - val_loss: 1.5543 - val_accuracy: 0.3534\n",
      "Epoch 33/80\n",
      "6435/6435 [==============================] - 0s 37us/step - loss: 1.6125 - accuracy: 0.3117 - val_loss: 1.5505 - val_accuracy: 0.3380\n",
      "Epoch 34/80\n",
      "6435/6435 [==============================] - 0s 33us/step - loss: 1.6099 - accuracy: 0.3108 - val_loss: 1.5517 - val_accuracy: 0.3492\n",
      "Epoch 00034: early stopping\n",
      "[[1.2553476e-01 1.2571627e-01 3.7021022e-11 ... 3.0252278e-01\n",
      "  1.5575607e-01 1.4928390e-01]\n",
      " [7.9197794e-02 7.4311957e-02 2.7634672e-17 ... 1.3106966e-03\n",
      "  7.8260534e-02 8.9829072e-02]\n",
      " [1.3367198e-01 1.3308205e-01 3.5680022e-15 ... 2.3494696e-02\n",
      "  1.2536892e-01 1.3453095e-01]\n",
      " ...\n",
      " [8.8969104e-02 8.5183710e-02 5.7144198e-17 ... 2.0997638e-03\n",
      "  8.2159832e-02 9.4965696e-02]\n",
      " [1.4503244e-01 1.2607458e-01 3.8869780e-10 ... 2.3301999e-01\n",
      "  1.5680888e-01 1.5001622e-01]\n",
      " [1.3043104e-01 1.2664589e-01 7.3635029e-11 ... 2.8196058e-01\n",
      "  1.5716174e-01 1.5049686e-01]]\n",
      "[11  5  5 ...  5 11 11]\n",
      "<class 'numpy.ndarray'>\n",
      "One CNN, r:  0\n",
      "Computing Time:  0:04:49.770803\n",
      "n, p1, p2 9 0 9\n",
      "Model: \"sequential_1\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv1d_1 (Conv1D)            (None, 3, 6)              12        \n",
      "_________________________________________________________________\n",
      "average_pooling1d_1 (Average (None, 1, 6)              0         \n",
      "_________________________________________________________________\n",
      "conv1d_2 (Conv1D)            (None, 1, 16)             112       \n",
      "_________________________________________________________________\n",
      "average_pooling1d_2 (Average (None, 1, 16)             0         \n",
      "_________________________________________________________________\n",
      "conv1d_3 (Conv1D)            (None, 1, 120)            2040      \n",
      "_________________________________________________________________\n",
      "flatten_1 (Flatten)          (None, 120)               0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 84)                10164     \n",
      "_________________________________________________________________\n",
      "preds (Dense)                (None, 14)                1190      \n",
      "=================================================================\n",
      "Total params: 13,518\n",
      "Trainable params: 13,518\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Train on 6435 samples, validate on 716 samples\n",
      "Epoch 1/80\n",
      "6435/6435 [==============================] - 0s 71us/step - loss: 2.6059 - accuracy: 0.1431 - val_loss: 2.5332 - val_accuracy: 0.1466\n",
      "Epoch 2/80\n",
      "6435/6435 [==============================] - 0s 41us/step - loss: 2.3508 - accuracy: 0.1745 - val_loss: 2.1756 - val_accuracy: 0.1983\n",
      "Epoch 3/80\n",
      "6435/6435 [==============================] - 0s 36us/step - loss: 2.0604 - accuracy: 0.2146 - val_loss: 2.0426 - val_accuracy: 0.2444\n",
      "Epoch 4/80\n",
      "6435/6435 [==============================] - 0s 39us/step - loss: 1.9432 - accuracy: 0.2356 - val_loss: 1.9494 - val_accuracy: 0.2877\n",
      "Epoch 5/80\n",
      "6435/6435 [==============================] - 0s 36us/step - loss: 1.8562 - accuracy: 0.2765 - val_loss: 1.8691 - val_accuracy: 0.2891\n",
      "Epoch 6/80\n",
      "6435/6435 [==============================] - 0s 37us/step - loss: 1.7953 - accuracy: 0.2844 - val_loss: 1.8005 - val_accuracy: 0.2863\n",
      "Epoch 7/80\n",
      "6435/6435 [==============================] - 0s 35us/step - loss: 1.7508 - accuracy: 0.2920 - val_loss: 1.7606 - val_accuracy: 0.2807\n",
      "Epoch 8/80\n",
      "6435/6435 [==============================] - 0s 39us/step - loss: 1.7205 - accuracy: 0.2889 - val_loss: 1.7229 - val_accuracy: 0.3128\n",
      "Epoch 9/80\n",
      "6435/6435 [==============================] - 0s 39us/step - loss: 1.7025 - accuracy: 0.2911 - val_loss: 1.7206 - val_accuracy: 0.3212\n",
      "Epoch 10/80\n",
      "6435/6435 [==============================] - 0s 37us/step - loss: 1.6924 - accuracy: 0.2903 - val_loss: 1.7012 - val_accuracy: 0.3352\n",
      "Epoch 11/80\n",
      "6435/6435 [==============================] - 0s 35us/step - loss: 1.6803 - accuracy: 0.2974 - val_loss: 1.7010 - val_accuracy: 0.2961\n",
      "Epoch 12/80\n",
      "6435/6435 [==============================] - 0s 39us/step - loss: 1.6785 - accuracy: 0.2928 - val_loss: 1.6827 - val_accuracy: 0.2975\n",
      "Epoch 13/80\n",
      "6435/6435 [==============================] - 0s 46us/step - loss: 1.6681 - accuracy: 0.2934 - val_loss: 1.6773 - val_accuracy: 0.3324\n",
      "Epoch 14/80\n",
      "6435/6435 [==============================] - 0s 33us/step - loss: 1.6688 - accuracy: 0.3013 - val_loss: 1.6868 - val_accuracy: 0.3115\n",
      "Epoch 15/80\n",
      "6435/6435 [==============================] - 0s 36us/step - loss: 1.6589 - accuracy: 0.2998 - val_loss: 1.6573 - val_accuracy: 0.3254\n",
      "Epoch 16/80\n",
      "6435/6435 [==============================] - 0s 37us/step - loss: 1.6538 - accuracy: 0.2981 - val_loss: 1.6654 - val_accuracy: 0.3268\n",
      "Epoch 17/80\n",
      "6435/6435 [==============================] - 0s 38us/step - loss: 1.6521 - accuracy: 0.2918 - val_loss: 1.6575 - val_accuracy: 0.3268\n",
      "Epoch 18/80\n",
      "6435/6435 [==============================] - 0s 42us/step - loss: 1.6600 - accuracy: 0.2987 - val_loss: 1.6693 - val_accuracy: 0.3156\n",
      "Epoch 19/80\n",
      "6435/6435 [==============================] - 0s 40us/step - loss: 1.6494 - accuracy: 0.2973 - val_loss: 1.6491 - val_accuracy: 0.3226\n",
      "Epoch 20/80\n",
      "6435/6435 [==============================] - 0s 36us/step - loss: 1.6469 - accuracy: 0.2993 - val_loss: 1.6507 - val_accuracy: 0.3366\n",
      "Epoch 21/80\n",
      "6435/6435 [==============================] - 0s 33us/step - loss: 1.6440 - accuracy: 0.3041 - val_loss: 1.6503 - val_accuracy: 0.3142\n",
      "Epoch 22/80\n",
      "6435/6435 [==============================] - 0s 40us/step - loss: 1.6493 - accuracy: 0.2971 - val_loss: 1.6513 - val_accuracy: 0.2933\n",
      "Epoch 23/80\n",
      "6435/6435 [==============================] - 0s 32us/step - loss: 1.6446 - accuracy: 0.3026 - val_loss: 1.6491 - val_accuracy: 0.3268\n",
      "Epoch 24/80\n",
      "6435/6435 [==============================] - 0s 35us/step - loss: 1.6427 - accuracy: 0.3026 - val_loss: 1.6393 - val_accuracy: 0.3352\n",
      "Epoch 25/80\n",
      "6435/6435 [==============================] - 0s 35us/step - loss: 1.6408 - accuracy: 0.2976 - val_loss: 1.6434 - val_accuracy: 0.3101\n",
      "Epoch 26/80\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6435/6435 [==============================] - 0s 36us/step - loss: 1.6392 - accuracy: 0.2993 - val_loss: 1.6340 - val_accuracy: 0.3212\n",
      "Epoch 27/80\n",
      "6435/6435 [==============================] - 0s 34us/step - loss: 1.6384 - accuracy: 0.3030 - val_loss: 1.6436 - val_accuracy: 0.3156\n",
      "Epoch 28/80\n",
      "6435/6435 [==============================] - 0s 32us/step - loss: 1.6391 - accuracy: 0.3013 - val_loss: 1.6412 - val_accuracy: 0.2961\n",
      "Epoch 29/80\n",
      "6435/6435 [==============================] - 0s 35us/step - loss: 1.6372 - accuracy: 0.2981 - val_loss: 1.6396 - val_accuracy: 0.3324\n",
      "Epoch 30/80\n",
      "6435/6435 [==============================] - 0s 34us/step - loss: 1.6398 - accuracy: 0.3010 - val_loss: 1.6393 - val_accuracy: 0.3059\n",
      "Epoch 31/80\n",
      "6435/6435 [==============================] - 0s 36us/step - loss: 1.6360 - accuracy: 0.3052 - val_loss: 1.6385 - val_accuracy: 0.3184\n",
      "Epoch 32/80\n",
      "6435/6435 [==============================] - 0s 33us/step - loss: 1.6368 - accuracy: 0.2999 - val_loss: 1.6455 - val_accuracy: 0.3198\n",
      "Epoch 33/80\n",
      "6435/6435 [==============================] - 0s 34us/step - loss: 1.6391 - accuracy: 0.3012 - val_loss: 1.6339 - val_accuracy: 0.3268\n",
      "Epoch 34/80\n",
      "6435/6435 [==============================] - 0s 34us/step - loss: 1.6406 - accuracy: 0.3029 - val_loss: 1.6416 - val_accuracy: 0.3017\n",
      "Epoch 35/80\n",
      "6435/6435 [==============================] - 0s 36us/step - loss: 1.6392 - accuracy: 0.2976 - val_loss: 1.6310 - val_accuracy: 0.3254\n",
      "Epoch 36/80\n",
      "6435/6435 [==============================] - 0s 36us/step - loss: 1.6383 - accuracy: 0.3005 - val_loss: 1.6439 - val_accuracy: 0.3184\n",
      "Epoch 37/80\n",
      "6435/6435 [==============================] - 0s 36us/step - loss: 1.6357 - accuracy: 0.2985 - val_loss: 1.6283 - val_accuracy: 0.3170\n",
      "Epoch 38/80\n",
      "6435/6435 [==============================] - 0s 32us/step - loss: 1.6297 - accuracy: 0.3037 - val_loss: 1.6272 - val_accuracy: 0.3212\n",
      "Epoch 39/80\n",
      "6435/6435 [==============================] - 0s 32us/step - loss: 1.6356 - accuracy: 0.2999 - val_loss: 1.6236 - val_accuracy: 0.3296\n",
      "Epoch 40/80\n",
      "6435/6435 [==============================] - 0s 39us/step - loss: 1.6327 - accuracy: 0.3002 - val_loss: 1.6392 - val_accuracy: 0.3045\n",
      "Epoch 41/80\n",
      "6435/6435 [==============================] - 0s 36us/step - loss: 1.6330 - accuracy: 0.2956 - val_loss: 1.6379 - val_accuracy: 0.3422\n",
      "Epoch 42/80\n",
      "6435/6435 [==============================] - 0s 36us/step - loss: 1.6330 - accuracy: 0.2984 - val_loss: 1.6263 - val_accuracy: 0.3240\n",
      "Epoch 43/80\n",
      "6435/6435 [==============================] - 0s 38us/step - loss: 1.6332 - accuracy: 0.2967 - val_loss: 1.6287 - val_accuracy: 0.3282\n",
      "Epoch 44/80\n",
      "6435/6435 [==============================] - 0s 32us/step - loss: 1.6292 - accuracy: 0.3024 - val_loss: 1.6444 - val_accuracy: 0.3073\n",
      "Epoch 45/80\n",
      "6435/6435 [==============================] - 0s 39us/step - loss: 1.6289 - accuracy: 0.3002 - val_loss: 1.6381 - val_accuracy: 0.3128\n",
      "Epoch 46/80\n",
      "6435/6435 [==============================] - 0s 34us/step - loss: 1.6297 - accuracy: 0.3035 - val_loss: 1.6394 - val_accuracy: 0.3059\n",
      "Epoch 47/80\n",
      "6435/6435 [==============================] - 0s 34us/step - loss: 1.6309 - accuracy: 0.2965 - val_loss: 1.6350 - val_accuracy: 0.3198\n",
      "Epoch 48/80\n",
      "6435/6435 [==============================] - 0s 38us/step - loss: 1.6270 - accuracy: 0.3041 - val_loss: 1.6292 - val_accuracy: 0.3017\n",
      "Epoch 49/80\n",
      "6435/6435 [==============================] - 0s 36us/step - loss: 1.6281 - accuracy: 0.2968 - val_loss: 1.6300 - val_accuracy: 0.3254\n",
      "Epoch 00049: early stopping\n",
      "[[1.7328624e-01 1.4345318e-01 3.4122991e-07 ... 2.1025898e-01\n",
      "  1.5512347e-01 1.2951665e-01]\n",
      " [8.9995734e-02 7.8087643e-02 4.8723438e-11 ... 3.4025172e-04\n",
      "  8.9327104e-02 7.6333165e-02]\n",
      " [1.6653183e-01 1.4098266e-01 1.0101820e-09 ... 1.2157603e-02\n",
      "  1.2142558e-01 1.0267908e-01]\n",
      " ...\n",
      " [1.0339408e-01 8.9801237e-02 7.7427328e-11 ... 6.0890522e-04\n",
      "  9.4297506e-02 8.0206007e-02]\n",
      " [1.4810506e-01 1.4337079e-01 1.2776887e-06 ... 1.6383064e-01\n",
      "  1.6076346e-01 1.3259497e-01]\n",
      " [1.6657841e-01 1.4425643e-01 5.0199060e-07 ... 1.9680691e-01\n",
      "  1.5763097e-01 1.3114765e-01]]\n",
      "[11  5  5 ...  5 11 11]\n",
      "<class 'numpy.ndarray'>\n",
      "One CNN, r:  0\n",
      "Computing Time:  0:05:03.036500\n",
      "n, p1, p2 10 0 10\n",
      "Model: \"sequential_1\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv1d_1 (Conv1D)            (None, 3, 6)              12        \n",
      "_________________________________________________________________\n",
      "average_pooling1d_1 (Average (None, 1, 6)              0         \n",
      "_________________________________________________________________\n",
      "conv1d_2 (Conv1D)            (None, 1, 16)             112       \n",
      "_________________________________________________________________\n",
      "average_pooling1d_2 (Average (None, 1, 16)             0         \n",
      "_________________________________________________________________\n",
      "conv1d_3 (Conv1D)            (None, 1, 120)            2040      \n",
      "_________________________________________________________________\n",
      "flatten_1 (Flatten)          (None, 120)               0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 84)                10164     \n",
      "_________________________________________________________________\n",
      "preds (Dense)                (None, 14)                1190      \n",
      "=================================================================\n",
      "Total params: 13,518\n",
      "Trainable params: 13,518\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Train on 6435 samples, validate on 716 samples\n",
      "Epoch 1/80\n",
      "6435/6435 [==============================] - 0s 75us/step - loss: 2.5955 - accuracy: 0.1775 - val_loss: 2.5030 - val_accuracy: 0.1899\n",
      "Epoch 2/80\n",
      "6435/6435 [==============================] - 0s 38us/step - loss: 2.3011 - accuracy: 0.2030 - val_loss: 2.1218 - val_accuracy: 0.2360\n",
      "Epoch 3/80\n",
      "6435/6435 [==============================] - 0s 41us/step - loss: 2.0006 - accuracy: 0.2859 - val_loss: 1.9192 - val_accuracy: 0.2500\n",
      "Epoch 4/80\n",
      "6435/6435 [==============================] - 0s 38us/step - loss: 1.8561 - accuracy: 0.2909 - val_loss: 1.8543 - val_accuracy: 0.2626\n",
      "Epoch 5/80\n",
      "6435/6435 [==============================] - 0s 37us/step - loss: 1.7685 - accuracy: 0.2970 - val_loss: 1.7510 - val_accuracy: 0.2793\n",
      "Epoch 6/80\n",
      "6435/6435 [==============================] - 0s 36us/step - loss: 1.6990 - accuracy: 0.3002 - val_loss: 1.7141 - val_accuracy: 0.2779\n",
      "Epoch 7/80\n",
      "6435/6435 [==============================] - 0s 37us/step - loss: 1.6491 - accuracy: 0.3111 - val_loss: 1.6877 - val_accuracy: 0.2751\n",
      "Epoch 8/80\n",
      "6435/6435 [==============================] - 0s 37us/step - loss: 1.6102 - accuracy: 0.3069 - val_loss: 1.6362 - val_accuracy: 0.2598\n",
      "Epoch 9/80\n",
      "6435/6435 [==============================] - 0s 36us/step - loss: 1.5762 - accuracy: 0.3026 - val_loss: 1.6078 - val_accuracy: 0.2793\n",
      "Epoch 10/80\n",
      "6435/6435 [==============================] - 0s 35us/step - loss: 1.5539 - accuracy: 0.3124 - val_loss: 1.5878 - val_accuracy: 0.2807\n",
      "Epoch 11/80\n",
      "6435/6435 [==============================] - 0s 35us/step - loss: 1.5398 - accuracy: 0.3086 - val_loss: 1.5775 - val_accuracy: 0.2905\n",
      "Epoch 12/80\n",
      "6435/6435 [==============================] - 0s 36us/step - loss: 1.5337 - accuracy: 0.3106 - val_loss: 1.5692 - val_accuracy: 0.2877\n",
      "Epoch 13/80\n",
      "6435/6435 [==============================] - 0s 32us/step - loss: 1.5287 - accuracy: 0.3100 - val_loss: 1.5731 - val_accuracy: 0.2905\n",
      "Epoch 14/80\n",
      "6435/6435 [==============================] - 0s 38us/step - loss: 1.5221 - accuracy: 0.3155 - val_loss: 1.5636 - val_accuracy: 0.3031\n",
      "Epoch 15/80\n",
      "6435/6435 [==============================] - 0s 34us/step - loss: 1.5167 - accuracy: 0.3178 - val_loss: 1.5527 - val_accuracy: 0.2919\n",
      "Epoch 16/80\n",
      "6435/6435 [==============================] - 0s 34us/step - loss: 1.5109 - accuracy: 0.3088 - val_loss: 1.5527 - val_accuracy: 0.2863\n",
      "Epoch 17/80\n",
      "6435/6435 [==============================] - 0s 36us/step - loss: 1.5142 - accuracy: 0.3099 - val_loss: 1.5743 - val_accuracy: 0.2821\n",
      "Epoch 18/80\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6435/6435 [==============================] - 0s 36us/step - loss: 1.5044 - accuracy: 0.3138 - val_loss: 1.5403 - val_accuracy: 0.2863\n",
      "Epoch 19/80\n",
      "6435/6435 [==============================] - 0s 36us/step - loss: 1.4956 - accuracy: 0.3246 - val_loss: 1.5408 - val_accuracy: 0.2919\n",
      "Epoch 20/80\n",
      "6435/6435 [==============================] - 0s 36us/step - loss: 1.4974 - accuracy: 0.3221 - val_loss: 1.5474 - val_accuracy: 0.2849\n",
      "Epoch 21/80\n",
      "6435/6435 [==============================] - 0s 34us/step - loss: 1.4977 - accuracy: 0.3102 - val_loss: 1.5448 - val_accuracy: 0.2905\n",
      "Epoch 22/80\n",
      "6435/6435 [==============================] - 0s 36us/step - loss: 1.4897 - accuracy: 0.3158 - val_loss: 1.5355 - val_accuracy: 0.2947\n",
      "Epoch 23/80\n",
      "6435/6435 [==============================] - 0s 34us/step - loss: 1.4880 - accuracy: 0.3225 - val_loss: 1.5287 - val_accuracy: 0.2975\n",
      "Epoch 24/80\n",
      "6435/6435 [==============================] - 0s 36us/step - loss: 1.4848 - accuracy: 0.3229 - val_loss: 1.5208 - val_accuracy: 0.2989\n",
      "Epoch 25/80\n",
      "6435/6435 [==============================] - 0s 37us/step - loss: 1.4887 - accuracy: 0.3254 - val_loss: 1.5340 - val_accuracy: 0.2849\n",
      "Epoch 26/80\n",
      "6435/6435 [==============================] - 0s 34us/step - loss: 1.4826 - accuracy: 0.3164 - val_loss: 1.5215 - val_accuracy: 0.2975\n",
      "Epoch 27/80\n",
      "6435/6435 [==============================] - 0s 37us/step - loss: 1.4792 - accuracy: 0.3209 - val_loss: 1.5334 - val_accuracy: 0.3017\n",
      "Epoch 28/80\n",
      "6435/6435 [==============================] - 0s 34us/step - loss: 1.4752 - accuracy: 0.3209 - val_loss: 1.5283 - val_accuracy: 0.2877\n",
      "Epoch 29/80\n",
      "6435/6435 [==============================] - 0s 34us/step - loss: 1.4767 - accuracy: 0.3138 - val_loss: 1.5088 - val_accuracy: 0.3268\n",
      "Epoch 30/80\n",
      "6435/6435 [==============================] - 0s 36us/step - loss: 1.4750 - accuracy: 0.3274 - val_loss: 1.5363 - val_accuracy: 0.2849\n",
      "Epoch 31/80\n",
      "6435/6435 [==============================] - 0s 34us/step - loss: 1.4708 - accuracy: 0.3201 - val_loss: 1.5188 - val_accuracy: 0.2933\n",
      "Epoch 32/80\n",
      "6435/6435 [==============================] - 0s 33us/step - loss: 1.4775 - accuracy: 0.3158 - val_loss: 1.5211 - val_accuracy: 0.3073\n",
      "Epoch 33/80\n",
      "6435/6435 [==============================] - 0s 37us/step - loss: 1.4667 - accuracy: 0.3262 - val_loss: 1.5240 - val_accuracy: 0.2891\n",
      "Epoch 34/80\n",
      "6435/6435 [==============================] - 0s 37us/step - loss: 1.4696 - accuracy: 0.3186 - val_loss: 1.5101 - val_accuracy: 0.2933\n",
      "Epoch 35/80\n",
      "6435/6435 [==============================] - 0s 36us/step - loss: 1.4660 - accuracy: 0.3220 - val_loss: 1.5056 - val_accuracy: 0.3128\n",
      "Epoch 36/80\n",
      "6435/6435 [==============================] - 0s 40us/step - loss: 1.4666 - accuracy: 0.3260 - val_loss: 1.5059 - val_accuracy: 0.2849\n",
      "Epoch 37/80\n",
      "6435/6435 [==============================] - 0s 36us/step - loss: 1.4625 - accuracy: 0.3240 - val_loss: 1.5010 - val_accuracy: 0.2919\n",
      "Epoch 38/80\n",
      "6435/6435 [==============================] - 0s 35us/step - loss: 1.4642 - accuracy: 0.3240 - val_loss: 1.5024 - val_accuracy: 0.3017\n",
      "Epoch 39/80\n",
      "6435/6435 [==============================] - 0s 33us/step - loss: 1.4624 - accuracy: 0.3215 - val_loss: 1.5159 - val_accuracy: 0.2989\n",
      "Epoch 40/80\n",
      "6435/6435 [==============================] - 0s 34us/step - loss: 1.4655 - accuracy: 0.3228 - val_loss: 1.5060 - val_accuracy: 0.2793\n",
      "Epoch 41/80\n",
      "6435/6435 [==============================] - 0s 35us/step - loss: 1.4598 - accuracy: 0.3248 - val_loss: 1.4996 - val_accuracy: 0.3268\n",
      "Epoch 42/80\n",
      "6435/6435 [==============================] - 0s 33us/step - loss: 1.4583 - accuracy: 0.3251 - val_loss: 1.4995 - val_accuracy: 0.2891\n",
      "Epoch 43/80\n",
      "6435/6435 [==============================] - 0s 36us/step - loss: 1.4530 - accuracy: 0.3221 - val_loss: 1.4999 - val_accuracy: 0.3045\n",
      "Epoch 44/80\n",
      "6435/6435 [==============================] - 0s 34us/step - loss: 1.4505 - accuracy: 0.3354 - val_loss: 1.5191 - val_accuracy: 0.2849\n",
      "Epoch 45/80\n",
      "6435/6435 [==============================] - 0s 39us/step - loss: 1.4540 - accuracy: 0.3195 - val_loss: 1.4970 - val_accuracy: 0.3156\n",
      "Epoch 46/80\n",
      "6435/6435 [==============================] - 0s 36us/step - loss: 1.4515 - accuracy: 0.3285 - val_loss: 1.4922 - val_accuracy: 0.3282\n",
      "Epoch 47/80\n",
      "6435/6435 [==============================] - 0s 39us/step - loss: 1.4525 - accuracy: 0.3262 - val_loss: 1.5044 - val_accuracy: 0.3073\n",
      "Epoch 48/80\n",
      "6435/6435 [==============================] - 0s 33us/step - loss: 1.4508 - accuracy: 0.3265 - val_loss: 1.4858 - val_accuracy: 0.3156\n",
      "Epoch 49/80\n",
      "6435/6435 [==============================] - 0s 33us/step - loss: 1.4461 - accuracy: 0.3316 - val_loss: 1.4943 - val_accuracy: 0.3142\n",
      "Epoch 50/80\n",
      "6435/6435 [==============================] - 0s 33us/step - loss: 1.4448 - accuracy: 0.3301 - val_loss: 1.5005 - val_accuracy: 0.2905\n",
      "Epoch 51/80\n",
      "6435/6435 [==============================] - 0s 36us/step - loss: 1.4459 - accuracy: 0.3372 - val_loss: 1.4909 - val_accuracy: 0.3128\n",
      "Epoch 52/80\n",
      "6435/6435 [==============================] - 0s 37us/step - loss: 1.4408 - accuracy: 0.3336 - val_loss: 1.4996 - val_accuracy: 0.3198\n",
      "Epoch 53/80\n",
      "6435/6435 [==============================] - 0s 38us/step - loss: 1.4430 - accuracy: 0.3350 - val_loss: 1.4929 - val_accuracy: 0.2933\n",
      "Epoch 54/80\n",
      "6435/6435 [==============================] - 0s 35us/step - loss: 1.4387 - accuracy: 0.3427 - val_loss: 1.4856 - val_accuracy: 0.3087\n",
      "Epoch 55/80\n",
      "6435/6435 [==============================] - 0s 34us/step - loss: 1.4388 - accuracy: 0.3439 - val_loss: 1.4691 - val_accuracy: 0.3254\n",
      "Epoch 56/80\n",
      "6435/6435 [==============================] - 0s 35us/step - loss: 1.4360 - accuracy: 0.3374 - val_loss: 1.4745 - val_accuracy: 0.3450\n",
      "Epoch 57/80\n",
      "6435/6435 [==============================] - 0s 36us/step - loss: 1.4314 - accuracy: 0.3335 - val_loss: 1.4698 - val_accuracy: 0.3408\n",
      "Epoch 58/80\n",
      "6435/6435 [==============================] - 0s 33us/step - loss: 1.4264 - accuracy: 0.3441 - val_loss: 1.4651 - val_accuracy: 0.3324\n",
      "Epoch 59/80\n",
      "6435/6435 [==============================] - 0s 35us/step - loss: 1.4211 - accuracy: 0.3462 - val_loss: 1.4541 - val_accuracy: 0.3715\n",
      "Epoch 60/80\n",
      "6435/6435 [==============================] - 0s 32us/step - loss: 1.4140 - accuracy: 0.3534 - val_loss: 1.4594 - val_accuracy: 0.3408\n",
      "Epoch 61/80\n",
      "6435/6435 [==============================] - 0s 36us/step - loss: 1.4123 - accuracy: 0.3531 - val_loss: 1.4623 - val_accuracy: 0.3268\n",
      "Epoch 62/80\n",
      "6435/6435 [==============================] - 0s 36us/step - loss: 1.4091 - accuracy: 0.3650 - val_loss: 1.4443 - val_accuracy: 0.3478\n",
      "Epoch 63/80\n",
      "6435/6435 [==============================] - 0s 39us/step - loss: 1.3973 - accuracy: 0.3624 - val_loss: 1.4265 - val_accuracy: 0.3534\n",
      "Epoch 64/80\n",
      "6435/6435 [==============================] - 0s 34us/step - loss: 1.3885 - accuracy: 0.3722 - val_loss: 1.4223 - val_accuracy: 0.3561\n",
      "Epoch 65/80\n",
      "6435/6435 [==============================] - 0s 34us/step - loss: 1.3829 - accuracy: 0.3748 - val_loss: 1.4190 - val_accuracy: 0.3436\n",
      "Epoch 66/80\n",
      "6435/6435 [==============================] - 0s 38us/step - loss: 1.3699 - accuracy: 0.3709 - val_loss: 1.3965 - val_accuracy: 0.3771\n",
      "Epoch 67/80\n",
      "6435/6435 [==============================] - 0s 37us/step - loss: 1.3626 - accuracy: 0.3781 - val_loss: 1.3936 - val_accuracy: 0.3520\n",
      "Epoch 68/80\n",
      "6435/6435 [==============================] - 0s 34us/step - loss: 1.3491 - accuracy: 0.3798 - val_loss: 1.3936 - val_accuracy: 0.3687\n",
      "Epoch 69/80\n",
      "6435/6435 [==============================] - 0s 36us/step - loss: 1.3358 - accuracy: 0.3851 - val_loss: 1.3658 - val_accuracy: 0.3953\n",
      "Epoch 70/80\n",
      "6435/6435 [==============================] - 0s 36us/step - loss: 1.3255 - accuracy: 0.3804 - val_loss: 1.3612 - val_accuracy: 0.3743\n",
      "Epoch 71/80\n",
      "6435/6435 [==============================] - 0s 33us/step - loss: 1.3152 - accuracy: 0.3832 - val_loss: 1.3494 - val_accuracy: 0.3589\n",
      "Epoch 72/80\n",
      "6435/6435 [==============================] - 0s 39us/step - loss: 1.3091 - accuracy: 0.3849 - val_loss: 1.3284 - val_accuracy: 0.3841\n",
      "Epoch 73/80\n",
      "6435/6435 [==============================] - 0s 36us/step - loss: 1.2982 - accuracy: 0.3779 - val_loss: 1.3383 - val_accuracy: 0.3841\n",
      "Epoch 74/80\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6435/6435 [==============================] - 0s 38us/step - loss: 1.2977 - accuracy: 0.3888 - val_loss: 1.3220 - val_accuracy: 0.3994\n",
      "Epoch 75/80\n",
      "6435/6435 [==============================] - 0s 34us/step - loss: 1.2861 - accuracy: 0.3924 - val_loss: 1.3225 - val_accuracy: 0.3687\n",
      "Epoch 76/80\n",
      "6435/6435 [==============================] - 0s 34us/step - loss: 1.2831 - accuracy: 0.3958 - val_loss: 1.3077 - val_accuracy: 0.3799\n",
      "Epoch 77/80\n",
      "6435/6435 [==============================] - 0s 34us/step - loss: 1.2831 - accuracy: 0.3927 - val_loss: 1.2985 - val_accuracy: 0.3743\n",
      "Epoch 78/80\n",
      "6435/6435 [==============================] - 0s 39us/step - loss: 1.2753 - accuracy: 0.3991 - val_loss: 1.3344 - val_accuracy: 0.3771\n",
      "Epoch 79/80\n",
      "6435/6435 [==============================] - 0s 34us/step - loss: 1.2744 - accuracy: 0.3924 - val_loss: 1.2971 - val_accuracy: 0.4008\n",
      "Epoch 80/80\n",
      "6435/6435 [==============================] - 0s 39us/step - loss: 1.2663 - accuracy: 0.3927 - val_loss: 1.3062 - val_accuracy: 0.3939\n",
      "[[1.30906790e-01 1.11194216e-01 1.57588413e-14 ... 3.32182527e-01\n",
      "  1.95261031e-01 2.08039910e-01]\n",
      " [3.20412278e-01 3.28388400e-02 2.37520450e-21 ... 1.85583241e-03\n",
      "  9.26761702e-03 1.13641182e-02]\n",
      " [2.16250345e-01 2.24120483e-01 2.49450442e-17 ... 5.68210557e-02\n",
      "  2.24310249e-01 2.68960088e-01]\n",
      " ...\n",
      " [2.24953786e-01 2.82128513e-01 1.58610125e-18 ... 5.98264346e-03\n",
      "  2.14368165e-01 2.69686341e-01]\n",
      " [1.44901752e-01 1.29221812e-01 1.41155601e-13 ... 2.03231111e-01\n",
      "  2.40585715e-01 2.49211714e-01]\n",
      " [1.54740125e-01 1.39704227e-01 4.08051414e-14 ... 2.11868882e-01\n",
      "  2.29035050e-01 2.41841078e-01]]\n",
      "[11  5 13 ...  1 13 13]\n",
      "<class 'numpy.ndarray'>\n",
      "One CNN, r:  0\n",
      "Computing Time:  0:05:23.255210\n",
      "n, p1, p2 11 0 11\n",
      "Model: \"sequential_1\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv1d_1 (Conv1D)            (None, 3, 6)              12        \n",
      "_________________________________________________________________\n",
      "average_pooling1d_1 (Average (None, 1, 6)              0         \n",
      "_________________________________________________________________\n",
      "conv1d_2 (Conv1D)            (None, 1, 16)             112       \n",
      "_________________________________________________________________\n",
      "average_pooling1d_2 (Average (None, 1, 16)             0         \n",
      "_________________________________________________________________\n",
      "conv1d_3 (Conv1D)            (None, 1, 120)            2040      \n",
      "_________________________________________________________________\n",
      "flatten_1 (Flatten)          (None, 120)               0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 84)                10164     \n",
      "_________________________________________________________________\n",
      "preds (Dense)                (None, 14)                1190      \n",
      "=================================================================\n",
      "Total params: 13,518\n",
      "Trainable params: 13,518\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Train on 6435 samples, validate on 716 samples\n",
      "Epoch 1/80\n",
      "6435/6435 [==============================] - 1s 79us/step - loss: 2.5978 - accuracy: 0.1392 - val_loss: 2.5303 - val_accuracy: 0.1578\n",
      "Epoch 2/80\n",
      "6435/6435 [==============================] - 0s 39us/step - loss: 2.3949 - accuracy: 0.1961 - val_loss: 2.2514 - val_accuracy: 0.2067\n",
      "Epoch 3/80\n",
      "6435/6435 [==============================] - 0s 37us/step - loss: 2.0474 - accuracy: 0.2713 - val_loss: 1.9561 - val_accuracy: 0.2682\n",
      "Epoch 4/80\n",
      "6435/6435 [==============================] - 0s 37us/step - loss: 1.8712 - accuracy: 0.2982 - val_loss: 1.8682 - val_accuracy: 0.2584\n",
      "Epoch 5/80\n",
      "6435/6435 [==============================] - 0s 36us/step - loss: 1.7902 - accuracy: 0.2979 - val_loss: 1.7963 - val_accuracy: 0.2696\n",
      "Epoch 6/80\n",
      "6435/6435 [==============================] - 0s 42us/step - loss: 1.7327 - accuracy: 0.3007 - val_loss: 1.7505 - val_accuracy: 0.2640\n",
      "Epoch 7/80\n",
      "6435/6435 [==============================] - 0s 35us/step - loss: 1.6922 - accuracy: 0.3058 - val_loss: 1.7247 - val_accuracy: 0.3073\n",
      "Epoch 8/80\n",
      "6435/6435 [==============================] - 0s 38us/step - loss: 1.6659 - accuracy: 0.3071 - val_loss: 1.7216 - val_accuracy: 0.2737\n",
      "Epoch 9/80\n",
      "6435/6435 [==============================] - 0s 36us/step - loss: 1.6425 - accuracy: 0.3069 - val_loss: 1.6717 - val_accuracy: 0.2877\n",
      "Epoch 10/80\n",
      "6435/6435 [==============================] - 0s 37us/step - loss: 1.6316 - accuracy: 0.3133 - val_loss: 1.6709 - val_accuracy: 0.2947\n",
      "Epoch 11/80\n",
      "6435/6435 [==============================] - 0s 34us/step - loss: 1.6254 - accuracy: 0.3102 - val_loss: 1.6653 - val_accuracy: 0.3101\n",
      "Epoch 12/80\n",
      "6435/6435 [==============================] - 0s 36us/step - loss: 1.6170 - accuracy: 0.3089 - val_loss: 1.6523 - val_accuracy: 0.3059\n",
      "Epoch 13/80\n",
      "6435/6435 [==============================] - 0s 35us/step - loss: 1.6155 - accuracy: 0.3106 - val_loss: 1.6591 - val_accuracy: 0.3101\n",
      "Epoch 14/80\n",
      "6435/6435 [==============================] - 0s 34us/step - loss: 1.6134 - accuracy: 0.3051 - val_loss: 1.6644 - val_accuracy: 0.2696\n",
      "Epoch 15/80\n",
      "6435/6435 [==============================] - 0s 34us/step - loss: 1.6091 - accuracy: 0.3091 - val_loss: 1.6559 - val_accuracy: 0.2821\n",
      "Epoch 16/80\n",
      "6435/6435 [==============================] - 0s 34us/step - loss: 1.6072 - accuracy: 0.3122 - val_loss: 1.6673 - val_accuracy: 0.2765\n",
      "Epoch 17/80\n",
      "6435/6435 [==============================] - 0s 36us/step - loss: 1.6104 - accuracy: 0.3066 - val_loss: 1.7248 - val_accuracy: 0.2891\n",
      "Epoch 18/80\n",
      "6435/6435 [==============================] - 0s 38us/step - loss: 1.6190 - accuracy: 0.3061 - val_loss: 1.6561 - val_accuracy: 0.2947\n",
      "Epoch 19/80\n",
      "6435/6435 [==============================] - 0s 33us/step - loss: 1.6058 - accuracy: 0.3114 - val_loss: 1.6578 - val_accuracy: 0.3059\n",
      "Epoch 20/80\n",
      "6435/6435 [==============================] - 0s 35us/step - loss: 1.6041 - accuracy: 0.3064 - val_loss: 1.6668 - val_accuracy: 0.2961\n",
      "Epoch 21/80\n",
      "6435/6435 [==============================] - 0s 35us/step - loss: 1.6060 - accuracy: 0.3131 - val_loss: 1.6591 - val_accuracy: 0.2877\n",
      "Epoch 22/80\n",
      "6435/6435 [==============================] - 0s 36us/step - loss: 1.6012 - accuracy: 0.3110 - val_loss: 1.6498 - val_accuracy: 0.2877\n",
      "Epoch 23/80\n",
      "6435/6435 [==============================] - 0s 36us/step - loss: 1.6011 - accuracy: 0.3200 - val_loss: 1.6557 - val_accuracy: 0.2835\n",
      "Epoch 24/80\n",
      "6435/6435 [==============================] - 0s 36us/step - loss: 1.5973 - accuracy: 0.3125 - val_loss: 1.6532 - val_accuracy: 0.2989\n",
      "Epoch 25/80\n",
      "6435/6435 [==============================] - 0s 36us/step - loss: 1.5974 - accuracy: 0.3106 - val_loss: 1.6692 - val_accuracy: 0.2849\n",
      "Epoch 26/80\n",
      "6435/6435 [==============================] - 0s 35us/step - loss: 1.6010 - accuracy: 0.3134 - val_loss: 1.6607 - val_accuracy: 0.2765\n",
      "Epoch 27/80\n",
      "6435/6435 [==============================] - 0s 34us/step - loss: 1.5993 - accuracy: 0.3136 - val_loss: 1.6487 - val_accuracy: 0.2877\n",
      "Epoch 28/80\n",
      "6435/6435 [==============================] - 0s 37us/step - loss: 1.5941 - accuracy: 0.3139 - val_loss: 1.6593 - val_accuracy: 0.2849\n",
      "Epoch 29/80\n",
      "6435/6435 [==============================] - 0s 37us/step - loss: 1.5953 - accuracy: 0.3128 - val_loss: 1.6486 - val_accuracy: 0.3031\n",
      "Epoch 30/80\n",
      "6435/6435 [==============================] - 0s 39us/step - loss: 1.5977 - accuracy: 0.3136 - val_loss: 1.6553 - val_accuracy: 0.2947\n",
      "Epoch 31/80\n",
      "6435/6435 [==============================] - 0s 36us/step - loss: 1.5942 - accuracy: 0.3173 - val_loss: 1.6536 - val_accuracy: 0.2891\n",
      "Epoch 32/80\n",
      "6435/6435 [==============================] - 0s 34us/step - loss: 1.5976 - accuracy: 0.3068 - val_loss: 1.6697 - val_accuracy: 0.2723\n",
      "Epoch 33/80\n",
      "6435/6435 [==============================] - 0s 36us/step - loss: 1.6003 - accuracy: 0.3158 - val_loss: 1.6486 - val_accuracy: 0.2821\n",
      "Epoch 34/80\n",
      "6435/6435 [==============================] - 0s 36us/step - loss: 1.5966 - accuracy: 0.3091 - val_loss: 1.6419 - val_accuracy: 0.2919\n",
      "Epoch 35/80\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6435/6435 [==============================] - 0s 35us/step - loss: 1.5948 - accuracy: 0.3092 - val_loss: 1.6539 - val_accuracy: 0.2751\n",
      "Epoch 36/80\n",
      "6435/6435 [==============================] - 0s 36us/step - loss: 1.5942 - accuracy: 0.3113 - val_loss: 1.6677 - val_accuracy: 0.2640\n",
      "Epoch 37/80\n",
      "6435/6435 [==============================] - 0s 34us/step - loss: 1.5942 - accuracy: 0.3111 - val_loss: 1.6443 - val_accuracy: 0.3101\n",
      "Epoch 38/80\n",
      "6435/6435 [==============================] - 0s 33us/step - loss: 1.5916 - accuracy: 0.3136 - val_loss: 1.6535 - val_accuracy: 0.2919\n",
      "Epoch 39/80\n",
      "6435/6435 [==============================] - 0s 33us/step - loss: 1.5969 - accuracy: 0.3134 - val_loss: 1.6500 - val_accuracy: 0.2919\n",
      "Epoch 40/80\n",
      "6435/6435 [==============================] - 0s 35us/step - loss: 1.5892 - accuracy: 0.3150 - val_loss: 1.6576 - val_accuracy: 0.2709\n",
      "Epoch 41/80\n",
      "6435/6435 [==============================] - 0s 35us/step - loss: 1.5964 - accuracy: 0.3181 - val_loss: 1.6617 - val_accuracy: 0.2905\n",
      "Epoch 42/80\n",
      "6435/6435 [==============================] - 0s 33us/step - loss: 1.5897 - accuracy: 0.3130 - val_loss: 1.6443 - val_accuracy: 0.2793\n",
      "Epoch 43/80\n",
      "6435/6435 [==============================] - 0s 31us/step - loss: 1.5864 - accuracy: 0.3111 - val_loss: 1.6532 - val_accuracy: 0.2765\n",
      "Epoch 44/80\n",
      "6435/6435 [==============================] - 0s 34us/step - loss: 1.5945 - accuracy: 0.3114 - val_loss: 1.6428 - val_accuracy: 0.3031\n",
      "Epoch 00044: early stopping\n",
      "[[1.54212669e-01 1.47180334e-01 1.89836211e-13 ... 2.30152339e-01\n",
      "  1.48261860e-01 1.42773628e-01]\n",
      " [2.93116689e-01 9.22311470e-02 4.09390840e-22 ... 4.33348760e-04\n",
      "  8.43222961e-02 7.72147328e-02]\n",
      " [2.76404381e-01 1.61487609e-01 5.14885810e-19 ... 1.69295687e-02\n",
      "  1.28915757e-01 1.05270922e-01]\n",
      " ...\n",
      " [2.93536395e-01 1.01789035e-01 1.23297712e-21 ... 7.67497753e-04\n",
      "  9.09336358e-02 8.18646997e-02]\n",
      " [1.51969463e-01 1.40198588e-01 4.67915203e-12 ... 1.77462071e-01\n",
      "  1.46809995e-01 1.35352910e-01]\n",
      " [1.54526860e-01 1.46098882e-01 4.80602374e-13 ... 2.14932993e-01\n",
      "  1.48784772e-01 1.41524047e-01]]\n",
      "[11  0  0 ...  0 11 11]\n",
      "<class 'numpy.ndarray'>\n",
      "One CNN, r:  0\n",
      "Computing Time:  0:05:35.210747\n",
      "n, p1, p2 12 0 12\n",
      "Model: \"sequential_1\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv1d_1 (Conv1D)            (None, 3, 6)              12        \n",
      "_________________________________________________________________\n",
      "average_pooling1d_1 (Average (None, 1, 6)              0         \n",
      "_________________________________________________________________\n",
      "conv1d_2 (Conv1D)            (None, 1, 16)             112       \n",
      "_________________________________________________________________\n",
      "average_pooling1d_2 (Average (None, 1, 16)             0         \n",
      "_________________________________________________________________\n",
      "conv1d_3 (Conv1D)            (None, 1, 120)            2040      \n",
      "_________________________________________________________________\n",
      "flatten_1 (Flatten)          (None, 120)               0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 84)                10164     \n",
      "_________________________________________________________________\n",
      "preds (Dense)                (None, 14)                1190      \n",
      "=================================================================\n",
      "Total params: 13,518\n",
      "Trainable params: 13,518\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Train on 6435 samples, validate on 716 samples\n",
      "Epoch 1/80\n",
      "6435/6435 [==============================] - 0s 78us/step - loss: 2.6087 - accuracy: 0.1394 - val_loss: 2.5607 - val_accuracy: 0.1341\n",
      "Epoch 2/80\n",
      "6435/6435 [==============================] - 0s 39us/step - loss: 2.4234 - accuracy: 0.1744 - val_loss: 2.2287 - val_accuracy: 0.2486\n",
      "Epoch 3/80\n",
      "6435/6435 [==============================] - 0s 39us/step - loss: 2.0796 - accuracy: 0.2755 - val_loss: 1.9478 - val_accuracy: 0.2947\n",
      "Epoch 4/80\n",
      "6435/6435 [==============================] - 0s 36us/step - loss: 1.9012 - accuracy: 0.3262 - val_loss: 1.8221 - val_accuracy: 0.3212\n",
      "Epoch 5/80\n",
      "6435/6435 [==============================] - 0s 39us/step - loss: 1.7991 - accuracy: 0.3413 - val_loss: 1.7577 - val_accuracy: 0.3352\n",
      "Epoch 6/80\n",
      "6435/6435 [==============================] - 0s 36us/step - loss: 1.7360 - accuracy: 0.3487 - val_loss: 1.6863 - val_accuracy: 0.3561\n",
      "Epoch 7/80\n",
      "6435/6435 [==============================] - 0s 37us/step - loss: 1.6819 - accuracy: 0.3580 - val_loss: 1.6413 - val_accuracy: 0.3645\n",
      "Epoch 8/80\n",
      "6435/6435 [==============================] - 0s 33us/step - loss: 1.6403 - accuracy: 0.3481 - val_loss: 1.5933 - val_accuracy: 0.3436\n",
      "Epoch 9/80\n",
      "6435/6435 [==============================] - 0s 35us/step - loss: 1.5947 - accuracy: 0.3456 - val_loss: 1.5715 - val_accuracy: 0.3547\n",
      "Epoch 10/80\n",
      "6435/6435 [==============================] - 0s 34us/step - loss: 1.5589 - accuracy: 0.3573 - val_loss: 1.5299 - val_accuracy: 0.3659\n",
      "Epoch 11/80\n",
      "6435/6435 [==============================] - 0s 37us/step - loss: 1.5276 - accuracy: 0.3528 - val_loss: 1.5098 - val_accuracy: 0.3589\n",
      "Epoch 12/80\n",
      "6435/6435 [==============================] - 0s 38us/step - loss: 1.5010 - accuracy: 0.3535 - val_loss: 1.4899 - val_accuracy: 0.3506\n",
      "Epoch 13/80\n",
      "6435/6435 [==============================] - 0s 34us/step - loss: 1.4860 - accuracy: 0.3545 - val_loss: 1.4768 - val_accuracy: 0.3561\n",
      "Epoch 14/80\n",
      "6435/6435 [==============================] - 0s 37us/step - loss: 1.4735 - accuracy: 0.3509 - val_loss: 1.4672 - val_accuracy: 0.3575\n",
      "Epoch 15/80\n",
      "6435/6435 [==============================] - 0s 35us/step - loss: 1.4605 - accuracy: 0.3607 - val_loss: 1.4601 - val_accuracy: 0.3366\n",
      "Epoch 16/80\n",
      "6435/6435 [==============================] - 0s 36us/step - loss: 1.4618 - accuracy: 0.3531 - val_loss: 1.4636 - val_accuracy: 0.3617\n",
      "Epoch 17/80\n",
      "6435/6435 [==============================] - 0s 34us/step - loss: 1.4490 - accuracy: 0.3554 - val_loss: 1.4528 - val_accuracy: 0.3534\n",
      "Epoch 18/80\n",
      "6435/6435 [==============================] - 0s 36us/step - loss: 1.4500 - accuracy: 0.3546 - val_loss: 1.4537 - val_accuracy: 0.3561\n",
      "Epoch 19/80\n",
      "6435/6435 [==============================] - 0s 37us/step - loss: 1.4464 - accuracy: 0.3528 - val_loss: 1.4687 - val_accuracy: 0.3659\n",
      "Epoch 20/80\n",
      "6435/6435 [==============================] - 0s 34us/step - loss: 1.4444 - accuracy: 0.3524 - val_loss: 1.4474 - val_accuracy: 0.3701\n",
      "Epoch 21/80\n",
      "6435/6435 [==============================] - 0s 34us/step - loss: 1.4422 - accuracy: 0.3526 - val_loss: 1.4465 - val_accuracy: 0.3506\n",
      "Epoch 22/80\n",
      "6435/6435 [==============================] - 0s 34us/step - loss: 1.4387 - accuracy: 0.3591 - val_loss: 1.4407 - val_accuracy: 0.3547\n",
      "Epoch 23/80\n",
      "6435/6435 [==============================] - 0s 34us/step - loss: 1.4428 - accuracy: 0.3514 - val_loss: 1.4330 - val_accuracy: 0.3827\n",
      "Epoch 24/80\n",
      "6435/6435 [==============================] - 0s 37us/step - loss: 1.4372 - accuracy: 0.3548 - val_loss: 1.4681 - val_accuracy: 0.3492\n",
      "Epoch 25/80\n",
      "6435/6435 [==============================] - 0s 42us/step - loss: 1.4416 - accuracy: 0.3493 - val_loss: 1.4300 - val_accuracy: 0.3729\n",
      "Epoch 26/80\n",
      "6435/6435 [==============================] - 0s 36us/step - loss: 1.4316 - accuracy: 0.3577 - val_loss: 1.4484 - val_accuracy: 0.3645\n",
      "Epoch 27/80\n",
      "6435/6435 [==============================] - 0s 38us/step - loss: 1.4358 - accuracy: 0.3483 - val_loss: 1.4327 - val_accuracy: 0.3645\n",
      "Epoch 28/80\n",
      "6435/6435 [==============================] - 0s 35us/step - loss: 1.4301 - accuracy: 0.3538 - val_loss: 1.4352 - val_accuracy: 0.3589\n",
      "Epoch 29/80\n",
      "6435/6435 [==============================] - 0s 37us/step - loss: 1.4349 - accuracy: 0.3531 - val_loss: 1.4276 - val_accuracy: 0.3757\n",
      "Epoch 30/80\n",
      "6435/6435 [==============================] - 0s 34us/step - loss: 1.4379 - accuracy: 0.3545 - val_loss: 1.4377 - val_accuracy: 0.3659\n",
      "Epoch 31/80\n",
      "6435/6435 [==============================] - 0s 34us/step - loss: 1.4454 - accuracy: 0.3540 - val_loss: 1.4304 - val_accuracy: 0.3659\n",
      "Epoch 32/80\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6435/6435 [==============================] - 0s 36us/step - loss: 1.4309 - accuracy: 0.3500 - val_loss: 1.4322 - val_accuracy: 0.3715\n",
      "Epoch 33/80\n",
      "6435/6435 [==============================] - 0s 32us/step - loss: 1.4326 - accuracy: 0.3568 - val_loss: 1.4282 - val_accuracy: 0.3701\n",
      "Epoch 34/80\n",
      "6435/6435 [==============================] - 0s 35us/step - loss: 1.4270 - accuracy: 0.3560 - val_loss: 1.4367 - val_accuracy: 0.3408\n",
      "Epoch 35/80\n",
      "6435/6435 [==============================] - 0s 32us/step - loss: 1.4263 - accuracy: 0.3607 - val_loss: 1.4346 - val_accuracy: 0.3617\n",
      "Epoch 36/80\n",
      "6435/6435 [==============================] - 0s 38us/step - loss: 1.4225 - accuracy: 0.3538 - val_loss: 1.4285 - val_accuracy: 0.3534\n",
      "Epoch 37/80\n",
      "6435/6435 [==============================] - 0s 33us/step - loss: 1.4261 - accuracy: 0.3518 - val_loss: 1.4316 - val_accuracy: 0.3645\n",
      "Epoch 38/80\n",
      "6435/6435 [==============================] - 0s 35us/step - loss: 1.4217 - accuracy: 0.3509 - val_loss: 1.4245 - val_accuracy: 0.3701\n",
      "Epoch 39/80\n",
      "6435/6435 [==============================] - 0s 37us/step - loss: 1.4209 - accuracy: 0.3524 - val_loss: 1.4293 - val_accuracy: 0.3478\n",
      "Epoch 40/80\n",
      "6435/6435 [==============================] - 0s 36us/step - loss: 1.4272 - accuracy: 0.3520 - val_loss: 1.4208 - val_accuracy: 0.3659\n",
      "Epoch 41/80\n",
      "6435/6435 [==============================] - 0s 34us/step - loss: 1.4232 - accuracy: 0.3476 - val_loss: 1.4229 - val_accuracy: 0.3547\n",
      "Epoch 42/80\n",
      "6435/6435 [==============================] - 0s 35us/step - loss: 1.4190 - accuracy: 0.3537 - val_loss: 1.4221 - val_accuracy: 0.3729\n",
      "Epoch 43/80\n",
      "6435/6435 [==============================] - 0s 34us/step - loss: 1.4192 - accuracy: 0.3542 - val_loss: 1.4182 - val_accuracy: 0.3659\n",
      "Epoch 44/80\n",
      "6435/6435 [==============================] - 0s 35us/step - loss: 1.4192 - accuracy: 0.3571 - val_loss: 1.4264 - val_accuracy: 0.3575\n",
      "Epoch 45/80\n",
      "6435/6435 [==============================] - 0s 33us/step - loss: 1.4194 - accuracy: 0.3565 - val_loss: 1.4396 - val_accuracy: 0.3617\n",
      "Epoch 46/80\n",
      "6435/6435 [==============================] - 0s 34us/step - loss: 1.4192 - accuracy: 0.3556 - val_loss: 1.4287 - val_accuracy: 0.3659\n",
      "Epoch 47/80\n",
      "6435/6435 [==============================] - 0s 35us/step - loss: 1.4200 - accuracy: 0.3543 - val_loss: 1.4112 - val_accuracy: 0.3743\n",
      "Epoch 48/80\n",
      "6435/6435 [==============================] - 0s 33us/step - loss: 1.4159 - accuracy: 0.3492 - val_loss: 1.4209 - val_accuracy: 0.3645\n",
      "Epoch 49/80\n",
      "6435/6435 [==============================] - 0s 34us/step - loss: 1.4176 - accuracy: 0.3521 - val_loss: 1.4170 - val_accuracy: 0.3575\n",
      "Epoch 50/80\n",
      "6435/6435 [==============================] - 0s 36us/step - loss: 1.4187 - accuracy: 0.3543 - val_loss: 1.4253 - val_accuracy: 0.3547\n",
      "Epoch 51/80\n",
      "6435/6435 [==============================] - 0s 35us/step - loss: 1.4224 - accuracy: 0.3557 - val_loss: 1.4247 - val_accuracy: 0.3631\n",
      "Epoch 52/80\n",
      "6435/6435 [==============================] - 0s 33us/step - loss: 1.4200 - accuracy: 0.3497 - val_loss: 1.4310 - val_accuracy: 0.3785\n",
      "Epoch 53/80\n",
      "6435/6435 [==============================] - 0s 36us/step - loss: 1.4191 - accuracy: 0.3537 - val_loss: 1.4582 - val_accuracy: 0.3603\n",
      "Epoch 54/80\n",
      "6435/6435 [==============================] - 0s 34us/step - loss: 1.4172 - accuracy: 0.3453 - val_loss: 1.4274 - val_accuracy: 0.3687\n",
      "Epoch 55/80\n",
      "6435/6435 [==============================] - 0s 37us/step - loss: 1.4134 - accuracy: 0.3548 - val_loss: 1.4095 - val_accuracy: 0.3673\n",
      "Epoch 56/80\n",
      "6435/6435 [==============================] - 0s 39us/step - loss: 1.4066 - accuracy: 0.3588 - val_loss: 1.4119 - val_accuracy: 0.3589\n",
      "Epoch 57/80\n",
      "6435/6435 [==============================] - 0s 38us/step - loss: 1.4096 - accuracy: 0.3514 - val_loss: 1.4061 - val_accuracy: 0.3603\n",
      "Epoch 58/80\n",
      "6435/6435 [==============================] - 0s 38us/step - loss: 1.4073 - accuracy: 0.3580 - val_loss: 1.4021 - val_accuracy: 0.3589\n",
      "Epoch 59/80\n",
      "6435/6435 [==============================] - 0s 35us/step - loss: 1.4015 - accuracy: 0.3540 - val_loss: 1.4167 - val_accuracy: 0.3631\n",
      "Epoch 60/80\n",
      "6435/6435 [==============================] - 0s 38us/step - loss: 1.4020 - accuracy: 0.3534 - val_loss: 1.3961 - val_accuracy: 0.3561\n",
      "Epoch 61/80\n",
      "6435/6435 [==============================] - 0s 35us/step - loss: 1.3982 - accuracy: 0.3562 - val_loss: 1.3940 - val_accuracy: 0.3659\n",
      "Epoch 62/80\n",
      "6435/6435 [==============================] - 0s 35us/step - loss: 1.4054 - accuracy: 0.3552 - val_loss: 1.3975 - val_accuracy: 0.3729\n",
      "Epoch 63/80\n",
      "6435/6435 [==============================] - 0s 33us/step - loss: 1.3966 - accuracy: 0.3630 - val_loss: 1.4022 - val_accuracy: 0.3520\n",
      "Epoch 64/80\n",
      "6435/6435 [==============================] - 0s 34us/step - loss: 1.3945 - accuracy: 0.3632 - val_loss: 1.3848 - val_accuracy: 0.3645\n",
      "Epoch 65/80\n",
      "6435/6435 [==============================] - 0s 37us/step - loss: 1.3960 - accuracy: 0.3552 - val_loss: 1.3869 - val_accuracy: 0.3715\n",
      "Epoch 66/80\n",
      "6435/6435 [==============================] - 0s 33us/step - loss: 1.3933 - accuracy: 0.3542 - val_loss: 1.4050 - val_accuracy: 0.3547\n",
      "Epoch 67/80\n",
      "6435/6435 [==============================] - 0s 34us/step - loss: 1.3912 - accuracy: 0.3594 - val_loss: 1.3909 - val_accuracy: 0.3520\n",
      "Epoch 68/80\n",
      "6435/6435 [==============================] - 0s 34us/step - loss: 1.3908 - accuracy: 0.3639 - val_loss: 1.3998 - val_accuracy: 0.3729\n",
      "Epoch 69/80\n",
      "6435/6435 [==============================] - 0s 36us/step - loss: 1.3894 - accuracy: 0.3570 - val_loss: 1.3874 - val_accuracy: 0.3659\n",
      "Epoch 70/80\n",
      "6435/6435 [==============================] - 0s 32us/step - loss: 1.3889 - accuracy: 0.3560 - val_loss: 1.3885 - val_accuracy: 0.3757\n",
      "Epoch 71/80\n",
      "6435/6435 [==============================] - 0s 36us/step - loss: 1.3894 - accuracy: 0.3563 - val_loss: 1.3936 - val_accuracy: 0.3785\n",
      "Epoch 72/80\n",
      "6435/6435 [==============================] - 0s 39us/step - loss: 1.3892 - accuracy: 0.3624 - val_loss: 1.4019 - val_accuracy: 0.3813\n",
      "Epoch 73/80\n",
      "6435/6435 [==============================] - 0s 34us/step - loss: 1.3885 - accuracy: 0.3503 - val_loss: 1.3841 - val_accuracy: 0.3617\n",
      "Epoch 74/80\n",
      "6435/6435 [==============================] - 0s 34us/step - loss: 1.3876 - accuracy: 0.3633 - val_loss: 1.3921 - val_accuracy: 0.3478\n",
      "Epoch 75/80\n",
      "6435/6435 [==============================] - 0s 33us/step - loss: 1.3873 - accuracy: 0.3619 - val_loss: 1.3878 - val_accuracy: 0.3534\n",
      "Epoch 76/80\n",
      "6435/6435 [==============================] - 0s 35us/step - loss: 1.3896 - accuracy: 0.3520 - val_loss: 1.4015 - val_accuracy: 0.3659\n",
      "Epoch 77/80\n",
      "6435/6435 [==============================] - 0s 32us/step - loss: 1.3867 - accuracy: 0.3552 - val_loss: 1.3940 - val_accuracy: 0.3492\n",
      "Epoch 78/80\n",
      "6435/6435 [==============================] - 0s 36us/step - loss: 1.3915 - accuracy: 0.3559 - val_loss: 1.3818 - val_accuracy: 0.3659\n",
      "Epoch 79/80\n",
      "6435/6435 [==============================] - 0s 36us/step - loss: 1.3842 - accuracy: 0.3649 - val_loss: 1.3903 - val_accuracy: 0.3631\n",
      "Epoch 80/80\n",
      "6435/6435 [==============================] - 0s 34us/step - loss: 1.3821 - accuracy: 0.3629 - val_loss: 1.3849 - val_accuracy: 0.3673\n",
      "[[3.5215139e-01 1.6408271e-01 3.0120387e-14 ... 9.7512038e-06\n",
      "  2.3336932e-01 2.2397278e-01]\n",
      " [6.0600057e-02 3.6890991e-02 2.2676502e-23 ... 2.4660710e-01\n",
      "  1.4178068e-02 1.1041051e-02]\n",
      " [3.8913277e-01 1.5770589e-01 2.4210595e-17 ... 2.8620343e-04\n",
      "  2.2511517e-01 2.1698204e-01]\n",
      " ...\n",
      " [3.9199755e-01 1.5758468e-01 1.8793178e-17 ... 2.1795892e-04\n",
      "  2.2462252e-01 2.1582031e-01]\n",
      " [3.0663043e-01 1.6448258e-01 1.5219981e-12 ... 1.0249905e-06\n",
      "  2.3565251e-01 2.2303972e-01]\n",
      " [3.2695630e-01 1.6570297e-01 2.9551383e-13 ... 2.4690864e-06\n",
      "  2.3671764e-01 2.2513407e-01]]\n",
      "[0 5 0 ... 0 0 0]\n",
      "<class 'numpy.ndarray'>\n",
      "One CNN, r:  0\n",
      "Computing Time:  0:05:55.161465\n",
      "n, p1, p2 13 0 13\n",
      "Model: \"sequential_1\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv1d_1 (Conv1D)            (None, 3, 6)              12        \n",
      "_________________________________________________________________\n",
      "average_pooling1d_1 (Average (None, 1, 6)              0         \n",
      "_________________________________________________________________\n",
      "conv1d_2 (Conv1D)            (None, 1, 16)             112       \n",
      "_________________________________________________________________\n",
      "average_pooling1d_2 (Average (None, 1, 16)             0         \n",
      "_________________________________________________________________\n",
      "conv1d_3 (Conv1D)            (None, 1, 120)            2040      \n",
      "_________________________________________________________________\n",
      "flatten_1 (Flatten)          (None, 120)               0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 84)                10164     \n",
      "_________________________________________________________________\n",
      "preds (Dense)                (None, 14)                1190      \n",
      "=================================================================\n",
      "Total params: 13,518\n",
      "Trainable params: 13,518\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 6435 samples, validate on 716 samples\n",
      "Epoch 1/80\n",
      "6435/6435 [==============================] - 0s 73us/step - loss: 2.6098 - accuracy: 0.1495 - val_loss: 2.5498 - val_accuracy: 0.1355\n",
      "Epoch 2/80\n",
      "6435/6435 [==============================] - 0s 39us/step - loss: 2.3576 - accuracy: 0.2132 - val_loss: 2.1330 - val_accuracy: 0.2640\n",
      "Epoch 3/80\n",
      "6435/6435 [==============================] - 0s 36us/step - loss: 1.9569 - accuracy: 0.2875 - val_loss: 1.8842 - val_accuracy: 0.2947\n",
      "Epoch 4/80\n",
      "6435/6435 [==============================] - 0s 36us/step - loss: 1.7946 - accuracy: 0.3246 - val_loss: 1.7844 - val_accuracy: 0.3087\n",
      "Epoch 5/80\n",
      "6435/6435 [==============================] - 0s 39us/step - loss: 1.7158 - accuracy: 0.3302 - val_loss: 1.7035 - val_accuracy: 0.2989\n",
      "Epoch 6/80\n",
      "6435/6435 [==============================] - 0s 34us/step - loss: 1.6482 - accuracy: 0.3316 - val_loss: 1.6244 - val_accuracy: 0.3198\n",
      "Epoch 7/80\n",
      "6435/6435 [==============================] - 0s 39us/step - loss: 1.5833 - accuracy: 0.3402 - val_loss: 1.5850 - val_accuracy: 0.3156\n",
      "Epoch 8/80\n",
      "6435/6435 [==============================] - 0s 36us/step - loss: 1.5581 - accuracy: 0.3441 - val_loss: 1.5800 - val_accuracy: 0.3184\n",
      "Epoch 9/80\n",
      "6435/6435 [==============================] - 0s 36us/step - loss: 1.5258 - accuracy: 0.3402 - val_loss: 1.5434 - val_accuracy: 0.3478\n",
      "Epoch 10/80\n",
      "6435/6435 [==============================] - 0s 36us/step - loss: 1.5047 - accuracy: 0.3497 - val_loss: 1.5025 - val_accuracy: 0.3422\n",
      "Epoch 11/80\n",
      "6435/6435 [==============================] - 0s 40us/step - loss: 1.4711 - accuracy: 0.3551 - val_loss: 1.4898 - val_accuracy: 0.3352\n",
      "Epoch 12/80\n",
      "6435/6435 [==============================] - 0s 34us/step - loss: 1.4554 - accuracy: 0.3584 - val_loss: 1.4663 - val_accuracy: 0.3310\n",
      "Epoch 13/80\n",
      "6435/6435 [==============================] - 0s 37us/step - loss: 1.4471 - accuracy: 0.3621 - val_loss: 1.4588 - val_accuracy: 0.3394\n",
      "Epoch 14/80\n",
      "6435/6435 [==============================] - 0s 36us/step - loss: 1.4419 - accuracy: 0.3593 - val_loss: 1.4467 - val_accuracy: 0.3464\n",
      "Epoch 15/80\n",
      "6435/6435 [==============================] - 0s 32us/step - loss: 1.4311 - accuracy: 0.3714 - val_loss: 1.4501 - val_accuracy: 0.3464\n",
      "Epoch 16/80\n",
      "6435/6435 [==============================] - 0s 37us/step - loss: 1.4272 - accuracy: 0.3594 - val_loss: 1.4282 - val_accuracy: 0.3547\n",
      "Epoch 17/80\n",
      "6435/6435 [==============================] - 0s 36us/step - loss: 1.4219 - accuracy: 0.3611 - val_loss: 1.4430 - val_accuracy: 0.3506\n",
      "Epoch 18/80\n",
      "6435/6435 [==============================] - 0s 36us/step - loss: 1.4202 - accuracy: 0.3618 - val_loss: 1.4245 - val_accuracy: 0.3492\n",
      "Epoch 19/80\n",
      "6435/6435 [==============================] - 0s 39us/step - loss: 1.4183 - accuracy: 0.3660 - val_loss: 1.4261 - val_accuracy: 0.3547\n",
      "Epoch 20/80\n",
      "6435/6435 [==============================] - 0s 36us/step - loss: 1.4080 - accuracy: 0.3678 - val_loss: 1.4283 - val_accuracy: 0.3506\n",
      "Epoch 21/80\n",
      "6435/6435 [==============================] - 0s 36us/step - loss: 1.4049 - accuracy: 0.3650 - val_loss: 1.4258 - val_accuracy: 0.3380\n",
      "Epoch 22/80\n",
      "6435/6435 [==============================] - 0s 36us/step - loss: 1.4138 - accuracy: 0.3649 - val_loss: 1.4228 - val_accuracy: 0.3547\n",
      "Epoch 23/80\n",
      "6435/6435 [==============================] - 0s 37us/step - loss: 1.4010 - accuracy: 0.3638 - val_loss: 1.4223 - val_accuracy: 0.3547\n",
      "Epoch 24/80\n",
      "6435/6435 [==============================] - 0s 34us/step - loss: 1.3983 - accuracy: 0.3713 - val_loss: 1.4172 - val_accuracy: 0.3687\n",
      "Epoch 25/80\n",
      "6435/6435 [==============================] - 0s 36us/step - loss: 1.3958 - accuracy: 0.3663 - val_loss: 1.4058 - val_accuracy: 0.3659\n",
      "Epoch 26/80\n",
      "6435/6435 [==============================] - 0s 41us/step - loss: 1.3884 - accuracy: 0.3674 - val_loss: 1.4094 - val_accuracy: 0.3547\n",
      "Epoch 27/80\n",
      "6435/6435 [==============================] - 0s 37us/step - loss: 1.3908 - accuracy: 0.3613 - val_loss: 1.4084 - val_accuracy: 0.3450\n",
      "Epoch 28/80\n",
      "6435/6435 [==============================] - 0s 38us/step - loss: 1.3881 - accuracy: 0.3750 - val_loss: 1.3948 - val_accuracy: 0.3506\n",
      "Epoch 29/80\n",
      "6435/6435 [==============================] - 0s 37us/step - loss: 1.3873 - accuracy: 0.3613 - val_loss: 1.3960 - val_accuracy: 0.3757\n",
      "Epoch 30/80\n",
      "6435/6435 [==============================] - 0s 39us/step - loss: 1.3817 - accuracy: 0.3717 - val_loss: 1.4013 - val_accuracy: 0.3659\n",
      "Epoch 31/80\n",
      "6435/6435 [==============================] - 0s 36us/step - loss: 1.3785 - accuracy: 0.3747 - val_loss: 1.4111 - val_accuracy: 0.3422\n",
      "Epoch 32/80\n",
      "6435/6435 [==============================] - 0s 37us/step - loss: 1.3825 - accuracy: 0.3688 - val_loss: 1.3858 - val_accuracy: 0.3687\n",
      "Epoch 33/80\n",
      "6435/6435 [==============================] - 0s 38us/step - loss: 1.3799 - accuracy: 0.3694 - val_loss: 1.3907 - val_accuracy: 0.3617\n",
      "Epoch 34/80\n",
      "6435/6435 [==============================] - 0s 36us/step - loss: 1.3734 - accuracy: 0.3751 - val_loss: 1.3924 - val_accuracy: 0.3547\n",
      "Epoch 35/80\n",
      "6435/6435 [==============================] - 0s 36us/step - loss: 1.3780 - accuracy: 0.3723 - val_loss: 1.3931 - val_accuracy: 0.3589\n",
      "Epoch 36/80\n",
      "6435/6435 [==============================] - 0s 35us/step - loss: 1.3763 - accuracy: 0.3680 - val_loss: 1.3966 - val_accuracy: 0.3575\n",
      "Epoch 37/80\n",
      "6435/6435 [==============================] - 0s 35us/step - loss: 1.3717 - accuracy: 0.3758 - val_loss: 1.3843 - val_accuracy: 0.3687\n",
      "Epoch 38/80\n",
      "6435/6435 [==============================] - 0s 39us/step - loss: 1.3684 - accuracy: 0.3806 - val_loss: 1.3906 - val_accuracy: 0.3575\n",
      "Epoch 39/80\n",
      "6435/6435 [==============================] - 0s 36us/step - loss: 1.3678 - accuracy: 0.3782 - val_loss: 1.3988 - val_accuracy: 0.3506\n",
      "Epoch 40/80\n",
      "6435/6435 [==============================] - 0s 34us/step - loss: 1.3753 - accuracy: 0.3737 - val_loss: 1.4060 - val_accuracy: 0.3478\n",
      "Epoch 41/80\n",
      "6435/6435 [==============================] - 0s 41us/step - loss: 1.3689 - accuracy: 0.3832 - val_loss: 1.4110 - val_accuracy: 0.3561\n",
      "Epoch 42/80\n",
      "6435/6435 [==============================] - 0s 37us/step - loss: 1.3692 - accuracy: 0.3730 - val_loss: 1.3825 - val_accuracy: 0.3478\n",
      "Epoch 43/80\n",
      "6435/6435 [==============================] - 0s 37us/step - loss: 1.3656 - accuracy: 0.3765 - val_loss: 1.3785 - val_accuracy: 0.3785\n",
      "Epoch 44/80\n",
      "6435/6435 [==============================] - 0s 37us/step - loss: 1.3571 - accuracy: 0.3790 - val_loss: 1.3784 - val_accuracy: 0.3547\n",
      "Epoch 45/80\n",
      "6435/6435 [==============================] - 0s 34us/step - loss: 1.3571 - accuracy: 0.3843 - val_loss: 1.3730 - val_accuracy: 0.3631\n",
      "Epoch 46/80\n",
      "6435/6435 [==============================] - 0s 39us/step - loss: 1.3531 - accuracy: 0.3772 - val_loss: 1.3823 - val_accuracy: 0.3687\n",
      "Epoch 47/80\n",
      "6435/6435 [==============================] - 0s 36us/step - loss: 1.3576 - accuracy: 0.3935 - val_loss: 1.3734 - val_accuracy: 0.3506\n",
      "Epoch 48/80\n",
      "6435/6435 [==============================] - 0s 33us/step - loss: 1.3492 - accuracy: 0.3810 - val_loss: 1.3585 - val_accuracy: 0.3645\n",
      "Epoch 49/80\n",
      "6435/6435 [==============================] - 0s 32us/step - loss: 1.3416 - accuracy: 0.3899 - val_loss: 1.3607 - val_accuracy: 0.3701\n",
      "Epoch 50/80\n",
      "6435/6435 [==============================] - 0s 34us/step - loss: 1.3410 - accuracy: 0.3978 - val_loss: 1.3565 - val_accuracy: 0.3729\n",
      "Epoch 51/80\n",
      "6435/6435 [==============================] - 0s 32us/step - loss: 1.3349 - accuracy: 0.3932 - val_loss: 1.3541 - val_accuracy: 0.3561\n",
      "Epoch 52/80\n",
      "6435/6435 [==============================] - 0s 32us/step - loss: 1.3298 - accuracy: 0.3970 - val_loss: 1.3488 - val_accuracy: 0.3855\n",
      "Epoch 53/80\n",
      "6435/6435 [==============================] - 0s 39us/step - loss: 1.3246 - accuracy: 0.3925 - val_loss: 1.3313 - val_accuracy: 0.3855\n",
      "Epoch 54/80\n",
      "6435/6435 [==============================] - 0s 34us/step - loss: 1.3126 - accuracy: 0.4051 - val_loss: 1.3359 - val_accuracy: 0.3729\n",
      "Epoch 55/80\n",
      "6435/6435 [==============================] - 0s 34us/step - loss: 1.3036 - accuracy: 0.4120 - val_loss: 1.3215 - val_accuracy: 0.3897\n",
      "Epoch 56/80\n",
      "6435/6435 [==============================] - 0s 36us/step - loss: 1.2958 - accuracy: 0.4092 - val_loss: 1.3061 - val_accuracy: 0.3785\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 57/80\n",
      "6435/6435 [==============================] - 0s 36us/step - loss: 1.2854 - accuracy: 0.4082 - val_loss: 1.2910 - val_accuracy: 0.3966\n",
      "Epoch 58/80\n",
      "6435/6435 [==============================] - 0s 34us/step - loss: 1.2712 - accuracy: 0.4213 - val_loss: 1.2775 - val_accuracy: 0.4120\n",
      "Epoch 59/80\n",
      "6435/6435 [==============================] - 0s 36us/step - loss: 1.2598 - accuracy: 0.4255 - val_loss: 1.2557 - val_accuracy: 0.4274\n",
      "Epoch 60/80\n",
      "6435/6435 [==============================] - 0s 34us/step - loss: 1.2510 - accuracy: 0.4280 - val_loss: 1.2560 - val_accuracy: 0.4190\n",
      "Epoch 61/80\n",
      "6435/6435 [==============================] - 0s 36us/step - loss: 1.2370 - accuracy: 0.4312 - val_loss: 1.2457 - val_accuracy: 0.4246\n",
      "Epoch 62/80\n",
      "6435/6435 [==============================] - 0s 34us/step - loss: 1.2342 - accuracy: 0.4281 - val_loss: 1.2306 - val_accuracy: 0.4316\n",
      "Epoch 63/80\n",
      "6435/6435 [==============================] - 0s 39us/step - loss: 1.2293 - accuracy: 0.4356 - val_loss: 1.2220 - val_accuracy: 0.4372\n",
      "Epoch 64/80\n",
      "6435/6435 [==============================] - 0s 36us/step - loss: 1.2168 - accuracy: 0.4342 - val_loss: 1.2143 - val_accuracy: 0.4288\n",
      "Epoch 65/80\n",
      "6435/6435 [==============================] - 0s 36us/step - loss: 1.2141 - accuracy: 0.4289 - val_loss: 1.2199 - val_accuracy: 0.4372\n",
      "Epoch 66/80\n",
      "6435/6435 [==============================] - 0s 36us/step - loss: 1.2097 - accuracy: 0.4314 - val_loss: 1.2014 - val_accuracy: 0.4162\n",
      "Epoch 67/80\n",
      "6435/6435 [==============================] - 0s 36us/step - loss: 1.2017 - accuracy: 0.4289 - val_loss: 1.2031 - val_accuracy: 0.4413\n",
      "Epoch 68/80\n",
      "6435/6435 [==============================] - 0s 36us/step - loss: 1.1987 - accuracy: 0.4379 - val_loss: 1.2068 - val_accuracy: 0.4330\n",
      "Epoch 69/80\n",
      "6435/6435 [==============================] - 0s 39us/step - loss: 1.1972 - accuracy: 0.4421 - val_loss: 1.1973 - val_accuracy: 0.4204\n",
      "Epoch 70/80\n",
      "6435/6435 [==============================] - 0s 39us/step - loss: 1.1934 - accuracy: 0.4370 - val_loss: 1.1919 - val_accuracy: 0.4316\n",
      "Epoch 71/80\n",
      "6435/6435 [==============================] - 0s 36us/step - loss: 1.1916 - accuracy: 0.4340 - val_loss: 1.1937 - val_accuracy: 0.4162\n",
      "Epoch 72/80\n",
      "6435/6435 [==============================] - 0s 36us/step - loss: 1.1908 - accuracy: 0.4334 - val_loss: 1.1907 - val_accuracy: 0.4218\n",
      "Epoch 73/80\n",
      "6435/6435 [==============================] - 0s 39us/step - loss: 1.1869 - accuracy: 0.4334 - val_loss: 1.1970 - val_accuracy: 0.4176\n",
      "Epoch 74/80\n",
      "6435/6435 [==============================] - 0s 39us/step - loss: 1.1907 - accuracy: 0.4284 - val_loss: 1.1904 - val_accuracy: 0.4176\n",
      "Epoch 75/80\n",
      "6435/6435 [==============================] - 0s 34us/step - loss: 1.1831 - accuracy: 0.4375 - val_loss: 1.2250 - val_accuracy: 0.4176\n",
      "Epoch 76/80\n",
      "6435/6435 [==============================] - 0s 32us/step - loss: 1.1874 - accuracy: 0.4382 - val_loss: 1.1813 - val_accuracy: 0.4260\n",
      "Epoch 77/80\n",
      "6435/6435 [==============================] - 0s 36us/step - loss: 1.1758 - accuracy: 0.4356 - val_loss: 1.1783 - val_accuracy: 0.4218\n",
      "Epoch 78/80\n",
      "6435/6435 [==============================] - 0s 34us/step - loss: 1.1769 - accuracy: 0.4421 - val_loss: 1.1795 - val_accuracy: 0.4288\n",
      "Epoch 79/80\n",
      "6435/6435 [==============================] - 0s 34us/step - loss: 1.1748 - accuracy: 0.4389 - val_loss: 1.1778 - val_accuracy: 0.4288\n",
      "Epoch 80/80\n",
      "6435/6435 [==============================] - 0s 36us/step - loss: 1.1757 - accuracy: 0.4359 - val_loss: 1.1772 - val_accuracy: 0.4148\n",
      "[[2.99508393e-01 1.10357858e-01 3.37502671e-15 ... 1.53572837e-04\n",
      "  2.99025327e-01 2.61752188e-01]\n",
      " [4.52809483e-02 3.50533463e-02 5.01476795e-23 ... 3.24394584e-01\n",
      "  1.90310203e-03 2.35617422e-02]\n",
      " [4.27663356e-01 1.82146728e-01 1.57782169e-18 ... 8.20750254e-04\n",
      "  4.77520339e-02 3.38294864e-01]\n",
      " ...\n",
      " [4.43630099e-01 1.81126863e-01 6.77703906e-20 ... 2.26846532e-04\n",
      "  4.69389278e-03 3.69763672e-01]\n",
      " [3.45698684e-01 1.15039475e-01 3.23664605e-14 ... 1.90704377e-05\n",
      "  1.66876420e-01 3.36407900e-01]\n",
      " [3.51376772e-01 1.24714494e-01 8.09309573e-15 ... 3.60870035e-05\n",
      "  1.77218452e-01 3.20254058e-01]]\n",
      "[ 0 11  0 ...  0  0  0]\n",
      "<class 'numpy.ndarray'>\n",
      "One CNN, r:  0\n",
      "Computing Time:  0:06:15.520794\n",
      "n, p1, p2 14 0 14\n",
      "Model: \"sequential_1\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv1d_1 (Conv1D)            (None, 3, 6)              12        \n",
      "_________________________________________________________________\n",
      "average_pooling1d_1 (Average (None, 1, 6)              0         \n",
      "_________________________________________________________________\n",
      "conv1d_2 (Conv1D)            (None, 1, 16)             112       \n",
      "_________________________________________________________________\n",
      "average_pooling1d_2 (Average (None, 1, 16)             0         \n",
      "_________________________________________________________________\n",
      "conv1d_3 (Conv1D)            (None, 1, 120)            2040      \n",
      "_________________________________________________________________\n",
      "flatten_1 (Flatten)          (None, 120)               0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 84)                10164     \n",
      "_________________________________________________________________\n",
      "preds (Dense)                (None, 14)                1190      \n",
      "=================================================================\n",
      "Total params: 13,518\n",
      "Trainable params: 13,518\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Train on 6435 samples, validate on 716 samples\n",
      "Epoch 1/80\n",
      "6435/6435 [==============================] - 1s 83us/step - loss: 2.6060 - accuracy: 0.1402 - val_loss: 2.5428 - val_accuracy: 0.1341\n",
      "Epoch 2/80\n",
      "6435/6435 [==============================] - 0s 39us/step - loss: 2.3719 - accuracy: 0.2057 - val_loss: 2.1497 - val_accuracy: 0.2989\n",
      "Epoch 3/80\n",
      "6435/6435 [==============================] - 0s 32us/step - loss: 2.0011 - accuracy: 0.2920 - val_loss: 1.8970 - val_accuracy: 0.3087\n",
      "Epoch 4/80\n",
      "6435/6435 [==============================] - 0s 34us/step - loss: 1.8340 - accuracy: 0.3189 - val_loss: 1.7940 - val_accuracy: 0.3352\n",
      "Epoch 5/80\n",
      "6435/6435 [==============================] - 0s 34us/step - loss: 1.7525 - accuracy: 0.3221 - val_loss: 1.7179 - val_accuracy: 0.3254\n",
      "Epoch 6/80\n",
      "6435/6435 [==============================] - 0s 36us/step - loss: 1.6849 - accuracy: 0.3234 - val_loss: 1.6445 - val_accuracy: 0.3561\n",
      "Epoch 7/80\n",
      "6435/6435 [==============================] - 0s 36us/step - loss: 1.6436 - accuracy: 0.3228 - val_loss: 1.6112 - val_accuracy: 0.3142\n",
      "Epoch 8/80\n",
      "6435/6435 [==============================] - 0s 34us/step - loss: 1.6064 - accuracy: 0.3273 - val_loss: 1.5924 - val_accuracy: 0.3087\n",
      "Epoch 9/80\n",
      "6435/6435 [==============================] - 0s 36us/step - loss: 1.5919 - accuracy: 0.3268 - val_loss: 1.5769 - val_accuracy: 0.3394\n",
      "Epoch 10/80\n",
      "6435/6435 [==============================] - 0s 34us/step - loss: 1.5775 - accuracy: 0.3265 - val_loss: 1.5739 - val_accuracy: 0.3212\n",
      "Epoch 11/80\n",
      "6435/6435 [==============================] - 0s 34us/step - loss: 1.5746 - accuracy: 0.3273 - val_loss: 1.5612 - val_accuracy: 0.3464\n",
      "Epoch 12/80\n",
      "6435/6435 [==============================] - 0s 34us/step - loss: 1.5667 - accuracy: 0.3282 - val_loss: 1.5597 - val_accuracy: 0.3547\n",
      "Epoch 13/80\n",
      "6435/6435 [==============================] - 0s 34us/step - loss: 1.5683 - accuracy: 0.3225 - val_loss: 1.5521 - val_accuracy: 0.3352\n",
      "Epoch 14/80\n",
      "6435/6435 [==============================] - 0s 36us/step - loss: 1.5567 - accuracy: 0.3245 - val_loss: 1.5606 - val_accuracy: 0.3394\n",
      "Epoch 15/80\n",
      "6435/6435 [==============================] - 0s 34us/step - loss: 1.5570 - accuracy: 0.3276 - val_loss: 1.5508 - val_accuracy: 0.3338\n",
      "Epoch 16/80\n",
      "6435/6435 [==============================] - 0s 32us/step - loss: 1.5541 - accuracy: 0.3276 - val_loss: 1.5465 - val_accuracy: 0.3352\n",
      "Epoch 17/80\n",
      "6435/6435 [==============================] - 0s 34us/step - loss: 1.5508 - accuracy: 0.3223 - val_loss: 1.5458 - val_accuracy: 0.3436\n",
      "Epoch 18/80\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6435/6435 [==============================] - 0s 36us/step - loss: 1.5504 - accuracy: 0.3322 - val_loss: 1.5497 - val_accuracy: 0.3478\n",
      "Epoch 19/80\n",
      "6435/6435 [==============================] - 0s 39us/step - loss: 1.5532 - accuracy: 0.3186 - val_loss: 1.5489 - val_accuracy: 0.3478\n",
      "Epoch 20/80\n",
      "6435/6435 [==============================] - 0s 36us/step - loss: 1.5512 - accuracy: 0.3318 - val_loss: 1.5415 - val_accuracy: 0.3408\n",
      "Epoch 21/80\n",
      "6435/6435 [==============================] - 0s 36us/step - loss: 1.5476 - accuracy: 0.3321 - val_loss: 1.5453 - val_accuracy: 0.3436\n",
      "Epoch 22/80\n",
      "6435/6435 [==============================] - 0s 36us/step - loss: 1.5518 - accuracy: 0.3267 - val_loss: 1.5458 - val_accuracy: 0.3394\n",
      "Epoch 23/80\n",
      "6435/6435 [==============================] - 0s 32us/step - loss: 1.5426 - accuracy: 0.3358 - val_loss: 1.5516 - val_accuracy: 0.3534\n",
      "Epoch 24/80\n",
      "6435/6435 [==============================] - 0s 32us/step - loss: 1.5461 - accuracy: 0.3298 - val_loss: 1.5413 - val_accuracy: 0.3184\n",
      "Epoch 25/80\n",
      "6435/6435 [==============================] - 0s 36us/step - loss: 1.5436 - accuracy: 0.3287 - val_loss: 1.5359 - val_accuracy: 0.3506\n",
      "Epoch 26/80\n",
      "6435/6435 [==============================] - 0s 35us/step - loss: 1.5448 - accuracy: 0.3214 - val_loss: 1.5502 - val_accuracy: 0.3478\n",
      "Epoch 27/80\n",
      "6435/6435 [==============================] - 0s 35us/step - loss: 1.5448 - accuracy: 0.3333 - val_loss: 1.5507 - val_accuracy: 0.3520\n",
      "Epoch 28/80\n",
      "6435/6435 [==============================] - 0s 36us/step - loss: 1.5412 - accuracy: 0.3273 - val_loss: 1.5322 - val_accuracy: 0.3534\n",
      "Epoch 29/80\n",
      "6435/6435 [==============================] - 0s 34us/step - loss: 1.5377 - accuracy: 0.3378 - val_loss: 1.5469 - val_accuracy: 0.3520\n",
      "Epoch 30/80\n",
      "6435/6435 [==============================] - 0s 36us/step - loss: 1.5394 - accuracy: 0.3291 - val_loss: 1.5360 - val_accuracy: 0.3561\n",
      "Epoch 31/80\n",
      "6435/6435 [==============================] - 0s 36us/step - loss: 1.5365 - accuracy: 0.3330 - val_loss: 1.5387 - val_accuracy: 0.3534\n",
      "Epoch 32/80\n",
      "6435/6435 [==============================] - 0s 34us/step - loss: 1.5364 - accuracy: 0.3316 - val_loss: 1.5315 - val_accuracy: 0.3520\n",
      "Epoch 33/80\n",
      "6435/6435 [==============================] - 0s 34us/step - loss: 1.5371 - accuracy: 0.3313 - val_loss: 1.5423 - val_accuracy: 0.3520\n",
      "Epoch 34/80\n",
      "6435/6435 [==============================] - 0s 36us/step - loss: 1.5376 - accuracy: 0.3301 - val_loss: 1.5344 - val_accuracy: 0.3394\n",
      "Epoch 35/80\n",
      "6435/6435 [==============================] - 0s 39us/step - loss: 1.5332 - accuracy: 0.3338 - val_loss: 1.5289 - val_accuracy: 0.3492\n",
      "Epoch 36/80\n",
      "6435/6435 [==============================] - 0s 44us/step - loss: 1.5349 - accuracy: 0.3366 - val_loss: 1.5511 - val_accuracy: 0.3366\n",
      "Epoch 37/80\n",
      "6435/6435 [==============================] - 0s 41us/step - loss: 1.5443 - accuracy: 0.3285 - val_loss: 1.5261 - val_accuracy: 0.3450\n",
      "Epoch 38/80\n",
      "6435/6435 [==============================] - 0s 36us/step - loss: 1.5323 - accuracy: 0.3368 - val_loss: 1.5260 - val_accuracy: 0.3338\n",
      "Epoch 39/80\n",
      "6435/6435 [==============================] - 0s 36us/step - loss: 1.5351 - accuracy: 0.3326 - val_loss: 1.5323 - val_accuracy: 0.3422\n",
      "Epoch 40/80\n",
      "6435/6435 [==============================] - 0s 39us/step - loss: 1.5385 - accuracy: 0.3277 - val_loss: 1.5473 - val_accuracy: 0.3380\n",
      "Epoch 41/80\n",
      "6435/6435 [==============================] - 0s 36us/step - loss: 1.5312 - accuracy: 0.3366 - val_loss: 1.5265 - val_accuracy: 0.3534\n",
      "Epoch 42/80\n",
      "6435/6435 [==============================] - 0s 34us/step - loss: 1.5354 - accuracy: 0.3319 - val_loss: 1.5362 - val_accuracy: 0.3436\n",
      "Epoch 43/80\n",
      "6435/6435 [==============================] - 0s 36us/step - loss: 1.5376 - accuracy: 0.3363 - val_loss: 1.5572 - val_accuracy: 0.3436\n",
      "Epoch 44/80\n",
      "6435/6435 [==============================] - 0s 34us/step - loss: 1.5359 - accuracy: 0.3312 - val_loss: 1.5282 - val_accuracy: 0.3366\n",
      "Epoch 45/80\n",
      "6435/6435 [==============================] - 0s 32us/step - loss: 1.5331 - accuracy: 0.3310 - val_loss: 1.5247 - val_accuracy: 0.3561\n",
      "Epoch 46/80\n",
      "6435/6435 [==============================] - 0s 34us/step - loss: 1.5294 - accuracy: 0.3347 - val_loss: 1.5410 - val_accuracy: 0.3506\n",
      "Epoch 47/80\n",
      "6435/6435 [==============================] - 0s 39us/step - loss: 1.5293 - accuracy: 0.3394 - val_loss: 1.5263 - val_accuracy: 0.3506\n",
      "Epoch 48/80\n",
      "6435/6435 [==============================] - 0s 39us/step - loss: 1.5292 - accuracy: 0.3332 - val_loss: 1.5250 - val_accuracy: 0.3534\n",
      "Epoch 49/80\n",
      "6435/6435 [==============================] - 0s 36us/step - loss: 1.5264 - accuracy: 0.3294 - val_loss: 1.5268 - val_accuracy: 0.3547\n",
      "Epoch 50/80\n",
      "6435/6435 [==============================] - 0s 36us/step - loss: 1.5281 - accuracy: 0.3388 - val_loss: 1.5253 - val_accuracy: 0.3534\n",
      "Epoch 51/80\n",
      "6435/6435 [==============================] - 0s 34us/step - loss: 1.5294 - accuracy: 0.3422 - val_loss: 1.5229 - val_accuracy: 0.3268\n",
      "Epoch 52/80\n",
      "6435/6435 [==============================] - 0s 36us/step - loss: 1.5273 - accuracy: 0.3382 - val_loss: 1.5424 - val_accuracy: 0.3436\n",
      "Epoch 53/80\n",
      "6435/6435 [==============================] - 0s 36us/step - loss: 1.5279 - accuracy: 0.3312 - val_loss: 1.5206 - val_accuracy: 0.3534\n",
      "Epoch 54/80\n",
      "6435/6435 [==============================] - 0s 34us/step - loss: 1.5264 - accuracy: 0.3374 - val_loss: 1.5202 - val_accuracy: 0.3631\n",
      "Epoch 55/80\n",
      "6435/6435 [==============================] - 0s 36us/step - loss: 1.5260 - accuracy: 0.3372 - val_loss: 1.5342 - val_accuracy: 0.3534\n",
      "Epoch 56/80\n",
      "6435/6435 [==============================] - 0s 36us/step - loss: 1.5303 - accuracy: 0.3405 - val_loss: 1.5227 - val_accuracy: 0.3464\n",
      "Epoch 57/80\n",
      "6435/6435 [==============================] - 0s 32us/step - loss: 1.5229 - accuracy: 0.3436 - val_loss: 1.5307 - val_accuracy: 0.3617\n",
      "Epoch 58/80\n",
      "6435/6435 [==============================] - 0s 34us/step - loss: 1.5293 - accuracy: 0.3329 - val_loss: 1.5266 - val_accuracy: 0.3575\n",
      "Epoch 59/80\n",
      "6435/6435 [==============================] - 0s 39us/step - loss: 1.5316 - accuracy: 0.3338 - val_loss: 1.5176 - val_accuracy: 0.3659\n",
      "Epoch 60/80\n",
      "6435/6435 [==============================] - 0s 34us/step - loss: 1.5340 - accuracy: 0.3368 - val_loss: 1.5150 - val_accuracy: 0.3659\n",
      "Epoch 61/80\n",
      "6435/6435 [==============================] - 0s 36us/step - loss: 1.5268 - accuracy: 0.3403 - val_loss: 1.5222 - val_accuracy: 0.3561\n",
      "Epoch 62/80\n",
      "6435/6435 [==============================] - 0s 34us/step - loss: 1.5239 - accuracy: 0.3305 - val_loss: 1.5155 - val_accuracy: 0.3561\n",
      "Epoch 63/80\n",
      "6435/6435 [==============================] - 0s 36us/step - loss: 1.5263 - accuracy: 0.3355 - val_loss: 1.5964 - val_accuracy: 0.3492\n",
      "Epoch 64/80\n",
      "6435/6435 [==============================] - 0s 34us/step - loss: 1.5308 - accuracy: 0.3361 - val_loss: 1.5180 - val_accuracy: 0.3603\n",
      "Epoch 65/80\n",
      "6435/6435 [==============================] - 0s 34us/step - loss: 1.5225 - accuracy: 0.3394 - val_loss: 1.5132 - val_accuracy: 0.3534\n",
      "Epoch 66/80\n",
      "6435/6435 [==============================] - 0s 36us/step - loss: 1.5220 - accuracy: 0.3434 - val_loss: 1.5140 - val_accuracy: 0.3561\n",
      "Epoch 67/80\n",
      "6435/6435 [==============================] - 0s 36us/step - loss: 1.5194 - accuracy: 0.3399 - val_loss: 1.5182 - val_accuracy: 0.3659\n",
      "Epoch 68/80\n",
      "6435/6435 [==============================] - 0s 34us/step - loss: 1.5212 - accuracy: 0.3439 - val_loss: 1.5082 - val_accuracy: 0.3631\n",
      "Epoch 69/80\n",
      "6435/6435 [==============================] - 0s 36us/step - loss: 1.5158 - accuracy: 0.3366 - val_loss: 1.5094 - val_accuracy: 0.3659\n",
      "Epoch 70/80\n",
      "6435/6435 [==============================] - 0s 36us/step - loss: 1.4999 - accuracy: 0.3447 - val_loss: 1.4884 - val_accuracy: 0.3534\n",
      "Epoch 71/80\n",
      "6435/6435 [==============================] - 0s 34us/step - loss: 1.4922 - accuracy: 0.3501 - val_loss: 1.4792 - val_accuracy: 0.3589\n",
      "Epoch 72/80\n",
      "6435/6435 [==============================] - 0s 36us/step - loss: 1.4789 - accuracy: 0.3492 - val_loss: 1.4667 - val_accuracy: 0.3631\n",
      "Epoch 73/80\n",
      "6435/6435 [==============================] - 0s 39us/step - loss: 1.4694 - accuracy: 0.3588 - val_loss: 1.4549 - val_accuracy: 0.3617\n",
      "Epoch 74/80\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6435/6435 [==============================] - 0s 34us/step - loss: 1.4621 - accuracy: 0.3587 - val_loss: 1.4553 - val_accuracy: 0.3729\n",
      "Epoch 75/80\n",
      "6435/6435 [==============================] - 0s 36us/step - loss: 1.4569 - accuracy: 0.3571 - val_loss: 1.4439 - val_accuracy: 0.3645\n",
      "Epoch 76/80\n",
      "6435/6435 [==============================] - 0s 36us/step - loss: 1.4539 - accuracy: 0.3613 - val_loss: 1.4411 - val_accuracy: 0.3492\n",
      "Epoch 77/80\n",
      "6435/6435 [==============================] - 0s 34us/step - loss: 1.4481 - accuracy: 0.3635 - val_loss: 1.4436 - val_accuracy: 0.3715\n",
      "Epoch 78/80\n",
      "6435/6435 [==============================] - 0s 34us/step - loss: 1.4447 - accuracy: 0.3618 - val_loss: 1.4405 - val_accuracy: 0.3617\n",
      "Epoch 79/80\n",
      "6435/6435 [==============================] - 0s 36us/step - loss: 1.4400 - accuracy: 0.3552 - val_loss: 1.4248 - val_accuracy: 0.3687\n",
      "Epoch 80/80\n",
      "6435/6435 [==============================] - 0s 36us/step - loss: 1.4367 - accuracy: 0.3632 - val_loss: 1.4282 - val_accuracy: 0.3701\n",
      "[[2.8297207e-01 1.8070768e-01 7.7261027e-13 ... 1.5872621e-04\n",
      "  1.9539015e-01 1.5774995e-01]\n",
      " [1.3867864e-01 7.2854459e-02 2.2720150e-20 ... 2.2681130e-01\n",
      "  6.9334591e-04 8.0318391e-02]\n",
      " [3.6267579e-01 2.4141866e-01 6.0194688e-17 ... 1.0873466e-02\n",
      "  1.5281838e-01 1.5696734e-01]\n",
      " ...\n",
      " [3.2324907e-01 2.2261518e-01 1.1311788e-18 ... 6.4280830e-02\n",
      "  3.3222251e-02 1.4504687e-01]\n",
      " [2.6862386e-01 1.6516380e-01 7.5080515e-12 ... 4.3125136e-05\n",
      "  1.4402857e-01 1.4499392e-01]\n",
      " [2.7423280e-01 1.7356639e-01 1.7668962e-12 ... 8.5304433e-05\n",
      "  1.7112912e-01 1.4953703e-01]]\n",
      "[0 5 0 ... 0 0 0]\n",
      "<class 'numpy.ndarray'>\n",
      "One CNN, r:  0\n",
      "Computing Time:  0:06:35.708307\n",
      "n, p1, p2 15 1 2\n",
      "Model: \"sequential_1\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv1d_1 (Conv1D)            (None, 3, 6)              12        \n",
      "_________________________________________________________________\n",
      "average_pooling1d_1 (Average (None, 1, 6)              0         \n",
      "_________________________________________________________________\n",
      "conv1d_2 (Conv1D)            (None, 1, 16)             112       \n",
      "_________________________________________________________________\n",
      "average_pooling1d_2 (Average (None, 1, 16)             0         \n",
      "_________________________________________________________________\n",
      "conv1d_3 (Conv1D)            (None, 1, 120)            2040      \n",
      "_________________________________________________________________\n",
      "flatten_1 (Flatten)          (None, 120)               0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 84)                10164     \n",
      "_________________________________________________________________\n",
      "preds (Dense)                (None, 14)                1190      \n",
      "=================================================================\n",
      "Total params: 13,518\n",
      "Trainable params: 13,518\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Train on 6435 samples, validate on 716 samples\n",
      "Epoch 1/80\n",
      "6435/6435 [==============================] - 0s 70us/step - loss: 2.6112 - accuracy: 0.1391 - val_loss: 2.5393 - val_accuracy: 0.1844\n",
      "Epoch 2/80\n",
      "6435/6435 [==============================] - 0s 39us/step - loss: 2.3543 - accuracy: 0.1748 - val_loss: 2.1546 - val_accuracy: 0.2263\n",
      "Epoch 3/80\n",
      "6435/6435 [==============================] - 0s 39us/step - loss: 2.0742 - accuracy: 0.2236 - val_loss: 1.9931 - val_accuracy: 0.2500\n",
      "Epoch 4/80\n",
      "6435/6435 [==============================] - 0s 39us/step - loss: 1.9620 - accuracy: 0.2555 - val_loss: 1.8990 - val_accuracy: 0.2444\n",
      "Epoch 5/80\n",
      "6435/6435 [==============================] - 0s 36us/step - loss: 1.8866 - accuracy: 0.2772 - val_loss: 1.8414 - val_accuracy: 0.2556\n",
      "Epoch 6/80\n",
      "6435/6435 [==============================] - 0s 34us/step - loss: 1.8221 - accuracy: 0.2842 - val_loss: 1.7883 - val_accuracy: 0.2640\n",
      "Epoch 7/80\n",
      "6435/6435 [==============================] - 0s 34us/step - loss: 1.7618 - accuracy: 0.2906 - val_loss: 1.7467 - val_accuracy: 0.2640\n",
      "Epoch 8/80\n",
      "6435/6435 [==============================] - 0s 36us/step - loss: 1.7265 - accuracy: 0.2900 - val_loss: 1.7296 - val_accuracy: 0.2807\n",
      "Epoch 9/80\n",
      "6435/6435 [==============================] - 0s 37us/step - loss: 1.7112 - accuracy: 0.2962 - val_loss: 1.7239 - val_accuracy: 0.2793\n",
      "Epoch 10/80\n",
      "6435/6435 [==============================] - 0s 34us/step - loss: 1.6949 - accuracy: 0.3018 - val_loss: 1.7096 - val_accuracy: 0.2654\n",
      "Epoch 11/80\n",
      "6435/6435 [==============================] - 0s 38us/step - loss: 1.6882 - accuracy: 0.3035 - val_loss: 1.7023 - val_accuracy: 0.2779\n",
      "Epoch 12/80\n",
      "6435/6435 [==============================] - 0s 32us/step - loss: 1.6815 - accuracy: 0.2909 - val_loss: 1.7118 - val_accuracy: 0.2779\n",
      "Epoch 13/80\n",
      "6435/6435 [==============================] - 0s 36us/step - loss: 1.6736 - accuracy: 0.2987 - val_loss: 1.6890 - val_accuracy: 0.2682\n",
      "Epoch 14/80\n",
      "6435/6435 [==============================] - 0s 39us/step - loss: 1.6660 - accuracy: 0.2963 - val_loss: 1.6985 - val_accuracy: 0.2737\n",
      "Epoch 15/80\n",
      "6435/6435 [==============================] - 0s 36us/step - loss: 1.6586 - accuracy: 0.2949 - val_loss: 1.6834 - val_accuracy: 0.2821\n",
      "Epoch 16/80\n",
      "6435/6435 [==============================] - 0s 38us/step - loss: 1.6570 - accuracy: 0.3111 - val_loss: 1.6933 - val_accuracy: 0.2682\n",
      "Epoch 17/80\n",
      "6435/6435 [==============================] - 0s 42us/step - loss: 1.6557 - accuracy: 0.3060 - val_loss: 1.6923 - val_accuracy: 0.2765\n",
      "Epoch 18/80\n",
      "6435/6435 [==============================] - 0s 40us/step - loss: 1.6501 - accuracy: 0.3029 - val_loss: 1.6890 - val_accuracy: 0.2933\n",
      "Epoch 19/80\n",
      "6435/6435 [==============================] - 0s 37us/step - loss: 1.6497 - accuracy: 0.3016 - val_loss: 1.6783 - val_accuracy: 0.2626\n",
      "Epoch 20/80\n",
      "6435/6435 [==============================] - 0s 34us/step - loss: 1.6467 - accuracy: 0.3038 - val_loss: 1.6819 - val_accuracy: 0.2919\n",
      "Epoch 21/80\n",
      "6435/6435 [==============================] - 0s 36us/step - loss: 1.6488 - accuracy: 0.2981 - val_loss: 1.6786 - val_accuracy: 0.2821\n",
      "Epoch 22/80\n",
      "6435/6435 [==============================] - 0s 33us/step - loss: 1.6468 - accuracy: 0.2999 - val_loss: 1.6720 - val_accuracy: 0.2682\n",
      "Epoch 23/80\n",
      "6435/6435 [==============================] - 0s 32us/step - loss: 1.6453 - accuracy: 0.3030 - val_loss: 1.6765 - val_accuracy: 0.2542\n",
      "Epoch 24/80\n",
      "6435/6435 [==============================] - 0s 32us/step - loss: 1.6391 - accuracy: 0.3043 - val_loss: 1.6699 - val_accuracy: 0.2793\n",
      "Epoch 25/80\n",
      "6435/6435 [==============================] - 0s 36us/step - loss: 1.6396 - accuracy: 0.3001 - val_loss: 1.6609 - val_accuracy: 0.2821\n",
      "Epoch 26/80\n",
      "6435/6435 [==============================] - 0s 34us/step - loss: 1.6379 - accuracy: 0.3064 - val_loss: 1.6607 - val_accuracy: 0.2807\n",
      "Epoch 27/80\n",
      "6435/6435 [==============================] - 0s 34us/step - loss: 1.6396 - accuracy: 0.3071 - val_loss: 1.6697 - val_accuracy: 0.2933\n",
      "Epoch 28/80\n",
      "6435/6435 [==============================] - 0s 34us/step - loss: 1.6361 - accuracy: 0.3057 - val_loss: 1.6814 - val_accuracy: 0.2723\n",
      "Epoch 29/80\n",
      "6435/6435 [==============================] - 0s 39us/step - loss: 1.6353 - accuracy: 0.3041 - val_loss: 1.6769 - val_accuracy: 0.2961\n",
      "Epoch 30/80\n",
      "6435/6435 [==============================] - 0s 34us/step - loss: 1.6395 - accuracy: 0.3077 - val_loss: 1.6825 - val_accuracy: 0.2709\n",
      "Epoch 31/80\n",
      "6435/6435 [==============================] - 0s 36us/step - loss: 1.6384 - accuracy: 0.3066 - val_loss: 1.6649 - val_accuracy: 0.2933\n",
      "Epoch 32/80\n",
      "6435/6435 [==============================] - 0s 36us/step - loss: 1.6382 - accuracy: 0.3015 - val_loss: 1.6766 - val_accuracy: 0.2654\n",
      "Epoch 33/80\n",
      "6435/6435 [==============================] - 0s 36us/step - loss: 1.6362 - accuracy: 0.3032 - val_loss: 1.6678 - val_accuracy: 0.2779\n",
      "Epoch 34/80\n",
      "6435/6435 [==============================] - 0s 37us/step - loss: 1.6287 - accuracy: 0.3078 - val_loss: 1.6701 - val_accuracy: 0.2723\n",
      "Epoch 35/80\n",
      "6435/6435 [==============================] - 0s 35us/step - loss: 1.6307 - accuracy: 0.3029 - val_loss: 1.6649 - val_accuracy: 0.2709\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 36/80\n",
      "6435/6435 [==============================] - 0s 36us/step - loss: 1.6353 - accuracy: 0.2981 - val_loss: 1.6723 - val_accuracy: 0.2388\n",
      "Epoch 00036: early stopping\n",
      "[[0.16183111 0.15203603 0.00073289 ... 0.25201038 0.12645346 0.13357005]\n",
      " [0.08029008 0.08952399 0.00213356 ... 0.00119044 0.07074699 0.06848476]\n",
      " [0.14987956 0.14870012 0.00064787 ... 0.01787692 0.0967303  0.10384998]\n",
      " ...\n",
      " [0.08982641 0.09822802 0.00178982 ... 0.00182758 0.07504009 0.07430949]\n",
      " [0.15715735 0.13062085 0.00131308 ... 0.19552654 0.12870526 0.13855061]\n",
      " [0.16155544 0.14614616 0.00087835 ... 0.23492011 0.12804043 0.1359841 ]]\n",
      "[11  4  4 ...  4 11 11]\n",
      "<class 'numpy.ndarray'>\n",
      "One CNN, r:  0\n",
      "Computing Time:  0:06:45.723957\n",
      "n, p1, p2 16 1 3\n",
      "Model: \"sequential_1\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv1d_1 (Conv1D)            (None, 3, 6)              12        \n",
      "_________________________________________________________________\n",
      "average_pooling1d_1 (Average (None, 1, 6)              0         \n",
      "_________________________________________________________________\n",
      "conv1d_2 (Conv1D)            (None, 1, 16)             112       \n",
      "_________________________________________________________________\n",
      "average_pooling1d_2 (Average (None, 1, 16)             0         \n",
      "_________________________________________________________________\n",
      "conv1d_3 (Conv1D)            (None, 1, 120)            2040      \n",
      "_________________________________________________________________\n",
      "flatten_1 (Flatten)          (None, 120)               0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 84)                10164     \n",
      "_________________________________________________________________\n",
      "preds (Dense)                (None, 14)                1190      \n",
      "=================================================================\n",
      "Total params: 13,518\n",
      "Trainable params: 13,518\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Train on 6435 samples, validate on 716 samples\n",
      "Epoch 1/80\n",
      "6435/6435 [==============================] - 0s 70us/step - loss: 2.5932 - accuracy: 0.1450 - val_loss: 2.4956 - val_accuracy: 0.1355\n",
      "Epoch 2/80\n",
      "6435/6435 [==============================] - 0s 36us/step - loss: 2.2970 - accuracy: 0.2059 - val_loss: 2.0899 - val_accuracy: 0.2151\n",
      "Epoch 3/80\n",
      "6435/6435 [==============================] - 0s 39us/step - loss: 1.9945 - accuracy: 0.2370 - val_loss: 1.9210 - val_accuracy: 0.2346\n",
      "Epoch 4/80\n",
      "6435/6435 [==============================] - 0s 34us/step - loss: 1.8717 - accuracy: 0.2493 - val_loss: 1.8239 - val_accuracy: 0.2318\n",
      "Epoch 5/80\n",
      "6435/6435 [==============================] - 0s 39us/step - loss: 1.7892 - accuracy: 0.2519 - val_loss: 1.7484 - val_accuracy: 0.2430\n",
      "Epoch 6/80\n",
      "6435/6435 [==============================] - 0s 39us/step - loss: 1.7172 - accuracy: 0.2726 - val_loss: 1.6994 - val_accuracy: 0.2640\n",
      "Epoch 7/80\n",
      "6435/6435 [==============================] - 0s 37us/step - loss: 1.6600 - accuracy: 0.2848 - val_loss: 1.6440 - val_accuracy: 0.2807\n",
      "Epoch 8/80\n",
      "6435/6435 [==============================] - 0s 33us/step - loss: 1.6188 - accuracy: 0.2929 - val_loss: 1.5950 - val_accuracy: 0.3170\n",
      "Epoch 9/80\n",
      "6435/6435 [==============================] - 0s 34us/step - loss: 1.5879 - accuracy: 0.3052 - val_loss: 1.5760 - val_accuracy: 0.2891\n",
      "Epoch 10/80\n",
      "6435/6435 [==============================] - 0s 36us/step - loss: 1.5670 - accuracy: 0.2991 - val_loss: 1.5678 - val_accuracy: 0.2626\n",
      "Epoch 11/80\n",
      "6435/6435 [==============================] - 0s 37us/step - loss: 1.5534 - accuracy: 0.3057 - val_loss: 1.5475 - val_accuracy: 0.2849\n",
      "Epoch 12/80\n",
      "6435/6435 [==============================] - 0s 36us/step - loss: 1.5379 - accuracy: 0.3041 - val_loss: 1.5293 - val_accuracy: 0.3115\n",
      "Epoch 13/80\n",
      "6435/6435 [==============================] - 0s 33us/step - loss: 1.5289 - accuracy: 0.3069 - val_loss: 1.5076 - val_accuracy: 0.3156\n",
      "Epoch 14/80\n",
      "6435/6435 [==============================] - 0s 37us/step - loss: 1.5290 - accuracy: 0.2971 - val_loss: 1.5275 - val_accuracy: 0.2919\n",
      "Epoch 15/80\n",
      "6435/6435 [==============================] - 0s 34us/step - loss: 1.5172 - accuracy: 0.3085 - val_loss: 1.5119 - val_accuracy: 0.2919\n",
      "Epoch 16/80\n",
      "6435/6435 [==============================] - 0s 32us/step - loss: 1.5157 - accuracy: 0.2970 - val_loss: 1.5449 - val_accuracy: 0.2751\n",
      "Epoch 17/80\n",
      "6435/6435 [==============================] - 0s 39us/step - loss: 1.5074 - accuracy: 0.3127 - val_loss: 1.4983 - val_accuracy: 0.3087\n",
      "Epoch 18/80\n",
      "6435/6435 [==============================] - 0s 34us/step - loss: 1.5001 - accuracy: 0.3078 - val_loss: 1.4946 - val_accuracy: 0.3156\n",
      "Epoch 19/80\n",
      "6435/6435 [==============================] - 0s 36us/step - loss: 1.4982 - accuracy: 0.3155 - val_loss: 1.4816 - val_accuracy: 0.2947\n",
      "Epoch 20/80\n",
      "6435/6435 [==============================] - 0s 45us/step - loss: 1.4921 - accuracy: 0.3120 - val_loss: 1.4974 - val_accuracy: 0.3142\n",
      "Epoch 21/80\n",
      "6435/6435 [==============================] - 0s 32us/step - loss: 1.4924 - accuracy: 0.3103 - val_loss: 1.4986 - val_accuracy: 0.2933\n",
      "Epoch 22/80\n",
      "6435/6435 [==============================] - 0s 34us/step - loss: 1.4930 - accuracy: 0.3047 - val_loss: 1.4861 - val_accuracy: 0.3226\n",
      "Epoch 23/80\n",
      "6435/6435 [==============================] - 0s 34us/step - loss: 1.4839 - accuracy: 0.3181 - val_loss: 1.4739 - val_accuracy: 0.3310\n",
      "Epoch 24/80\n",
      "6435/6435 [==============================] - 0s 36us/step - loss: 1.4797 - accuracy: 0.3203 - val_loss: 1.4709 - val_accuracy: 0.3324\n",
      "Epoch 25/80\n",
      "6435/6435 [==============================] - 0s 36us/step - loss: 1.4831 - accuracy: 0.3204 - val_loss: 1.4831 - val_accuracy: 0.3128\n",
      "Epoch 26/80\n",
      "6435/6435 [==============================] - 0s 36us/step - loss: 1.4815 - accuracy: 0.3144 - val_loss: 1.4781 - val_accuracy: 0.2835\n",
      "Epoch 27/80\n",
      "6435/6435 [==============================] - 0s 36us/step - loss: 1.4741 - accuracy: 0.3229 - val_loss: 1.4789 - val_accuracy: 0.2989\n",
      "Epoch 28/80\n",
      "6435/6435 [==============================] - 0s 36us/step - loss: 1.4718 - accuracy: 0.3231 - val_loss: 1.4732 - val_accuracy: 0.3073\n",
      "Epoch 29/80\n",
      "6435/6435 [==============================] - 0s 35us/step - loss: 1.4694 - accuracy: 0.3195 - val_loss: 1.4685 - val_accuracy: 0.3338\n",
      "Epoch 30/80\n",
      "6435/6435 [==============================] - 0s 34us/step - loss: 1.4707 - accuracy: 0.3232 - val_loss: 1.4699 - val_accuracy: 0.3338\n",
      "Epoch 31/80\n",
      "6435/6435 [==============================] - 0s 37us/step - loss: 1.4680 - accuracy: 0.3232 - val_loss: 1.4896 - val_accuracy: 0.3045\n",
      "Epoch 32/80\n",
      "6435/6435 [==============================] - 0s 35us/step - loss: 1.4700 - accuracy: 0.3200 - val_loss: 1.4698 - val_accuracy: 0.3324\n",
      "Epoch 33/80\n",
      "6435/6435 [==============================] - 0s 36us/step - loss: 1.4681 - accuracy: 0.3270 - val_loss: 1.4587 - val_accuracy: 0.3268\n",
      "Epoch 34/80\n",
      "6435/6435 [==============================] - 0s 34us/step - loss: 1.4615 - accuracy: 0.3221 - val_loss: 1.4498 - val_accuracy: 0.3631\n",
      "Epoch 35/80\n",
      "6435/6435 [==============================] - 0s 36us/step - loss: 1.4575 - accuracy: 0.3242 - val_loss: 1.4446 - val_accuracy: 0.3324\n",
      "Epoch 36/80\n",
      "6435/6435 [==============================] - 0s 33us/step - loss: 1.4596 - accuracy: 0.3175 - val_loss: 1.4425 - val_accuracy: 0.3408\n",
      "Epoch 37/80\n",
      "6435/6435 [==============================] - 0s 34us/step - loss: 1.4510 - accuracy: 0.3308 - val_loss: 1.4521 - val_accuracy: 0.3296\n",
      "Epoch 38/80\n",
      "6435/6435 [==============================] - 0s 35us/step - loss: 1.4592 - accuracy: 0.3383 - val_loss: 1.4532 - val_accuracy: 0.3408\n",
      "Epoch 39/80\n",
      "6435/6435 [==============================] - 0s 32us/step - loss: 1.4488 - accuracy: 0.3316 - val_loss: 1.4422 - val_accuracy: 0.3282\n",
      "Epoch 40/80\n",
      "6435/6435 [==============================] - 0s 34us/step - loss: 1.4430 - accuracy: 0.3358 - val_loss: 1.4410 - val_accuracy: 0.3534\n",
      "Epoch 41/80\n",
      "6435/6435 [==============================] - 0s 34us/step - loss: 1.4419 - accuracy: 0.3448 - val_loss: 1.4320 - val_accuracy: 0.3631\n",
      "Epoch 42/80\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6435/6435 [==============================] - 0s 39us/step - loss: 1.4468 - accuracy: 0.3441 - val_loss: 1.4244 - val_accuracy: 0.3715\n",
      "Epoch 43/80\n",
      "6435/6435 [==============================] - 0s 36us/step - loss: 1.4355 - accuracy: 0.3456 - val_loss: 1.4323 - val_accuracy: 0.3603\n",
      "Epoch 44/80\n",
      "6435/6435 [==============================] - 0s 34us/step - loss: 1.4334 - accuracy: 0.3512 - val_loss: 1.4271 - val_accuracy: 0.3492\n",
      "Epoch 45/80\n",
      "6435/6435 [==============================] - 0s 36us/step - loss: 1.4171 - accuracy: 0.3599 - val_loss: 1.4030 - val_accuracy: 0.3575\n",
      "Epoch 46/80\n",
      "6435/6435 [==============================] - 0s 36us/step - loss: 1.4126 - accuracy: 0.3580 - val_loss: 1.3898 - val_accuracy: 0.3631\n",
      "Epoch 47/80\n",
      "6435/6435 [==============================] - 0s 36us/step - loss: 1.3985 - accuracy: 0.3644 - val_loss: 1.3899 - val_accuracy: 0.3338\n",
      "Epoch 48/80\n",
      "6435/6435 [==============================] - 0s 36us/step - loss: 1.3934 - accuracy: 0.3660 - val_loss: 1.3721 - val_accuracy: 0.3785\n",
      "Epoch 49/80\n",
      "6435/6435 [==============================] - 0s 36us/step - loss: 1.3780 - accuracy: 0.3787 - val_loss: 1.3507 - val_accuracy: 0.3743\n",
      "Epoch 50/80\n",
      "6435/6435 [==============================] - 0s 41us/step - loss: 1.3649 - accuracy: 0.3834 - val_loss: 1.3533 - val_accuracy: 0.3757\n",
      "Epoch 51/80\n",
      "6435/6435 [==============================] - 0s 37us/step - loss: 1.3615 - accuracy: 0.3824 - val_loss: 1.3361 - val_accuracy: 0.3659\n",
      "Epoch 52/80\n",
      "6435/6435 [==============================] - 0s 38us/step - loss: 1.3444 - accuracy: 0.3796 - val_loss: 1.3238 - val_accuracy: 0.3883\n",
      "Epoch 53/80\n",
      "6435/6435 [==============================] - 0s 36us/step - loss: 1.3343 - accuracy: 0.3691 - val_loss: 1.3167 - val_accuracy: 0.3673\n",
      "Epoch 54/80\n",
      "6435/6435 [==============================] - 0s 36us/step - loss: 1.3291 - accuracy: 0.3815 - val_loss: 1.2856 - val_accuracy: 0.3855\n",
      "Epoch 55/80\n",
      "6435/6435 [==============================] - 0s 39us/step - loss: 1.3172 - accuracy: 0.3835 - val_loss: 1.3019 - val_accuracy: 0.3827\n",
      "Epoch 56/80\n",
      "6435/6435 [==============================] - 0s 40us/step - loss: 1.3172 - accuracy: 0.3828 - val_loss: 1.2876 - val_accuracy: 0.3855\n",
      "Epoch 57/80\n",
      "6435/6435 [==============================] - 0s 36us/step - loss: 1.3090 - accuracy: 0.3964 - val_loss: 1.2748 - val_accuracy: 0.3785\n",
      "Epoch 58/80\n",
      "6435/6435 [==============================] - 0s 38us/step - loss: 1.3020 - accuracy: 0.3815 - val_loss: 1.2661 - val_accuracy: 0.4218\n",
      "Epoch 59/80\n",
      "6435/6435 [==============================] - 0s 37us/step - loss: 1.2968 - accuracy: 0.3932 - val_loss: 1.2948 - val_accuracy: 0.3911\n",
      "Epoch 60/80\n",
      "6435/6435 [==============================] - 0s 36us/step - loss: 1.3002 - accuracy: 0.3883 - val_loss: 1.2670 - val_accuracy: 0.3953\n",
      "Epoch 61/80\n",
      "6435/6435 [==============================] - 0s 36us/step - loss: 1.2936 - accuracy: 0.3894 - val_loss: 1.2556 - val_accuracy: 0.4232\n",
      "Epoch 62/80\n",
      "6435/6435 [==============================] - 0s 34us/step - loss: 1.2893 - accuracy: 0.3919 - val_loss: 1.2802 - val_accuracy: 0.3771\n",
      "Epoch 63/80\n",
      "6435/6435 [==============================] - 0s 35us/step - loss: 1.2893 - accuracy: 0.3964 - val_loss: 1.2738 - val_accuracy: 0.3980\n",
      "Epoch 64/80\n",
      "6435/6435 [==============================] - 0s 38us/step - loss: 1.2814 - accuracy: 0.3930 - val_loss: 1.2723 - val_accuracy: 0.3994\n",
      "Epoch 65/80\n",
      "6435/6435 [==============================] - 0s 33us/step - loss: 1.2843 - accuracy: 0.3918 - val_loss: 1.2447 - val_accuracy: 0.4078\n",
      "Epoch 66/80\n",
      "6435/6435 [==============================] - 0s 39us/step - loss: 1.2831 - accuracy: 0.3927 - val_loss: 1.2328 - val_accuracy: 0.4316\n",
      "Epoch 67/80\n",
      "6435/6435 [==============================] - 0s 40us/step - loss: 1.2705 - accuracy: 0.3927 - val_loss: 1.2425 - val_accuracy: 0.4302\n",
      "Epoch 68/80\n",
      "6435/6435 [==============================] - 0s 37us/step - loss: 1.2748 - accuracy: 0.3882 - val_loss: 1.2381 - val_accuracy: 0.3827\n",
      "Epoch 69/80\n",
      "6435/6435 [==============================] - 0s 34us/step - loss: 1.2715 - accuracy: 0.3974 - val_loss: 1.2427 - val_accuracy: 0.4036\n",
      "Epoch 70/80\n",
      "6435/6435 [==============================] - 0s 34us/step - loss: 1.2710 - accuracy: 0.3995 - val_loss: 1.2379 - val_accuracy: 0.3966\n",
      "Epoch 71/80\n",
      "6435/6435 [==============================] - 0s 32us/step - loss: 1.2666 - accuracy: 0.4022 - val_loss: 1.2351 - val_accuracy: 0.3994\n",
      "Epoch 72/80\n",
      "6435/6435 [==============================] - 0s 35us/step - loss: 1.2667 - accuracy: 0.4014 - val_loss: 1.2522 - val_accuracy: 0.3841\n",
      "Epoch 73/80\n",
      "6435/6435 [==============================] - 0s 37us/step - loss: 1.2613 - accuracy: 0.3978 - val_loss: 1.2309 - val_accuracy: 0.4260\n",
      "Epoch 74/80\n",
      "6435/6435 [==============================] - 0s 35us/step - loss: 1.2617 - accuracy: 0.4028 - val_loss: 1.2256 - val_accuracy: 0.4078\n",
      "Epoch 75/80\n",
      "6435/6435 [==============================] - 0s 36us/step - loss: 1.2626 - accuracy: 0.3938 - val_loss: 1.2352 - val_accuracy: 0.4162\n",
      "Epoch 76/80\n",
      "6435/6435 [==============================] - 0s 34us/step - loss: 1.2537 - accuracy: 0.4006 - val_loss: 1.2323 - val_accuracy: 0.3869\n",
      "Epoch 77/80\n",
      "6435/6435 [==============================] - 0s 34us/step - loss: 1.2553 - accuracy: 0.4005 - val_loss: 1.2313 - val_accuracy: 0.3966\n",
      "Epoch 78/80\n",
      "6435/6435 [==============================] - 0s 36us/step - loss: 1.2517 - accuracy: 0.4011 - val_loss: 1.2190 - val_accuracy: 0.4106\n",
      "Epoch 79/80\n",
      "6435/6435 [==============================] - 0s 38us/step - loss: 1.2481 - accuracy: 0.3974 - val_loss: 1.2129 - val_accuracy: 0.4274\n",
      "Epoch 80/80\n",
      "6435/6435 [==============================] - 0s 35us/step - loss: 1.2480 - accuracy: 0.3952 - val_loss: 1.2194 - val_accuracy: 0.3980\n",
      "[[1.15776196e-01 1.39347300e-01 6.38243180e-15 ... 3.00042987e-01\n",
      "  2.17302293e-01 2.11802065e-01]\n",
      " [2.72951443e-02 4.23615687e-02 6.85195589e-24 ... 9.66956490e-04\n",
      "  9.15671140e-03 8.42459593e-03]\n",
      " [1.79767460e-01 2.45120034e-01 5.46695206e-18 ... 4.43083793e-02\n",
      "  2.80427903e-01 2.45235756e-01]\n",
      " ...\n",
      " [1.77309752e-01 2.73687094e-01 6.52850541e-19 ... 5.19378576e-03\n",
      "  2.79209286e-01 2.63417244e-01]\n",
      " [9.66622010e-02 1.33756801e-01 8.70332520e-14 ... 1.53228268e-01\n",
      "  3.09409022e-01 2.88661510e-01]\n",
      " [1.10930704e-01 1.48661032e-01 2.26057813e-14 ... 1.62264317e-01\n",
      "  2.93324709e-01 2.72977114e-01]]\n",
      "[11  4 12 ... 12 12 12]\n",
      "<class 'numpy.ndarray'>\n",
      "One CNN, r:  0\n",
      "Computing Time:  0:07:05.942637\n",
      "n, p1, p2 17 1 4\n",
      "Model: \"sequential_1\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv1d_1 (Conv1D)            (None, 3, 6)              12        \n",
      "_________________________________________________________________\n",
      "average_pooling1d_1 (Average (None, 1, 6)              0         \n",
      "_________________________________________________________________\n",
      "conv1d_2 (Conv1D)            (None, 1, 16)             112       \n",
      "_________________________________________________________________\n",
      "average_pooling1d_2 (Average (None, 1, 16)             0         \n",
      "_________________________________________________________________\n",
      "conv1d_3 (Conv1D)            (None, 1, 120)            2040      \n",
      "_________________________________________________________________\n",
      "flatten_1 (Flatten)          (None, 120)               0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 84)                10164     \n",
      "_________________________________________________________________\n",
      "preds (Dense)                (None, 14)                1190      \n",
      "=================================================================\n",
      "Total params: 13,518\n",
      "Trainable params: 13,518\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Train on 6435 samples, validate on 716 samples\n",
      "Epoch 1/80\n",
      "6435/6435 [==============================] - 0s 70us/step - loss: 2.5788 - accuracy: 0.1444 - val_loss: 2.4438 - val_accuracy: 0.1872\n",
      "Epoch 2/80\n",
      "6435/6435 [==============================] - 0s 45us/step - loss: 2.2260 - accuracy: 0.2204 - val_loss: 2.0436 - val_accuracy: 0.2095\n",
      "Epoch 3/80\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6435/6435 [==============================] - 0s 40us/step - loss: 1.9312 - accuracy: 0.2328 - val_loss: 1.8544 - val_accuracy: 0.2165\n",
      "Epoch 4/80\n",
      "6435/6435 [==============================] - 0s 38us/step - loss: 1.8001 - accuracy: 0.2410 - val_loss: 1.7668 - val_accuracy: 0.2528\n",
      "Epoch 5/80\n",
      "6435/6435 [==============================] - 0s 36us/step - loss: 1.7253 - accuracy: 0.2572 - val_loss: 1.7085 - val_accuracy: 0.2207\n",
      "Epoch 6/80\n",
      "6435/6435 [==============================] - 0s 37us/step - loss: 1.6630 - accuracy: 0.2800 - val_loss: 1.6940 - val_accuracy: 0.2640\n",
      "Epoch 7/80\n",
      "6435/6435 [==============================] - 0s 41us/step - loss: 1.6227 - accuracy: 0.2932 - val_loss: 1.6218 - val_accuracy: 0.2542\n",
      "Epoch 8/80\n",
      "6435/6435 [==============================] - 0s 36us/step - loss: 1.5894 - accuracy: 0.2908 - val_loss: 1.5875 - val_accuracy: 0.2821\n",
      "Epoch 9/80\n",
      "6435/6435 [==============================] - 0s 39us/step - loss: 1.5701 - accuracy: 0.2890 - val_loss: 1.5690 - val_accuracy: 0.2947\n",
      "Epoch 10/80\n",
      "6435/6435 [==============================] - 0s 34us/step - loss: 1.5501 - accuracy: 0.2996 - val_loss: 1.5558 - val_accuracy: 0.3073\n",
      "Epoch 11/80\n",
      "6435/6435 [==============================] - 0s 39us/step - loss: 1.5361 - accuracy: 0.3111 - val_loss: 1.5407 - val_accuracy: 0.2975\n",
      "Epoch 12/80\n",
      "6435/6435 [==============================] - 0s 36us/step - loss: 1.5188 - accuracy: 0.3082 - val_loss: 1.5691 - val_accuracy: 0.2626\n",
      "Epoch 13/80\n",
      "6435/6435 [==============================] - 0s 36us/step - loss: 1.5185 - accuracy: 0.2957 - val_loss: 1.5474 - val_accuracy: 0.2835\n",
      "Epoch 14/80\n",
      "6435/6435 [==============================] - 0s 36us/step - loss: 1.5152 - accuracy: 0.3038 - val_loss: 1.5356 - val_accuracy: 0.2626\n",
      "Epoch 15/80\n",
      "6435/6435 [==============================] - 0s 36us/step - loss: 1.5033 - accuracy: 0.3078 - val_loss: 1.5096 - val_accuracy: 0.2835\n",
      "Epoch 16/80\n",
      "6435/6435 [==============================] - 0s 36us/step - loss: 1.4956 - accuracy: 0.3066 - val_loss: 1.5093 - val_accuracy: 0.3115\n",
      "Epoch 17/80\n",
      "6435/6435 [==============================] - 0s 36us/step - loss: 1.4935 - accuracy: 0.3114 - val_loss: 1.5014 - val_accuracy: 0.2961\n",
      "Epoch 18/80\n",
      "6435/6435 [==============================] - 0s 36us/step - loss: 1.4927 - accuracy: 0.3037 - val_loss: 1.5146 - val_accuracy: 0.2877\n",
      "Epoch 19/80\n",
      "6435/6435 [==============================] - 0s 34us/step - loss: 1.4899 - accuracy: 0.3058 - val_loss: 1.5279 - val_accuracy: 0.2933\n",
      "Epoch 20/80\n",
      "6435/6435 [==============================] - 0s 36us/step - loss: 1.4824 - accuracy: 0.3164 - val_loss: 1.4901 - val_accuracy: 0.3087\n",
      "Epoch 21/80\n",
      "6435/6435 [==============================] - 0s 36us/step - loss: 1.4779 - accuracy: 0.3144 - val_loss: 1.4852 - val_accuracy: 0.3045\n",
      "Epoch 22/80\n",
      "6435/6435 [==============================] - 0s 37us/step - loss: 1.4777 - accuracy: 0.3097 - val_loss: 1.4926 - val_accuracy: 0.3003\n",
      "Epoch 23/80\n",
      "6435/6435 [==============================] - 0s 35us/step - loss: 1.4821 - accuracy: 0.3184 - val_loss: 1.4970 - val_accuracy: 0.2989\n",
      "Epoch 24/80\n",
      "6435/6435 [==============================] - 0s 39us/step - loss: 1.4767 - accuracy: 0.3100 - val_loss: 1.4861 - val_accuracy: 0.2989\n",
      "Epoch 25/80\n",
      "6435/6435 [==============================] - 0s 43us/step - loss: 1.4731 - accuracy: 0.3111 - val_loss: 1.4942 - val_accuracy: 0.2877\n",
      "Epoch 26/80\n",
      "6435/6435 [==============================] - 0s 36us/step - loss: 1.4764 - accuracy: 0.3097 - val_loss: 1.5019 - val_accuracy: 0.3128\n",
      "Epoch 27/80\n",
      "6435/6435 [==============================] - 0s 39us/step - loss: 1.4778 - accuracy: 0.3091 - val_loss: 1.4887 - val_accuracy: 0.3059\n",
      "Epoch 28/80\n",
      "6435/6435 [==============================] - 0s 36us/step - loss: 1.4681 - accuracy: 0.3173 - val_loss: 1.4772 - val_accuracy: 0.3254\n",
      "Epoch 29/80\n",
      "6435/6435 [==============================] - 0s 34us/step - loss: 1.4711 - accuracy: 0.3077 - val_loss: 1.4768 - val_accuracy: 0.3059\n",
      "Epoch 30/80\n",
      "6435/6435 [==============================] - 0s 34us/step - loss: 1.4713 - accuracy: 0.3049 - val_loss: 1.4915 - val_accuracy: 0.2807\n",
      "Epoch 31/80\n",
      "6435/6435 [==============================] - 0s 34us/step - loss: 1.4662 - accuracy: 0.3193 - val_loss: 1.4892 - val_accuracy: 0.3212\n",
      "Epoch 32/80\n",
      "6435/6435 [==============================] - 0s 34us/step - loss: 1.4667 - accuracy: 0.3203 - val_loss: 1.4757 - val_accuracy: 0.3115\n",
      "Epoch 33/80\n",
      "6435/6435 [==============================] - 0s 36us/step - loss: 1.4687 - accuracy: 0.3167 - val_loss: 1.4721 - val_accuracy: 0.3059\n",
      "Epoch 34/80\n",
      "6435/6435 [==============================] - 0s 34us/step - loss: 1.4650 - accuracy: 0.3184 - val_loss: 1.4722 - val_accuracy: 0.3156\n",
      "Epoch 35/80\n",
      "6435/6435 [==============================] - 0s 37us/step - loss: 1.4724 - accuracy: 0.3083 - val_loss: 1.4775 - val_accuracy: 0.3310\n",
      "Epoch 36/80\n",
      "6435/6435 [==============================] - 0s 32us/step - loss: 1.4676 - accuracy: 0.3153 - val_loss: 1.4747 - val_accuracy: 0.2947\n",
      "Epoch 37/80\n",
      "6435/6435 [==============================] - 0s 36us/step - loss: 1.4699 - accuracy: 0.3189 - val_loss: 1.4762 - val_accuracy: 0.2723\n",
      "Epoch 38/80\n",
      "6435/6435 [==============================] - 0s 36us/step - loss: 1.4657 - accuracy: 0.3141 - val_loss: 1.4693 - val_accuracy: 0.2919\n",
      "Epoch 39/80\n",
      "6435/6435 [==============================] - 0s 34us/step - loss: 1.4628 - accuracy: 0.3096 - val_loss: 1.4946 - val_accuracy: 0.3101\n",
      "Epoch 40/80\n",
      "6435/6435 [==============================] - 0s 33us/step - loss: 1.4635 - accuracy: 0.3144 - val_loss: 1.4666 - val_accuracy: 0.3198\n",
      "Epoch 41/80\n",
      "6435/6435 [==============================] - 0s 34us/step - loss: 1.4619 - accuracy: 0.3155 - val_loss: 1.4762 - val_accuracy: 0.2863\n",
      "Epoch 42/80\n",
      "6435/6435 [==============================] - 0s 37us/step - loss: 1.4659 - accuracy: 0.3040 - val_loss: 1.4723 - val_accuracy: 0.2863\n",
      "Epoch 43/80\n",
      "6435/6435 [==============================] - 0s 37us/step - loss: 1.4691 - accuracy: 0.3164 - val_loss: 1.4565 - val_accuracy: 0.3310\n",
      "Epoch 44/80\n",
      "6435/6435 [==============================] - 0s 38us/step - loss: 1.4575 - accuracy: 0.3221 - val_loss: 1.4629 - val_accuracy: 0.2905\n",
      "Epoch 45/80\n",
      "6435/6435 [==============================] - 0s 37us/step - loss: 1.4609 - accuracy: 0.3179 - val_loss: 1.4944 - val_accuracy: 0.3003\n",
      "Epoch 46/80\n",
      "6435/6435 [==============================] - 0s 34us/step - loss: 1.4583 - accuracy: 0.3134 - val_loss: 1.4613 - val_accuracy: 0.2919\n",
      "Epoch 47/80\n",
      "6435/6435 [==============================] - 0s 35us/step - loss: 1.4546 - accuracy: 0.3198 - val_loss: 1.4589 - val_accuracy: 0.3045\n",
      "Epoch 48/80\n",
      "6435/6435 [==============================] - 0s 31us/step - loss: 1.4573 - accuracy: 0.3221 - val_loss: 1.4756 - val_accuracy: 0.2807\n",
      "Epoch 49/80\n",
      "6435/6435 [==============================] - 0s 34us/step - loss: 1.4579 - accuracy: 0.3181 - val_loss: 1.4709 - val_accuracy: 0.3115\n",
      "Epoch 50/80\n",
      "6435/6435 [==============================] - 0s 40us/step - loss: 1.4529 - accuracy: 0.3249 - val_loss: 1.4903 - val_accuracy: 0.2891\n",
      "Epoch 51/80\n",
      "6435/6435 [==============================] - 0s 36us/step - loss: 1.4562 - accuracy: 0.3114 - val_loss: 1.4639 - val_accuracy: 0.3073\n",
      "Epoch 52/80\n",
      "6435/6435 [==============================] - 0s 34us/step - loss: 1.4550 - accuracy: 0.3128 - val_loss: 1.4667 - val_accuracy: 0.2863\n",
      "Epoch 53/80\n",
      "6435/6435 [==============================] - 0s 38us/step - loss: 1.4575 - accuracy: 0.3120 - val_loss: 1.4520 - val_accuracy: 0.3296\n",
      "Epoch 54/80\n",
      "6435/6435 [==============================] - 0s 35us/step - loss: 1.4645 - accuracy: 0.3131 - val_loss: 1.4602 - val_accuracy: 0.2947\n",
      "Epoch 55/80\n",
      "6435/6435 [==============================] - 0s 36us/step - loss: 1.4571 - accuracy: 0.3192 - val_loss: 1.4561 - val_accuracy: 0.3338\n",
      "Epoch 56/80\n",
      "6435/6435 [==============================] - 0s 34us/step - loss: 1.4571 - accuracy: 0.3183 - val_loss: 1.4571 - val_accuracy: 0.3240\n",
      "Epoch 57/80\n",
      "6435/6435 [==============================] - 0s 35us/step - loss: 1.4538 - accuracy: 0.3179 - val_loss: 1.4649 - val_accuracy: 0.2947\n",
      "Epoch 58/80\n",
      "6435/6435 [==============================] - 0s 36us/step - loss: 1.4534 - accuracy: 0.3260 - val_loss: 1.4498 - val_accuracy: 0.3408\n",
      "Epoch 59/80\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6435/6435 [==============================] - 0s 37us/step - loss: 1.4496 - accuracy: 0.3262 - val_loss: 1.4981 - val_accuracy: 0.2779\n",
      "Epoch 60/80\n",
      "6435/6435 [==============================] - 0s 34us/step - loss: 1.4482 - accuracy: 0.3106 - val_loss: 1.4667 - val_accuracy: 0.3170\n",
      "Epoch 61/80\n",
      "6435/6435 [==============================] - 0s 39us/step - loss: 1.4462 - accuracy: 0.3206 - val_loss: 1.4577 - val_accuracy: 0.3156\n",
      "Epoch 62/80\n",
      "6435/6435 [==============================] - 0s 36us/step - loss: 1.4504 - accuracy: 0.3192 - val_loss: 1.4604 - val_accuracy: 0.3170\n",
      "Epoch 63/80\n",
      "6435/6435 [==============================] - 0s 34us/step - loss: 1.4517 - accuracy: 0.3130 - val_loss: 1.4861 - val_accuracy: 0.2723\n",
      "Epoch 64/80\n",
      "6435/6435 [==============================] - 0s 34us/step - loss: 1.4506 - accuracy: 0.3218 - val_loss: 1.4475 - val_accuracy: 0.3534\n",
      "Epoch 65/80\n",
      "6435/6435 [==============================] - 0s 36us/step - loss: 1.4480 - accuracy: 0.3243 - val_loss: 1.4708 - val_accuracy: 0.3073\n",
      "Epoch 66/80\n",
      "6435/6435 [==============================] - 0s 40us/step - loss: 1.4580 - accuracy: 0.3214 - val_loss: 1.4487 - val_accuracy: 0.3366\n",
      "Epoch 67/80\n",
      "6435/6435 [==============================] - 0s 35us/step - loss: 1.4471 - accuracy: 0.3186 - val_loss: 1.4766 - val_accuracy: 0.2961\n",
      "Epoch 68/80\n",
      "6435/6435 [==============================] - 0s 35us/step - loss: 1.4493 - accuracy: 0.3223 - val_loss: 1.4683 - val_accuracy: 0.3547\n",
      "Epoch 69/80\n",
      "6435/6435 [==============================] - 0s 33us/step - loss: 1.4486 - accuracy: 0.3186 - val_loss: 1.4477 - val_accuracy: 0.3017\n",
      "Epoch 70/80\n",
      "6435/6435 [==============================] - 0s 35us/step - loss: 1.4404 - accuracy: 0.3267 - val_loss: 1.4366 - val_accuracy: 0.3296\n",
      "Epoch 71/80\n",
      "6435/6435 [==============================] - 0s 38us/step - loss: 1.4382 - accuracy: 0.3225 - val_loss: 1.4414 - val_accuracy: 0.3338\n",
      "Epoch 72/80\n",
      "6435/6435 [==============================] - 0s 32us/step - loss: 1.4484 - accuracy: 0.3235 - val_loss: 1.4554 - val_accuracy: 0.3492\n",
      "Epoch 73/80\n",
      "6435/6435 [==============================] - 0s 34us/step - loss: 1.4397 - accuracy: 0.3326 - val_loss: 1.4464 - val_accuracy: 0.3017\n",
      "Epoch 74/80\n",
      "6435/6435 [==============================] - 0s 32us/step - loss: 1.4372 - accuracy: 0.3346 - val_loss: 1.4436 - val_accuracy: 0.3478\n",
      "Epoch 75/80\n",
      "6435/6435 [==============================] - 0s 39us/step - loss: 1.4394 - accuracy: 0.3321 - val_loss: 1.4624 - val_accuracy: 0.3282\n",
      "Epoch 76/80\n",
      "6435/6435 [==============================] - 0s 36us/step - loss: 1.4395 - accuracy: 0.3257 - val_loss: 1.4470 - val_accuracy: 0.3338\n",
      "Epoch 77/80\n",
      "6435/6435 [==============================] - 0s 34us/step - loss: 1.4410 - accuracy: 0.3192 - val_loss: 1.4533 - val_accuracy: 0.3631\n",
      "Epoch 78/80\n",
      "6435/6435 [==============================] - 0s 34us/step - loss: 1.4449 - accuracy: 0.3257 - val_loss: 1.4384 - val_accuracy: 0.3142\n",
      "Epoch 79/80\n",
      "6435/6435 [==============================] - 0s 36us/step - loss: 1.4387 - accuracy: 0.3312 - val_loss: 1.4505 - val_accuracy: 0.3254\n",
      "Epoch 80/80\n",
      "6435/6435 [==============================] - 0s 36us/step - loss: 1.4333 - accuracy: 0.3299 - val_loss: 1.4386 - val_accuracy: 0.3366\n",
      "Epoch 00080: early stopping\n",
      "[[1.18484892e-01 1.33544490e-01 1.91155292e-13 ... 2.13946596e-01\n",
      "  2.72934139e-01 2.21227378e-01]\n",
      " [2.13207304e-02 2.97708549e-02 1.13594082e-21 ... 8.46531056e-03\n",
      "  5.19790500e-03 2.75708083e-03]\n",
      " [1.33099586e-01 1.49593174e-01 1.15658537e-15 ... 2.46607155e-01\n",
      "  2.54203796e-01 1.95039988e-01]\n",
      " ...\n",
      " [1.33331135e-01 1.52760193e-01 1.51702701e-15 ... 2.35708594e-01\n",
      "  2.59425819e-01 2.00572252e-01]\n",
      " [1.05352663e-01 1.19065545e-01 5.63119560e-12 ... 1.66695192e-01\n",
      "  2.83617496e-01 2.38063827e-01]\n",
      " [1.10897489e-01 1.25317484e-01 1.64279007e-12 ... 1.81536928e-01\n",
      "  2.82775998e-01 2.34725893e-01]]\n",
      "[12  4 12 ... 12 12 12]\n",
      "<class 'numpy.ndarray'>\n",
      "One CNN, r:  0\n",
      "Computing Time:  0:07:26.286667\n",
      "n, p1, p2 18 1 5\n",
      "Model: \"sequential_1\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv1d_1 (Conv1D)            (None, 3, 6)              12        \n",
      "_________________________________________________________________\n",
      "average_pooling1d_1 (Average (None, 1, 6)              0         \n",
      "_________________________________________________________________\n",
      "conv1d_2 (Conv1D)            (None, 1, 16)             112       \n",
      "_________________________________________________________________\n",
      "average_pooling1d_2 (Average (None, 1, 16)             0         \n",
      "_________________________________________________________________\n",
      "conv1d_3 (Conv1D)            (None, 1, 120)            2040      \n",
      "_________________________________________________________________\n",
      "flatten_1 (Flatten)          (None, 120)               0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 84)                10164     \n",
      "_________________________________________________________________\n",
      "preds (Dense)                (None, 14)                1190      \n",
      "=================================================================\n",
      "Total params: 13,518\n",
      "Trainable params: 13,518\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Train on 6435 samples, validate on 716 samples\n",
      "Epoch 1/80\n",
      "6435/6435 [==============================] - 0s 75us/step - loss: 2.6040 - accuracy: 0.1391 - val_loss: 2.5567 - val_accuracy: 0.1341\n",
      "Epoch 2/80\n",
      "6435/6435 [==============================] - 0s 41us/step - loss: 2.4381 - accuracy: 0.1781 - val_loss: 2.2732 - val_accuracy: 0.2542\n",
      "Epoch 3/80\n",
      "6435/6435 [==============================] - 0s 36us/step - loss: 2.1207 - accuracy: 0.2811 - val_loss: 1.9884 - val_accuracy: 0.3184\n",
      "Epoch 4/80\n",
      "6435/6435 [==============================] - 0s 36us/step - loss: 1.9002 - accuracy: 0.3088 - val_loss: 1.8456 - val_accuracy: 0.3003\n",
      "Epoch 5/80\n",
      "6435/6435 [==============================] - 0s 36us/step - loss: 1.7870 - accuracy: 0.3162 - val_loss: 1.7568 - val_accuracy: 0.3408\n",
      "Epoch 6/80\n",
      "6435/6435 [==============================] - 0s 34us/step - loss: 1.7166 - accuracy: 0.3201 - val_loss: 1.7111 - val_accuracy: 0.3073\n",
      "Epoch 7/80\n",
      "6435/6435 [==============================] - 0s 41us/step - loss: 1.6669 - accuracy: 0.3203 - val_loss: 1.6610 - val_accuracy: 0.3338\n",
      "Epoch 8/80\n",
      "6435/6435 [==============================] - 0s 36us/step - loss: 1.6344 - accuracy: 0.3223 - val_loss: 1.6455 - val_accuracy: 0.3212\n",
      "Epoch 9/80\n",
      "6435/6435 [==============================] - 0s 36us/step - loss: 1.6181 - accuracy: 0.3245 - val_loss: 1.6224 - val_accuracy: 0.3380\n",
      "Epoch 10/80\n",
      "6435/6435 [==============================] - 0s 36us/step - loss: 1.6074 - accuracy: 0.3280 - val_loss: 1.6124 - val_accuracy: 0.3282\n",
      "Epoch 11/80\n",
      "6435/6435 [==============================] - 0s 36us/step - loss: 1.6029 - accuracy: 0.3234 - val_loss: 1.6139 - val_accuracy: 0.3310\n",
      "Epoch 12/80\n",
      "6435/6435 [==============================] - 0s 34us/step - loss: 1.6052 - accuracy: 0.3327 - val_loss: 1.6131 - val_accuracy: 0.3087\n",
      "Epoch 13/80\n",
      "6435/6435 [==============================] - 0s 38us/step - loss: 1.5947 - accuracy: 0.3293 - val_loss: 1.6101 - val_accuracy: 0.3352\n",
      "Epoch 14/80\n",
      "6435/6435 [==============================] - 0s 36us/step - loss: 1.5905 - accuracy: 0.3285 - val_loss: 1.5977 - val_accuracy: 0.3296\n",
      "Epoch 15/80\n",
      "6435/6435 [==============================] - 0s 35us/step - loss: 1.5873 - accuracy: 0.3285 - val_loss: 1.5989 - val_accuracy: 0.3352\n",
      "Epoch 16/80\n",
      "6435/6435 [==============================] - 0s 39us/step - loss: 1.5883 - accuracy: 0.3305 - val_loss: 1.6025 - val_accuracy: 0.3240\n",
      "Epoch 17/80\n",
      "6435/6435 [==============================] - 0s 34us/step - loss: 1.5962 - accuracy: 0.3313 - val_loss: 1.6019 - val_accuracy: 0.3254\n",
      "Epoch 18/80\n",
      "6435/6435 [==============================] - 0s 37us/step - loss: 1.5841 - accuracy: 0.3243 - val_loss: 1.5866 - val_accuracy: 0.3296\n",
      "Epoch 19/80\n",
      "6435/6435 [==============================] - 0s 34us/step - loss: 1.5800 - accuracy: 0.3360 - val_loss: 1.5991 - val_accuracy: 0.3366\n",
      "Epoch 20/80\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6435/6435 [==============================] - 0s 39us/step - loss: 1.5771 - accuracy: 0.3273 - val_loss: 1.5877 - val_accuracy: 0.3240\n",
      "Epoch 21/80\n",
      "6435/6435 [==============================] - 0s 36us/step - loss: 1.5824 - accuracy: 0.3270 - val_loss: 1.5959 - val_accuracy: 0.3240\n",
      "Epoch 22/80\n",
      "6435/6435 [==============================] - 0s 36us/step - loss: 1.5822 - accuracy: 0.3313 - val_loss: 1.6045 - val_accuracy: 0.3450\n",
      "Epoch 23/80\n",
      "6435/6435 [==============================] - 0s 37us/step - loss: 1.5769 - accuracy: 0.3310 - val_loss: 1.5890 - val_accuracy: 0.3324\n",
      "Epoch 24/80\n",
      "6435/6435 [==============================] - 0s 36us/step - loss: 1.5773 - accuracy: 0.3262 - val_loss: 1.5983 - val_accuracy: 0.3380\n",
      "Epoch 25/80\n",
      "6435/6435 [==============================] - 0s 33us/step - loss: 1.5725 - accuracy: 0.3355 - val_loss: 1.5884 - val_accuracy: 0.3296\n",
      "Epoch 26/80\n",
      "6435/6435 [==============================] - 0s 36us/step - loss: 1.5716 - accuracy: 0.3322 - val_loss: 1.6118 - val_accuracy: 0.3268\n",
      "Epoch 27/80\n",
      "6435/6435 [==============================] - 0s 32us/step - loss: 1.5735 - accuracy: 0.3243 - val_loss: 1.5851 - val_accuracy: 0.3296\n",
      "Epoch 28/80\n",
      "6435/6435 [==============================] - 0s 36us/step - loss: 1.5701 - accuracy: 0.3322 - val_loss: 1.5781 - val_accuracy: 0.3324\n",
      "Epoch 29/80\n",
      "6435/6435 [==============================] - 0s 36us/step - loss: 1.5725 - accuracy: 0.3329 - val_loss: 1.5802 - val_accuracy: 0.3352\n",
      "Epoch 30/80\n",
      "6435/6435 [==============================] - 0s 34us/step - loss: 1.5761 - accuracy: 0.3291 - val_loss: 1.5789 - val_accuracy: 0.3282\n",
      "Epoch 31/80\n",
      "6435/6435 [==============================] - 0s 34us/step - loss: 1.5747 - accuracy: 0.3280 - val_loss: 1.5827 - val_accuracy: 0.3296\n",
      "Epoch 32/80\n",
      "6435/6435 [==============================] - 0s 36us/step - loss: 1.5747 - accuracy: 0.3298 - val_loss: 1.5770 - val_accuracy: 0.3338\n",
      "Epoch 33/80\n",
      "6435/6435 [==============================] - 0s 34us/step - loss: 1.5675 - accuracy: 0.3350 - val_loss: 1.5756 - val_accuracy: 0.3296\n",
      "Epoch 34/80\n",
      "6435/6435 [==============================] - 0s 34us/step - loss: 1.5691 - accuracy: 0.3322 - val_loss: 1.5825 - val_accuracy: 0.3338\n",
      "Epoch 35/80\n",
      "6435/6435 [==============================] - 0s 34us/step - loss: 1.5683 - accuracy: 0.3291 - val_loss: 1.5782 - val_accuracy: 0.3394\n",
      "Epoch 36/80\n",
      "6435/6435 [==============================] - 0s 36us/step - loss: 1.5707 - accuracy: 0.3301 - val_loss: 1.5723 - val_accuracy: 0.3394\n",
      "Epoch 37/80\n",
      "6435/6435 [==============================] - 0s 37us/step - loss: 1.5654 - accuracy: 0.3358 - val_loss: 1.5719 - val_accuracy: 0.3240\n",
      "Epoch 38/80\n",
      "6435/6435 [==============================] - 0s 35us/step - loss: 1.5658 - accuracy: 0.3341 - val_loss: 1.5698 - val_accuracy: 0.3338\n",
      "Epoch 39/80\n",
      "6435/6435 [==============================] - 0s 34us/step - loss: 1.5641 - accuracy: 0.3335 - val_loss: 1.5681 - val_accuracy: 0.3296\n",
      "Epoch 40/80\n",
      "6435/6435 [==============================] - 0s 34us/step - loss: 1.5654 - accuracy: 0.3291 - val_loss: 1.5783 - val_accuracy: 0.3338\n",
      "Epoch 41/80\n",
      "6435/6435 [==============================] - 0s 35us/step - loss: 1.5629 - accuracy: 0.3340 - val_loss: 1.5795 - val_accuracy: 0.3310\n",
      "Epoch 42/80\n",
      "6435/6435 [==============================] - 0s 34us/step - loss: 1.5651 - accuracy: 0.3324 - val_loss: 1.5793 - val_accuracy: 0.3366\n",
      "Epoch 43/80\n",
      "6435/6435 [==============================] - 0s 34us/step - loss: 1.5670 - accuracy: 0.3344 - val_loss: 1.5824 - val_accuracy: 0.3310\n",
      "Epoch 44/80\n",
      "6435/6435 [==============================] - 0s 36us/step - loss: 1.5682 - accuracy: 0.3391 - val_loss: 1.5709 - val_accuracy: 0.3352\n",
      "Epoch 45/80\n",
      "6435/6435 [==============================] - 0s 35us/step - loss: 1.5619 - accuracy: 0.3340 - val_loss: 1.5597 - val_accuracy: 0.3422\n",
      "Epoch 46/80\n",
      "6435/6435 [==============================] - 0s 38us/step - loss: 1.5626 - accuracy: 0.3321 - val_loss: 1.6004 - val_accuracy: 0.3310\n",
      "Epoch 47/80\n",
      "6435/6435 [==============================] - 0s 35us/step - loss: 1.5685 - accuracy: 0.3302 - val_loss: 1.5699 - val_accuracy: 0.3324\n",
      "Epoch 48/80\n",
      "6435/6435 [==============================] - 0s 34us/step - loss: 1.5660 - accuracy: 0.3341 - val_loss: 1.5668 - val_accuracy: 0.3380\n",
      "Epoch 49/80\n",
      "6435/6435 [==============================] - 0s 34us/step - loss: 1.5610 - accuracy: 0.3285 - val_loss: 1.5656 - val_accuracy: 0.3310\n",
      "Epoch 50/80\n",
      "6435/6435 [==============================] - 0s 39us/step - loss: 1.5587 - accuracy: 0.3344 - val_loss: 1.5690 - val_accuracy: 0.3394\n",
      "Epoch 51/80\n",
      "6435/6435 [==============================] - 0s 39us/step - loss: 1.5603 - accuracy: 0.3374 - val_loss: 1.5844 - val_accuracy: 0.3324\n",
      "Epoch 52/80\n",
      "6435/6435 [==============================] - 0s 32us/step - loss: 1.5631 - accuracy: 0.3336 - val_loss: 1.5679 - val_accuracy: 0.3310\n",
      "Epoch 53/80\n",
      "6435/6435 [==============================] - 0s 39us/step - loss: 1.5564 - accuracy: 0.3330 - val_loss: 1.5684 - val_accuracy: 0.3338\n",
      "Epoch 54/80\n",
      "6435/6435 [==============================] - 0s 36us/step - loss: 1.5560 - accuracy: 0.3340 - val_loss: 1.5785 - val_accuracy: 0.3380\n",
      "Epoch 55/80\n",
      "6435/6435 [==============================] - 0s 37us/step - loss: 1.5562 - accuracy: 0.3375 - val_loss: 1.5670 - val_accuracy: 0.3338\n",
      "Epoch 00055: early stopping\n",
      "[[1.5187666e-01 1.8373078e-01 5.3959536e-14 ... 2.0117396e-01\n",
      "  1.3465931e-01 1.4584514e-01]\n",
      " [8.4448420e-02 4.0549955e-01 3.7310112e-22 ... 4.7013810e-04\n",
      "  7.4292004e-02 9.1477603e-02]\n",
      " [1.5127358e-01 4.1220170e-01 2.5166988e-19 ... 2.2591949e-02\n",
      "  1.0597781e-01 1.3142675e-01]\n",
      " ...\n",
      " [9.3733981e-02 4.1286007e-01 1.0248647e-21 ... 8.6129602e-04\n",
      "  7.9624921e-02 9.8162554e-02]\n",
      " [1.4662854e-01 1.6692911e-01 1.0642767e-12 ... 1.6191341e-01\n",
      "  1.3881363e-01 1.5157184e-01]\n",
      " [1.5083805e-01 1.7928757e-01 1.2857270e-13 ... 1.8952557e-01\n",
      "  1.3630562e-01 1.4797768e-01]]\n",
      "[11  1  1 ...  1  1 11]\n",
      "<class 'numpy.ndarray'>\n",
      "One CNN, r:  0\n",
      "Computing Time:  0:07:40.630366\n",
      "n, p1, p2 19 1 6\n",
      "Model: \"sequential_1\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv1d_1 (Conv1D)            (None, 3, 6)              12        \n",
      "_________________________________________________________________\n",
      "average_pooling1d_1 (Average (None, 1, 6)              0         \n",
      "_________________________________________________________________\n",
      "conv1d_2 (Conv1D)            (None, 1, 16)             112       \n",
      "_________________________________________________________________\n",
      "average_pooling1d_2 (Average (None, 1, 16)             0         \n",
      "_________________________________________________________________\n",
      "conv1d_3 (Conv1D)            (None, 1, 120)            2040      \n",
      "_________________________________________________________________\n",
      "flatten_1 (Flatten)          (None, 120)               0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 84)                10164     \n",
      "_________________________________________________________________\n",
      "preds (Dense)                (None, 14)                1190      \n",
      "=================================================================\n",
      "Total params: 13,518\n",
      "Trainable params: 13,518\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Train on 6435 samples, validate on 716 samples\n",
      "Epoch 1/80\n",
      "6435/6435 [==============================] - 0s 78us/step - loss: 2.6051 - accuracy: 0.1360 - val_loss: 2.5663 - val_accuracy: 0.1159\n",
      "Epoch 2/80\n",
      "6435/6435 [==============================] - 0s 39us/step - loss: 2.3802 - accuracy: 0.1869 - val_loss: 2.2095 - val_accuracy: 0.2039\n",
      "Epoch 3/80\n",
      "6435/6435 [==============================] - 0s 41us/step - loss: 2.0334 - accuracy: 0.2455 - val_loss: 1.9486 - val_accuracy: 0.2221\n",
      "Epoch 4/80\n",
      "6435/6435 [==============================] - 0s 39us/step - loss: 1.8429 - accuracy: 0.2833 - val_loss: 1.8561 - val_accuracy: 0.2598\n",
      "Epoch 5/80\n",
      "6435/6435 [==============================] - 0s 39us/step - loss: 1.7373 - accuracy: 0.2988 - val_loss: 1.7298 - val_accuracy: 0.2891\n",
      "Epoch 6/80\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6435/6435 [==============================] - 0s 34us/step - loss: 1.6585 - accuracy: 0.3026 - val_loss: 1.6576 - val_accuracy: 0.2975\n",
      "Epoch 7/80\n",
      "6435/6435 [==============================] - 0s 37us/step - loss: 1.6013 - accuracy: 0.3138 - val_loss: 1.6323 - val_accuracy: 0.3128\n",
      "Epoch 8/80\n",
      "6435/6435 [==============================] - 0s 37us/step - loss: 1.5809 - accuracy: 0.3189 - val_loss: 1.6217 - val_accuracy: 0.3115\n",
      "Epoch 9/80\n",
      "6435/6435 [==============================] - 0s 36us/step - loss: 1.5500 - accuracy: 0.3221 - val_loss: 1.5684 - val_accuracy: 0.3380\n",
      "Epoch 10/80\n",
      "6435/6435 [==============================] - 0s 33us/step - loss: 1.5394 - accuracy: 0.3229 - val_loss: 1.5677 - val_accuracy: 0.3366\n",
      "Epoch 11/80\n",
      "6435/6435 [==============================] - 0s 37us/step - loss: 1.5266 - accuracy: 0.3265 - val_loss: 1.5823 - val_accuracy: 0.2975\n",
      "Epoch 12/80\n",
      "6435/6435 [==============================] - 0s 38us/step - loss: 1.5196 - accuracy: 0.3259 - val_loss: 1.5555 - val_accuracy: 0.3282\n",
      "Epoch 13/80\n",
      "6435/6435 [==============================] - 0s 39us/step - loss: 1.5061 - accuracy: 0.3366 - val_loss: 1.5699 - val_accuracy: 0.3115\n",
      "Epoch 14/80\n",
      "6435/6435 [==============================] - 0s 39us/step - loss: 1.5069 - accuracy: 0.3229 - val_loss: 1.5394 - val_accuracy: 0.3031\n",
      "Epoch 15/80\n",
      "6435/6435 [==============================] - 0s 37us/step - loss: 1.4966 - accuracy: 0.3246 - val_loss: 1.5216 - val_accuracy: 0.3338\n",
      "Epoch 16/80\n",
      "6435/6435 [==============================] - 0s 38us/step - loss: 1.4911 - accuracy: 0.3355 - val_loss: 1.5220 - val_accuracy: 0.3380\n",
      "Epoch 17/80\n",
      "6435/6435 [==============================] - 0s 38us/step - loss: 1.4842 - accuracy: 0.3322 - val_loss: 1.5304 - val_accuracy: 0.3296\n",
      "Epoch 18/80\n",
      "6435/6435 [==============================] - 0s 37us/step - loss: 1.4856 - accuracy: 0.3298 - val_loss: 1.5103 - val_accuracy: 0.3450\n",
      "Epoch 19/80\n",
      "6435/6435 [==============================] - 0s 36us/step - loss: 1.4850 - accuracy: 0.3354 - val_loss: 1.5032 - val_accuracy: 0.3338\n",
      "Epoch 20/80\n",
      "6435/6435 [==============================] - 0s 37us/step - loss: 1.4786 - accuracy: 0.3318 - val_loss: 1.5295 - val_accuracy: 0.3170\n",
      "Epoch 21/80\n",
      "6435/6435 [==============================] - 0s 33us/step - loss: 1.4675 - accuracy: 0.3335 - val_loss: 1.5269 - val_accuracy: 0.3003\n",
      "Epoch 22/80\n",
      "6435/6435 [==============================] - 0s 40us/step - loss: 1.4687 - accuracy: 0.3263 - val_loss: 1.5190 - val_accuracy: 0.3198\n",
      "Epoch 23/80\n",
      "6435/6435 [==============================] - 0s 35us/step - loss: 1.4665 - accuracy: 0.3271 - val_loss: 1.4960 - val_accuracy: 0.3380\n",
      "Epoch 24/80\n",
      "6435/6435 [==============================] - 0s 36us/step - loss: 1.4603 - accuracy: 0.3288 - val_loss: 1.4937 - val_accuracy: 0.3394\n",
      "Epoch 25/80\n",
      "6435/6435 [==============================] - 0s 36us/step - loss: 1.4641 - accuracy: 0.3307 - val_loss: 1.5117 - val_accuracy: 0.3352\n",
      "Epoch 26/80\n",
      "6435/6435 [==============================] - 0s 39us/step - loss: 1.4548 - accuracy: 0.3336 - val_loss: 1.4978 - val_accuracy: 0.3450\n",
      "Epoch 27/80\n",
      "6435/6435 [==============================] - 0s 34us/step - loss: 1.4576 - accuracy: 0.3296 - val_loss: 1.4993 - val_accuracy: 0.3366\n",
      "Epoch 28/80\n",
      "6435/6435 [==============================] - 0s 36us/step - loss: 1.4575 - accuracy: 0.3341 - val_loss: 1.5316 - val_accuracy: 0.3142\n",
      "Epoch 29/80\n",
      "6435/6435 [==============================] - 0s 40us/step - loss: 1.4547 - accuracy: 0.3394 - val_loss: 1.4991 - val_accuracy: 0.3087\n",
      "Epoch 30/80\n",
      "6435/6435 [==============================] - 0s 32us/step - loss: 1.4495 - accuracy: 0.3326 - val_loss: 1.5013 - val_accuracy: 0.3282\n",
      "Epoch 31/80\n",
      "6435/6435 [==============================] - 0s 38us/step - loss: 1.4500 - accuracy: 0.3293 - val_loss: 1.4814 - val_accuracy: 0.3268\n",
      "Epoch 32/80\n",
      "6435/6435 [==============================] - 0s 35us/step - loss: 1.4477 - accuracy: 0.3287 - val_loss: 1.4976 - val_accuracy: 0.3394\n",
      "Epoch 33/80\n",
      "6435/6435 [==============================] - 0s 34us/step - loss: 1.4406 - accuracy: 0.3391 - val_loss: 1.4770 - val_accuracy: 0.3352\n",
      "Epoch 34/80\n",
      "6435/6435 [==============================] - 0s 36us/step - loss: 1.4427 - accuracy: 0.3395 - val_loss: 1.4977 - val_accuracy: 0.3324\n",
      "Epoch 35/80\n",
      "6435/6435 [==============================] - 0s 39us/step - loss: 1.4446 - accuracy: 0.3293 - val_loss: 1.4805 - val_accuracy: 0.3184\n",
      "Epoch 36/80\n",
      "6435/6435 [==============================] - 0s 41us/step - loss: 1.4363 - accuracy: 0.3335 - val_loss: 1.4839 - val_accuracy: 0.3170\n",
      "Epoch 37/80\n",
      "6435/6435 [==============================] - 0s 36us/step - loss: 1.4354 - accuracy: 0.3417 - val_loss: 1.4768 - val_accuracy: 0.3324\n",
      "Epoch 38/80\n",
      "6435/6435 [==============================] - 0s 39us/step - loss: 1.4356 - accuracy: 0.3322 - val_loss: 1.4710 - val_accuracy: 0.3352\n",
      "Epoch 39/80\n",
      "6435/6435 [==============================] - 0s 34us/step - loss: 1.4332 - accuracy: 0.3349 - val_loss: 1.4628 - val_accuracy: 0.3394\n",
      "Epoch 40/80\n",
      "6435/6435 [==============================] - 0s 38us/step - loss: 1.4310 - accuracy: 0.3428 - val_loss: 1.4761 - val_accuracy: 0.3101\n",
      "Epoch 41/80\n",
      "6435/6435 [==============================] - 0s 32us/step - loss: 1.4333 - accuracy: 0.3374 - val_loss: 1.4767 - val_accuracy: 0.3408\n",
      "Epoch 42/80\n",
      "6435/6435 [==============================] - 0s 36us/step - loss: 1.4274 - accuracy: 0.3472 - val_loss: 1.4714 - val_accuracy: 0.3128\n",
      "Epoch 43/80\n",
      "6435/6435 [==============================] - 0s 39us/step - loss: 1.4300 - accuracy: 0.3428 - val_loss: 1.4586 - val_accuracy: 0.3450\n",
      "Epoch 44/80\n",
      "6435/6435 [==============================] - 0s 34us/step - loss: 1.4280 - accuracy: 0.3444 - val_loss: 1.4554 - val_accuracy: 0.3338\n",
      "Epoch 45/80\n",
      "6435/6435 [==============================] - 0s 39us/step - loss: 1.4283 - accuracy: 0.3391 - val_loss: 1.4736 - val_accuracy: 0.3464\n",
      "Epoch 46/80\n",
      "6435/6435 [==============================] - 0s 39us/step - loss: 1.4330 - accuracy: 0.3385 - val_loss: 1.4783 - val_accuracy: 0.3240\n",
      "Epoch 47/80\n",
      "6435/6435 [==============================] - 0s 34us/step - loss: 1.4190 - accuracy: 0.3458 - val_loss: 1.4577 - val_accuracy: 0.3478\n",
      "Epoch 48/80\n",
      "6435/6435 [==============================] - 0s 36us/step - loss: 1.4179 - accuracy: 0.3363 - val_loss: 1.4753 - val_accuracy: 0.3184\n",
      "Epoch 49/80\n",
      "6435/6435 [==============================] - 0s 36us/step - loss: 1.4173 - accuracy: 0.3455 - val_loss: 1.4543 - val_accuracy: 0.3436\n",
      "Epoch 50/80\n",
      "6435/6435 [==============================] - 0s 34us/step - loss: 1.4251 - accuracy: 0.3445 - val_loss: 1.4514 - val_accuracy: 0.3547\n",
      "Epoch 51/80\n",
      "6435/6435 [==============================] - 0s 34us/step - loss: 1.4118 - accuracy: 0.3520 - val_loss: 1.4588 - val_accuracy: 0.3422\n",
      "Epoch 52/80\n",
      "6435/6435 [==============================] - 0s 39us/step - loss: 1.4113 - accuracy: 0.3576 - val_loss: 1.4521 - val_accuracy: 0.3268\n",
      "Epoch 53/80\n",
      "6435/6435 [==============================] - 0s 39us/step - loss: 1.4102 - accuracy: 0.3529 - val_loss: 1.4469 - val_accuracy: 0.3408\n",
      "Epoch 54/80\n",
      "6435/6435 [==============================] - 0s 34us/step - loss: 1.4052 - accuracy: 0.3507 - val_loss: 1.4466 - val_accuracy: 0.3338\n",
      "Epoch 55/80\n",
      "6435/6435 [==============================] - 0s 36us/step - loss: 1.4015 - accuracy: 0.3580 - val_loss: 1.4372 - val_accuracy: 0.3701\n",
      "Epoch 56/80\n",
      "6435/6435 [==============================] - 0s 35us/step - loss: 1.3987 - accuracy: 0.3565 - val_loss: 1.4286 - val_accuracy: 0.3603\n",
      "Epoch 57/80\n",
      "6435/6435 [==============================] - 0s 36us/step - loss: 1.3900 - accuracy: 0.3621 - val_loss: 1.4341 - val_accuracy: 0.3603\n",
      "Epoch 58/80\n",
      "6435/6435 [==============================] - 0s 41us/step - loss: 1.3882 - accuracy: 0.3661 - val_loss: 1.4453 - val_accuracy: 0.3310\n",
      "Epoch 59/80\n",
      "6435/6435 [==============================] - 0s 37us/step - loss: 1.3851 - accuracy: 0.3705 - val_loss: 1.4079 - val_accuracy: 0.3911\n",
      "Epoch 60/80\n",
      "6435/6435 [==============================] - 0s 39us/step - loss: 1.3804 - accuracy: 0.3744 - val_loss: 1.4090 - val_accuracy: 0.3743\n",
      "Epoch 61/80\n",
      "6435/6435 [==============================] - 0s 34us/step - loss: 1.3659 - accuracy: 0.3817 - val_loss: 1.3904 - val_accuracy: 0.4050\n",
      "Epoch 62/80\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6435/6435 [==============================] - 0s 34us/step - loss: 1.3544 - accuracy: 0.3977 - val_loss: 1.3979 - val_accuracy: 0.3645\n",
      "Epoch 63/80\n",
      "6435/6435 [==============================] - 0s 36us/step - loss: 1.3440 - accuracy: 0.3883 - val_loss: 1.3876 - val_accuracy: 0.3687\n",
      "Epoch 64/80\n",
      "6435/6435 [==============================] - 0s 39us/step - loss: 1.3384 - accuracy: 0.3869 - val_loss: 1.3673 - val_accuracy: 0.3939\n",
      "Epoch 65/80\n",
      "6435/6435 [==============================] - 0s 35us/step - loss: 1.3236 - accuracy: 0.4014 - val_loss: 1.3498 - val_accuracy: 0.3869\n",
      "Epoch 66/80\n",
      "6435/6435 [==============================] - 0s 38us/step - loss: 1.3084 - accuracy: 0.4048 - val_loss: 1.3434 - val_accuracy: 0.3659\n",
      "Epoch 67/80\n",
      "6435/6435 [==============================] - 0s 38us/step - loss: 1.2974 - accuracy: 0.4033 - val_loss: 1.3322 - val_accuracy: 0.3743\n",
      "Epoch 68/80\n",
      "6435/6435 [==============================] - 0s 34us/step - loss: 1.2848 - accuracy: 0.4126 - val_loss: 1.3123 - val_accuracy: 0.4148\n",
      "Epoch 69/80\n",
      "6435/6435 [==============================] - 0s 34us/step - loss: 1.2799 - accuracy: 0.4064 - val_loss: 1.3184 - val_accuracy: 0.3729\n",
      "Epoch 70/80\n",
      "6435/6435 [==============================] - 0s 34us/step - loss: 1.2716 - accuracy: 0.4067 - val_loss: 1.3105 - val_accuracy: 0.3966\n",
      "Epoch 71/80\n",
      "6435/6435 [==============================] - 0s 36us/step - loss: 1.2655 - accuracy: 0.4064 - val_loss: 1.2944 - val_accuracy: 0.3855\n",
      "Epoch 72/80\n",
      "6435/6435 [==============================] - 0s 39us/step - loss: 1.2614 - accuracy: 0.4044 - val_loss: 1.2895 - val_accuracy: 0.3855\n",
      "Epoch 73/80\n",
      "6435/6435 [==============================] - 0s 39us/step - loss: 1.2573 - accuracy: 0.4160 - val_loss: 1.2848 - val_accuracy: 0.3743\n",
      "Epoch 74/80\n",
      "6435/6435 [==============================] - 0s 39us/step - loss: 1.2481 - accuracy: 0.4148 - val_loss: 1.2980 - val_accuracy: 0.3757\n",
      "Epoch 75/80\n",
      "6435/6435 [==============================] - 0s 36us/step - loss: 1.2512 - accuracy: 0.4056 - val_loss: 1.2871 - val_accuracy: 0.4008\n",
      "Epoch 76/80\n",
      "6435/6435 [==============================] - 0s 37us/step - loss: 1.2482 - accuracy: 0.4154 - val_loss: 1.2635 - val_accuracy: 0.4078\n",
      "Epoch 77/80\n",
      "6435/6435 [==============================] - 0s 36us/step - loss: 1.2433 - accuracy: 0.4146 - val_loss: 1.2734 - val_accuracy: 0.3966\n",
      "Epoch 78/80\n",
      "6435/6435 [==============================] - 0s 34us/step - loss: 1.2402 - accuracy: 0.4227 - val_loss: 1.2750 - val_accuracy: 0.3911\n",
      "Epoch 79/80\n",
      "6435/6435 [==============================] - 0s 39us/step - loss: 1.2376 - accuracy: 0.4238 - val_loss: 1.2767 - val_accuracy: 0.3911\n",
      "Epoch 80/80\n",
      "6435/6435 [==============================] - 0s 36us/step - loss: 1.2296 - accuracy: 0.4121 - val_loss: 1.2823 - val_accuracy: 0.4008\n",
      "[[1.03642456e-01 9.25611109e-02 1.87816647e-14 ... 3.52436751e-01\n",
      "  2.21653074e-01 2.21085429e-01]\n",
      " [4.04186323e-02 4.10849191e-02 2.27811377e-21 ... 5.03209326e-03\n",
      "  2.11990960e-02 1.76853314e-02]\n",
      " [1.99932903e-01 1.96697280e-01 9.74680316e-18 ... 8.08695555e-02\n",
      "  2.60626256e-01 2.58780718e-01]\n",
      " ...\n",
      " [2.31934711e-01 2.24812016e-01 2.31637145e-19 ... 1.16513334e-02\n",
      "  2.68553555e-01 2.62485057e-01]\n",
      " [1.07608147e-01 9.53727514e-02 1.48693801e-13 ... 1.81870043e-01\n",
      "  3.03381175e-01 2.96263695e-01]\n",
      " [1.18142121e-01 1.04103878e-01 3.76143784e-14 ... 1.97934195e-01\n",
      "  2.86021084e-01 2.84914881e-01]]\n",
      "[11  9 12 ... 12 12 12]\n",
      "<class 'numpy.ndarray'>\n",
      "One CNN, r:  0\n",
      "Computing Time:  0:08:01.229648\n",
      "n, p1, p2 20 1 7\n",
      "Model: \"sequential_1\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv1d_1 (Conv1D)            (None, 3, 6)              12        \n",
      "_________________________________________________________________\n",
      "average_pooling1d_1 (Average (None, 1, 6)              0         \n",
      "_________________________________________________________________\n",
      "conv1d_2 (Conv1D)            (None, 1, 16)             112       \n",
      "_________________________________________________________________\n",
      "average_pooling1d_2 (Average (None, 1, 16)             0         \n",
      "_________________________________________________________________\n",
      "conv1d_3 (Conv1D)            (None, 1, 120)            2040      \n",
      "_________________________________________________________________\n",
      "flatten_1 (Flatten)          (None, 120)               0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 84)                10164     \n",
      "_________________________________________________________________\n",
      "preds (Dense)                (None, 14)                1190      \n",
      "=================================================================\n",
      "Total params: 13,518\n",
      "Trainable params: 13,518\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Train on 6435 samples, validate on 716 samples\n",
      "Epoch 1/80\n",
      "6435/6435 [==============================] - 1s 78us/step - loss: 2.5982 - accuracy: 0.1308 - val_loss: 2.5218 - val_accuracy: 0.1257\n",
      "Epoch 2/80\n",
      "6435/6435 [==============================] - 0s 41us/step - loss: 2.3300 - accuracy: 0.2011 - val_loss: 2.1215 - val_accuracy: 0.2402\n",
      "Epoch 3/80\n",
      "6435/6435 [==============================] - 0s 39us/step - loss: 2.0046 - accuracy: 0.2617 - val_loss: 1.9155 - val_accuracy: 0.2542\n",
      "Epoch 4/80\n",
      "6435/6435 [==============================] - 0s 39us/step - loss: 1.8776 - accuracy: 0.2889 - val_loss: 1.8290 - val_accuracy: 0.2891\n",
      "Epoch 5/80\n",
      "6435/6435 [==============================] - 0s 41us/step - loss: 1.8091 - accuracy: 0.3033 - val_loss: 1.7633 - val_accuracy: 0.2933\n",
      "Epoch 6/80\n",
      "6435/6435 [==============================] - 0s 39us/step - loss: 1.7534 - accuracy: 0.3092 - val_loss: 1.7189 - val_accuracy: 0.3073\n",
      "Epoch 7/80\n",
      "6435/6435 [==============================] - 0s 39us/step - loss: 1.7156 - accuracy: 0.3032 - val_loss: 1.6615 - val_accuracy: 0.3003\n",
      "Epoch 8/80\n",
      "6435/6435 [==============================] - 0s 39us/step - loss: 1.6745 - accuracy: 0.3141 - val_loss: 1.6251 - val_accuracy: 0.3240\n",
      "Epoch 9/80\n",
      "6435/6435 [==============================] - 0s 39us/step - loss: 1.6466 - accuracy: 0.3148 - val_loss: 1.6154 - val_accuracy: 0.3059\n",
      "Epoch 10/80\n",
      "6435/6435 [==============================] - 0s 39us/step - loss: 1.6297 - accuracy: 0.3218 - val_loss: 1.6066 - val_accuracy: 0.3073\n",
      "Epoch 11/80\n",
      "6435/6435 [==============================] - 0s 39us/step - loss: 1.6264 - accuracy: 0.3105 - val_loss: 1.5856 - val_accuracy: 0.3087\n",
      "Epoch 12/80\n",
      "6435/6435 [==============================] - 0s 36us/step - loss: 1.6141 - accuracy: 0.3217 - val_loss: 1.5886 - val_accuracy: 0.3128\n",
      "Epoch 13/80\n",
      "6435/6435 [==============================] - 0s 37us/step - loss: 1.6093 - accuracy: 0.3167 - val_loss: 1.5846 - val_accuracy: 0.3296\n",
      "Epoch 14/80\n",
      "6435/6435 [==============================] - 0s 35us/step - loss: 1.6065 - accuracy: 0.3148 - val_loss: 1.5826 - val_accuracy: 0.3240\n",
      "Epoch 15/80\n",
      "6435/6435 [==============================] - 0s 34us/step - loss: 1.6092 - accuracy: 0.3218 - val_loss: 1.5780 - val_accuracy: 0.3380\n",
      "Epoch 16/80\n",
      "6435/6435 [==============================] - 0s 46us/step - loss: 1.6017 - accuracy: 0.3176 - val_loss: 1.5688 - val_accuracy: 0.3226\n",
      "Epoch 17/80\n",
      "6435/6435 [==============================] - 0s 40us/step - loss: 1.5992 - accuracy: 0.3198 - val_loss: 1.5664 - val_accuracy: 0.3408\n",
      "Epoch 18/80\n",
      "6435/6435 [==============================] - 0s 35us/step - loss: 1.5971 - accuracy: 0.3239 - val_loss: 1.5802 - val_accuracy: 0.3212\n",
      "Epoch 19/80\n",
      "6435/6435 [==============================] - 0s 36us/step - loss: 1.5968 - accuracy: 0.3242 - val_loss: 1.5829 - val_accuracy: 0.3198\n",
      "Epoch 20/80\n",
      "6435/6435 [==============================] - 0s 36us/step - loss: 1.5979 - accuracy: 0.3223 - val_loss: 1.5701 - val_accuracy: 0.3142\n",
      "Epoch 21/80\n",
      "6435/6435 [==============================] - 0s 36us/step - loss: 1.5903 - accuracy: 0.3262 - val_loss: 1.5756 - val_accuracy: 0.2891\n",
      "Epoch 22/80\n",
      "6435/6435 [==============================] - 0s 34us/step - loss: 1.5922 - accuracy: 0.3192 - val_loss: 1.5740 - val_accuracy: 0.2947\n",
      "Epoch 23/80\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6435/6435 [==============================] - 0s 36us/step - loss: 1.5886 - accuracy: 0.3234 - val_loss: 1.5742 - val_accuracy: 0.3310\n",
      "Epoch 24/80\n",
      "6435/6435 [==============================] - 0s 37us/step - loss: 1.5889 - accuracy: 0.3223 - val_loss: 1.5846 - val_accuracy: 0.3073\n",
      "Epoch 25/80\n",
      "6435/6435 [==============================] - 0s 38us/step - loss: 1.5874 - accuracy: 0.3228 - val_loss: 1.5724 - val_accuracy: 0.3156\n",
      "Epoch 26/80\n",
      "6435/6435 [==============================] - 0s 41us/step - loss: 1.5882 - accuracy: 0.3282 - val_loss: 1.5623 - val_accuracy: 0.3226\n",
      "Epoch 27/80\n",
      "6435/6435 [==============================] - 0s 37us/step - loss: 1.5830 - accuracy: 0.3248 - val_loss: 1.5753 - val_accuracy: 0.2989\n",
      "Epoch 28/80\n",
      "6435/6435 [==============================] - 0s 38us/step - loss: 1.5844 - accuracy: 0.3267 - val_loss: 1.5660 - val_accuracy: 0.3142\n",
      "Epoch 29/80\n",
      "6435/6435 [==============================] - 0s 34us/step - loss: 1.5843 - accuracy: 0.3201 - val_loss: 1.5644 - val_accuracy: 0.3128\n",
      "Epoch 30/80\n",
      "6435/6435 [==============================] - 0s 39us/step - loss: 1.5844 - accuracy: 0.3246 - val_loss: 1.5592 - val_accuracy: 0.3059\n",
      "Epoch 31/80\n",
      "6435/6435 [==============================] - 0s 36us/step - loss: 1.5844 - accuracy: 0.3226 - val_loss: 1.5547 - val_accuracy: 0.3296\n",
      "Epoch 32/80\n",
      "6435/6435 [==============================] - 0s 36us/step - loss: 1.5802 - accuracy: 0.3322 - val_loss: 1.5600 - val_accuracy: 0.3212\n",
      "Epoch 33/80\n",
      "6435/6435 [==============================] - 0s 36us/step - loss: 1.5785 - accuracy: 0.3271 - val_loss: 1.5682 - val_accuracy: 0.3310\n",
      "Epoch 34/80\n",
      "6435/6435 [==============================] - 0s 36us/step - loss: 1.5813 - accuracy: 0.3259 - val_loss: 1.5643 - val_accuracy: 0.2891\n",
      "Epoch 35/80\n",
      "6435/6435 [==============================] - 0s 37us/step - loss: 1.5807 - accuracy: 0.3326 - val_loss: 1.5545 - val_accuracy: 0.3380\n",
      "Epoch 36/80\n",
      "6435/6435 [==============================] - 0s 35us/step - loss: 1.5767 - accuracy: 0.3262 - val_loss: 1.5617 - val_accuracy: 0.3282\n",
      "Epoch 37/80\n",
      "6435/6435 [==============================] - 0s 39us/step - loss: 1.5791 - accuracy: 0.3296 - val_loss: 1.5642 - val_accuracy: 0.3142\n",
      "Epoch 38/80\n",
      "6435/6435 [==============================] - 0s 41us/step - loss: 1.5792 - accuracy: 0.3263 - val_loss: 1.5603 - val_accuracy: 0.3240\n",
      "Epoch 39/80\n",
      "6435/6435 [==============================] - 0s 39us/step - loss: 1.5800 - accuracy: 0.3313 - val_loss: 1.5491 - val_accuracy: 0.3296\n",
      "Epoch 40/80\n",
      "6435/6435 [==============================] - 0s 34us/step - loss: 1.5741 - accuracy: 0.3296 - val_loss: 1.5501 - val_accuracy: 0.3226\n",
      "Epoch 41/80\n",
      "6435/6435 [==============================] - 0s 36us/step - loss: 1.5669 - accuracy: 0.3293 - val_loss: 1.5536 - val_accuracy: 0.3184\n",
      "Epoch 42/80\n",
      "6435/6435 [==============================] - 0s 36us/step - loss: 1.5572 - accuracy: 0.3386 - val_loss: 1.5500 - val_accuracy: 0.3156\n",
      "Epoch 43/80\n",
      "6435/6435 [==============================] - 0s 36us/step - loss: 1.5588 - accuracy: 0.3350 - val_loss: 1.5377 - val_accuracy: 0.3087\n",
      "Epoch 44/80\n",
      "6435/6435 [==============================] - 0s 35us/step - loss: 1.5481 - accuracy: 0.3340 - val_loss: 1.5378 - val_accuracy: 0.3422\n",
      "Epoch 45/80\n",
      "6435/6435 [==============================] - 0s 36us/step - loss: 1.5350 - accuracy: 0.3411 - val_loss: 1.5095 - val_accuracy: 0.3198\n",
      "Epoch 46/80\n",
      "6435/6435 [==============================] - 0s 37us/step - loss: 1.5281 - accuracy: 0.3442 - val_loss: 1.5039 - val_accuracy: 0.3156\n",
      "Epoch 47/80\n",
      "6435/6435 [==============================] - 0s 33us/step - loss: 1.5218 - accuracy: 0.3489 - val_loss: 1.4949 - val_accuracy: 0.3282\n",
      "Epoch 48/80\n",
      "6435/6435 [==============================] - 0s 39us/step - loss: 1.5167 - accuracy: 0.3395 - val_loss: 1.5109 - val_accuracy: 0.3142\n",
      "Epoch 49/80\n",
      "6435/6435 [==============================] - 0s 36us/step - loss: 1.5161 - accuracy: 0.3456 - val_loss: 1.4953 - val_accuracy: 0.3282\n",
      "Epoch 50/80\n",
      "6435/6435 [==============================] - 0s 34us/step - loss: 1.5094 - accuracy: 0.3391 - val_loss: 1.4943 - val_accuracy: 0.3198\n",
      "Epoch 51/80\n",
      "6435/6435 [==============================] - 0s 36us/step - loss: 1.5054 - accuracy: 0.3461 - val_loss: 1.4851 - val_accuracy: 0.3366\n",
      "Epoch 52/80\n",
      "6435/6435 [==============================] - 0s 36us/step - loss: 1.5019 - accuracy: 0.3414 - val_loss: 1.4858 - val_accuracy: 0.3128\n",
      "Epoch 53/80\n",
      "6435/6435 [==============================] - 0s 39us/step - loss: 1.4999 - accuracy: 0.3464 - val_loss: 1.4842 - val_accuracy: 0.3240\n",
      "Epoch 54/80\n",
      "6435/6435 [==============================] - 0s 36us/step - loss: 1.4968 - accuracy: 0.3484 - val_loss: 1.4700 - val_accuracy: 0.3366\n",
      "Epoch 55/80\n",
      "6435/6435 [==============================] - 0s 36us/step - loss: 1.4920 - accuracy: 0.3493 - val_loss: 1.4621 - val_accuracy: 0.3310\n",
      "Epoch 56/80\n",
      "6435/6435 [==============================] - 0s 37us/step - loss: 1.4909 - accuracy: 0.3473 - val_loss: 1.4711 - val_accuracy: 0.3422\n",
      "Epoch 57/80\n",
      "6435/6435 [==============================] - 0s 38us/step - loss: 1.4816 - accuracy: 0.3455 - val_loss: 1.4600 - val_accuracy: 0.3534\n",
      "Epoch 58/80\n",
      "6435/6435 [==============================] - 0s 34us/step - loss: 1.4736 - accuracy: 0.3556 - val_loss: 1.4522 - val_accuracy: 0.3115\n",
      "Epoch 59/80\n",
      "6435/6435 [==============================] - 0s 34us/step - loss: 1.4671 - accuracy: 0.3579 - val_loss: 1.4465 - val_accuracy: 0.3156\n",
      "Epoch 60/80\n",
      "6435/6435 [==============================] - 0s 41us/step - loss: 1.4631 - accuracy: 0.3571 - val_loss: 1.4318 - val_accuracy: 0.3520\n",
      "Epoch 61/80\n",
      "6435/6435 [==============================] - 0s 39us/step - loss: 1.4569 - accuracy: 0.3565 - val_loss: 1.4449 - val_accuracy: 0.3268\n",
      "Epoch 62/80\n",
      "6435/6435 [==============================] - 0s 36us/step - loss: 1.4493 - accuracy: 0.3542 - val_loss: 1.4307 - val_accuracy: 0.3212\n",
      "Epoch 63/80\n",
      "6435/6435 [==============================] - 0s 34us/step - loss: 1.4381 - accuracy: 0.3699 - val_loss: 1.4243 - val_accuracy: 0.3310\n",
      "Epoch 64/80\n",
      "6435/6435 [==============================] - 0s 34us/step - loss: 1.4297 - accuracy: 0.3658 - val_loss: 1.3994 - val_accuracy: 0.3673\n",
      "Epoch 65/80\n",
      "6435/6435 [==============================] - 0s 36us/step - loss: 1.4201 - accuracy: 0.3751 - val_loss: 1.3890 - val_accuracy: 0.3785\n",
      "Epoch 66/80\n",
      "6435/6435 [==============================] - 0s 39us/step - loss: 1.4087 - accuracy: 0.3768 - val_loss: 1.3975 - val_accuracy: 0.3352\n",
      "Epoch 67/80\n",
      "6435/6435 [==============================] - 0s 36us/step - loss: 1.3895 - accuracy: 0.3876 - val_loss: 1.3578 - val_accuracy: 0.3464\n",
      "Epoch 68/80\n",
      "6435/6435 [==============================] - 0s 34us/step - loss: 1.3731 - accuracy: 0.3907 - val_loss: 1.3436 - val_accuracy: 0.3911\n",
      "Epoch 69/80\n",
      "6435/6435 [==============================] - 0s 39us/step - loss: 1.3559 - accuracy: 0.3916 - val_loss: 1.3293 - val_accuracy: 0.4008\n",
      "Epoch 70/80\n",
      "6435/6435 [==============================] - 0s 34us/step - loss: 1.3372 - accuracy: 0.3927 - val_loss: 1.3360 - val_accuracy: 0.3911\n",
      "Epoch 71/80\n",
      "6435/6435 [==============================] - 0s 39us/step - loss: 1.3229 - accuracy: 0.3981 - val_loss: 1.3067 - val_accuracy: 0.3534\n",
      "Epoch 72/80\n",
      "6435/6435 [==============================] - 0s 39us/step - loss: 1.3038 - accuracy: 0.4057 - val_loss: 1.2918 - val_accuracy: 0.3771\n",
      "Epoch 73/80\n",
      "6435/6435 [==============================] - 0s 38us/step - loss: 1.2913 - accuracy: 0.4005 - val_loss: 1.2812 - val_accuracy: 0.3925\n",
      "Epoch 74/80\n",
      "6435/6435 [==============================] - 0s 34us/step - loss: 1.2814 - accuracy: 0.4079 - val_loss: 1.2670 - val_accuracy: 0.3841\n",
      "Epoch 75/80\n",
      "6435/6435 [==============================] - 0s 34us/step - loss: 1.2729 - accuracy: 0.4047 - val_loss: 1.2799 - val_accuracy: 0.3953\n",
      "Epoch 76/80\n",
      "6435/6435 [==============================] - 0s 34us/step - loss: 1.2665 - accuracy: 0.4126 - val_loss: 1.2802 - val_accuracy: 0.3897\n",
      "Epoch 77/80\n",
      "6435/6435 [==============================] - 0s 36us/step - loss: 1.2657 - accuracy: 0.4073 - val_loss: 1.2675 - val_accuracy: 0.3855\n",
      "Epoch 78/80\n",
      "6435/6435 [==============================] - 0s 34us/step - loss: 1.2520 - accuracy: 0.4163 - val_loss: 1.2542 - val_accuracy: 0.3925\n",
      "Epoch 79/80\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6435/6435 [==============================] - 0s 36us/step - loss: 1.2488 - accuracy: 0.4095 - val_loss: 1.2538 - val_accuracy: 0.3911\n",
      "Epoch 80/80\n",
      "6435/6435 [==============================] - 0s 37us/step - loss: 1.2439 - accuracy: 0.4141 - val_loss: 1.2472 - val_accuracy: 0.3757\n",
      "[[1.1785960e-01 9.9152975e-02 3.8346269e-16 ... 3.2131916e-01\n",
      "  2.3459671e-01 2.1581072e-01]\n",
      " [2.5078792e-02 3.0624252e-02 5.0057864e-25 ... 1.2657747e-03\n",
      "  4.3931842e-02 4.7672108e-02]\n",
      " [2.1451721e-01 2.4021243e-01 5.8327902e-21 ... 5.9018642e-02\n",
      "  2.5415432e-01 2.1656270e-01]\n",
      " ...\n",
      " [2.3570786e-01 3.3217984e-01 3.3142555e-23 ... 5.7620141e-03\n",
      "  2.2191282e-01 1.9833945e-01]\n",
      " [1.3545822e-01 1.2163892e-01 2.7287152e-15 ... 1.7716649e-01\n",
      "  2.8337574e-01 2.5679657e-01]\n",
      " [1.4333364e-01 1.2907998e-01 5.1562421e-16 ... 1.9198510e-01\n",
      "  2.7347323e-01 2.4662222e-01]]\n",
      "[11  5 12 ...  1 12 12]\n",
      "<class 'numpy.ndarray'>\n",
      "One CNN, r:  0\n",
      "Computing Time:  0:08:22.052332\n",
      "n, p1, p2 21 1 8\n",
      "Model: \"sequential_1\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv1d_1 (Conv1D)            (None, 3, 6)              12        \n",
      "_________________________________________________________________\n",
      "average_pooling1d_1 (Average (None, 1, 6)              0         \n",
      "_________________________________________________________________\n",
      "conv1d_2 (Conv1D)            (None, 1, 16)             112       \n",
      "_________________________________________________________________\n",
      "average_pooling1d_2 (Average (None, 1, 16)             0         \n",
      "_________________________________________________________________\n",
      "conv1d_3 (Conv1D)            (None, 1, 120)            2040      \n",
      "_________________________________________________________________\n",
      "flatten_1 (Flatten)          (None, 120)               0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 84)                10164     \n",
      "_________________________________________________________________\n",
      "preds (Dense)                (None, 14)                1190      \n",
      "=================================================================\n",
      "Total params: 13,518\n",
      "Trainable params: 13,518\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Train on 6435 samples, validate on 716 samples\n",
      "Epoch 1/80\n",
      "6435/6435 [==============================] - 0s 78us/step - loss: 2.6131 - accuracy: 0.1388 - val_loss: 2.5790 - val_accuracy: 0.1522\n",
      "Epoch 2/80\n",
      "6435/6435 [==============================] - 0s 39us/step - loss: 2.5099 - accuracy: 0.1608 - val_loss: 2.3931 - val_accuracy: 0.2039\n",
      "Epoch 3/80\n",
      "6435/6435 [==============================] - 0s 36us/step - loss: 2.2269 - accuracy: 0.2023 - val_loss: 2.0702 - val_accuracy: 0.2919\n",
      "Epoch 4/80\n",
      "6435/6435 [==============================] - 0s 43us/step - loss: 1.9971 - accuracy: 0.2793 - val_loss: 1.9149 - val_accuracy: 0.3003\n",
      "Epoch 5/80\n",
      "6435/6435 [==============================] - 0s 34us/step - loss: 1.8967 - accuracy: 0.2845 - val_loss: 1.8596 - val_accuracy: 0.3003\n",
      "Epoch 6/80\n",
      "6435/6435 [==============================] - 0s 38us/step - loss: 1.8537 - accuracy: 0.2894 - val_loss: 1.8099 - val_accuracy: 0.2835\n",
      "Epoch 7/80\n",
      "6435/6435 [==============================] - 0s 33us/step - loss: 1.8038 - accuracy: 0.2928 - val_loss: 1.7711 - val_accuracy: 0.3087\n",
      "Epoch 8/80\n",
      "6435/6435 [==============================] - 0s 36us/step - loss: 1.7663 - accuracy: 0.2946 - val_loss: 1.7391 - val_accuracy: 0.2975\n",
      "Epoch 9/80\n",
      "6435/6435 [==============================] - 0s 36us/step - loss: 1.7283 - accuracy: 0.2981 - val_loss: 1.7338 - val_accuracy: 0.2961\n",
      "Epoch 10/80\n",
      "6435/6435 [==============================] - 0s 34us/step - loss: 1.7016 - accuracy: 0.3066 - val_loss: 1.6848 - val_accuracy: 0.3170\n",
      "Epoch 11/80\n",
      "6435/6435 [==============================] - 0s 35us/step - loss: 1.6770 - accuracy: 0.3100 - val_loss: 1.6815 - val_accuracy: 0.3156\n",
      "Epoch 12/80\n",
      "6435/6435 [==============================] - 0s 34us/step - loss: 1.6619 - accuracy: 0.3141 - val_loss: 1.6718 - val_accuracy: 0.3170\n",
      "Epoch 13/80\n",
      "6435/6435 [==============================] - 0s 35us/step - loss: 1.6481 - accuracy: 0.3148 - val_loss: 1.6556 - val_accuracy: 0.3198\n",
      "Epoch 14/80\n",
      "6435/6435 [==============================] - 0s 35us/step - loss: 1.6399 - accuracy: 0.3142 - val_loss: 1.6579 - val_accuracy: 0.3170\n",
      "Epoch 15/80\n",
      "6435/6435 [==============================] - 0s 36us/step - loss: 1.6329 - accuracy: 0.3134 - val_loss: 1.6630 - val_accuracy: 0.3059\n",
      "Epoch 16/80\n",
      "6435/6435 [==============================] - 0s 39us/step - loss: 1.6349 - accuracy: 0.3117 - val_loss: 1.6607 - val_accuracy: 0.3059\n",
      "Epoch 17/80\n",
      "6435/6435 [==============================] - 0s 36us/step - loss: 1.6280 - accuracy: 0.3189 - val_loss: 1.6554 - val_accuracy: 0.3198\n",
      "Epoch 18/80\n",
      "6435/6435 [==============================] - 0s 36us/step - loss: 1.6281 - accuracy: 0.3144 - val_loss: 1.6463 - val_accuracy: 0.3184\n",
      "Epoch 19/80\n",
      "6435/6435 [==============================] - 0s 44us/step - loss: 1.6225 - accuracy: 0.3162 - val_loss: 1.6447 - val_accuracy: 0.3212\n",
      "Epoch 20/80\n",
      "6435/6435 [==============================] - 0s 36us/step - loss: 1.6230 - accuracy: 0.3102 - val_loss: 1.6393 - val_accuracy: 0.3142\n",
      "Epoch 21/80\n",
      "6435/6435 [==============================] - 0s 36us/step - loss: 1.6229 - accuracy: 0.3212 - val_loss: 1.6543 - val_accuracy: 0.3184\n",
      "Epoch 22/80\n",
      "6435/6435 [==============================] - 0s 39us/step - loss: 1.6182 - accuracy: 0.3167 - val_loss: 1.6456 - val_accuracy: 0.3128\n",
      "Epoch 23/80\n",
      "6435/6435 [==============================] - 0s 36us/step - loss: 1.6175 - accuracy: 0.3178 - val_loss: 1.6651 - val_accuracy: 0.3087\n",
      "Epoch 24/80\n",
      "6435/6435 [==============================] - 0s 37us/step - loss: 1.6198 - accuracy: 0.3139 - val_loss: 1.6515 - val_accuracy: 0.3128\n",
      "Epoch 25/80\n",
      "6435/6435 [==============================] - 0s 33us/step - loss: 1.6229 - accuracy: 0.3133 - val_loss: 1.6520 - val_accuracy: 0.3142\n",
      "Epoch 26/80\n",
      "6435/6435 [==============================] - 0s 32us/step - loss: 1.6150 - accuracy: 0.3133 - val_loss: 1.6460 - val_accuracy: 0.3142\n",
      "Epoch 27/80\n",
      "6435/6435 [==============================] - 0s 34us/step - loss: 1.6157 - accuracy: 0.3166 - val_loss: 1.6422 - val_accuracy: 0.3073\n",
      "Epoch 28/80\n",
      "6435/6435 [==============================] - 0s 34us/step - loss: 1.6131 - accuracy: 0.3173 - val_loss: 1.6433 - val_accuracy: 0.3059\n",
      "Epoch 29/80\n",
      "6435/6435 [==============================] - 0s 39us/step - loss: 1.6146 - accuracy: 0.3201 - val_loss: 1.6598 - val_accuracy: 0.3031\n",
      "Epoch 30/80\n",
      "6435/6435 [==============================] - 0s 34us/step - loss: 1.6149 - accuracy: 0.3183 - val_loss: 1.6390 - val_accuracy: 0.3170\n",
      "Epoch 31/80\n",
      "6435/6435 [==============================] - 0s 38us/step - loss: 1.6116 - accuracy: 0.3221 - val_loss: 1.6646 - val_accuracy: 0.3226\n",
      "Epoch 32/80\n",
      "6435/6435 [==============================] - 0s 35us/step - loss: 1.6147 - accuracy: 0.3164 - val_loss: 1.6458 - val_accuracy: 0.3198\n",
      "Epoch 33/80\n",
      "6435/6435 [==============================] - 0s 36us/step - loss: 1.6134 - accuracy: 0.3173 - val_loss: 1.6407 - val_accuracy: 0.3156\n",
      "Epoch 34/80\n",
      "6435/6435 [==============================] - 0s 34us/step - loss: 1.6145 - accuracy: 0.3136 - val_loss: 1.6337 - val_accuracy: 0.3198\n",
      "Epoch 35/80\n",
      "6435/6435 [==============================] - 0s 34us/step - loss: 1.6073 - accuracy: 0.3217 - val_loss: 1.6420 - val_accuracy: 0.3198\n",
      "Epoch 36/80\n",
      "6435/6435 [==============================] - 0s 39us/step - loss: 1.6105 - accuracy: 0.3184 - val_loss: 1.6470 - val_accuracy: 0.3156\n",
      "Epoch 37/80\n",
      "6435/6435 [==============================] - 0s 32us/step - loss: 1.6107 - accuracy: 0.3198 - val_loss: 1.6399 - val_accuracy: 0.3142\n",
      "Epoch 38/80\n",
      "6435/6435 [==============================] - 0s 39us/step - loss: 1.6051 - accuracy: 0.3159 - val_loss: 1.6544 - val_accuracy: 0.3184\n",
      "Epoch 39/80\n",
      "6435/6435 [==============================] - 0s 37us/step - loss: 1.6076 - accuracy: 0.3254 - val_loss: 1.6469 - val_accuracy: 0.3045\n",
      "Epoch 40/80\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6435/6435 [==============================] - 0s 35us/step - loss: 1.6108 - accuracy: 0.3176 - val_loss: 1.6455 - val_accuracy: 0.3212\n",
      "Epoch 41/80\n",
      "6435/6435 [==============================] - 0s 38us/step - loss: 1.6149 - accuracy: 0.3138 - val_loss: 1.6417 - val_accuracy: 0.3115\n",
      "Epoch 42/80\n",
      "6435/6435 [==============================] - 0s 44us/step - loss: 1.6115 - accuracy: 0.3214 - val_loss: 1.6398 - val_accuracy: 0.3170\n",
      "Epoch 43/80\n",
      "6435/6435 [==============================] - 0s 38us/step - loss: 1.6072 - accuracy: 0.3179 - val_loss: 1.6521 - val_accuracy: 0.3268\n",
      "Epoch 44/80\n",
      "6435/6435 [==============================] - 0s 36us/step - loss: 1.6088 - accuracy: 0.3189 - val_loss: 1.6347 - val_accuracy: 0.3156\n",
      "Epoch 00044: early stopping\n",
      "[[1.55211434e-01 1.55981004e-01 1.62975568e-12 ... 2.62264103e-01\n",
      "  1.46926880e-01 1.42951638e-01]\n",
      " [8.51332694e-02 9.77878720e-02 3.62844068e-19 ... 8.12032958e-04\n",
      "  8.29090849e-02 6.78618923e-02]\n",
      " [1.63179159e-01 1.54792026e-01 7.20098509e-17 ... 2.12200023e-02\n",
      "  1.34144187e-01 1.16685845e-01]\n",
      " ...\n",
      " [9.79617089e-02 1.09245181e-01 8.27429594e-19 ... 1.36460352e-03\n",
      "  8.95104781e-02 7.33035207e-02]\n",
      " [1.48732126e-01 1.81554750e-01 2.72283029e-11 ... 1.99464172e-01\n",
      "  1.40544668e-01 1.36594400e-01]\n",
      " [1.54314190e-01 1.64013565e-01 3.69125347e-12 ... 2.43958309e-01\n",
      "  1.46003187e-01 1.42008767e-01]]\n",
      "[11  5  5 ...  5 11 11]\n",
      "<class 'numpy.ndarray'>\n",
      "One CNN, r:  0\n",
      "Computing Time:  0:08:34.119836\n",
      "n, p1, p2 22 1 9\n",
      "Model: \"sequential_1\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv1d_1 (Conv1D)            (None, 3, 6)              12        \n",
      "_________________________________________________________________\n",
      "average_pooling1d_1 (Average (None, 1, 6)              0         \n",
      "_________________________________________________________________\n",
      "conv1d_2 (Conv1D)            (None, 1, 16)             112       \n",
      "_________________________________________________________________\n",
      "average_pooling1d_2 (Average (None, 1, 16)             0         \n",
      "_________________________________________________________________\n",
      "conv1d_3 (Conv1D)            (None, 1, 120)            2040      \n",
      "_________________________________________________________________\n",
      "flatten_1 (Flatten)          (None, 120)               0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 84)                10164     \n",
      "_________________________________________________________________\n",
      "preds (Dense)                (None, 14)                1190      \n",
      "=================================================================\n",
      "Total params: 13,518\n",
      "Trainable params: 13,518\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Train on 6435 samples, validate on 716 samples\n",
      "Epoch 1/80\n",
      "6435/6435 [==============================] - 0s 75us/step - loss: 2.6116 - accuracy: 0.1333 - val_loss: 2.5540 - val_accuracy: 0.1453\n",
      "Epoch 2/80\n",
      "6435/6435 [==============================] - 0s 39us/step - loss: 2.4244 - accuracy: 0.1770 - val_loss: 2.2444 - val_accuracy: 0.1941\n",
      "Epoch 3/80\n",
      "6435/6435 [==============================] - 0s 39us/step - loss: 2.1234 - accuracy: 0.2012 - val_loss: 2.0737 - val_accuracy: 0.1816\n",
      "Epoch 4/80\n",
      "6435/6435 [==============================] - 0s 36us/step - loss: 1.9832 - accuracy: 0.2328 - val_loss: 1.9752 - val_accuracy: 0.2542\n",
      "Epoch 5/80\n",
      "6435/6435 [==============================] - 0s 36us/step - loss: 1.8963 - accuracy: 0.2390 - val_loss: 1.8943 - val_accuracy: 0.2430\n",
      "Epoch 6/80\n",
      "6435/6435 [==============================] - 0s 39us/step - loss: 1.8176 - accuracy: 0.2507 - val_loss: 1.8071 - val_accuracy: 0.2821\n",
      "Epoch 7/80\n",
      "6435/6435 [==============================] - 0s 36us/step - loss: 1.7350 - accuracy: 0.2819 - val_loss: 1.7255 - val_accuracy: 0.2696\n",
      "Epoch 8/80\n",
      "6435/6435 [==============================] - 0s 36us/step - loss: 1.6733 - accuracy: 0.2777 - val_loss: 1.6789 - val_accuracy: 0.2612\n",
      "Epoch 9/80\n",
      "6435/6435 [==============================] - 0s 37us/step - loss: 1.6317 - accuracy: 0.3027 - val_loss: 1.6380 - val_accuracy: 0.2835\n",
      "Epoch 10/80\n",
      "6435/6435 [==============================] - 0s 35us/step - loss: 1.6046 - accuracy: 0.2985 - val_loss: 1.6270 - val_accuracy: 0.2863\n",
      "Epoch 11/80\n",
      "6435/6435 [==============================] - 0s 36us/step - loss: 1.5836 - accuracy: 0.2985 - val_loss: 1.6103 - val_accuracy: 0.2682\n",
      "Epoch 12/80\n",
      "6435/6435 [==============================] - 0s 36us/step - loss: 1.5793 - accuracy: 0.3060 - val_loss: 1.5864 - val_accuracy: 0.2947\n",
      "Epoch 13/80\n",
      "6435/6435 [==============================] - 0s 44us/step - loss: 1.5533 - accuracy: 0.3096 - val_loss: 1.5877 - val_accuracy: 0.2863\n",
      "Epoch 14/80\n",
      "6435/6435 [==============================] - 0s 39us/step - loss: 1.5370 - accuracy: 0.3106 - val_loss: 1.5656 - val_accuracy: 0.2863\n",
      "Epoch 15/80\n",
      "6435/6435 [==============================] - 0s 34us/step - loss: 1.5340 - accuracy: 0.3141 - val_loss: 1.5792 - val_accuracy: 0.2961\n",
      "Epoch 16/80\n",
      "6435/6435 [==============================] - 0s 36us/step - loss: 1.5254 - accuracy: 0.3068 - val_loss: 1.5555 - val_accuracy: 0.2989\n",
      "Epoch 17/80\n",
      "6435/6435 [==============================] - ETA: 0s - loss: 1.5210 - accuracy: 0.31 - 0s 36us/step - loss: 1.5184 - accuracy: 0.3159 - val_loss: 1.5591 - val_accuracy: 0.2989\n",
      "Epoch 18/80\n",
      "6435/6435 [==============================] - 0s 40us/step - loss: 1.5086 - accuracy: 0.3169 - val_loss: 1.5485 - val_accuracy: 0.3073\n",
      "Epoch 19/80\n",
      "6435/6435 [==============================] - 0s 36us/step - loss: 1.5070 - accuracy: 0.3164 - val_loss: 1.5365 - val_accuracy: 0.3115\n",
      "Epoch 20/80\n",
      "6435/6435 [==============================] - 0s 40us/step - loss: 1.5018 - accuracy: 0.3113 - val_loss: 1.5378 - val_accuracy: 0.2989\n",
      "Epoch 21/80\n",
      "6435/6435 [==============================] - 0s 35us/step - loss: 1.5018 - accuracy: 0.3159 - val_loss: 1.5349 - val_accuracy: 0.3031\n",
      "Epoch 22/80\n",
      "6435/6435 [==============================] - 0s 38us/step - loss: 1.4955 - accuracy: 0.3102 - val_loss: 1.5342 - val_accuracy: 0.2863\n",
      "Epoch 23/80\n",
      "6435/6435 [==============================] - 0s 37us/step - loss: 1.4939 - accuracy: 0.3181 - val_loss: 1.5234 - val_accuracy: 0.3101\n",
      "Epoch 24/80\n",
      "6435/6435 [==============================] - 0s 36us/step - loss: 1.4906 - accuracy: 0.3200 - val_loss: 1.5374 - val_accuracy: 0.3045\n",
      "Epoch 25/80\n",
      "6435/6435 [==============================] - 0s 36us/step - loss: 1.4889 - accuracy: 0.3124 - val_loss: 1.5120 - val_accuracy: 0.3115\n",
      "Epoch 26/80\n",
      "6435/6435 [==============================] - 0s 36us/step - loss: 1.4892 - accuracy: 0.3175 - val_loss: 1.5256 - val_accuracy: 0.2975\n",
      "Epoch 27/80\n",
      "6435/6435 [==============================] - 0s 39us/step - loss: 1.4842 - accuracy: 0.3226 - val_loss: 1.5228 - val_accuracy: 0.3031\n",
      "Epoch 28/80\n",
      "6435/6435 [==============================] - 0s 36us/step - loss: 1.4809 - accuracy: 0.3178 - val_loss: 1.5517 - val_accuracy: 0.3073\n",
      "Epoch 29/80\n",
      "6435/6435 [==============================] - 0s 36us/step - loss: 1.4881 - accuracy: 0.3097 - val_loss: 1.5172 - val_accuracy: 0.2877\n",
      "Epoch 30/80\n",
      "6435/6435 [==============================] - 0s 36us/step - loss: 1.4798 - accuracy: 0.3203 - val_loss: 1.5314 - val_accuracy: 0.3031\n",
      "Epoch 31/80\n",
      "6435/6435 [==============================] - 0s 38us/step - loss: 1.4834 - accuracy: 0.3144 - val_loss: 1.5295 - val_accuracy: 0.2905\n",
      "Epoch 32/80\n",
      "6435/6435 [==============================] - 0s 37us/step - loss: 1.4774 - accuracy: 0.3212 - val_loss: 1.5176 - val_accuracy: 0.3142\n",
      "Epoch 33/80\n",
      "6435/6435 [==============================] - 0s 37us/step - loss: 1.4756 - accuracy: 0.3228 - val_loss: 1.5117 - val_accuracy: 0.2975\n",
      "Epoch 34/80\n",
      "6435/6435 [==============================] - 0s 33us/step - loss: 1.4741 - accuracy: 0.3164 - val_loss: 1.5049 - val_accuracy: 0.3087\n",
      "Epoch 35/80\n",
      "6435/6435 [==============================] - 0s 39us/step - loss: 1.4748 - accuracy: 0.3173 - val_loss: 1.5115 - val_accuracy: 0.2975\n",
      "Epoch 36/80\n",
      "6435/6435 [==============================] - 0s 36us/step - loss: 1.4722 - accuracy: 0.3211 - val_loss: 1.5176 - val_accuracy: 0.2975\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 37/80\n",
      "6435/6435 [==============================] - 0s 36us/step - loss: 1.4749 - accuracy: 0.3229 - val_loss: 1.5030 - val_accuracy: 0.3142\n",
      "Epoch 38/80\n",
      "6435/6435 [==============================] - 0s 36us/step - loss: 1.4701 - accuracy: 0.3178 - val_loss: 1.5041 - val_accuracy: 0.3184\n",
      "Epoch 39/80\n",
      "6435/6435 [==============================] - 0s 34us/step - loss: 1.4719 - accuracy: 0.3298 - val_loss: 1.5120 - val_accuracy: 0.3240\n",
      "Epoch 40/80\n",
      "6435/6435 [==============================] - 0s 36us/step - loss: 1.4688 - accuracy: 0.3229 - val_loss: 1.5197 - val_accuracy: 0.3226\n",
      "Epoch 41/80\n",
      "6435/6435 [==============================] - 0s 36us/step - loss: 1.4702 - accuracy: 0.3232 - val_loss: 1.4977 - val_accuracy: 0.3170\n",
      "Epoch 42/80\n",
      "6435/6435 [==============================] - 0s 37us/step - loss: 1.4655 - accuracy: 0.3245 - val_loss: 1.4969 - val_accuracy: 0.3128\n",
      "Epoch 43/80\n",
      "6435/6435 [==============================] - 0s 35us/step - loss: 1.4627 - accuracy: 0.3226 - val_loss: 1.4993 - val_accuracy: 0.3142\n",
      "Epoch 44/80\n",
      "6435/6435 [==============================] - 0s 39us/step - loss: 1.4603 - accuracy: 0.3242 - val_loss: 1.5027 - val_accuracy: 0.3017\n",
      "Epoch 45/80\n",
      "6435/6435 [==============================] - 0s 36us/step - loss: 1.4643 - accuracy: 0.3207 - val_loss: 1.5096 - val_accuracy: 0.3017\n",
      "Epoch 46/80\n",
      "6435/6435 [==============================] - 0s 39us/step - loss: 1.4618 - accuracy: 0.3327 - val_loss: 1.4869 - val_accuracy: 0.3240\n",
      "Epoch 47/80\n",
      "6435/6435 [==============================] - 0s 34us/step - loss: 1.4585 - accuracy: 0.3267 - val_loss: 1.4952 - val_accuracy: 0.3115\n",
      "Epoch 48/80\n",
      "6435/6435 [==============================] - 0s 39us/step - loss: 1.4592 - accuracy: 0.3262 - val_loss: 1.5004 - val_accuracy: 0.3450\n",
      "Epoch 49/80\n",
      "6435/6435 [==============================] - 0s 36us/step - loss: 1.4585 - accuracy: 0.3271 - val_loss: 1.4890 - val_accuracy: 0.3212\n",
      "Epoch 50/80\n",
      "6435/6435 [==============================] - 0s 36us/step - loss: 1.4559 - accuracy: 0.3374 - val_loss: 1.4884 - val_accuracy: 0.3045\n",
      "Epoch 51/80\n",
      "6435/6435 [==============================] - 0s 35us/step - loss: 1.4526 - accuracy: 0.3461 - val_loss: 1.4800 - val_accuracy: 0.3380\n",
      "Epoch 52/80\n",
      "6435/6435 [==============================] - 0s 33us/step - loss: 1.4508 - accuracy: 0.3355 - val_loss: 1.4875 - val_accuracy: 0.3115\n",
      "Epoch 53/80\n",
      "6435/6435 [==============================] - 0s 39us/step - loss: 1.4456 - accuracy: 0.3448 - val_loss: 1.4745 - val_accuracy: 0.3450\n",
      "Epoch 54/80\n",
      "6435/6435 [==============================] - 0s 36us/step - loss: 1.4453 - accuracy: 0.3441 - val_loss: 1.4765 - val_accuracy: 0.3394\n",
      "Epoch 55/80\n",
      "6435/6435 [==============================] - 0s 41us/step - loss: 1.4427 - accuracy: 0.3450 - val_loss: 1.5519 - val_accuracy: 0.3059\n",
      "Epoch 56/80\n",
      "6435/6435 [==============================] - 0s 36us/step - loss: 1.4439 - accuracy: 0.3437 - val_loss: 1.4633 - val_accuracy: 0.3366\n",
      "Epoch 57/80\n",
      "6435/6435 [==============================] - 0s 36us/step - loss: 1.4304 - accuracy: 0.3625 - val_loss: 1.4613 - val_accuracy: 0.3380\n",
      "Epoch 58/80\n",
      "6435/6435 [==============================] - 0s 39us/step - loss: 1.4304 - accuracy: 0.3615 - val_loss: 1.4751 - val_accuracy: 0.3366\n",
      "Epoch 59/80\n",
      "6435/6435 [==============================] - 0s 36us/step - loss: 1.4252 - accuracy: 0.3692 - val_loss: 1.4620 - val_accuracy: 0.3226\n",
      "Epoch 60/80\n",
      "6435/6435 [==============================] - 0s 34us/step - loss: 1.4211 - accuracy: 0.3559 - val_loss: 1.4665 - val_accuracy: 0.3184\n",
      "Epoch 61/80\n",
      "6435/6435 [==============================] - 0s 36us/step - loss: 1.4153 - accuracy: 0.3646 - val_loss: 1.4406 - val_accuracy: 0.3589\n",
      "Epoch 62/80\n",
      "6435/6435 [==============================] - 0s 39us/step - loss: 1.4061 - accuracy: 0.3602 - val_loss: 1.4362 - val_accuracy: 0.3575\n",
      "Epoch 63/80\n",
      "6435/6435 [==============================] - 0s 36us/step - loss: 1.3953 - accuracy: 0.3726 - val_loss: 1.4353 - val_accuracy: 0.3492\n",
      "Epoch 64/80\n",
      "6435/6435 [==============================] - 0s 39us/step - loss: 1.3903 - accuracy: 0.3772 - val_loss: 1.4231 - val_accuracy: 0.3422\n",
      "Epoch 65/80\n",
      "6435/6435 [==============================] - 0s 36us/step - loss: 1.3841 - accuracy: 0.3643 - val_loss: 1.4039 - val_accuracy: 0.3603\n",
      "Epoch 66/80\n",
      "6435/6435 [==============================] - 0s 36us/step - loss: 1.3684 - accuracy: 0.3829 - val_loss: 1.3862 - val_accuracy: 0.3422\n",
      "Epoch 67/80\n",
      "6435/6435 [==============================] - 0s 36us/step - loss: 1.3517 - accuracy: 0.3787 - val_loss: 1.3864 - val_accuracy: 0.3631\n",
      "Epoch 68/80\n",
      "6435/6435 [==============================] - 0s 39us/step - loss: 1.3377 - accuracy: 0.3922 - val_loss: 1.3862 - val_accuracy: 0.3617\n",
      "Epoch 69/80\n",
      "6435/6435 [==============================] - 0s 38us/step - loss: 1.3257 - accuracy: 0.3865 - val_loss: 1.3483 - val_accuracy: 0.3771\n",
      "Epoch 70/80\n",
      "6435/6435 [==============================] - 0s 35us/step - loss: 1.3181 - accuracy: 0.3876 - val_loss: 1.3484 - val_accuracy: 0.3673\n",
      "Epoch 71/80\n",
      "6435/6435 [==============================] - 0s 36us/step - loss: 1.3107 - accuracy: 0.3915 - val_loss: 1.3381 - val_accuracy: 0.3701\n",
      "Epoch 72/80\n",
      "6435/6435 [==============================] - 0s 34us/step - loss: 1.3032 - accuracy: 0.3848 - val_loss: 1.3830 - val_accuracy: 0.3645\n",
      "Epoch 73/80\n",
      "6435/6435 [==============================] - 0s 39us/step - loss: 1.3033 - accuracy: 0.3899 - val_loss: 1.3225 - val_accuracy: 0.3631\n",
      "Epoch 74/80\n",
      "6435/6435 [==============================] - 0s 34us/step - loss: 1.2915 - accuracy: 0.3880 - val_loss: 1.3183 - val_accuracy: 0.3771\n",
      "Epoch 75/80\n",
      "6435/6435 [==============================] - 0s 36us/step - loss: 1.2965 - accuracy: 0.3874 - val_loss: 1.3094 - val_accuracy: 0.3729\n",
      "Epoch 76/80\n",
      "6435/6435 [==============================] - 0s 36us/step - loss: 1.2846 - accuracy: 0.3837 - val_loss: 1.3273 - val_accuracy: 0.3729\n",
      "Epoch 77/80\n",
      "6435/6435 [==============================] - 0s 39us/step - loss: 1.2831 - accuracy: 0.3927 - val_loss: 1.3068 - val_accuracy: 0.3701\n",
      "Epoch 78/80\n",
      "6435/6435 [==============================] - 0s 39us/step - loss: 1.2816 - accuracy: 0.3901 - val_loss: 1.2993 - val_accuracy: 0.3729\n",
      "Epoch 79/80\n",
      "6435/6435 [==============================] - 0s 34us/step - loss: 1.2773 - accuracy: 0.3894 - val_loss: 1.3069 - val_accuracy: 0.3715\n",
      "Epoch 80/80\n",
      "6435/6435 [==============================] - 0s 38us/step - loss: 1.2745 - accuracy: 0.3921 - val_loss: 1.3098 - val_accuracy: 0.3659\n",
      "[[9.81030464e-02 1.12993725e-01 5.69986558e-10 ... 3.27990919e-01\n",
      "  2.27344871e-01 2.16463536e-01]\n",
      " [3.41346636e-02 3.59028056e-02 2.55690384e-15 ... 3.04785930e-03\n",
      "  1.08001381e-02 8.85243155e-03]\n",
      " [1.78867131e-01 2.08215654e-01 1.50558403e-11 ... 8.42898861e-02\n",
      "  2.49017969e-01 2.71656811e-01]\n",
      " ...\n",
      " [2.21942395e-01 2.59048551e-01 5.07135610e-12 ... 1.47383092e-02\n",
      "  2.35672027e-01 2.66442090e-01]\n",
      " [1.15313798e-01 1.22199446e-01 3.39289019e-09 ... 1.67862803e-01\n",
      "  2.84679264e-01 2.79168457e-01]\n",
      " [1.17062457e-01 1.31701827e-01 1.53916091e-09 ... 1.90759182e-01\n",
      "  2.76935190e-01 2.62803465e-01]]\n",
      "[11  5 13 ... 13 12 12]\n",
      "<class 'numpy.ndarray'>\n",
      "One CNN, r:  0\n",
      "Computing Time:  0:08:54.833498\n",
      "n, p1, p2 23 1 10\n",
      "Model: \"sequential_1\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv1d_1 (Conv1D)            (None, 3, 6)              12        \n",
      "_________________________________________________________________\n",
      "average_pooling1d_1 (Average (None, 1, 6)              0         \n",
      "_________________________________________________________________\n",
      "conv1d_2 (Conv1D)            (None, 1, 16)             112       \n",
      "_________________________________________________________________\n",
      "average_pooling1d_2 (Average (None, 1, 16)             0         \n",
      "_________________________________________________________________\n",
      "conv1d_3 (Conv1D)            (None, 1, 120)            2040      \n",
      "_________________________________________________________________\n",
      "flatten_1 (Flatten)          (None, 120)               0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 84)                10164     \n",
      "_________________________________________________________________\n",
      "preds (Dense)                (None, 14)                1190      \n",
      "=================================================================\n",
      "Total params: 13,518\n",
      "Trainable params: 13,518\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 6435 samples, validate on 716 samples\n",
      "Epoch 1/80\n",
      "6435/6435 [==============================] - 0s 73us/step - loss: 2.5941 - accuracy: 0.1430 - val_loss: 2.4982 - val_accuracy: 0.1369\n",
      "Epoch 2/80\n",
      "6435/6435 [==============================] - 0s 39us/step - loss: 2.3130 - accuracy: 0.2151 - val_loss: 2.0978 - val_accuracy: 0.2709\n",
      "Epoch 3/80\n",
      "6435/6435 [==============================] - 0s 36us/step - loss: 2.0255 - accuracy: 0.2797 - val_loss: 1.9130 - val_accuracy: 0.2723\n",
      "Epoch 4/80\n",
      "6435/6435 [==============================] - 0s 39us/step - loss: 1.9119 - accuracy: 0.2873 - val_loss: 1.8445 - val_accuracy: 0.3087\n",
      "Epoch 5/80\n",
      "6435/6435 [==============================] - 0s 39us/step - loss: 1.8380 - accuracy: 0.2802 - val_loss: 1.7749 - val_accuracy: 0.2626\n",
      "Epoch 6/80\n",
      "6435/6435 [==============================] - 0s 36us/step - loss: 1.7867 - accuracy: 0.2839 - val_loss: 1.7159 - val_accuracy: 0.2835\n",
      "Epoch 7/80\n",
      "6435/6435 [==============================] - 0s 39us/step - loss: 1.7325 - accuracy: 0.2936 - val_loss: 1.6740 - val_accuracy: 0.3003\n",
      "Epoch 8/80\n",
      "6435/6435 [==============================] - 0s 36us/step - loss: 1.6857 - accuracy: 0.2904 - val_loss: 1.6293 - val_accuracy: 0.2905\n",
      "Epoch 9/80\n",
      "6435/6435 [==============================] - 0s 36us/step - loss: 1.6435 - accuracy: 0.2920 - val_loss: 1.5878 - val_accuracy: 0.2975\n",
      "Epoch 10/80\n",
      "6435/6435 [==============================] - 0s 36us/step - loss: 1.6111 - accuracy: 0.2900 - val_loss: 1.5737 - val_accuracy: 0.2891\n",
      "Epoch 11/80\n",
      "6435/6435 [==============================] - 0s 39us/step - loss: 1.5858 - accuracy: 0.2971 - val_loss: 1.5400 - val_accuracy: 0.3045\n",
      "Epoch 12/80\n",
      "6435/6435 [==============================] - 0s 34us/step - loss: 1.5673 - accuracy: 0.2932 - val_loss: 1.5347 - val_accuracy: 0.2877\n",
      "Epoch 13/80\n",
      "6435/6435 [==============================] - 0s 39us/step - loss: 1.5561 - accuracy: 0.2965 - val_loss: 1.5394 - val_accuracy: 0.2961\n",
      "Epoch 14/80\n",
      "6435/6435 [==============================] - 0s 41us/step - loss: 1.5468 - accuracy: 0.2928 - val_loss: 1.5075 - val_accuracy: 0.2989\n",
      "Epoch 15/80\n",
      "6435/6435 [==============================] - 0s 39us/step - loss: 1.5453 - accuracy: 0.2866 - val_loss: 1.5198 - val_accuracy: 0.2891\n",
      "Epoch 16/80\n",
      "6435/6435 [==============================] - 0s 44us/step - loss: 1.5359 - accuracy: 0.2957 - val_loss: 1.4947 - val_accuracy: 0.3128\n",
      "Epoch 17/80\n",
      "6435/6435 [==============================] - 0s 39us/step - loss: 1.5296 - accuracy: 0.2987 - val_loss: 1.5007 - val_accuracy: 0.2947\n",
      "Epoch 18/80\n",
      "6435/6435 [==============================] - 0s 36us/step - loss: 1.5218 - accuracy: 0.2954 - val_loss: 1.4995 - val_accuracy: 0.3101\n",
      "Epoch 19/80\n",
      "6435/6435 [==============================] - 0s 39us/step - loss: 1.5214 - accuracy: 0.2934 - val_loss: 1.5106 - val_accuracy: 0.3115\n",
      "Epoch 20/80\n",
      "6435/6435 [==============================] - 0s 39us/step - loss: 1.5229 - accuracy: 0.2942 - val_loss: 1.4998 - val_accuracy: 0.3282\n",
      "Epoch 21/80\n",
      "6435/6435 [==============================] - ETA: 0s - loss: 1.5305 - accuracy: 0.29 - 0s 36us/step - loss: 1.5243 - accuracy: 0.2985 - val_loss: 1.5060 - val_accuracy: 0.2765\n",
      "Epoch 22/80\n",
      "6435/6435 [==============================] - 0s 41us/step - loss: 1.5104 - accuracy: 0.3035 - val_loss: 1.4946 - val_accuracy: 0.3087\n",
      "Epoch 23/80\n",
      "6435/6435 [==============================] - 0s 36us/step - loss: 1.5144 - accuracy: 0.2976 - val_loss: 1.4774 - val_accuracy: 0.3436\n",
      "Epoch 24/80\n",
      "6435/6435 [==============================] - 0s 38us/step - loss: 1.5136 - accuracy: 0.3077 - val_loss: 1.4826 - val_accuracy: 0.3422\n",
      "Epoch 25/80\n",
      "6435/6435 [==============================] - 0s 34us/step - loss: 1.5085 - accuracy: 0.3061 - val_loss: 1.5018 - val_accuracy: 0.3045\n",
      "Epoch 26/80\n",
      "6435/6435 [==============================] - 0s 36us/step - loss: 1.5068 - accuracy: 0.2953 - val_loss: 1.4873 - val_accuracy: 0.3254\n",
      "Epoch 27/80\n",
      "6435/6435 [==============================] - 0s 36us/step - loss: 1.5127 - accuracy: 0.2976 - val_loss: 1.4751 - val_accuracy: 0.3352\n",
      "Epoch 28/80\n",
      "6435/6435 [==============================] - 0s 36us/step - loss: 1.5025 - accuracy: 0.3049 - val_loss: 1.4896 - val_accuracy: 0.3296\n",
      "Epoch 29/80\n",
      "6435/6435 [==============================] - 0s 36us/step - loss: 1.5040 - accuracy: 0.3004 - val_loss: 1.4816 - val_accuracy: 0.3254\n",
      "Epoch 30/80\n",
      "6435/6435 [==============================] - 0s 39us/step - loss: 1.5071 - accuracy: 0.3103 - val_loss: 1.4669 - val_accuracy: 0.3366\n",
      "Epoch 31/80\n",
      "6435/6435 [==============================] - 0s 39us/step - loss: 1.5032 - accuracy: 0.3033 - val_loss: 1.4801 - val_accuracy: 0.3366\n",
      "Epoch 32/80\n",
      "6435/6435 [==============================] - 0s 36us/step - loss: 1.5038 - accuracy: 0.3091 - val_loss: 1.4740 - val_accuracy: 0.3073\n",
      "Epoch 33/80\n",
      "6435/6435 [==============================] - 0s 37us/step - loss: 1.5024 - accuracy: 0.3170 - val_loss: 1.4696 - val_accuracy: 0.3394\n",
      "Epoch 34/80\n",
      "6435/6435 [==============================] - 0s 34us/step - loss: 1.5016 - accuracy: 0.3047 - val_loss: 1.4832 - val_accuracy: 0.2961\n",
      "Epoch 35/80\n",
      "6435/6435 [==============================] - 0s 37us/step - loss: 1.5032 - accuracy: 0.3024 - val_loss: 1.4757 - val_accuracy: 0.3338\n",
      "Epoch 36/80\n",
      "6435/6435 [==============================] - 0s 35us/step - loss: 1.4978 - accuracy: 0.3088 - val_loss: 1.4642 - val_accuracy: 0.3254\n",
      "Epoch 37/80\n",
      "6435/6435 [==============================] - 0s 39us/step - loss: 1.4972 - accuracy: 0.3060 - val_loss: 1.4679 - val_accuracy: 0.3408\n",
      "Epoch 38/80\n",
      "6435/6435 [==============================] - 0s 39us/step - loss: 1.4983 - accuracy: 0.3041 - val_loss: 1.4685 - val_accuracy: 0.3170\n",
      "Epoch 39/80\n",
      "6435/6435 [==============================] - 0s 39us/step - loss: 1.4929 - accuracy: 0.3069 - val_loss: 1.4608 - val_accuracy: 0.3226\n",
      "Epoch 40/80\n",
      "6435/6435 [==============================] - 0s 36us/step - loss: 1.4998 - accuracy: 0.3075 - val_loss: 1.4937 - val_accuracy: 0.3212\n",
      "Epoch 41/80\n",
      "6435/6435 [==============================] - 0s 36us/step - loss: 1.4948 - accuracy: 0.3139 - val_loss: 1.4651 - val_accuracy: 0.2975\n",
      "Epoch 42/80\n",
      "6435/6435 [==============================] - 0s 39us/step - loss: 1.4911 - accuracy: 0.3097 - val_loss: 1.4646 - val_accuracy: 0.3226\n",
      "Epoch 43/80\n",
      "6435/6435 [==============================] - 0s 36us/step - loss: 1.4978 - accuracy: 0.3114 - val_loss: 1.4696 - val_accuracy: 0.3366\n",
      "Epoch 44/80\n",
      "6435/6435 [==============================] - 0s 39us/step - loss: 1.4914 - accuracy: 0.3130 - val_loss: 1.4842 - val_accuracy: 0.2961\n",
      "Epoch 45/80\n",
      "6435/6435 [==============================] - 0s 36us/step - loss: 1.4893 - accuracy: 0.3077 - val_loss: 1.4794 - val_accuracy: 0.2989\n",
      "Epoch 46/80\n",
      "6435/6435 [==============================] - 0s 39us/step - loss: 1.4906 - accuracy: 0.3038 - val_loss: 1.4787 - val_accuracy: 0.3142\n",
      "Epoch 47/80\n",
      "6435/6435 [==============================] - 0s 36us/step - loss: 1.4903 - accuracy: 0.3133 - val_loss: 1.4710 - val_accuracy: 0.3184\n",
      "Epoch 48/80\n",
      "6435/6435 [==============================] - 0s 38us/step - loss: 1.4929 - accuracy: 0.3055 - val_loss: 1.4893 - val_accuracy: 0.3073\n",
      "Epoch 49/80\n",
      "6435/6435 [==============================] - 0s 37us/step - loss: 1.4892 - accuracy: 0.3125 - val_loss: 1.4723 - val_accuracy: 0.3450\n",
      "Epoch 00049: early stopping\n",
      "[[1.3602774e-01 1.7976968e-01 2.8691947e-13 ... 2.0776330e-01\n",
      "  2.1472834e-01 2.4339080e-01]\n",
      " [3.0161494e-02 2.8092733e-01 8.3699134e-19 ... 3.3562738e-03\n",
      "  1.7364547e-02 2.2150874e-02]\n",
      " [1.3028538e-01 1.7935249e-01 3.0459074e-15 ... 2.5177577e-01\n",
      "  2.0683804e-01 2.1131553e-01]\n",
      " ...\n",
      " [1.3067357e-01 1.8006250e-01 2.4686110e-15 ... 2.5096667e-01\n",
      "  2.0696391e-01 2.1160012e-01]\n",
      " [1.3560219e-01 1.7425968e-01 5.6495750e-12 ... 1.7417333e-01\n",
      "  2.1268928e-01 2.5972122e-01]\n",
      " [1.3640232e-01 1.7725921e-01 1.6954987e-12 ... 1.8737550e-01\n",
      "  2.1440157e-01 2.5427699e-01]]\n",
      "[13  5 11 ... 11 13 13]\n",
      "<class 'numpy.ndarray'>\n",
      "One CNN, r:  0\n",
      "Computing Time:  0:09:08.442670\n",
      "n, p1, p2 24 1 11\n",
      "Model: \"sequential_1\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv1d_1 (Conv1D)            (None, 3, 6)              12        \n",
      "_________________________________________________________________\n",
      "average_pooling1d_1 (Average (None, 1, 6)              0         \n",
      "_________________________________________________________________\n",
      "conv1d_2 (Conv1D)            (None, 1, 16)             112       \n",
      "_________________________________________________________________\n",
      "average_pooling1d_2 (Average (None, 1, 16)             0         \n",
      "_________________________________________________________________\n",
      "conv1d_3 (Conv1D)            (None, 1, 120)            2040      \n",
      "_________________________________________________________________\n",
      "flatten_1 (Flatten)          (None, 120)               0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 84)                10164     \n",
      "_________________________________________________________________\n",
      "preds (Dense)                (None, 14)                1190      \n",
      "=================================================================\n",
      "Total params: 13,518\n",
      "Trainable params: 13,518\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 6435 samples, validate on 716 samples\n",
      "Epoch 1/80\n",
      "6435/6435 [==============================] - 0s 74us/step - loss: 2.6071 - accuracy: 0.1453 - val_loss: 2.5526 - val_accuracy: 0.1173\n",
      "Epoch 2/80\n",
      "6435/6435 [==============================] - 0s 38us/step - loss: 2.3705 - accuracy: 0.1765 - val_loss: 2.1739 - val_accuracy: 0.1997\n",
      "Epoch 3/80\n",
      "6435/6435 [==============================] - 0s 36us/step - loss: 2.0396 - accuracy: 0.2726 - val_loss: 1.9335 - val_accuracy: 0.2877\n",
      "Epoch 4/80\n",
      "6435/6435 [==============================] - 0s 39us/step - loss: 1.8907 - accuracy: 0.2889 - val_loss: 1.8185 - val_accuracy: 0.2975\n",
      "Epoch 5/80\n",
      "6435/6435 [==============================] - 0s 36us/step - loss: 1.7997 - accuracy: 0.2945 - val_loss: 1.7527 - val_accuracy: 0.2849\n",
      "Epoch 6/80\n",
      "6435/6435 [==============================] - 0s 36us/step - loss: 1.7309 - accuracy: 0.2923 - val_loss: 1.6751 - val_accuracy: 0.3045\n",
      "Epoch 7/80\n",
      "6435/6435 [==============================] - 0s 37us/step - loss: 1.6631 - accuracy: 0.3026 - val_loss: 1.6180 - val_accuracy: 0.2933\n",
      "Epoch 8/80\n",
      "6435/6435 [==============================] - 0s 36us/step - loss: 1.6096 - accuracy: 0.3049 - val_loss: 1.5719 - val_accuracy: 0.3128\n",
      "Epoch 9/80\n",
      "6435/6435 [==============================] - 0s 41us/step - loss: 1.5806 - accuracy: 0.2999 - val_loss: 1.5455 - val_accuracy: 0.3128\n",
      "Epoch 10/80\n",
      "6435/6435 [==============================] - 0s 35us/step - loss: 1.5536 - accuracy: 0.3009 - val_loss: 1.5402 - val_accuracy: 0.2835\n",
      "Epoch 11/80\n",
      "6435/6435 [==============================] - 0s 31us/step - loss: 1.5435 - accuracy: 0.3060 - val_loss: 1.5095 - val_accuracy: 0.3198\n",
      "Epoch 12/80\n",
      "6435/6435 [==============================] - 0s 35us/step - loss: 1.5215 - accuracy: 0.3029 - val_loss: 1.4823 - val_accuracy: 0.3128\n",
      "Epoch 13/80\n",
      "6435/6435 [==============================] - 0s 35us/step - loss: 1.5082 - accuracy: 0.3110 - val_loss: 1.4886 - val_accuracy: 0.3059\n",
      "Epoch 14/80\n",
      "6435/6435 [==============================] - 0s 34us/step - loss: 1.4999 - accuracy: 0.3131 - val_loss: 1.4714 - val_accuracy: 0.3156\n",
      "Epoch 15/80\n",
      "6435/6435 [==============================] - 0s 39us/step - loss: 1.4923 - accuracy: 0.3106 - val_loss: 1.4633 - val_accuracy: 0.3282\n",
      "Epoch 16/80\n",
      "6435/6435 [==============================] - 0s 35us/step - loss: 1.4895 - accuracy: 0.3134 - val_loss: 1.4609 - val_accuracy: 0.3101\n",
      "Epoch 17/80\n",
      "6435/6435 [==============================] - 0s 38us/step - loss: 1.4840 - accuracy: 0.3116 - val_loss: 1.4557 - val_accuracy: 0.3338\n",
      "Epoch 18/80\n",
      "6435/6435 [==============================] - 0s 34us/step - loss: 1.4872 - accuracy: 0.3094 - val_loss: 1.4509 - val_accuracy: 0.3310\n",
      "Epoch 19/80\n",
      "6435/6435 [==============================] - 0s 38us/step - loss: 1.4747 - accuracy: 0.3175 - val_loss: 1.4571 - val_accuracy: 0.3045\n",
      "Epoch 20/80\n",
      "6435/6435 [==============================] - 0s 32us/step - loss: 1.4798 - accuracy: 0.3099 - val_loss: 1.4688 - val_accuracy: 0.2947\n",
      "Epoch 21/80\n",
      "6435/6435 [==============================] - 0s 41us/step - loss: 1.4750 - accuracy: 0.3183 - val_loss: 1.4499 - val_accuracy: 0.3547\n",
      "Epoch 22/80\n",
      "6435/6435 [==============================] - 0s 36us/step - loss: 1.4753 - accuracy: 0.3204 - val_loss: 1.4482 - val_accuracy: 0.3101\n",
      "Epoch 23/80\n",
      "6435/6435 [==============================] - 0s 42us/step - loss: 1.4728 - accuracy: 0.3203 - val_loss: 1.4530 - val_accuracy: 0.3142\n",
      "Epoch 24/80\n",
      "6435/6435 [==============================] - 0s 36us/step - loss: 1.4666 - accuracy: 0.3193 - val_loss: 1.4389 - val_accuracy: 0.3115\n",
      "Epoch 25/80\n",
      "6435/6435 [==============================] - 0s 36us/step - loss: 1.4687 - accuracy: 0.3243 - val_loss: 1.4509 - val_accuracy: 0.3142\n",
      "Epoch 26/80\n",
      "6435/6435 [==============================] - 0s 39us/step - loss: 1.4626 - accuracy: 0.3232 - val_loss: 1.4366 - val_accuracy: 0.3296\n",
      "Epoch 27/80\n",
      "6435/6435 [==============================] - 0s 37us/step - loss: 1.4623 - accuracy: 0.3256 - val_loss: 1.4545 - val_accuracy: 0.3031\n",
      "Epoch 28/80\n",
      "6435/6435 [==============================] - 0s 33us/step - loss: 1.4644 - accuracy: 0.3242 - val_loss: 1.4306 - val_accuracy: 0.3212\n",
      "Epoch 29/80\n",
      "6435/6435 [==============================] - 0s 44us/step - loss: 1.4617 - accuracy: 0.3155 - val_loss: 1.4365 - val_accuracy: 0.3520\n",
      "Epoch 30/80\n",
      "6435/6435 [==============================] - 0s 38us/step - loss: 1.4681 - accuracy: 0.3161 - val_loss: 1.4280 - val_accuracy: 0.3310\n",
      "Epoch 31/80\n",
      "6435/6435 [==============================] - 0s 38us/step - loss: 1.4555 - accuracy: 0.3350 - val_loss: 1.4347 - val_accuracy: 0.3254\n",
      "Epoch 32/80\n",
      "6435/6435 [==============================] - 0s 35us/step - loss: 1.4593 - accuracy: 0.3265 - val_loss: 1.4429 - val_accuracy: 0.3184\n",
      "Epoch 33/80\n",
      "6435/6435 [==============================] - 0s 40us/step - loss: 1.4633 - accuracy: 0.3221 - val_loss: 1.4307 - val_accuracy: 0.3575\n",
      "Epoch 34/80\n",
      "6435/6435 [==============================] - 0s 37us/step - loss: 1.4514 - accuracy: 0.3221 - val_loss: 1.4346 - val_accuracy: 0.3282\n",
      "Epoch 35/80\n",
      "6435/6435 [==============================] - 0s 34us/step - loss: 1.4476 - accuracy: 0.3274 - val_loss: 1.4257 - val_accuracy: 0.3380\n",
      "Epoch 36/80\n",
      "6435/6435 [==============================] - 0s 36us/step - loss: 1.4510 - accuracy: 0.3338 - val_loss: 1.4446 - val_accuracy: 0.3575\n",
      "Epoch 37/80\n",
      "6435/6435 [==============================] - 0s 36us/step - loss: 1.4487 - accuracy: 0.3409 - val_loss: 1.4258 - val_accuracy: 0.3156\n",
      "Epoch 38/80\n",
      "6435/6435 [==============================] - 0s 36us/step - loss: 1.4485 - accuracy: 0.3260 - val_loss: 1.4287 - val_accuracy: 0.3198\n",
      "Epoch 39/80\n",
      "6435/6435 [==============================] - 0s 39us/step - loss: 1.4481 - accuracy: 0.3310 - val_loss: 1.4277 - val_accuracy: 0.3115\n",
      "Epoch 40/80\n",
      "6435/6435 [==============================] - 0s 37us/step - loss: 1.4459 - accuracy: 0.3391 - val_loss: 1.4169 - val_accuracy: 0.3450\n",
      "Epoch 41/80\n",
      "6435/6435 [==============================] - 0s 36us/step - loss: 1.4431 - accuracy: 0.3368 - val_loss: 1.4132 - val_accuracy: 0.3380\n",
      "Epoch 42/80\n",
      "6435/6435 [==============================] - 0s 36us/step - loss: 1.4416 - accuracy: 0.3392 - val_loss: 1.4206 - val_accuracy: 0.3324\n",
      "Epoch 43/80\n",
      "6435/6435 [==============================] - 0s 37us/step - loss: 1.4353 - accuracy: 0.3495 - val_loss: 1.4192 - val_accuracy: 0.3631\n",
      "Epoch 44/80\n",
      "6435/6435 [==============================] - 0s 34us/step - loss: 1.4342 - accuracy: 0.3484 - val_loss: 1.4103 - val_accuracy: 0.3464\n",
      "Epoch 45/80\n",
      "6435/6435 [==============================] - 0s 35us/step - loss: 1.4326 - accuracy: 0.3498 - val_loss: 1.4172 - val_accuracy: 0.3240\n",
      "Epoch 46/80\n",
      "6435/6435 [==============================] - 0s 35us/step - loss: 1.4261 - accuracy: 0.3467 - val_loss: 1.4050 - val_accuracy: 0.3575\n",
      "Epoch 47/80\n",
      "6435/6435 [==============================] - 0s 38us/step - loss: 1.4302 - accuracy: 0.3498 - val_loss: 1.4421 - val_accuracy: 0.3492\n",
      "Epoch 48/80\n",
      "6435/6435 [==============================] - 0s 37us/step - loss: 1.4202 - accuracy: 0.3646 - val_loss: 1.3960 - val_accuracy: 0.3771\n",
      "Epoch 49/80\n",
      "6435/6435 [==============================] - 0s 40us/step - loss: 1.4149 - accuracy: 0.3658 - val_loss: 1.3879 - val_accuracy: 0.3841\n",
      "Epoch 50/80\n",
      "6435/6435 [==============================] - 0s 38us/step - loss: 1.4114 - accuracy: 0.3708 - val_loss: 1.3810 - val_accuracy: 0.3939\n",
      "Epoch 51/80\n",
      "6435/6435 [==============================] - 0s 39us/step - loss: 1.4006 - accuracy: 0.3653 - val_loss: 1.3771 - val_accuracy: 0.3687\n",
      "Epoch 52/80\n",
      "6435/6435 [==============================] - 0s 35us/step - loss: 1.3915 - accuracy: 0.3681 - val_loss: 1.3702 - val_accuracy: 0.3603\n",
      "Epoch 53/80\n",
      "6435/6435 [==============================] - 0s 36us/step - loss: 1.3815 - accuracy: 0.3773 - val_loss: 1.3617 - val_accuracy: 0.3743\n",
      "Epoch 54/80\n",
      "6435/6435 [==============================] - 0s 38us/step - loss: 1.3680 - accuracy: 0.3759 - val_loss: 1.3557 - val_accuracy: 0.4134\n",
      "Epoch 55/80\n",
      "6435/6435 [==============================] - 0s 36us/step - loss: 1.3573 - accuracy: 0.3772 - val_loss: 1.3361 - val_accuracy: 0.3827\n",
      "Epoch 56/80\n",
      "6435/6435 [==============================] - 0s 37us/step - loss: 1.3451 - accuracy: 0.3835 - val_loss: 1.3172 - val_accuracy: 0.3994\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 57/80\n",
      "6435/6435 [==============================] - 0s 35us/step - loss: 1.3315 - accuracy: 0.3916 - val_loss: 1.3109 - val_accuracy: 0.3911\n",
      "Epoch 58/80\n",
      "6435/6435 [==============================] - 0s 36us/step - loss: 1.3225 - accuracy: 0.3967 - val_loss: 1.3113 - val_accuracy: 0.3673\n",
      "Epoch 59/80\n",
      "6435/6435 [==============================] - 0s 39us/step - loss: 1.3144 - accuracy: 0.3826 - val_loss: 1.3008 - val_accuracy: 0.3966\n",
      "Epoch 60/80\n",
      "6435/6435 [==============================] - 0s 36us/step - loss: 1.3076 - accuracy: 0.3887 - val_loss: 1.2962 - val_accuracy: 0.4036\n",
      "Epoch 61/80\n",
      "6435/6435 [==============================] - 0s 37us/step - loss: 1.3023 - accuracy: 0.3958 - val_loss: 1.2963 - val_accuracy: 0.3953\n",
      "Epoch 62/80\n",
      "6435/6435 [==============================] - 0s 38us/step - loss: 1.2957 - accuracy: 0.3893 - val_loss: 1.2864 - val_accuracy: 0.4120\n",
      "Epoch 63/80\n",
      "6435/6435 [==============================] - 0s 36us/step - loss: 1.2953 - accuracy: 0.3910 - val_loss: 1.2855 - val_accuracy: 0.3771\n",
      "Epoch 64/80\n",
      "6435/6435 [==============================] - 0s 37us/step - loss: 1.2893 - accuracy: 0.3941 - val_loss: 1.2788 - val_accuracy: 0.3980\n",
      "Epoch 65/80\n",
      "6435/6435 [==============================] - 0s 34us/step - loss: 1.2870 - accuracy: 0.3961 - val_loss: 1.2732 - val_accuracy: 0.4036\n",
      "Epoch 66/80\n",
      "6435/6435 [==============================] - 0s 38us/step - loss: 1.2830 - accuracy: 0.3927 - val_loss: 1.2778 - val_accuracy: 0.3897\n",
      "Epoch 67/80\n",
      "6435/6435 [==============================] - 0s 36us/step - loss: 1.2802 - accuracy: 0.3953 - val_loss: 1.2722 - val_accuracy: 0.3994\n",
      "Epoch 68/80\n",
      "6435/6435 [==============================] - 0s 38us/step - loss: 1.2781 - accuracy: 0.3905 - val_loss: 1.2789 - val_accuracy: 0.3757\n",
      "Epoch 69/80\n",
      "6435/6435 [==============================] - 0s 35us/step - loss: 1.2766 - accuracy: 0.3961 - val_loss: 1.2614 - val_accuracy: 0.3980\n",
      "Epoch 70/80\n",
      "6435/6435 [==============================] - 0s 37us/step - loss: 1.2716 - accuracy: 0.4036 - val_loss: 1.2652 - val_accuracy: 0.3855\n",
      "Epoch 71/80\n",
      "6435/6435 [==============================] - 0s 36us/step - loss: 1.2700 - accuracy: 0.3980 - val_loss: 1.2584 - val_accuracy: 0.4134\n",
      "Epoch 72/80\n",
      "6435/6435 [==============================] - 0s 34us/step - loss: 1.2689 - accuracy: 0.3974 - val_loss: 1.2583 - val_accuracy: 0.4050\n",
      "Epoch 73/80\n",
      "6435/6435 [==============================] - 0s 34us/step - loss: 1.2678 - accuracy: 0.3981 - val_loss: 1.2727 - val_accuracy: 0.4232\n",
      "Epoch 74/80\n",
      "6435/6435 [==============================] - 0s 34us/step - loss: 1.2668 - accuracy: 0.4014 - val_loss: 1.2592 - val_accuracy: 0.4050\n",
      "Epoch 75/80\n",
      "6435/6435 [==============================] - 0s 36us/step - loss: 1.2614 - accuracy: 0.4012 - val_loss: 1.2557 - val_accuracy: 0.4036\n",
      "Epoch 76/80\n",
      "6435/6435 [==============================] - 0s 36us/step - loss: 1.2597 - accuracy: 0.3977 - val_loss: 1.2497 - val_accuracy: 0.3994\n",
      "Epoch 77/80\n",
      "6435/6435 [==============================] - 0s 38us/step - loss: 1.2669 - accuracy: 0.4039 - val_loss: 1.2616 - val_accuracy: 0.3897\n",
      "Epoch 78/80\n",
      "6435/6435 [==============================] - 0s 37us/step - loss: 1.2578 - accuracy: 0.4050 - val_loss: 1.2339 - val_accuracy: 0.4274\n",
      "Epoch 79/80\n",
      "6435/6435 [==============================] - 0s 38us/step - loss: 1.2534 - accuracy: 0.4057 - val_loss: 1.2404 - val_accuracy: 0.4106\n",
      "Epoch 80/80\n",
      "6435/6435 [==============================] - 0s 37us/step - loss: 1.2539 - accuracy: 0.4031 - val_loss: 1.2335 - val_accuracy: 0.4232\n",
      "[[1.08647622e-01 1.05426282e-01 1.03491305e-13 ... 3.78706545e-01\n",
      "  1.72106251e-01 2.10580900e-01]\n",
      " [5.21329865e-02 3.47723156e-01 4.40903867e-21 ... 2.17007287e-03\n",
      "  3.77847464e-03 5.24090230e-03]\n",
      " [2.18632773e-01 1.84359983e-01 1.63357742e-16 ... 9.11627263e-02\n",
      "  2.24937677e-01 2.75709957e-01]\n",
      " ...\n",
      " [2.39667788e-01 1.91358745e-01 1.49740387e-17 ... 9.63450596e-03\n",
      "  2.48648643e-01 3.09549779e-01]\n",
      " [1.20673604e-01 1.20956026e-01 1.52302520e-12 ... 1.98400885e-01\n",
      "  2.33838141e-01 2.93885052e-01]\n",
      " [1.31366029e-01 1.26663402e-01 3.99757159e-13 ... 2.21591681e-01\n",
      "  2.20392168e-01 2.76811361e-01]]\n",
      "[11  1 13 ... 13 13 13]\n",
      "<class 'numpy.ndarray'>\n",
      "One CNN, r:  0\n",
      "Computing Time:  0:09:29.102441\n",
      "n, p1, p2 25 1 12\n",
      "Model: \"sequential_1\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv1d_1 (Conv1D)            (None, 3, 6)              12        \n",
      "_________________________________________________________________\n",
      "average_pooling1d_1 (Average (None, 1, 6)              0         \n",
      "_________________________________________________________________\n",
      "conv1d_2 (Conv1D)            (None, 1, 16)             112       \n",
      "_________________________________________________________________\n",
      "average_pooling1d_2 (Average (None, 1, 16)             0         \n",
      "_________________________________________________________________\n",
      "conv1d_3 (Conv1D)            (None, 1, 120)            2040      \n",
      "_________________________________________________________________\n",
      "flatten_1 (Flatten)          (None, 120)               0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 84)                10164     \n",
      "_________________________________________________________________\n",
      "preds (Dense)                (None, 14)                1190      \n",
      "=================================================================\n",
      "Total params: 13,518\n",
      "Trainable params: 13,518\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Train on 6435 samples, validate on 716 samples\n",
      "Epoch 1/80\n",
      "6435/6435 [==============================] - 0s 73us/step - loss: 2.6000 - accuracy: 0.1389 - val_loss: 2.5088 - val_accuracy: 0.1229\n",
      "Epoch 2/80\n",
      "6435/6435 [==============================] - 0s 46us/step - loss: 2.2741 - accuracy: 0.2326 - val_loss: 2.0209 - val_accuracy: 0.3059\n",
      "Epoch 3/80\n",
      "6435/6435 [==============================] - 0s 42us/step - loss: 1.8961 - accuracy: 0.3145 - val_loss: 1.7767 - val_accuracy: 0.3394\n",
      "Epoch 4/80\n",
      "6435/6435 [==============================] - 0s 41us/step - loss: 1.7271 - accuracy: 0.3354 - val_loss: 1.6590 - val_accuracy: 0.3296\n",
      "Epoch 5/80\n",
      "6435/6435 [==============================] - 0s 41us/step - loss: 1.6318 - accuracy: 0.3478 - val_loss: 1.5720 - val_accuracy: 0.3617\n",
      "Epoch 6/80\n",
      "6435/6435 [==============================] - 0s 44us/step - loss: 1.5608 - accuracy: 0.3489 - val_loss: 1.5209 - val_accuracy: 0.3534\n",
      "Epoch 7/80\n",
      "6435/6435 [==============================] - 0s 40us/step - loss: 1.5145 - accuracy: 0.3464 - val_loss: 1.4875 - val_accuracy: 0.3534\n",
      "Epoch 8/80\n",
      "6435/6435 [==============================] - 0s 36us/step - loss: 1.4942 - accuracy: 0.3574 - val_loss: 1.4786 - val_accuracy: 0.3226\n",
      "Epoch 9/80\n",
      "6435/6435 [==============================] - 0s 39us/step - loss: 1.4674 - accuracy: 0.3646 - val_loss: 1.4427 - val_accuracy: 0.3547\n",
      "Epoch 10/80\n",
      "6435/6435 [==============================] - 0s 39us/step - loss: 1.4565 - accuracy: 0.3596 - val_loss: 1.4323 - val_accuracy: 0.3478\n",
      "Epoch 11/80\n",
      "6435/6435 [==============================] - 0s 38us/step - loss: 1.4456 - accuracy: 0.3630 - val_loss: 1.4165 - val_accuracy: 0.3673\n",
      "Epoch 12/80\n",
      "6435/6435 [==============================] - 0s 37us/step - loss: 1.4357 - accuracy: 0.3643 - val_loss: 1.4037 - val_accuracy: 0.3520\n",
      "Epoch 13/80\n",
      "6435/6435 [==============================] - 0s 38us/step - loss: 1.4252 - accuracy: 0.3643 - val_loss: 1.4137 - val_accuracy: 0.3645\n",
      "Epoch 14/80\n",
      "6435/6435 [==============================] - 0s 37us/step - loss: 1.4237 - accuracy: 0.3616 - val_loss: 1.4117 - val_accuracy: 0.3561\n",
      "Epoch 15/80\n",
      "6435/6435 [==============================] - 0s 38us/step - loss: 1.4153 - accuracy: 0.3605 - val_loss: 1.3957 - val_accuracy: 0.3589\n",
      "Epoch 16/80\n",
      "6435/6435 [==============================] - 0s 41us/step - loss: 1.4089 - accuracy: 0.3647 - val_loss: 1.3986 - val_accuracy: 0.3547\n",
      "Epoch 17/80\n",
      "6435/6435 [==============================] - 0s 37us/step - loss: 1.4142 - accuracy: 0.3584 - val_loss: 1.3924 - val_accuracy: 0.3561\n",
      "Epoch 18/80\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6435/6435 [==============================] - 0s 35us/step - loss: 1.4101 - accuracy: 0.3585 - val_loss: 1.3911 - val_accuracy: 0.3506\n",
      "Epoch 19/80\n",
      "6435/6435 [==============================] - 0s 39us/step - loss: 1.4050 - accuracy: 0.3619 - val_loss: 1.3901 - val_accuracy: 0.3534\n",
      "Epoch 20/80\n",
      "6435/6435 [==============================] - 0s 40us/step - loss: 1.4077 - accuracy: 0.3543 - val_loss: 1.3785 - val_accuracy: 0.3617\n",
      "Epoch 21/80\n",
      "6435/6435 [==============================] - 0s 37us/step - loss: 1.3976 - accuracy: 0.3650 - val_loss: 1.3700 - val_accuracy: 0.3520\n",
      "Epoch 22/80\n",
      "6435/6435 [==============================] - 0s 38us/step - loss: 1.3982 - accuracy: 0.3675 - val_loss: 1.3753 - val_accuracy: 0.3184\n",
      "Epoch 23/80\n",
      "6435/6435 [==============================] - 0s 35us/step - loss: 1.3981 - accuracy: 0.3557 - val_loss: 1.3859 - val_accuracy: 0.3534\n",
      "Epoch 24/80\n",
      "6435/6435 [==============================] - 0s 42us/step - loss: 1.3953 - accuracy: 0.3633 - val_loss: 1.3897 - val_accuracy: 0.3492\n",
      "Epoch 25/80\n",
      "6435/6435 [==============================] - 0s 42us/step - loss: 1.3965 - accuracy: 0.3562 - val_loss: 1.3709 - val_accuracy: 0.3575\n",
      "Epoch 26/80\n",
      "6435/6435 [==============================] - 0s 39us/step - loss: 1.3990 - accuracy: 0.3548 - val_loss: 1.3846 - val_accuracy: 0.3520\n",
      "Epoch 27/80\n",
      "6435/6435 [==============================] - 0s 38us/step - loss: 1.3951 - accuracy: 0.3587 - val_loss: 1.3658 - val_accuracy: 0.3422\n",
      "Epoch 28/80\n",
      "6435/6435 [==============================] - 0s 37us/step - loss: 1.3915 - accuracy: 0.3571 - val_loss: 1.3656 - val_accuracy: 0.3547\n",
      "Epoch 29/80\n",
      "6435/6435 [==============================] - 0s 36us/step - loss: 1.3937 - accuracy: 0.3605 - val_loss: 1.3680 - val_accuracy: 0.3575\n",
      "Epoch 30/80\n",
      "6435/6435 [==============================] - 0s 37us/step - loss: 1.3937 - accuracy: 0.3549 - val_loss: 1.3617 - val_accuracy: 0.3715\n",
      "Epoch 31/80\n",
      "6435/6435 [==============================] - 0s 38us/step - loss: 1.3846 - accuracy: 0.3607 - val_loss: 1.3688 - val_accuracy: 0.3352\n",
      "Epoch 32/80\n",
      "6435/6435 [==============================] - 0s 40us/step - loss: 1.3876 - accuracy: 0.3548 - val_loss: 1.3754 - val_accuracy: 0.3575\n",
      "Epoch 33/80\n",
      "6435/6435 [==============================] - 0s 36us/step - loss: 1.3865 - accuracy: 0.3570 - val_loss: 1.3560 - val_accuracy: 0.3492\n",
      "Epoch 34/80\n",
      "6435/6435 [==============================] - 0s 35us/step - loss: 1.3907 - accuracy: 0.3661 - val_loss: 1.3702 - val_accuracy: 0.3645\n",
      "Epoch 35/80\n",
      "6435/6435 [==============================] - 0s 42us/step - loss: 1.3855 - accuracy: 0.3621 - val_loss: 1.3612 - val_accuracy: 0.3561\n",
      "Epoch 36/80\n",
      "6435/6435 [==============================] - 0s 39us/step - loss: 1.3833 - accuracy: 0.3521 - val_loss: 1.3613 - val_accuracy: 0.3575\n",
      "Epoch 37/80\n",
      "6435/6435 [==============================] - 0s 39us/step - loss: 1.3809 - accuracy: 0.3604 - val_loss: 1.3674 - val_accuracy: 0.3631\n",
      "Epoch 38/80\n",
      "6435/6435 [==============================] - 0s 38us/step - loss: 1.3820 - accuracy: 0.3571 - val_loss: 1.3544 - val_accuracy: 0.3450\n",
      "Epoch 39/80\n",
      "6435/6435 [==============================] - 0s 38us/step - loss: 1.3791 - accuracy: 0.3616 - val_loss: 1.3571 - val_accuracy: 0.3631\n",
      "Epoch 40/80\n",
      "6435/6435 [==============================] - 0s 39us/step - loss: 1.3767 - accuracy: 0.3644 - val_loss: 1.3603 - val_accuracy: 0.3394\n",
      "Epoch 41/80\n",
      "6435/6435 [==============================] - 0s 39us/step - loss: 1.3792 - accuracy: 0.3601 - val_loss: 1.3589 - val_accuracy: 0.3631\n",
      "Epoch 42/80\n",
      "6435/6435 [==============================] - 0s 36us/step - loss: 1.3831 - accuracy: 0.3610 - val_loss: 1.4150 - val_accuracy: 0.3436\n",
      "Epoch 43/80\n",
      "6435/6435 [==============================] - 0s 39us/step - loss: 1.3871 - accuracy: 0.3608 - val_loss: 1.3544 - val_accuracy: 0.3771\n",
      "Epoch 44/80\n",
      "6435/6435 [==============================] - 0s 39us/step - loss: 1.3783 - accuracy: 0.3577 - val_loss: 1.3644 - val_accuracy: 0.3561\n",
      "Epoch 45/80\n",
      "6435/6435 [==============================] - 0s 36us/step - loss: 1.3759 - accuracy: 0.3671 - val_loss: 1.3545 - val_accuracy: 0.3589\n",
      "Epoch 46/80\n",
      "6435/6435 [==============================] - 0s 34us/step - loss: 1.3751 - accuracy: 0.3560 - val_loss: 1.3561 - val_accuracy: 0.3296\n",
      "Epoch 47/80\n",
      "6435/6435 [==============================] - 0s 36us/step - loss: 1.3770 - accuracy: 0.3607 - val_loss: 1.3612 - val_accuracy: 0.3520\n",
      "Epoch 48/80\n",
      "6435/6435 [==============================] - 0s 39us/step - loss: 1.3709 - accuracy: 0.3638 - val_loss: 1.3564 - val_accuracy: 0.3352\n",
      "Epoch 00048: early stopping\n",
      "[[2.0618294e-01 3.1087393e-01 1.1051203e-11 ... 4.4856864e-05\n",
      "  2.3015648e-01 2.2739781e-01]\n",
      " [3.5628423e-02 3.3946317e-02 3.2545700e-16 ... 2.6571044e-01\n",
      "  1.1464550e-02 1.4130003e-02]\n",
      " [2.1105824e-01 3.4973890e-01 4.6516420e-13 ... 8.1493222e-04\n",
      "  2.0979105e-01 2.1216531e-01]\n",
      " ...\n",
      " [2.1347257e-01 3.4818062e-01 4.0251599e-13 ... 7.0301851e-04\n",
      "  2.1021466e-01 2.1205074e-01]\n",
      " [1.9410047e-01 2.5454021e-01 8.8398594e-11 ... 8.0060108e-06\n",
      "  2.4227901e-01 2.4667124e-01]\n",
      " [2.0083322e-01 2.7767968e-01 3.6926007e-11 ... 1.5962934e-05\n",
      "  2.3916875e-01 2.4053358e-01]]\n",
      "[1 5 1 ... 1 1 1]\n",
      "<class 'numpy.ndarray'>\n",
      "One CNN, r:  0\n",
      "Computing Time:  0:09:42.611129\n",
      "n, p1, p2 26 1 13\n",
      "Model: \"sequential_1\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv1d_1 (Conv1D)            (None, 3, 6)              12        \n",
      "_________________________________________________________________\n",
      "average_pooling1d_1 (Average (None, 1, 6)              0         \n",
      "_________________________________________________________________\n",
      "conv1d_2 (Conv1D)            (None, 1, 16)             112       \n",
      "_________________________________________________________________\n",
      "average_pooling1d_2 (Average (None, 1, 16)             0         \n",
      "_________________________________________________________________\n",
      "conv1d_3 (Conv1D)            (None, 1, 120)            2040      \n",
      "_________________________________________________________________\n",
      "flatten_1 (Flatten)          (None, 120)               0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 84)                10164     \n",
      "_________________________________________________________________\n",
      "preds (Dense)                (None, 14)                1190      \n",
      "=================================================================\n",
      "Total params: 13,518\n",
      "Trainable params: 13,518\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Train on 6435 samples, validate on 716 samples\n",
      "Epoch 1/80\n",
      "6435/6435 [==============================] - 0s 73us/step - loss: 2.5917 - accuracy: 0.1397 - val_loss: 2.4765 - val_accuracy: 0.2025\n",
      "Epoch 2/80\n",
      "6435/6435 [==============================] - 0s 41us/step - loss: 2.2829 - accuracy: 0.2103 - val_loss: 2.0397 - val_accuracy: 0.3240\n",
      "Epoch 3/80\n",
      "6435/6435 [==============================] - 0s 39us/step - loss: 1.9623 - accuracy: 0.3004 - val_loss: 1.8305 - val_accuracy: 0.3520\n",
      "Epoch 4/80\n",
      "6435/6435 [==============================] - 0s 34us/step - loss: 1.8089 - accuracy: 0.3259 - val_loss: 1.7074 - val_accuracy: 0.3715\n",
      "Epoch 5/80\n",
      "6435/6435 [==============================] - 0s 36us/step - loss: 1.7129 - accuracy: 0.3315 - val_loss: 1.6355 - val_accuracy: 0.3506\n",
      "Epoch 6/80\n",
      "6435/6435 [==============================] - 0s 39us/step - loss: 1.6282 - accuracy: 0.3445 - val_loss: 1.5908 - val_accuracy: 0.3673\n",
      "Epoch 7/80\n",
      "6435/6435 [==============================] - 0s 39us/step - loss: 1.5678 - accuracy: 0.3469 - val_loss: 1.5084 - val_accuracy: 0.3799\n",
      "Epoch 8/80\n",
      "6435/6435 [==============================] - 0s 39us/step - loss: 1.5201 - accuracy: 0.3487 - val_loss: 1.4768 - val_accuracy: 0.3841\n",
      "Epoch 9/80\n",
      "6435/6435 [==============================] - 0s 38us/step - loss: 1.4899 - accuracy: 0.3520 - val_loss: 1.4671 - val_accuracy: 0.3617\n",
      "Epoch 10/80\n",
      "6435/6435 [==============================] - 0s 36us/step - loss: 1.4664 - accuracy: 0.3557 - val_loss: 1.4567 - val_accuracy: 0.3547\n",
      "Epoch 11/80\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6435/6435 [==============================] - 0s 39us/step - loss: 1.4523 - accuracy: 0.3594 - val_loss: 1.4488 - val_accuracy: 0.3827\n",
      "Epoch 12/80\n",
      "6435/6435 [==============================] - 0s 39us/step - loss: 1.4439 - accuracy: 0.3552 - val_loss: 1.4245 - val_accuracy: 0.3771\n",
      "Epoch 13/80\n",
      "6435/6435 [==============================] - 0s 38us/step - loss: 1.4392 - accuracy: 0.3531 - val_loss: 1.4170 - val_accuracy: 0.3883\n",
      "Epoch 14/80\n",
      "6435/6435 [==============================] - 0s 37us/step - loss: 1.4317 - accuracy: 0.3509 - val_loss: 1.4269 - val_accuracy: 0.3534\n",
      "Epoch 15/80\n",
      "6435/6435 [==============================] - 0s 36us/step - loss: 1.4315 - accuracy: 0.3524 - val_loss: 1.4307 - val_accuracy: 0.3673\n",
      "Epoch 16/80\n",
      "6435/6435 [==============================] - 0s 36us/step - loss: 1.4264 - accuracy: 0.3556 - val_loss: 1.4218 - val_accuracy: 0.3673\n",
      "Epoch 17/80\n",
      "6435/6435 [==============================] - 0s 44us/step - loss: 1.4148 - accuracy: 0.3611 - val_loss: 1.4079 - val_accuracy: 0.3589\n",
      "Epoch 18/80\n",
      "6435/6435 [==============================] - 0s 40us/step - loss: 1.4145 - accuracy: 0.3610 - val_loss: 1.4290 - val_accuracy: 0.3897\n",
      "Epoch 19/80\n",
      "6435/6435 [==============================] - 0s 37us/step - loss: 1.4145 - accuracy: 0.3594 - val_loss: 1.4070 - val_accuracy: 0.3631\n",
      "Epoch 20/80\n",
      "6435/6435 [==============================] - 0s 39us/step - loss: 1.4070 - accuracy: 0.3691 - val_loss: 1.4050 - val_accuracy: 0.3883\n",
      "Epoch 21/80\n",
      "6435/6435 [==============================] - 0s 37us/step - loss: 1.4027 - accuracy: 0.3593 - val_loss: 1.4161 - val_accuracy: 0.3422\n",
      "Epoch 22/80\n",
      "6435/6435 [==============================] - 0s 36us/step - loss: 1.4043 - accuracy: 0.3636 - val_loss: 1.3876 - val_accuracy: 0.3925\n",
      "Epoch 23/80\n",
      "6435/6435 [==============================] - 0s 38us/step - loss: 1.3994 - accuracy: 0.3686 - val_loss: 1.3828 - val_accuracy: 0.3953\n",
      "Epoch 24/80\n",
      "6435/6435 [==============================] - 0s 41us/step - loss: 1.4048 - accuracy: 0.3680 - val_loss: 1.3875 - val_accuracy: 0.3813\n",
      "Epoch 25/80\n",
      "6435/6435 [==============================] - 0s 37us/step - loss: 1.3966 - accuracy: 0.3627 - val_loss: 1.3931 - val_accuracy: 0.3966\n",
      "Epoch 26/80\n",
      "6435/6435 [==============================] - 0s 39us/step - loss: 1.3932 - accuracy: 0.3643 - val_loss: 1.3923 - val_accuracy: 0.3701\n",
      "Epoch 27/80\n",
      "6435/6435 [==============================] - 0s 41us/step - loss: 1.3906 - accuracy: 0.3672 - val_loss: 1.3756 - val_accuracy: 0.4050\n",
      "Epoch 28/80\n",
      "6435/6435 [==============================] - 0s 38us/step - loss: 1.3890 - accuracy: 0.3726 - val_loss: 1.3994 - val_accuracy: 0.3603\n",
      "Epoch 29/80\n",
      "6435/6435 [==============================] - 0s 39us/step - loss: 1.3924 - accuracy: 0.3681 - val_loss: 1.4083 - val_accuracy: 0.3380\n",
      "Epoch 30/80\n",
      "6435/6435 [==============================] - 0s 44us/step - loss: 1.3893 - accuracy: 0.3605 - val_loss: 1.4015 - val_accuracy: 0.3687\n",
      "Epoch 31/80\n",
      "6435/6435 [==============================] - 0s 38us/step - loss: 1.3867 - accuracy: 0.3725 - val_loss: 1.4043 - val_accuracy: 0.3715\n",
      "Epoch 32/80\n",
      "6435/6435 [==============================] - 0s 37us/step - loss: 1.3922 - accuracy: 0.3705 - val_loss: 1.3977 - val_accuracy: 0.3422\n",
      "Epoch 33/80\n",
      "6435/6435 [==============================] - 0s 41us/step - loss: 1.3848 - accuracy: 0.3730 - val_loss: 1.3699 - val_accuracy: 0.3939\n",
      "Epoch 34/80\n",
      "6435/6435 [==============================] - 0s 36us/step - loss: 1.3820 - accuracy: 0.3694 - val_loss: 1.3797 - val_accuracy: 0.3953\n",
      "Epoch 35/80\n",
      "6435/6435 [==============================] - 0s 39us/step - loss: 1.3822 - accuracy: 0.3660 - val_loss: 1.3598 - val_accuracy: 0.3953\n",
      "Epoch 36/80\n",
      "6435/6435 [==============================] - 0s 39us/step - loss: 1.3804 - accuracy: 0.3625 - val_loss: 1.3811 - val_accuracy: 0.3506\n",
      "Epoch 37/80\n",
      "6435/6435 [==============================] - 0s 36us/step - loss: 1.3735 - accuracy: 0.3750 - val_loss: 1.3756 - val_accuracy: 0.4078\n",
      "Epoch 38/80\n",
      "6435/6435 [==============================] - 0s 40us/step - loss: 1.3766 - accuracy: 0.3772 - val_loss: 1.3701 - val_accuracy: 0.3897\n",
      "Epoch 39/80\n",
      "6435/6435 [==============================] - 0s 41us/step - loss: 1.3747 - accuracy: 0.3737 - val_loss: 1.3529 - val_accuracy: 0.4120\n",
      "Epoch 40/80\n",
      "6435/6435 [==============================] - 0s 39us/step - loss: 1.3726 - accuracy: 0.3754 - val_loss: 1.3547 - val_accuracy: 0.4078\n",
      "Epoch 41/80\n",
      "6435/6435 [==============================] - 0s 37us/step - loss: 1.3711 - accuracy: 0.3801 - val_loss: 1.3545 - val_accuracy: 0.4176\n",
      "Epoch 42/80\n",
      "6435/6435 [==============================] - 0s 37us/step - loss: 1.3711 - accuracy: 0.3787 - val_loss: 1.3578 - val_accuracy: 0.3827\n",
      "Epoch 43/80\n",
      "6435/6435 [==============================] - 0s 36us/step - loss: 1.3640 - accuracy: 0.3737 - val_loss: 1.3605 - val_accuracy: 0.3813\n",
      "Epoch 44/80\n",
      "6435/6435 [==============================] - 0s 38us/step - loss: 1.3643 - accuracy: 0.3745 - val_loss: 1.3785 - val_accuracy: 0.3631\n",
      "Epoch 45/80\n",
      "6435/6435 [==============================] - 0s 33us/step - loss: 1.3631 - accuracy: 0.3784 - val_loss: 1.3705 - val_accuracy: 0.3785\n",
      "Epoch 46/80\n",
      "6435/6435 [==============================] - 0s 35us/step - loss: 1.3627 - accuracy: 0.3770 - val_loss: 1.3564 - val_accuracy: 0.4134\n",
      "Epoch 47/80\n",
      "6435/6435 [==============================] - 0s 34us/step - loss: 1.3606 - accuracy: 0.3765 - val_loss: 1.3503 - val_accuracy: 0.3911\n",
      "Epoch 48/80\n",
      "6435/6435 [==============================] - 0s 39us/step - loss: 1.3592 - accuracy: 0.3756 - val_loss: 1.3530 - val_accuracy: 0.4106\n",
      "Epoch 49/80\n",
      "6435/6435 [==============================] - 0s 36us/step - loss: 1.3557 - accuracy: 0.3828 - val_loss: 1.3414 - val_accuracy: 0.4022\n",
      "Epoch 50/80\n",
      "6435/6435 [==============================] - 0s 36us/step - loss: 1.3562 - accuracy: 0.3820 - val_loss: 1.3452 - val_accuracy: 0.4134\n",
      "Epoch 51/80\n",
      "6435/6435 [==============================] - 0s 36us/step - loss: 1.3474 - accuracy: 0.3947 - val_loss: 1.3383 - val_accuracy: 0.4008\n",
      "Epoch 52/80\n",
      "6435/6435 [==============================] - 0s 34us/step - loss: 1.3456 - accuracy: 0.3904 - val_loss: 1.3260 - val_accuracy: 0.4036\n",
      "Epoch 53/80\n",
      "6435/6435 [==============================] - 0s 39us/step - loss: 1.3400 - accuracy: 0.3988 - val_loss: 1.3376 - val_accuracy: 0.4078\n",
      "Epoch 54/80\n",
      "6435/6435 [==============================] - 0s 41us/step - loss: 1.3393 - accuracy: 0.3918 - val_loss: 1.3203 - val_accuracy: 0.4288\n",
      "Epoch 55/80\n",
      "6435/6435 [==============================] - 0s 34us/step - loss: 1.3303 - accuracy: 0.3992 - val_loss: 1.3186 - val_accuracy: 0.4162\n",
      "Epoch 56/80\n",
      "6435/6435 [==============================] - 0s 44us/step - loss: 1.3246 - accuracy: 0.3975 - val_loss: 1.3257 - val_accuracy: 0.3841\n",
      "Epoch 57/80\n",
      "6435/6435 [==============================] - 0s 36us/step - loss: 1.3155 - accuracy: 0.3988 - val_loss: 1.2933 - val_accuracy: 0.4232\n",
      "Epoch 58/80\n",
      "6435/6435 [==============================] - 0s 41us/step - loss: 1.3074 - accuracy: 0.4061 - val_loss: 1.2878 - val_accuracy: 0.4288\n",
      "Epoch 59/80\n",
      "6435/6435 [==============================] - 0s 35us/step - loss: 1.2948 - accuracy: 0.4079 - val_loss: 1.3013 - val_accuracy: 0.4176\n",
      "Epoch 60/80\n",
      "6435/6435 [==============================] - 0s 37us/step - loss: 1.2929 - accuracy: 0.4048 - val_loss: 1.2502 - val_accuracy: 0.4581\n",
      "Epoch 61/80\n",
      "6435/6435 [==============================] - 0s 39us/step - loss: 1.2739 - accuracy: 0.4246 - val_loss: 1.2407 - val_accuracy: 0.4246\n",
      "Epoch 62/80\n",
      "6435/6435 [==============================] - 0s 36us/step - loss: 1.2655 - accuracy: 0.4204 - val_loss: 1.2289 - val_accuracy: 0.4302\n",
      "Epoch 63/80\n",
      "6435/6435 [==============================] - 0s 40us/step - loss: 1.2521 - accuracy: 0.4275 - val_loss: 1.2233 - val_accuracy: 0.4344\n",
      "Epoch 64/80\n",
      "6435/6435 [==============================] - 0s 39us/step - loss: 1.2423 - accuracy: 0.4207 - val_loss: 1.2021 - val_accuracy: 0.4385\n",
      "Epoch 65/80\n",
      "6435/6435 [==============================] - 0s 38us/step - loss: 1.2360 - accuracy: 0.4281 - val_loss: 1.1842 - val_accuracy: 0.4721\n",
      "Epoch 66/80\n",
      "6435/6435 [==============================] - 0s 40us/step - loss: 1.2239 - accuracy: 0.4213 - val_loss: 1.1761 - val_accuracy: 0.4567\n",
      "Epoch 67/80\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6435/6435 [==============================] - 0s 36us/step - loss: 1.2130 - accuracy: 0.4242 - val_loss: 1.1820 - val_accuracy: 0.4316\n",
      "Epoch 68/80\n",
      "6435/6435 [==============================] - 0s 38us/step - loss: 1.2075 - accuracy: 0.4284 - val_loss: 1.1586 - val_accuracy: 0.4721\n",
      "Epoch 69/80\n",
      "6435/6435 [==============================] - 0s 37us/step - loss: 1.2027 - accuracy: 0.4345 - val_loss: 1.1700 - val_accuracy: 0.4469\n",
      "Epoch 70/80\n",
      "6435/6435 [==============================] - 0s 39us/step - loss: 1.1986 - accuracy: 0.4275 - val_loss: 1.1571 - val_accuracy: 0.4665\n",
      "Epoch 71/80\n",
      "6435/6435 [==============================] - 0s 39us/step - loss: 1.1983 - accuracy: 0.4291 - val_loss: 1.1517 - val_accuracy: 0.4539\n",
      "Epoch 72/80\n",
      "6435/6435 [==============================] - 0s 39us/step - loss: 1.1930 - accuracy: 0.4353 - val_loss: 1.1441 - val_accuracy: 0.4763\n",
      "Epoch 73/80\n",
      "6435/6435 [==============================] - 0s 39us/step - loss: 1.1906 - accuracy: 0.4308 - val_loss: 1.1658 - val_accuracy: 0.4413\n",
      "Epoch 74/80\n",
      "6435/6435 [==============================] - 0s 39us/step - loss: 1.1902 - accuracy: 0.4340 - val_loss: 1.1494 - val_accuracy: 0.4693\n",
      "Epoch 75/80\n",
      "6435/6435 [==============================] - 0s 39us/step - loss: 1.1851 - accuracy: 0.4328 - val_loss: 1.1522 - val_accuracy: 0.4595\n",
      "Epoch 76/80\n",
      "6435/6435 [==============================] - 0s 41us/step - loss: 1.1854 - accuracy: 0.4334 - val_loss: 1.1479 - val_accuracy: 0.4609\n",
      "Epoch 77/80\n",
      "6435/6435 [==============================] - 0s 39us/step - loss: 1.1835 - accuracy: 0.4337 - val_loss: 1.1572 - val_accuracy: 0.4609\n",
      "Epoch 78/80\n",
      "6435/6435 [==============================] - 0s 35us/step - loss: 1.1826 - accuracy: 0.4287 - val_loss: 1.1449 - val_accuracy: 0.4749\n",
      "Epoch 79/80\n",
      "6435/6435 [==============================] - 0s 37us/step - loss: 1.1817 - accuracy: 0.4284 - val_loss: 1.1411 - val_accuracy: 0.4497\n",
      "Epoch 80/80\n",
      "6435/6435 [==============================] - 0s 35us/step - loss: 1.1816 - accuracy: 0.4244 - val_loss: 1.1399 - val_accuracy: 0.4581\n",
      "[[1.12746887e-01 2.94661552e-01 5.93674009e-14 ... 1.00161604e-04\n",
      "  3.75034839e-01 1.93468466e-01]\n",
      " [3.01355571e-02 4.03805301e-02 1.21521112e-20 ... 3.06954086e-01\n",
      "  2.39043310e-03 6.11455413e-03]\n",
      " [1.80427834e-01 4.50423688e-01 4.72986043e-17 ... 6.27033296e-04\n",
      "  7.66728222e-02 2.88646370e-01]\n",
      " ...\n",
      " [1.99559808e-01 4.96216178e-01 1.42722425e-18 ... 2.09245089e-04\n",
      "  9.81245562e-03 2.93642759e-01]\n",
      " [1.14965737e-01 3.68320495e-01 4.99711817e-13 ... 8.71084740e-06\n",
      "  1.86023638e-01 2.99707413e-01]\n",
      " [1.24887936e-01 3.70246947e-01 1.24361310e-13 ... 2.01477978e-05\n",
      "  2.05365106e-01 2.79168040e-01]]\n",
      "[12  5  1 ...  1  1  1]\n",
      "<class 'numpy.ndarray'>\n",
      "One CNN, r:  0\n",
      "Computing Time:  0:10:03.986641\n",
      "n, p1, p2 27 1 14\n",
      "Model: \"sequential_1\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv1d_1 (Conv1D)            (None, 3, 6)              12        \n",
      "_________________________________________________________________\n",
      "average_pooling1d_1 (Average (None, 1, 6)              0         \n",
      "_________________________________________________________________\n",
      "conv1d_2 (Conv1D)            (None, 1, 16)             112       \n",
      "_________________________________________________________________\n",
      "average_pooling1d_2 (Average (None, 1, 16)             0         \n",
      "_________________________________________________________________\n",
      "conv1d_3 (Conv1D)            (None, 1, 120)            2040      \n",
      "_________________________________________________________________\n",
      "flatten_1 (Flatten)          (None, 120)               0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 84)                10164     \n",
      "_________________________________________________________________\n",
      "preds (Dense)                (None, 14)                1190      \n",
      "=================================================================\n",
      "Total params: 13,518\n",
      "Trainable params: 13,518\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Train on 6435 samples, validate on 716 samples\n",
      "Epoch 1/80\n",
      "6435/6435 [==============================] - 0s 71us/step - loss: 2.5708 - accuracy: 0.1498 - val_loss: 2.4235 - val_accuracy: 0.2011\n",
      "Epoch 2/80\n",
      "6435/6435 [==============================] - 0s 42us/step - loss: 2.1867 - accuracy: 0.2479 - val_loss: 1.9641 - val_accuracy: 0.3059\n",
      "Epoch 3/80\n",
      "6435/6435 [==============================] - 0s 39us/step - loss: 1.8784 - accuracy: 0.3122 - val_loss: 1.7566 - val_accuracy: 0.3045\n",
      "Epoch 4/80\n",
      "6435/6435 [==============================] - 0s 36us/step - loss: 1.7307 - accuracy: 0.3349 - val_loss: 1.6518 - val_accuracy: 0.3394\n",
      "Epoch 5/80\n",
      "6435/6435 [==============================] - 0s 35us/step - loss: 1.6304 - accuracy: 0.3395 - val_loss: 1.5843 - val_accuracy: 0.3142\n",
      "Epoch 6/80\n",
      "6435/6435 [==============================] - 0s 36us/step - loss: 1.5656 - accuracy: 0.3428 - val_loss: 1.5078 - val_accuracy: 0.3617\n",
      "Epoch 7/80\n",
      "6435/6435 [==============================] - 0s 36us/step - loss: 1.5162 - accuracy: 0.3542 - val_loss: 1.4787 - val_accuracy: 0.3310\n",
      "Epoch 8/80\n",
      "6435/6435 [==============================] - 0s 36us/step - loss: 1.4879 - accuracy: 0.3473 - val_loss: 1.4582 - val_accuracy: 0.3729\n",
      "Epoch 9/80\n",
      "6435/6435 [==============================] - 0s 36us/step - loss: 1.4724 - accuracy: 0.3548 - val_loss: 1.4466 - val_accuracy: 0.3170\n",
      "Epoch 10/80\n",
      "6435/6435 [==============================] - 0s 36us/step - loss: 1.4621 - accuracy: 0.3549 - val_loss: 1.4590 - val_accuracy: 0.3296\n",
      "Epoch 11/80\n",
      "6435/6435 [==============================] - 0s 36us/step - loss: 1.4488 - accuracy: 0.3512 - val_loss: 1.4145 - val_accuracy: 0.3617\n",
      "Epoch 12/80\n",
      "6435/6435 [==============================] - 0s 39us/step - loss: 1.4368 - accuracy: 0.3529 - val_loss: 1.4399 - val_accuracy: 0.3520\n",
      "Epoch 13/80\n",
      "6435/6435 [==============================] - 0s 36us/step - loss: 1.4376 - accuracy: 0.3587 - val_loss: 1.4254 - val_accuracy: 0.3338\n",
      "Epoch 14/80\n",
      "6435/6435 [==============================] - 0s 39us/step - loss: 1.4291 - accuracy: 0.3559 - val_loss: 1.4185 - val_accuracy: 0.3450\n",
      "Epoch 15/80\n",
      "6435/6435 [==============================] - 0s 39us/step - loss: 1.4291 - accuracy: 0.3641 - val_loss: 1.4050 - val_accuracy: 0.3436\n",
      "Epoch 16/80\n",
      "6435/6435 [==============================] - 0s 36us/step - loss: 1.4178 - accuracy: 0.3616 - val_loss: 1.4001 - val_accuracy: 0.3785\n",
      "Epoch 17/80\n",
      "6435/6435 [==============================] - 0s 48us/step - loss: 1.4181 - accuracy: 0.3650 - val_loss: 1.3995 - val_accuracy: 0.3799\n",
      "Epoch 18/80\n",
      "6435/6435 [==============================] - 0s 44us/step - loss: 1.4184 - accuracy: 0.3565 - val_loss: 1.4043 - val_accuracy: 0.3492\n",
      "Epoch 19/80\n",
      "6435/6435 [==============================] - 0s 36us/step - loss: 1.4112 - accuracy: 0.3587 - val_loss: 1.3890 - val_accuracy: 0.3813\n",
      "Epoch 20/80\n",
      "6435/6435 [==============================] - 0s 41us/step - loss: 1.4106 - accuracy: 0.3523 - val_loss: 1.3933 - val_accuracy: 0.3394\n",
      "Epoch 21/80\n",
      "6435/6435 [==============================] - 0s 41us/step - loss: 1.4166 - accuracy: 0.3588 - val_loss: 1.4038 - val_accuracy: 0.3408\n",
      "Epoch 22/80\n",
      "6435/6435 [==============================] - 0s 37us/step - loss: 1.4035 - accuracy: 0.3638 - val_loss: 1.4092 - val_accuracy: 0.3338\n",
      "Epoch 23/80\n",
      "6435/6435 [==============================] - 0s 34us/step - loss: 1.3999 - accuracy: 0.3604 - val_loss: 1.4226 - val_accuracy: 0.3408\n",
      "Epoch 24/80\n",
      "6435/6435 [==============================] - 0s 36us/step - loss: 1.3994 - accuracy: 0.3643 - val_loss: 1.3847 - val_accuracy: 0.3855\n",
      "Epoch 25/80\n",
      "6435/6435 [==============================] - 0s 37us/step - loss: 1.3989 - accuracy: 0.3627 - val_loss: 1.3812 - val_accuracy: 0.3813\n",
      "Epoch 26/80\n",
      "6435/6435 [==============================] - 0s 36us/step - loss: 1.3964 - accuracy: 0.3650 - val_loss: 1.4092 - val_accuracy: 0.3492\n",
      "Epoch 27/80\n",
      "6435/6435 [==============================] - 0s 37us/step - loss: 1.3967 - accuracy: 0.3691 - val_loss: 1.3880 - val_accuracy: 0.3464\n",
      "Epoch 28/80\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6435/6435 [==============================] - 0s 39us/step - loss: 1.3939 - accuracy: 0.3655 - val_loss: 1.3851 - val_accuracy: 0.3575\n",
      "Epoch 29/80\n",
      "6435/6435 [==============================] - 0s 35us/step - loss: 1.3961 - accuracy: 0.3658 - val_loss: 1.3856 - val_accuracy: 0.3436\n",
      "Epoch 30/80\n",
      "6435/6435 [==============================] - 0s 38us/step - loss: 1.3896 - accuracy: 0.3629 - val_loss: 1.3806 - val_accuracy: 0.3673\n",
      "Epoch 31/80\n",
      "6435/6435 [==============================] - 0s 37us/step - loss: 1.3865 - accuracy: 0.3625 - val_loss: 1.3828 - val_accuracy: 0.3394\n",
      "Epoch 32/80\n",
      "6435/6435 [==============================] - 0s 36us/step - loss: 1.3842 - accuracy: 0.3686 - val_loss: 1.3926 - val_accuracy: 0.3757\n",
      "Epoch 33/80\n",
      "6435/6435 [==============================] - 0s 36us/step - loss: 1.3820 - accuracy: 0.3647 - val_loss: 1.3907 - val_accuracy: 0.3841\n",
      "Epoch 34/80\n",
      "6435/6435 [==============================] - 0s 36us/step - loss: 1.3866 - accuracy: 0.3699 - val_loss: 1.3818 - val_accuracy: 0.3994\n",
      "Epoch 35/80\n",
      "6435/6435 [==============================] - 0s 39us/step - loss: 1.3880 - accuracy: 0.3652 - val_loss: 1.3756 - val_accuracy: 0.3799\n",
      "Epoch 36/80\n",
      "6435/6435 [==============================] - 0s 39us/step - loss: 1.3787 - accuracy: 0.3809 - val_loss: 1.3807 - val_accuracy: 0.3813\n",
      "Epoch 37/80\n",
      "6435/6435 [==============================] - 0s 36us/step - loss: 1.3787 - accuracy: 0.3672 - val_loss: 1.3765 - val_accuracy: 0.4120\n",
      "Epoch 38/80\n",
      "6435/6435 [==============================] - 0s 36us/step - loss: 1.3763 - accuracy: 0.3750 - val_loss: 1.3682 - val_accuracy: 0.3799\n",
      "Epoch 39/80\n",
      "6435/6435 [==============================] - 0s 40us/step - loss: 1.3727 - accuracy: 0.3675 - val_loss: 1.3975 - val_accuracy: 0.3575\n",
      "Epoch 40/80\n",
      "6435/6435 [==============================] - 0s 42us/step - loss: 1.3757 - accuracy: 0.3722 - val_loss: 1.3714 - val_accuracy: 0.3338\n",
      "Epoch 41/80\n",
      "6435/6435 [==============================] - 0s 39us/step - loss: 1.3711 - accuracy: 0.3663 - val_loss: 1.3810 - val_accuracy: 0.3422\n",
      "Epoch 42/80\n",
      "6435/6435 [==============================] - 0s 40us/step - loss: 1.3681 - accuracy: 0.3772 - val_loss: 1.3827 - val_accuracy: 0.3617\n",
      "Epoch 43/80\n",
      "6435/6435 [==============================] - 0s 39us/step - loss: 1.3678 - accuracy: 0.3674 - val_loss: 1.3833 - val_accuracy: 0.3226\n",
      "Epoch 44/80\n",
      "6435/6435 [==============================] - 0s 37us/step - loss: 1.3638 - accuracy: 0.3806 - val_loss: 1.3580 - val_accuracy: 0.3520\n",
      "Epoch 45/80\n",
      "6435/6435 [==============================] - 0s 36us/step - loss: 1.3625 - accuracy: 0.3781 - val_loss: 1.3574 - val_accuracy: 0.3799\n",
      "Epoch 46/80\n",
      "6435/6435 [==============================] - 0s 39us/step - loss: 1.3627 - accuracy: 0.3846 - val_loss: 1.3609 - val_accuracy: 0.3561\n",
      "Epoch 47/80\n",
      "6435/6435 [==============================] - 0s 40us/step - loss: 1.3548 - accuracy: 0.3843 - val_loss: 1.3478 - val_accuracy: 0.4078\n",
      "Epoch 48/80\n",
      "6435/6435 [==============================] - 0s 37us/step - loss: 1.3493 - accuracy: 0.3829 - val_loss: 1.3651 - val_accuracy: 0.3715\n",
      "Epoch 49/80\n",
      "6435/6435 [==============================] - 0s 39us/step - loss: 1.3493 - accuracy: 0.3916 - val_loss: 1.3532 - val_accuracy: 0.4022\n",
      "Epoch 50/80\n",
      "6435/6435 [==============================] - 0s 34us/step - loss: 1.3455 - accuracy: 0.3977 - val_loss: 1.3422 - val_accuracy: 0.4204\n",
      "Epoch 51/80\n",
      "6435/6435 [==============================] - 0s 36us/step - loss: 1.3342 - accuracy: 0.3893 - val_loss: 1.3333 - val_accuracy: 0.3869\n",
      "Epoch 52/80\n",
      "6435/6435 [==============================] - 0s 41us/step - loss: 1.3281 - accuracy: 0.3918 - val_loss: 1.3232 - val_accuracy: 0.4218\n",
      "Epoch 53/80\n",
      "6435/6435 [==============================] - 0s 37us/step - loss: 1.3289 - accuracy: 0.3924 - val_loss: 1.3152 - val_accuracy: 0.4344\n",
      "Epoch 54/80\n",
      "6435/6435 [==============================] - 0s 39us/step - loss: 1.3155 - accuracy: 0.4012 - val_loss: 1.3067 - val_accuracy: 0.4022\n",
      "Epoch 55/80\n",
      "6435/6435 [==============================] - 0s 34us/step - loss: 1.3035 - accuracy: 0.4179 - val_loss: 1.2974 - val_accuracy: 0.3799\n",
      "Epoch 56/80\n",
      "6435/6435 [==============================] - 0s 39us/step - loss: 1.2969 - accuracy: 0.4095 - val_loss: 1.3021 - val_accuracy: 0.4497\n",
      "Epoch 57/80\n",
      "6435/6435 [==============================] - 0s 36us/step - loss: 1.2947 - accuracy: 0.4183 - val_loss: 1.2734 - val_accuracy: 0.4553\n",
      "Epoch 58/80\n",
      "6435/6435 [==============================] - 0s 39us/step - loss: 1.2787 - accuracy: 0.4124 - val_loss: 1.2644 - val_accuracy: 0.4022\n",
      "Epoch 59/80\n",
      "6435/6435 [==============================] - 0s 35us/step - loss: 1.2656 - accuracy: 0.4264 - val_loss: 1.2503 - val_accuracy: 0.4190\n",
      "Epoch 60/80\n",
      "6435/6435 [==============================] - 0s 35us/step - loss: 1.2598 - accuracy: 0.4176 - val_loss: 1.2320 - val_accuracy: 0.4693\n",
      "Epoch 61/80\n",
      "6435/6435 [==============================] - 0s 40us/step - loss: 1.2452 - accuracy: 0.4218 - val_loss: 1.2256 - val_accuracy: 0.4358\n",
      "Epoch 62/80\n",
      "6435/6435 [==============================] - 0s 39us/step - loss: 1.2422 - accuracy: 0.4249 - val_loss: 1.2147 - val_accuracy: 0.4469\n",
      "Epoch 63/80\n",
      "6435/6435 [==============================] - 0s 37us/step - loss: 1.2331 - accuracy: 0.4326 - val_loss: 1.2207 - val_accuracy: 0.4344\n",
      "Epoch 64/80\n",
      "6435/6435 [==============================] - 0s 38us/step - loss: 1.2250 - accuracy: 0.4295 - val_loss: 1.2073 - val_accuracy: 0.4385\n",
      "Epoch 65/80\n",
      "6435/6435 [==============================] - 0s 38us/step - loss: 1.2232 - accuracy: 0.4402 - val_loss: 1.1986 - val_accuracy: 0.4302\n",
      "Epoch 66/80\n",
      "6435/6435 [==============================] - 0s 37us/step - loss: 1.2162 - accuracy: 0.4350 - val_loss: 1.2007 - val_accuracy: 0.4372\n",
      "Epoch 67/80\n",
      "6435/6435 [==============================] - 0s 41us/step - loss: 1.2132 - accuracy: 0.4278 - val_loss: 1.1978 - val_accuracy: 0.4372\n",
      "Epoch 68/80\n",
      "6435/6435 [==============================] - 0s 36us/step - loss: 1.2106 - accuracy: 0.4300 - val_loss: 1.2069 - val_accuracy: 0.4469\n",
      "Epoch 69/80\n",
      "6435/6435 [==============================] - 0s 39us/step - loss: 1.2136 - accuracy: 0.4334 - val_loss: 1.1879 - val_accuracy: 0.4399\n",
      "Epoch 70/80\n",
      "6435/6435 [==============================] - 0s 41us/step - loss: 1.2101 - accuracy: 0.4283 - val_loss: 1.1751 - val_accuracy: 0.4539\n",
      "Epoch 71/80\n",
      "6435/6435 [==============================] - 0s 36us/step - loss: 1.2047 - accuracy: 0.4253 - val_loss: 1.1726 - val_accuracy: 0.4469\n",
      "Epoch 72/80\n",
      "6435/6435 [==============================] - 0s 39us/step - loss: 1.2041 - accuracy: 0.4270 - val_loss: 1.1876 - val_accuracy: 0.4330\n",
      "Epoch 73/80\n",
      "6435/6435 [==============================] - 0s 39us/step - loss: 1.1985 - accuracy: 0.4354 - val_loss: 1.1762 - val_accuracy: 0.4358\n",
      "Epoch 74/80\n",
      "6435/6435 [==============================] - 0s 36us/step - loss: 1.2059 - accuracy: 0.4214 - val_loss: 1.1944 - val_accuracy: 0.4246\n",
      "Epoch 75/80\n",
      "6435/6435 [==============================] - 0s 39us/step - loss: 1.2032 - accuracy: 0.4364 - val_loss: 1.1698 - val_accuracy: 0.4511\n",
      "Epoch 76/80\n",
      "6435/6435 [==============================] - 0s 39us/step - loss: 1.2022 - accuracy: 0.4281 - val_loss: 1.1681 - val_accuracy: 0.4316\n",
      "Epoch 77/80\n",
      "6435/6435 [==============================] - 0s 36us/step - loss: 1.1925 - accuracy: 0.4412 - val_loss: 1.1664 - val_accuracy: 0.4274\n",
      "Epoch 78/80\n",
      "6435/6435 [==============================] - 0s 39us/step - loss: 1.1950 - accuracy: 0.4357 - val_loss: 1.1857 - val_accuracy: 0.4358\n",
      "Epoch 79/80\n",
      "6435/6435 [==============================] - 0s 36us/step - loss: 1.1885 - accuracy: 0.4284 - val_loss: 1.1649 - val_accuracy: 0.4399\n",
      "Epoch 80/80\n",
      "6435/6435 [==============================] - 0s 43us/step - loss: 1.1925 - accuracy: 0.4342 - val_loss: 1.1589 - val_accuracy: 0.4441\n",
      "[[1.18522860e-01 2.66864568e-01 1.37474247e-13 ... 1.03711034e-04\n",
      "  3.87844890e-01 2.03863934e-01]\n",
      " [4.66457009e-02 4.78744395e-02 5.94960359e-21 ... 2.75295615e-01\n",
      "  4.30569658e-03 1.58685371e-02]\n",
      " [2.65063912e-01 3.91579747e-01 1.41060023e-16 ... 5.60786575e-04\n",
      "  9.22641754e-02 2.46105954e-01]\n",
      " ...\n",
      " [3.16651195e-01 4.16143447e-01 9.17723141e-18 ... 1.98273861e-04\n",
      "  1.17938751e-02 2.54250973e-01]\n",
      " [1.30189657e-01 3.15237671e-01 1.38017451e-12 ... 2.18824862e-05\n",
      "  2.19850525e-01 2.89148182e-01]\n",
      " [1.45389497e-01 3.26314062e-01 3.74669236e-13 ... 3.69481641e-05\n",
      "  2.30788782e-01 2.70195007e-01]]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[12 10  1 ...  1  1  1]\n",
      "<class 'numpy.ndarray'>\n",
      "One CNN, r:  0\n",
      "Computing Time:  0:10:25.177494\n",
      "n, p1, p2 28 2 3\n",
      "Model: \"sequential_1\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv1d_1 (Conv1D)            (None, 3, 6)              12        \n",
      "_________________________________________________________________\n",
      "average_pooling1d_1 (Average (None, 1, 6)              0         \n",
      "_________________________________________________________________\n",
      "conv1d_2 (Conv1D)            (None, 1, 16)             112       \n",
      "_________________________________________________________________\n",
      "average_pooling1d_2 (Average (None, 1, 16)             0         \n",
      "_________________________________________________________________\n",
      "conv1d_3 (Conv1D)            (None, 1, 120)            2040      \n",
      "_________________________________________________________________\n",
      "flatten_1 (Flatten)          (None, 120)               0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 84)                10164     \n",
      "_________________________________________________________________\n",
      "preds (Dense)                (None, 14)                1190      \n",
      "=================================================================\n",
      "Total params: 13,518\n",
      "Trainable params: 13,518\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Train on 6435 samples, validate on 716 samples\n",
      "Epoch 1/80\n",
      "6435/6435 [==============================] - 1s 83us/step - loss: 2.6154 - accuracy: 0.1134 - val_loss: 2.5734 - val_accuracy: 0.0908\n",
      "Epoch 2/80\n",
      "6435/6435 [==============================] - 0s 49us/step - loss: 2.4197 - accuracy: 0.1277 - val_loss: 2.2458 - val_accuracy: 0.1355\n",
      "Epoch 3/80\n",
      "6435/6435 [==============================] - 0s 49us/step - loss: 2.1169 - accuracy: 0.1936 - val_loss: 1.9882 - val_accuracy: 0.2556\n",
      "Epoch 4/80\n",
      "6435/6435 [==============================] - 0s 44us/step - loss: 1.9054 - accuracy: 0.2578 - val_loss: 1.8134 - val_accuracy: 0.2975\n",
      "Epoch 5/80\n",
      "6435/6435 [==============================] - 0s 38us/step - loss: 1.7611 - accuracy: 0.2890 - val_loss: 1.7058 - val_accuracy: 0.3017\n",
      "Epoch 6/80\n",
      "6435/6435 [==============================] - 0s 40us/step - loss: 1.6709 - accuracy: 0.2876 - val_loss: 1.6452 - val_accuracy: 0.3226\n",
      "Epoch 7/80\n",
      "6435/6435 [==============================] - 0s 39us/step - loss: 1.6139 - accuracy: 0.3015 - val_loss: 1.6056 - val_accuracy: 0.2919\n",
      "Epoch 8/80\n",
      "6435/6435 [==============================] - 0s 42us/step - loss: 1.5878 - accuracy: 0.3002 - val_loss: 1.5754 - val_accuracy: 0.3254\n",
      "Epoch 9/80\n",
      "6435/6435 [==============================] - 0s 37us/step - loss: 1.5646 - accuracy: 0.3074 - val_loss: 1.5466 - val_accuracy: 0.3184\n",
      "Epoch 10/80\n",
      "6435/6435 [==============================] - 0s 37us/step - loss: 1.5451 - accuracy: 0.3082 - val_loss: 1.5352 - val_accuracy: 0.3478\n",
      "Epoch 11/80\n",
      "6435/6435 [==============================] - 0s 40us/step - loss: 1.5355 - accuracy: 0.3066 - val_loss: 1.5304 - val_accuracy: 0.3282\n",
      "Epoch 12/80\n",
      "6435/6435 [==============================] - 0s 36us/step - loss: 1.5201 - accuracy: 0.3141 - val_loss: 1.5184 - val_accuracy: 0.3170\n",
      "Epoch 13/80\n",
      "6435/6435 [==============================] - 0s 37us/step - loss: 1.5336 - accuracy: 0.3097 - val_loss: 1.5102 - val_accuracy: 0.3324\n",
      "Epoch 14/80\n",
      "6435/6435 [==============================] - 0s 40us/step - loss: 1.5174 - accuracy: 0.3117 - val_loss: 1.5224 - val_accuracy: 0.3087\n",
      "Epoch 15/80\n",
      "6435/6435 [==============================] - 0s 39us/step - loss: 1.5151 - accuracy: 0.3074 - val_loss: 1.5123 - val_accuracy: 0.3198\n",
      "Epoch 16/80\n",
      "6435/6435 [==============================] - 0s 35us/step - loss: 1.5067 - accuracy: 0.3092 - val_loss: 1.5000 - val_accuracy: 0.3184\n",
      "Epoch 17/80\n",
      "6435/6435 [==============================] - 0s 38us/step - loss: 1.5025 - accuracy: 0.3110 - val_loss: 1.4995 - val_accuracy: 0.3254\n",
      "Epoch 18/80\n",
      "6435/6435 [==============================] - 0s 38us/step - loss: 1.4992 - accuracy: 0.3103 - val_loss: 1.4943 - val_accuracy: 0.2989\n",
      "Epoch 19/80\n",
      "6435/6435 [==============================] - 0s 38us/step - loss: 1.4952 - accuracy: 0.3145 - val_loss: 1.4930 - val_accuracy: 0.3212\n",
      "Epoch 20/80\n",
      "6435/6435 [==============================] - 0s 41us/step - loss: 1.4980 - accuracy: 0.3147 - val_loss: 1.4960 - val_accuracy: 0.3017\n",
      "Epoch 21/80\n",
      "6435/6435 [==============================] - 0s 39us/step - loss: 1.4943 - accuracy: 0.3144 - val_loss: 1.4795 - val_accuracy: 0.3394\n",
      "Epoch 22/80\n",
      "6435/6435 [==============================] - 0s 37us/step - loss: 1.4879 - accuracy: 0.3102 - val_loss: 1.4848 - val_accuracy: 0.3212\n",
      "Epoch 23/80\n",
      "6435/6435 [==============================] - 0s 35us/step - loss: 1.4842 - accuracy: 0.3307 - val_loss: 1.4851 - val_accuracy: 0.3170\n",
      "Epoch 24/80\n",
      "6435/6435 [==============================] - 0s 39us/step - loss: 1.4853 - accuracy: 0.3078 - val_loss: 1.4740 - val_accuracy: 0.3240\n",
      "Epoch 25/80\n",
      "6435/6435 [==============================] - 0s 40us/step - loss: 1.4793 - accuracy: 0.3166 - val_loss: 1.4718 - val_accuracy: 0.3087\n",
      "Epoch 26/80\n",
      "6435/6435 [==============================] - 0s 35us/step - loss: 1.4817 - accuracy: 0.3203 - val_loss: 1.4740 - val_accuracy: 0.3128\n",
      "Epoch 27/80\n",
      "6435/6435 [==============================] - 0s 36us/step - loss: 1.4828 - accuracy: 0.3141 - val_loss: 1.4643 - val_accuracy: 0.3240\n",
      "Epoch 28/80\n",
      "6435/6435 [==============================] - 0s 36us/step - loss: 1.4764 - accuracy: 0.3214 - val_loss: 1.4720 - val_accuracy: 0.3031\n",
      "Epoch 29/80\n",
      "6435/6435 [==============================] - 0s 41us/step - loss: 1.4780 - accuracy: 0.3195 - val_loss: 1.4710 - val_accuracy: 0.2863\n",
      "Epoch 30/80\n",
      "6435/6435 [==============================] - 0s 42us/step - loss: 1.4735 - accuracy: 0.3131 - val_loss: 1.4987 - val_accuracy: 0.3184\n",
      "Epoch 31/80\n",
      "6435/6435 [==============================] - 0s 38us/step - loss: 1.4832 - accuracy: 0.3179 - val_loss: 1.4611 - val_accuracy: 0.3184\n",
      "Epoch 32/80\n",
      "6435/6435 [==============================] - 0s 42us/step - loss: 1.4694 - accuracy: 0.3183 - val_loss: 1.4777 - val_accuracy: 0.2821\n",
      "Epoch 33/80\n",
      "6435/6435 [==============================] - 0s 36us/step - loss: 1.4695 - accuracy: 0.3156 - val_loss: 1.4510 - val_accuracy: 0.3408\n",
      "Epoch 34/80\n",
      "6435/6435 [==============================] - 0s 36us/step - loss: 1.4658 - accuracy: 0.3259 - val_loss: 1.4566 - val_accuracy: 0.3156\n",
      "Epoch 35/80\n",
      "6435/6435 [==============================] - 0s 36us/step - loss: 1.4636 - accuracy: 0.3350 - val_loss: 1.4571 - val_accuracy: 0.3045\n",
      "Epoch 36/80\n",
      "6435/6435 [==============================] - 0s 37us/step - loss: 1.4653 - accuracy: 0.3212 - val_loss: 1.4548 - val_accuracy: 0.3142\n",
      "Epoch 37/80\n",
      "6435/6435 [==============================] - 0s 36us/step - loss: 1.4605 - accuracy: 0.3274 - val_loss: 1.4527 - val_accuracy: 0.3142\n",
      "Epoch 38/80\n",
      "6435/6435 [==============================] - 0s 41us/step - loss: 1.4620 - accuracy: 0.3159 - val_loss: 1.4440 - val_accuracy: 0.3226\n",
      "Epoch 39/80\n",
      "6435/6435 [==============================] - 0s 39us/step - loss: 1.4539 - accuracy: 0.3273 - val_loss: 1.4432 - val_accuracy: 0.3170\n",
      "Epoch 40/80\n",
      "6435/6435 [==============================] - 0s 37us/step - loss: 1.4526 - accuracy: 0.3346 - val_loss: 1.4525 - val_accuracy: 0.3282\n",
      "Epoch 41/80\n",
      "6435/6435 [==============================] - 0s 38us/step - loss: 1.4510 - accuracy: 0.3400 - val_loss: 1.4694 - val_accuracy: 0.2961\n",
      "Epoch 42/80\n",
      "6435/6435 [==============================] - 0s 37us/step - loss: 1.4562 - accuracy: 0.3346 - val_loss: 1.4605 - val_accuracy: 0.2961\n",
      "Epoch 43/80\n",
      "6435/6435 [==============================] - 0s 38us/step - loss: 1.4471 - accuracy: 0.3444 - val_loss: 1.4226 - val_accuracy: 0.3436\n",
      "Epoch 44/80\n",
      "6435/6435 [==============================] - 0s 35us/step - loss: 1.4403 - accuracy: 0.3444 - val_loss: 1.4242 - val_accuracy: 0.3813\n",
      "Epoch 45/80\n",
      "6435/6435 [==============================] - 0s 36us/step - loss: 1.4348 - accuracy: 0.3461 - val_loss: 1.4294 - val_accuracy: 0.3478\n",
      "Epoch 46/80\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6435/6435 [==============================] - 0s 35us/step - loss: 1.4282 - accuracy: 0.3557 - val_loss: 1.4196 - val_accuracy: 0.3701\n",
      "Epoch 47/80\n",
      "6435/6435 [==============================] - 0s 34us/step - loss: 1.4177 - accuracy: 0.3616 - val_loss: 1.4040 - val_accuracy: 0.3534\n",
      "Epoch 48/80\n",
      "6435/6435 [==============================] - 0s 37us/step - loss: 1.4101 - accuracy: 0.3683 - val_loss: 1.3952 - val_accuracy: 0.3673\n",
      "Epoch 49/80\n",
      "6435/6435 [==============================] - 0s 37us/step - loss: 1.4009 - accuracy: 0.3643 - val_loss: 1.3873 - val_accuracy: 0.3506\n",
      "Epoch 50/80\n",
      "6435/6435 [==============================] - 0s 37us/step - loss: 1.3923 - accuracy: 0.3689 - val_loss: 1.3772 - val_accuracy: 0.3883\n",
      "Epoch 51/80\n",
      "6435/6435 [==============================] - 0s 39us/step - loss: 1.3743 - accuracy: 0.3754 - val_loss: 1.3635 - val_accuracy: 0.3547\n",
      "Epoch 52/80\n",
      "6435/6435 [==============================] - 0s 40us/step - loss: 1.3575 - accuracy: 0.3669 - val_loss: 1.3635 - val_accuracy: 0.3715\n",
      "Epoch 53/80\n",
      "6435/6435 [==============================] - 0s 39us/step - loss: 1.3451 - accuracy: 0.3798 - val_loss: 1.3436 - val_accuracy: 0.3799\n",
      "Epoch 54/80\n",
      "6435/6435 [==============================] - 0s 35us/step - loss: 1.3344 - accuracy: 0.3751 - val_loss: 1.3379 - val_accuracy: 0.3757\n",
      "Epoch 55/80\n",
      "6435/6435 [==============================] - 0s 41us/step - loss: 1.3279 - accuracy: 0.3818 - val_loss: 1.3202 - val_accuracy: 0.3617\n",
      "Epoch 56/80\n",
      "6435/6435 [==============================] - 0s 39us/step - loss: 1.3101 - accuracy: 0.3862 - val_loss: 1.3160 - val_accuracy: 0.3464\n",
      "Epoch 57/80\n",
      "6435/6435 [==============================] - 0s 41us/step - loss: 1.3062 - accuracy: 0.3866 - val_loss: 1.3087 - val_accuracy: 0.3785\n",
      "Epoch 58/80\n",
      "6435/6435 [==============================] - 0s 36us/step - loss: 1.3004 - accuracy: 0.3901 - val_loss: 1.3098 - val_accuracy: 0.3799\n",
      "Epoch 59/80\n",
      "6435/6435 [==============================] - 0s 39us/step - loss: 1.2946 - accuracy: 0.3918 - val_loss: 1.2974 - val_accuracy: 0.3911\n",
      "Epoch 60/80\n",
      "6435/6435 [==============================] - 0s 46us/step - loss: 1.2969 - accuracy: 0.3902 - val_loss: 1.3032 - val_accuracy: 0.3506\n",
      "Epoch 61/80\n",
      "6435/6435 [==============================] - 0s 44us/step - loss: 1.2891 - accuracy: 0.3879 - val_loss: 1.2953 - val_accuracy: 0.3785\n",
      "Epoch 62/80\n",
      "6435/6435 [==============================] - 0s 46us/step - loss: 1.2828 - accuracy: 0.3958 - val_loss: 1.2924 - val_accuracy: 0.3687\n",
      "Epoch 63/80\n",
      "6435/6435 [==============================] - 0s 39us/step - loss: 1.2801 - accuracy: 0.3975 - val_loss: 1.2897 - val_accuracy: 0.3897\n",
      "Epoch 64/80\n",
      "6435/6435 [==============================] - 0s 34us/step - loss: 1.2819 - accuracy: 0.4003 - val_loss: 1.2846 - val_accuracy: 0.3841\n",
      "Epoch 65/80\n",
      "6435/6435 [==============================] - 0s 37us/step - loss: 1.2722 - accuracy: 0.3915 - val_loss: 1.2908 - val_accuracy: 0.3757\n",
      "Epoch 66/80\n",
      "6435/6435 [==============================] - 0s 38us/step - loss: 1.2743 - accuracy: 0.3960 - val_loss: 1.2919 - val_accuracy: 0.3757\n",
      "Epoch 67/80\n",
      "6435/6435 [==============================] - 0s 34us/step - loss: 1.2742 - accuracy: 0.3969 - val_loss: 1.2986 - val_accuracy: 0.4036\n",
      "Epoch 68/80\n",
      "6435/6435 [==============================] - 0s 34us/step - loss: 1.2696 - accuracy: 0.4028 - val_loss: 1.2807 - val_accuracy: 0.3659\n",
      "Epoch 69/80\n",
      "6435/6435 [==============================] - 0s 37us/step - loss: 1.2675 - accuracy: 0.3893 - val_loss: 1.2862 - val_accuracy: 0.3855\n",
      "Epoch 70/80\n",
      "6435/6435 [==============================] - 0s 37us/step - loss: 1.2660 - accuracy: 0.3891 - val_loss: 1.2733 - val_accuracy: 0.3939\n",
      "Epoch 71/80\n",
      "6435/6435 [==============================] - 0s 35us/step - loss: 1.2615 - accuracy: 0.3974 - val_loss: 1.2706 - val_accuracy: 0.4106\n",
      "Epoch 72/80\n",
      "6435/6435 [==============================] - 0s 44us/step - loss: 1.2561 - accuracy: 0.4003 - val_loss: 1.2689 - val_accuracy: 0.3869\n",
      "Epoch 73/80\n",
      "6435/6435 [==============================] - 0s 34us/step - loss: 1.2532 - accuracy: 0.3981 - val_loss: 1.2686 - val_accuracy: 0.3757\n",
      "Epoch 74/80\n",
      "6435/6435 [==============================] - 0s 34us/step - loss: 1.2570 - accuracy: 0.4006 - val_loss: 1.2701 - val_accuracy: 0.4036\n",
      "Epoch 75/80\n",
      "6435/6435 [==============================] - 0s 36us/step - loss: 1.2551 - accuracy: 0.3946 - val_loss: 1.2686 - val_accuracy: 0.3813\n",
      "Epoch 76/80\n",
      "6435/6435 [==============================] - 0s 34us/step - loss: 1.2534 - accuracy: 0.4016 - val_loss: 1.2615 - val_accuracy: 0.4078\n",
      "Epoch 77/80\n",
      "6435/6435 [==============================] - 0s 36us/step - loss: 1.2495 - accuracy: 0.3980 - val_loss: 1.2632 - val_accuracy: 0.4036\n",
      "Epoch 78/80\n",
      "6435/6435 [==============================] - 0s 41us/step - loss: 1.2424 - accuracy: 0.4103 - val_loss: 1.2583 - val_accuracy: 0.3883\n",
      "Epoch 79/80\n",
      "6435/6435 [==============================] - 0s 36us/step - loss: 1.2418 - accuracy: 0.4034 - val_loss: 1.2620 - val_accuracy: 0.3994\n",
      "Epoch 80/80\n",
      "6435/6435 [==============================] - 0s 39us/step - loss: 1.2404 - accuracy: 0.4006 - val_loss: 1.2564 - val_accuracy: 0.3897\n",
      "[[1.08965307e-01 1.16129957e-01 1.29057284e-04 ... 3.14433068e-01\n",
      "  2.14506343e-01 2.21335381e-01]\n",
      " [4.60670479e-02 4.65857275e-02 1.46362989e-03 ... 4.85396106e-03\n",
      "  1.98589303e-02 1.70188881e-02]\n",
      " [1.99734494e-01 2.06758231e-01 4.12075569e-05 ... 6.30871579e-02\n",
      "  2.57423490e-01 2.70729721e-01]\n",
      " ...\n",
      " [2.40187988e-01 2.26058319e-01 1.25576735e-05 ... 5.76677686e-03\n",
      "  2.52247274e-01 2.75010407e-01]\n",
      " [1.06188700e-01 1.14333279e-01 7.01505633e-05 ... 1.43251181e-01\n",
      "  2.95817107e-01 3.11375916e-01]\n",
      " [1.17228396e-01 1.26327798e-01 6.67751810e-05 ... 1.59372911e-01\n",
      "  2.81903386e-01 2.94431448e-01]]\n",
      "[11  4 13 ... 13 13 13]\n",
      "<class 'numpy.ndarray'>\n",
      "One CNN, r:  0\n",
      "Computing Time:  0:10:46.708351\n",
      "n, p1, p2 29 2 4\n",
      "Model: \"sequential_1\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv1d_1 (Conv1D)            (None, 3, 6)              12        \n",
      "_________________________________________________________________\n",
      "average_pooling1d_1 (Average (None, 1, 6)              0         \n",
      "_________________________________________________________________\n",
      "conv1d_2 (Conv1D)            (None, 1, 16)             112       \n",
      "_________________________________________________________________\n",
      "average_pooling1d_2 (Average (None, 1, 16)             0         \n",
      "_________________________________________________________________\n",
      "conv1d_3 (Conv1D)            (None, 1, 120)            2040      \n",
      "_________________________________________________________________\n",
      "flatten_1 (Flatten)          (None, 120)               0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 84)                10164     \n",
      "_________________________________________________________________\n",
      "preds (Dense)                (None, 14)                1190      \n",
      "=================================================================\n",
      "Total params: 13,518\n",
      "Trainable params: 13,518\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Train on 6435 samples, validate on 716 samples\n",
      "Epoch 1/80\n",
      "6435/6435 [==============================] - 0s 75us/step - loss: 2.6122 - accuracy: 0.1144 - val_loss: 2.5558 - val_accuracy: 0.1006\n",
      "Epoch 2/80\n",
      "6435/6435 [==============================] - 0s 41us/step - loss: 2.3871 - accuracy: 0.1318 - val_loss: 2.2434 - val_accuracy: 0.1327\n",
      "Epoch 3/80\n",
      "6435/6435 [==============================] - 0s 41us/step - loss: 2.1144 - accuracy: 0.1863 - val_loss: 2.0324 - val_accuracy: 0.2751\n",
      "Epoch 4/80\n",
      "6435/6435 [==============================] - 0s 41us/step - loss: 1.9243 - accuracy: 0.2757 - val_loss: 1.8618 - val_accuracy: 0.2612\n",
      "Epoch 5/80\n",
      "6435/6435 [==============================] - 0s 41us/step - loss: 1.7639 - accuracy: 0.2864 - val_loss: 1.7343 - val_accuracy: 0.3059\n",
      "Epoch 6/80\n",
      "6435/6435 [==============================] - 0s 39us/step - loss: 1.6628 - accuracy: 0.2982 - val_loss: 1.6474 - val_accuracy: 0.2626\n",
      "Epoch 7/80\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6435/6435 [==============================] - 0s 39us/step - loss: 1.6028 - accuracy: 0.3041 - val_loss: 1.5916 - val_accuracy: 0.3128\n",
      "Epoch 8/80\n",
      "6435/6435 [==============================] - 0s 39us/step - loss: 1.5654 - accuracy: 0.3119 - val_loss: 1.5517 - val_accuracy: 0.3198\n",
      "Epoch 9/80\n",
      "6435/6435 [==============================] - 0s 36us/step - loss: 1.5519 - accuracy: 0.3054 - val_loss: 1.5552 - val_accuracy: 0.3142\n",
      "Epoch 10/80\n",
      "6435/6435 [==============================] - 0s 39us/step - loss: 1.5388 - accuracy: 0.3110 - val_loss: 1.5547 - val_accuracy: 0.3073\n",
      "Epoch 11/80\n",
      "6435/6435 [==============================] - 0s 39us/step - loss: 1.5220 - accuracy: 0.3231 - val_loss: 1.5256 - val_accuracy: 0.3198\n",
      "Epoch 12/80\n",
      "6435/6435 [==============================] - 0s 34us/step - loss: 1.5129 - accuracy: 0.3223 - val_loss: 1.5228 - val_accuracy: 0.3212\n",
      "Epoch 13/80\n",
      "6435/6435 [==============================] - 0s 39us/step - loss: 1.5139 - accuracy: 0.3332 - val_loss: 1.4957 - val_accuracy: 0.3170\n",
      "Epoch 14/80\n",
      "6435/6435 [==============================] - 0s 36us/step - loss: 1.5017 - accuracy: 0.3181 - val_loss: 1.4897 - val_accuracy: 0.3254\n",
      "Epoch 15/80\n",
      "6435/6435 [==============================] - 0s 41us/step - loss: 1.4906 - accuracy: 0.3270 - val_loss: 1.5046 - val_accuracy: 0.3101\n",
      "Epoch 16/80\n",
      "6435/6435 [==============================] - 0s 36us/step - loss: 1.4896 - accuracy: 0.3301 - val_loss: 1.4951 - val_accuracy: 0.3003\n",
      "Epoch 17/80\n",
      "6435/6435 [==============================] - 0s 34us/step - loss: 1.4804 - accuracy: 0.3338 - val_loss: 1.4770 - val_accuracy: 0.3310\n",
      "Epoch 18/80\n",
      "6435/6435 [==============================] - 0s 34us/step - loss: 1.4754 - accuracy: 0.3374 - val_loss: 1.4724 - val_accuracy: 0.3422\n",
      "Epoch 19/80\n",
      "6435/6435 [==============================] - 0s 39us/step - loss: 1.4701 - accuracy: 0.3441 - val_loss: 1.4820 - val_accuracy: 0.3198\n",
      "Epoch 20/80\n",
      "6435/6435 [==============================] - 0s 39us/step - loss: 1.4636 - accuracy: 0.3416 - val_loss: 1.4724 - val_accuracy: 0.3212\n",
      "Epoch 21/80\n",
      "6435/6435 [==============================] - 0s 34us/step - loss: 1.4528 - accuracy: 0.3549 - val_loss: 1.4666 - val_accuracy: 0.3296\n",
      "Epoch 22/80\n",
      "6435/6435 [==============================] - 0s 34us/step - loss: 1.4490 - accuracy: 0.3470 - val_loss: 1.4491 - val_accuracy: 0.3366\n",
      "Epoch 23/80\n",
      "6435/6435 [==============================] - 0s 39us/step - loss: 1.4349 - accuracy: 0.3618 - val_loss: 1.4359 - val_accuracy: 0.3478\n",
      "Epoch 24/80\n",
      "6435/6435 [==============================] - 0s 41us/step - loss: 1.4238 - accuracy: 0.3703 - val_loss: 1.4243 - val_accuracy: 0.3575\n",
      "Epoch 25/80\n",
      "6435/6435 [==============================] - 0s 34us/step - loss: 1.4142 - accuracy: 0.3636 - val_loss: 1.4047 - val_accuracy: 0.3603\n",
      "Epoch 26/80\n",
      "6435/6435 [==============================] - 0s 36us/step - loss: 1.3992 - accuracy: 0.3740 - val_loss: 1.3969 - val_accuracy: 0.3603\n",
      "Epoch 27/80\n",
      "6435/6435 [==============================] - 0s 34us/step - loss: 1.3787 - accuracy: 0.3829 - val_loss: 1.3971 - val_accuracy: 0.3771\n",
      "Epoch 28/80\n",
      "6435/6435 [==============================] - 0s 32us/step - loss: 1.3624 - accuracy: 0.3801 - val_loss: 1.3527 - val_accuracy: 0.3617\n",
      "Epoch 29/80\n",
      "6435/6435 [==============================] - 0s 36us/step - loss: 1.3487 - accuracy: 0.3835 - val_loss: 1.3493 - val_accuracy: 0.3617\n",
      "Epoch 30/80\n",
      "6435/6435 [==============================] - 0s 36us/step - loss: 1.3390 - accuracy: 0.3913 - val_loss: 1.3561 - val_accuracy: 0.3645\n",
      "Epoch 31/80\n",
      "6435/6435 [==============================] - 0s 34us/step - loss: 1.3298 - accuracy: 0.3776 - val_loss: 1.3389 - val_accuracy: 0.3506\n",
      "Epoch 32/80\n",
      "6435/6435 [==============================] - 0s 34us/step - loss: 1.3206 - accuracy: 0.3821 - val_loss: 1.3133 - val_accuracy: 0.3953\n",
      "Epoch 33/80\n",
      "6435/6435 [==============================] - 0s 36us/step - loss: 1.3149 - accuracy: 0.3933 - val_loss: 1.3331 - val_accuracy: 0.3743\n",
      "Epoch 34/80\n",
      "6435/6435 [==============================] - 0s 32us/step - loss: 1.3111 - accuracy: 0.3862 - val_loss: 1.2974 - val_accuracy: 0.3841\n",
      "Epoch 35/80\n",
      "6435/6435 [==============================] - 0s 36us/step - loss: 1.3041 - accuracy: 0.3921 - val_loss: 1.2942 - val_accuracy: 0.3827\n",
      "Epoch 36/80\n",
      "6435/6435 [==============================] - 0s 36us/step - loss: 1.2941 - accuracy: 0.3865 - val_loss: 1.2942 - val_accuracy: 0.3743\n",
      "Epoch 37/80\n",
      "6435/6435 [==============================] - 0s 39us/step - loss: 1.2951 - accuracy: 0.3863 - val_loss: 1.3088 - val_accuracy: 0.3687\n",
      "Epoch 38/80\n",
      "6435/6435 [==============================] - 0s 39us/step - loss: 1.2922 - accuracy: 0.3904 - val_loss: 1.2879 - val_accuracy: 0.3827\n",
      "Epoch 39/80\n",
      "6435/6435 [==============================] - 0s 34us/step - loss: 1.2891 - accuracy: 0.4030 - val_loss: 1.2980 - val_accuracy: 0.3841\n",
      "Epoch 40/80\n",
      "6435/6435 [==============================] - 0s 34us/step - loss: 1.2876 - accuracy: 0.4008 - val_loss: 1.2836 - val_accuracy: 0.3925\n",
      "Epoch 41/80\n",
      "6435/6435 [==============================] - 0s 34us/step - loss: 1.2875 - accuracy: 0.4022 - val_loss: 1.3077 - val_accuracy: 0.3813\n",
      "Epoch 42/80\n",
      "6435/6435 [==============================] - 0s 34us/step - loss: 1.2871 - accuracy: 0.3916 - val_loss: 1.3205 - val_accuracy: 0.3631\n",
      "Epoch 43/80\n",
      "6435/6435 [==============================] - 0s 36us/step - loss: 1.2797 - accuracy: 0.3891 - val_loss: 1.2869 - val_accuracy: 0.3841\n",
      "Epoch 44/80\n",
      "6435/6435 [==============================] - 0s 34us/step - loss: 1.2740 - accuracy: 0.3997 - val_loss: 1.2795 - val_accuracy: 0.3701\n",
      "Epoch 45/80\n",
      "6435/6435 [==============================] - 0s 34us/step - loss: 1.2779 - accuracy: 0.4008 - val_loss: 1.2655 - val_accuracy: 0.3980\n",
      "Epoch 46/80\n",
      "6435/6435 [==============================] - 0s 34us/step - loss: 1.2755 - accuracy: 0.3911 - val_loss: 1.2936 - val_accuracy: 0.3729\n",
      "Epoch 47/80\n",
      "6435/6435 [==============================] - 0s 32us/step - loss: 1.2712 - accuracy: 0.3977 - val_loss: 1.2830 - val_accuracy: 0.3827\n",
      "Epoch 48/80\n",
      "6435/6435 [==============================] - 0s 34us/step - loss: 1.2727 - accuracy: 0.3929 - val_loss: 1.2775 - val_accuracy: 0.3911\n",
      "Epoch 49/80\n",
      "6435/6435 [==============================] - 0s 32us/step - loss: 1.2673 - accuracy: 0.3943 - val_loss: 1.2791 - val_accuracy: 0.3659\n",
      "Epoch 50/80\n",
      "6435/6435 [==============================] - 0s 34us/step - loss: 1.2684 - accuracy: 0.3890 - val_loss: 1.2669 - val_accuracy: 0.3855\n",
      "Epoch 51/80\n",
      "6435/6435 [==============================] - 0s 34us/step - loss: 1.2584 - accuracy: 0.4064 - val_loss: 1.2733 - val_accuracy: 0.3841\n",
      "Epoch 52/80\n",
      "6435/6435 [==============================] - 0s 34us/step - loss: 1.2587 - accuracy: 0.3991 - val_loss: 1.2555 - val_accuracy: 0.4008\n",
      "Epoch 53/80\n",
      "6435/6435 [==============================] - 0s 36us/step - loss: 1.2560 - accuracy: 0.3939 - val_loss: 1.2600 - val_accuracy: 0.3869\n",
      "Epoch 54/80\n",
      "6435/6435 [==============================] - 0s 36us/step - loss: 1.2577 - accuracy: 0.3969 - val_loss: 1.2556 - val_accuracy: 0.3925\n",
      "Epoch 55/80\n",
      "6435/6435 [==============================] - 0s 36us/step - loss: 1.2512 - accuracy: 0.3955 - val_loss: 1.2484 - val_accuracy: 0.3785\n",
      "Epoch 56/80\n",
      "6435/6435 [==============================] - 0s 34us/step - loss: 1.2477 - accuracy: 0.4011 - val_loss: 1.2673 - val_accuracy: 0.3687\n",
      "Epoch 57/80\n",
      "6435/6435 [==============================] - 0s 34us/step - loss: 1.2510 - accuracy: 0.3988 - val_loss: 1.2736 - val_accuracy: 0.3827\n",
      "Epoch 58/80\n",
      "6435/6435 [==============================] - 0s 34us/step - loss: 1.2430 - accuracy: 0.4113 - val_loss: 1.2617 - val_accuracy: 0.3771\n",
      "Epoch 59/80\n",
      "6435/6435 [==============================] - 0s 36us/step - loss: 1.2482 - accuracy: 0.3949 - val_loss: 1.2576 - val_accuracy: 0.3883\n",
      "Epoch 60/80\n",
      "6435/6435 [==============================] - 0s 34us/step - loss: 1.2427 - accuracy: 0.4103 - val_loss: 1.2618 - val_accuracy: 0.3645\n",
      "Epoch 61/80\n",
      "6435/6435 [==============================] - 0s 36us/step - loss: 1.2377 - accuracy: 0.4067 - val_loss: 1.2402 - val_accuracy: 0.3911\n",
      "Epoch 62/80\n",
      "6435/6435 [==============================] - 0s 36us/step - loss: 1.2400 - accuracy: 0.4065 - val_loss: 1.2404 - val_accuracy: 0.3841\n",
      "Epoch 63/80\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6435/6435 [==============================] - 0s 41us/step - loss: 1.2362 - accuracy: 0.4085 - val_loss: 1.2569 - val_accuracy: 0.3841\n",
      "Epoch 64/80\n",
      "6435/6435 [==============================] - 0s 36us/step - loss: 1.2357 - accuracy: 0.4068 - val_loss: 1.2327 - val_accuracy: 0.4078\n",
      "Epoch 65/80\n",
      "6435/6435 [==============================] - 0s 36us/step - loss: 1.2336 - accuracy: 0.4096 - val_loss: 1.2683 - val_accuracy: 0.3743\n",
      "Epoch 66/80\n",
      "6435/6435 [==============================] - 0s 36us/step - loss: 1.2325 - accuracy: 0.4031 - val_loss: 1.2488 - val_accuracy: 0.3897\n",
      "Epoch 67/80\n",
      "6435/6435 [==============================] - 0s 36us/step - loss: 1.2324 - accuracy: 0.4129 - val_loss: 1.2404 - val_accuracy: 0.3799\n",
      "Epoch 68/80\n",
      "6435/6435 [==============================] - 0s 39us/step - loss: 1.2284 - accuracy: 0.4082 - val_loss: 1.2410 - val_accuracy: 0.3715\n",
      "Epoch 69/80\n",
      "6435/6435 [==============================] - 0s 32us/step - loss: 1.2290 - accuracy: 0.4115 - val_loss: 1.2414 - val_accuracy: 0.3813\n",
      "Epoch 70/80\n",
      "6435/6435 [==============================] - 0s 36us/step - loss: 1.2340 - accuracy: 0.4019 - val_loss: 1.2387 - val_accuracy: 0.3799\n",
      "Epoch 71/80\n",
      "6435/6435 [==============================] - 0s 36us/step - loss: 1.2263 - accuracy: 0.4090 - val_loss: 1.2543 - val_accuracy: 0.3687\n",
      "Epoch 72/80\n",
      "6435/6435 [==============================] - 0s 36us/step - loss: 1.2263 - accuracy: 0.4057 - val_loss: 1.2424 - val_accuracy: 0.4078\n",
      "Epoch 73/80\n",
      "6435/6435 [==============================] - 0s 36us/step - loss: 1.2247 - accuracy: 0.4081 - val_loss: 1.2379 - val_accuracy: 0.3771\n",
      "Epoch 74/80\n",
      "6435/6435 [==============================] - 0s 36us/step - loss: 1.2231 - accuracy: 0.4104 - val_loss: 1.2426 - val_accuracy: 0.3883\n",
      "Epoch 00074: early stopping\n",
      "[[1.4243259e-01 1.3188441e-01 1.6801856e-05 ... 2.2340082e-01\n",
      "  2.6238486e-01 2.3220098e-01]\n",
      " [6.9073074e-02 6.6481017e-02 1.1870157e-03 ... 4.9145351e-04\n",
      "  1.6202848e-02 1.3093666e-02]\n",
      " [1.6654639e-01 1.4166747e-01 7.7420646e-06 ... 2.7568821e-02\n",
      "  3.7325549e-01 2.9000455e-01]\n",
      " ...\n",
      " [2.1305469e-01 2.0061396e-01 6.2868362e-06 ... 2.1640370e-03\n",
      "  3.3020687e-01 2.5359473e-01]\n",
      " [1.2148098e-01 1.1137094e-01 1.1456861e-05 ... 1.0396813e-01\n",
      "  3.3727843e-01 3.1124288e-01]\n",
      " [1.3645336e-01 1.2476211e-01 1.1058039e-05 ... 1.2116817e-01\n",
      "  3.2041836e-01 2.8892985e-01]]\n",
      "[12  9 12 ... 12 12 12]\n",
      "<class 'numpy.ndarray'>\n",
      "One CNN, r:  0\n",
      "Computing Time:  0:11:05.770808\n",
      "n, p1, p2 30 2 5\n",
      "Model: \"sequential_1\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv1d_1 (Conv1D)            (None, 3, 6)              12        \n",
      "_________________________________________________________________\n",
      "average_pooling1d_1 (Average (None, 1, 6)              0         \n",
      "_________________________________________________________________\n",
      "conv1d_2 (Conv1D)            (None, 1, 16)             112       \n",
      "_________________________________________________________________\n",
      "average_pooling1d_2 (Average (None, 1, 16)             0         \n",
      "_________________________________________________________________\n",
      "conv1d_3 (Conv1D)            (None, 1, 120)            2040      \n",
      "_________________________________________________________________\n",
      "flatten_1 (Flatten)          (None, 120)               0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 84)                10164     \n",
      "_________________________________________________________________\n",
      "preds (Dense)                (None, 14)                1190      \n",
      "=================================================================\n",
      "Total params: 13,518\n",
      "Trainable params: 13,518\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Train on 6435 samples, validate on 716 samples\n",
      "Epoch 1/80\n",
      "6435/6435 [==============================] - 0s 75us/step - loss: 2.6029 - accuracy: 0.1419 - val_loss: 2.5090 - val_accuracy: 0.1536\n",
      "Epoch 2/80\n",
      "6435/6435 [==============================] - 0s 41us/step - loss: 2.3408 - accuracy: 0.1360 - val_loss: 2.1466 - val_accuracy: 0.1774\n",
      "Epoch 3/80\n",
      "6435/6435 [==============================] - 0s 41us/step - loss: 2.0815 - accuracy: 0.2138 - val_loss: 2.0020 - val_accuracy: 0.2835\n",
      "Epoch 4/80\n",
      "6435/6435 [==============================] - 0s 36us/step - loss: 1.9661 - accuracy: 0.2780 - val_loss: 1.9169 - val_accuracy: 0.2779\n",
      "Epoch 5/80\n",
      "6435/6435 [==============================] - 0s 46us/step - loss: 1.8780 - accuracy: 0.2824 - val_loss: 1.8514 - val_accuracy: 0.2696\n",
      "Epoch 6/80\n",
      "6435/6435 [==============================] - 0s 39us/step - loss: 1.8070 - accuracy: 0.2864 - val_loss: 1.7793 - val_accuracy: 0.2863\n",
      "Epoch 7/80\n",
      "6435/6435 [==============================] - 0s 34us/step - loss: 1.7479 - accuracy: 0.2881 - val_loss: 1.7349 - val_accuracy: 0.2961\n",
      "Epoch 8/80\n",
      "6435/6435 [==============================] - 0s 39us/step - loss: 1.6952 - accuracy: 0.2959 - val_loss: 1.6661 - val_accuracy: 0.3017\n",
      "Epoch 9/80\n",
      "6435/6435 [==============================] - 0s 34us/step - loss: 1.6387 - accuracy: 0.3066 - val_loss: 1.6264 - val_accuracy: 0.3059\n",
      "Epoch 10/80\n",
      "6435/6435 [==============================] - 0s 34us/step - loss: 1.6011 - accuracy: 0.3117 - val_loss: 1.6018 - val_accuracy: 0.2821\n",
      "Epoch 11/80\n",
      "6435/6435 [==============================] - 0s 37us/step - loss: 1.5777 - accuracy: 0.3133 - val_loss: 1.5793 - val_accuracy: 0.3101\n",
      "Epoch 12/80\n",
      "6435/6435 [==============================] - 0s 41us/step - loss: 1.5620 - accuracy: 0.3058 - val_loss: 1.5944 - val_accuracy: 0.3003\n",
      "Epoch 13/80\n",
      "6435/6435 [==============================] - 0s 36us/step - loss: 1.5502 - accuracy: 0.3094 - val_loss: 1.5731 - val_accuracy: 0.3045\n",
      "Epoch 14/80\n",
      "6435/6435 [==============================] - 0s 36us/step - loss: 1.5432 - accuracy: 0.3193 - val_loss: 1.5541 - val_accuracy: 0.3142\n",
      "Epoch 15/80\n",
      "6435/6435 [==============================] - 0s 36us/step - loss: 1.5365 - accuracy: 0.3130 - val_loss: 1.5569 - val_accuracy: 0.3045\n",
      "Epoch 16/80\n",
      "6435/6435 [==============================] - 0s 36us/step - loss: 1.5359 - accuracy: 0.3072 - val_loss: 1.5626 - val_accuracy: 0.3128\n",
      "Epoch 17/80\n",
      "6435/6435 [==============================] - 0s 36us/step - loss: 1.5166 - accuracy: 0.3190 - val_loss: 1.5437 - val_accuracy: 0.3184\n",
      "Epoch 18/80\n",
      "6435/6435 [==============================] - 0s 36us/step - loss: 1.5138 - accuracy: 0.3214 - val_loss: 1.5488 - val_accuracy: 0.3142\n",
      "Epoch 19/80\n",
      "6435/6435 [==============================] - 0s 39us/step - loss: 1.5084 - accuracy: 0.3145 - val_loss: 1.5256 - val_accuracy: 0.3128\n",
      "Epoch 20/80\n",
      "6435/6435 [==============================] - 0s 36us/step - loss: 1.5003 - accuracy: 0.3226 - val_loss: 1.5235 - val_accuracy: 0.3142\n",
      "Epoch 21/80\n",
      "6435/6435 [==============================] - 0s 37us/step - loss: 1.4979 - accuracy: 0.3190 - val_loss: 1.5172 - val_accuracy: 0.3184\n",
      "Epoch 22/80\n",
      "6435/6435 [==============================] - 0s 36us/step - loss: 1.4972 - accuracy: 0.3242 - val_loss: 1.5141 - val_accuracy: 0.3115\n",
      "Epoch 23/80\n",
      "6435/6435 [==============================] - 0s 36us/step - loss: 1.4920 - accuracy: 0.3251 - val_loss: 1.5220 - val_accuracy: 0.3156\n",
      "Epoch 24/80\n",
      "6435/6435 [==============================] - 0s 39us/step - loss: 1.4868 - accuracy: 0.3207 - val_loss: 1.5226 - val_accuracy: 0.2975\n",
      "Epoch 25/80\n",
      "6435/6435 [==============================] - 0s 40us/step - loss: 1.4854 - accuracy: 0.3229 - val_loss: 1.5115 - val_accuracy: 0.2919\n",
      "Epoch 26/80\n",
      "6435/6435 [==============================] - 0s 39us/step - loss: 1.4836 - accuracy: 0.3221 - val_loss: 1.5359 - val_accuracy: 0.3170\n",
      "Epoch 27/80\n",
      "6435/6435 [==============================] - 0s 41us/step - loss: 1.4782 - accuracy: 0.3287 - val_loss: 1.5040 - val_accuracy: 0.3296\n",
      "Epoch 28/80\n",
      "6435/6435 [==============================] - 0s 36us/step - loss: 1.4744 - accuracy: 0.3262 - val_loss: 1.4960 - val_accuracy: 0.3282\n",
      "Epoch 29/80\n",
      "6435/6435 [==============================] - 0s 39us/step - loss: 1.4781 - accuracy: 0.3159 - val_loss: 1.4931 - val_accuracy: 0.3142\n",
      "Epoch 30/80\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6435/6435 [==============================] - 0s 41us/step - loss: 1.4711 - accuracy: 0.3156 - val_loss: 1.5037 - val_accuracy: 0.3310\n",
      "Epoch 31/80\n",
      "6435/6435 [==============================] - 0s 37us/step - loss: 1.4734 - accuracy: 0.3204 - val_loss: 1.4830 - val_accuracy: 0.3338\n",
      "Epoch 32/80\n",
      "6435/6435 [==============================] - 0s 36us/step - loss: 1.4615 - accuracy: 0.3260 - val_loss: 1.4834 - val_accuracy: 0.3366\n",
      "Epoch 33/80\n",
      "6435/6435 [==============================] - 0s 39us/step - loss: 1.4596 - accuracy: 0.3237 - val_loss: 1.4789 - val_accuracy: 0.3338\n",
      "Epoch 34/80\n",
      "6435/6435 [==============================] - 0s 39us/step - loss: 1.4541 - accuracy: 0.3416 - val_loss: 1.4716 - val_accuracy: 0.3324\n",
      "Epoch 35/80\n",
      "6435/6435 [==============================] - 0s 36us/step - loss: 1.4515 - accuracy: 0.3374 - val_loss: 1.4826 - val_accuracy: 0.3352\n",
      "Epoch 36/80\n",
      "6435/6435 [==============================] - 0s 39us/step - loss: 1.4452 - accuracy: 0.3374 - val_loss: 1.4603 - val_accuracy: 0.3338\n",
      "Epoch 37/80\n",
      "6435/6435 [==============================] - 0s 42us/step - loss: 1.4366 - accuracy: 0.3510 - val_loss: 1.4726 - val_accuracy: 0.3659\n",
      "Epoch 38/80\n",
      "6435/6435 [==============================] - 0s 35us/step - loss: 1.4281 - accuracy: 0.3476 - val_loss: 1.4478 - val_accuracy: 0.3324\n",
      "Epoch 39/80\n",
      "6435/6435 [==============================] - 0s 40us/step - loss: 1.4157 - accuracy: 0.3644 - val_loss: 1.4316 - val_accuracy: 0.3561\n",
      "Epoch 40/80\n",
      "6435/6435 [==============================] - 0s 41us/step - loss: 1.4038 - accuracy: 0.3636 - val_loss: 1.4059 - val_accuracy: 0.3617\n",
      "Epoch 41/80\n",
      "6435/6435 [==============================] - 0s 36us/step - loss: 1.3902 - accuracy: 0.3691 - val_loss: 1.4004 - val_accuracy: 0.3575\n",
      "Epoch 42/80\n",
      "6435/6435 [==============================] - 0s 34us/step - loss: 1.3782 - accuracy: 0.3703 - val_loss: 1.3710 - val_accuracy: 0.3715\n",
      "Epoch 43/80\n",
      "6435/6435 [==============================] - 0s 44us/step - loss: 1.3539 - accuracy: 0.3768 - val_loss: 1.3731 - val_accuracy: 0.3883\n",
      "Epoch 44/80\n",
      "6435/6435 [==============================] - 0s 34us/step - loss: 1.3467 - accuracy: 0.3815 - val_loss: 1.3453 - val_accuracy: 0.3939\n",
      "Epoch 45/80\n",
      "6435/6435 [==============================] - 0s 39us/step - loss: 1.3262 - accuracy: 0.3806 - val_loss: 1.3559 - val_accuracy: 0.3520\n",
      "Epoch 46/80\n",
      "6435/6435 [==============================] - 0s 39us/step - loss: 1.3188 - accuracy: 0.3747 - val_loss: 1.3322 - val_accuracy: 0.3855\n",
      "Epoch 47/80\n",
      "6435/6435 [==============================] - 0s 36us/step - loss: 1.3089 - accuracy: 0.3776 - val_loss: 1.3200 - val_accuracy: 0.3869\n",
      "Epoch 48/80\n",
      "6435/6435 [==============================] - 0s 41us/step - loss: 1.2957 - accuracy: 0.3860 - val_loss: 1.3237 - val_accuracy: 0.3785\n",
      "Epoch 49/80\n",
      "6435/6435 [==============================] - 0s 46us/step - loss: 1.2966 - accuracy: 0.3879 - val_loss: 1.3160 - val_accuracy: 0.3911\n",
      "Epoch 50/80\n",
      "6435/6435 [==============================] - 0s 34us/step - loss: 1.2891 - accuracy: 0.3843 - val_loss: 1.2902 - val_accuracy: 0.4008\n",
      "Epoch 51/80\n",
      "6435/6435 [==============================] - 0s 36us/step - loss: 1.2870 - accuracy: 0.3927 - val_loss: 1.3148 - val_accuracy: 0.4078\n",
      "Epoch 52/80\n",
      "6435/6435 [==============================] - 0s 36us/step - loss: 1.2960 - accuracy: 0.3851 - val_loss: 1.3273 - val_accuracy: 0.3855\n",
      "Epoch 53/80\n",
      "6435/6435 [==============================] - 0s 36us/step - loss: 1.2790 - accuracy: 0.3883 - val_loss: 1.2912 - val_accuracy: 0.3827\n",
      "Epoch 54/80\n",
      "6435/6435 [==============================] - 0s 38us/step - loss: 1.2774 - accuracy: 0.3950 - val_loss: 1.2912 - val_accuracy: 0.3855\n",
      "Epoch 55/80\n",
      "6435/6435 [==============================] - 0s 37us/step - loss: 1.2776 - accuracy: 0.3905 - val_loss: 1.2851 - val_accuracy: 0.3911\n",
      "Epoch 56/80\n",
      "6435/6435 [==============================] - 0s 36us/step - loss: 1.2727 - accuracy: 0.3939 - val_loss: 1.2896 - val_accuracy: 0.3939\n",
      "Epoch 57/80\n",
      "6435/6435 [==============================] - 0s 36us/step - loss: 1.2653 - accuracy: 0.3941 - val_loss: 1.2705 - val_accuracy: 0.4260\n",
      "Epoch 58/80\n",
      "6435/6435 [==============================] - 0s 37us/step - loss: 1.2652 - accuracy: 0.3873 - val_loss: 1.2779 - val_accuracy: 0.4050\n",
      "Epoch 59/80\n",
      "6435/6435 [==============================] - 0s 40us/step - loss: 1.2665 - accuracy: 0.3885 - val_loss: 1.2888 - val_accuracy: 0.3771\n",
      "Epoch 60/80\n",
      "6435/6435 [==============================] - 0s 38us/step - loss: 1.2702 - accuracy: 0.3922 - val_loss: 1.2670 - val_accuracy: 0.3827\n",
      "Epoch 61/80\n",
      "6435/6435 [==============================] - 0s 37us/step - loss: 1.2550 - accuracy: 0.3938 - val_loss: 1.2565 - val_accuracy: 0.4022\n",
      "Epoch 62/80\n",
      "6435/6435 [==============================] - 0s 36us/step - loss: 1.2508 - accuracy: 0.3992 - val_loss: 1.2577 - val_accuracy: 0.3897\n",
      "Epoch 63/80\n",
      "6435/6435 [==============================] - 0s 39us/step - loss: 1.2483 - accuracy: 0.3975 - val_loss: 1.2711 - val_accuracy: 0.3897\n",
      "Epoch 64/80\n",
      "6435/6435 [==============================] - 0s 38us/step - loss: 1.2530 - accuracy: 0.4009 - val_loss: 1.2588 - val_accuracy: 0.3897\n",
      "Epoch 65/80\n",
      "6435/6435 [==============================] - 0s 35us/step - loss: 1.2517 - accuracy: 0.3950 - val_loss: 1.2465 - val_accuracy: 0.4106\n",
      "Epoch 66/80\n",
      "6435/6435 [==============================] - 0s 39us/step - loss: 1.2437 - accuracy: 0.3997 - val_loss: 1.2451 - val_accuracy: 0.4008\n",
      "Epoch 67/80\n",
      "6435/6435 [==============================] - 0s 36us/step - loss: 1.2417 - accuracy: 0.4034 - val_loss: 1.2425 - val_accuracy: 0.4008\n",
      "Epoch 68/80\n",
      "6435/6435 [==============================] - 0s 32us/step - loss: 1.2410 - accuracy: 0.3955 - val_loss: 1.2511 - val_accuracy: 0.4022\n",
      "Epoch 69/80\n",
      "6435/6435 [==============================] - 0s 34us/step - loss: 1.2402 - accuracy: 0.3963 - val_loss: 1.2501 - val_accuracy: 0.4106\n",
      "Epoch 70/80\n",
      "6435/6435 [==============================] - 0s 34us/step - loss: 1.2332 - accuracy: 0.3947 - val_loss: 1.2535 - val_accuracy: 0.3743\n",
      "Epoch 71/80\n",
      "6435/6435 [==============================] - 0s 32us/step - loss: 1.2333 - accuracy: 0.4050 - val_loss: 1.2377 - val_accuracy: 0.4008\n",
      "Epoch 72/80\n",
      "6435/6435 [==============================] - 0s 34us/step - loss: 1.2297 - accuracy: 0.4034 - val_loss: 1.2296 - val_accuracy: 0.4050\n",
      "Epoch 73/80\n",
      "6435/6435 [==============================] - 0s 34us/step - loss: 1.2345 - accuracy: 0.3998 - val_loss: 1.2405 - val_accuracy: 0.3980\n",
      "Epoch 74/80\n",
      "6435/6435 [==============================] - 0s 39us/step - loss: 1.2266 - accuracy: 0.4047 - val_loss: 1.2350 - val_accuracy: 0.3939\n",
      "Epoch 75/80\n",
      "6435/6435 [==============================] - 0s 34us/step - loss: 1.2302 - accuracy: 0.4016 - val_loss: 1.2366 - val_accuracy: 0.3701\n",
      "Epoch 76/80\n",
      "6435/6435 [==============================] - 0s 34us/step - loss: 1.2320 - accuracy: 0.3967 - val_loss: 1.2425 - val_accuracy: 0.3980\n",
      "Epoch 77/80\n",
      "6435/6435 [==============================] - 0s 34us/step - loss: 1.2351 - accuracy: 0.3879 - val_loss: 1.2310 - val_accuracy: 0.3785\n",
      "Epoch 78/80\n",
      "6435/6435 [==============================] - 0s 36us/step - loss: 1.2261 - accuracy: 0.4056 - val_loss: 1.2306 - val_accuracy: 0.4064\n",
      "Epoch 79/80\n",
      "6435/6435 [==============================] - 0s 36us/step - loss: 1.2203 - accuracy: 0.4040 - val_loss: 1.2617 - val_accuracy: 0.3883\n",
      "Epoch 80/80\n",
      "6435/6435 [==============================] - 0s 39us/step - loss: 1.2254 - accuracy: 0.4090 - val_loss: 1.2246 - val_accuracy: 0.3841\n",
      "[[1.3727374e-01 9.4866179e-02 1.4134905e-03 ... 3.3850706e-01\n",
      "  1.9479178e-01 2.1887998e-01]\n",
      " [4.9179506e-02 3.2101765e-02 3.1165045e-01 ... 1.2884799e-03\n",
      "  1.2136044e-02 1.2764988e-02]\n",
      " [2.6430508e-01 1.5255572e-01 1.7949945e-03 ... 8.5727043e-02\n",
      "  2.2154765e-01 2.7346149e-01]\n",
      " ...\n",
      " [3.0832830e-01 1.9650042e-01 3.5337964e-04 ... 7.7859713e-03\n",
      "  2.2569540e-01 2.6118580e-01]\n",
      " [1.0304869e-01 7.3754787e-02 1.6092561e-04 ... 1.3853291e-01\n",
      "  2.9975328e-01 3.6990663e-01]\n",
      " [1.2397859e-01 8.5338883e-02 2.7210472e-04 ... 1.7121005e-01\n",
      "  2.7751663e-01 3.3212686e-01]]\n",
      "[11  2 13 ...  0 13 13]\n",
      "<class 'numpy.ndarray'>\n",
      "One CNN, r:  0\n",
      "Computing Time:  0:11:26.812012\n",
      "n, p1, p2 31 2 6\n",
      "Model: \"sequential_1\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv1d_1 (Conv1D)            (None, 3, 6)              12        \n",
      "_________________________________________________________________\n",
      "average_pooling1d_1 (Average (None, 1, 6)              0         \n",
      "_________________________________________________________________\n",
      "conv1d_2 (Conv1D)            (None, 1, 16)             112       \n",
      "_________________________________________________________________\n",
      "average_pooling1d_2 (Average (None, 1, 16)             0         \n",
      "_________________________________________________________________\n",
      "conv1d_3 (Conv1D)            (None, 1, 120)            2040      \n",
      "_________________________________________________________________\n",
      "flatten_1 (Flatten)          (None, 120)               0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 84)                10164     \n",
      "_________________________________________________________________\n",
      "preds (Dense)                (None, 14)                1190      \n",
      "=================================================================\n",
      "Total params: 13,518\n",
      "Trainable params: 13,518\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 6435 samples, validate on 716 samples\n",
      "Epoch 1/80\n",
      "6435/6435 [==============================] - 0s 73us/step - loss: 2.6136 - accuracy: 0.1409 - val_loss: 2.5417 - val_accuracy: 0.1732\n",
      "Epoch 2/80\n",
      "6435/6435 [==============================] - 0s 41us/step - loss: 2.3768 - accuracy: 0.1613 - val_loss: 2.1438 - val_accuracy: 0.1788\n",
      "Epoch 3/80\n",
      "6435/6435 [==============================] - 0s 36us/step - loss: 2.0657 - accuracy: 0.2053 - val_loss: 1.9418 - val_accuracy: 0.2612\n",
      "Epoch 4/80\n",
      "6435/6435 [==============================] - 0s 36us/step - loss: 1.9493 - accuracy: 0.2483 - val_loss: 1.8664 - val_accuracy: 0.2696\n",
      "Epoch 5/80\n",
      "6435/6435 [==============================] - 0s 36us/step - loss: 1.8859 - accuracy: 0.2591 - val_loss: 1.8090 - val_accuracy: 0.2779\n",
      "Epoch 6/80\n",
      "6435/6435 [==============================] - 0s 41us/step - loss: 1.8235 - accuracy: 0.2667 - val_loss: 1.7533 - val_accuracy: 0.2793\n",
      "Epoch 7/80\n",
      "6435/6435 [==============================] - 0s 44us/step - loss: 1.7640 - accuracy: 0.2733 - val_loss: 1.6974 - val_accuracy: 0.3031\n",
      "Epoch 8/80\n",
      "6435/6435 [==============================] - 0s 44us/step - loss: 1.7162 - accuracy: 0.2936 - val_loss: 1.6692 - val_accuracy: 0.2863\n",
      "Epoch 9/80\n",
      "6435/6435 [==============================] - 0s 39us/step - loss: 1.6870 - accuracy: 0.2805 - val_loss: 1.6216 - val_accuracy: 0.2961\n",
      "Epoch 10/80\n",
      "6435/6435 [==============================] - 0s 39us/step - loss: 1.6480 - accuracy: 0.2990 - val_loss: 1.5884 - val_accuracy: 0.3282\n",
      "Epoch 11/80\n",
      "6435/6435 [==============================] - 0s 39us/step - loss: 1.6171 - accuracy: 0.3026 - val_loss: 1.5700 - val_accuracy: 0.3128\n",
      "Epoch 12/80\n",
      "6435/6435 [==============================] - 0s 36us/step - loss: 1.6002 - accuracy: 0.2996 - val_loss: 1.5687 - val_accuracy: 0.3059\n",
      "Epoch 13/80\n",
      "6435/6435 [==============================] - 0s 39us/step - loss: 1.5834 - accuracy: 0.2970 - val_loss: 1.5346 - val_accuracy: 0.3101\n",
      "Epoch 14/80\n",
      "6435/6435 [==============================] - 0s 36us/step - loss: 1.5690 - accuracy: 0.3051 - val_loss: 1.5193 - val_accuracy: 0.3324\n",
      "Epoch 15/80\n",
      "6435/6435 [==============================] - 0s 34us/step - loss: 1.5624 - accuracy: 0.3089 - val_loss: 1.5329 - val_accuracy: 0.2989\n",
      "Epoch 16/80\n",
      "6435/6435 [==============================] - 0s 39us/step - loss: 1.5563 - accuracy: 0.3033 - val_loss: 1.5154 - val_accuracy: 0.3142\n",
      "Epoch 17/80\n",
      "6435/6435 [==============================] - 0s 39us/step - loss: 1.5550 - accuracy: 0.3026 - val_loss: 1.5060 - val_accuracy: 0.3310\n",
      "Epoch 18/80\n",
      "6435/6435 [==============================] - 0s 39us/step - loss: 1.5533 - accuracy: 0.3046 - val_loss: 1.5208 - val_accuracy: 0.3128\n",
      "Epoch 19/80\n",
      "6435/6435 [==============================] - 0s 36us/step - loss: 1.5410 - accuracy: 0.3002 - val_loss: 1.5079 - val_accuracy: 0.3101\n",
      "Epoch 20/80\n",
      "6435/6435 [==============================] - 0s 39us/step - loss: 1.5379 - accuracy: 0.3068 - val_loss: 1.4960 - val_accuracy: 0.3296\n",
      "Epoch 21/80\n",
      "6435/6435 [==============================] - 0s 36us/step - loss: 1.5343 - accuracy: 0.3083 - val_loss: 1.5010 - val_accuracy: 0.3282\n",
      "Epoch 22/80\n",
      "6435/6435 [==============================] - 0s 39us/step - loss: 1.5320 - accuracy: 0.3078 - val_loss: 1.4994 - val_accuracy: 0.3101\n",
      "Epoch 23/80\n",
      "6435/6435 [==============================] - 0s 37us/step - loss: 1.5281 - accuracy: 0.3009 - val_loss: 1.4952 - val_accuracy: 0.3240\n",
      "Epoch 24/80\n",
      "6435/6435 [==============================] - 0s 36us/step - loss: 1.5258 - accuracy: 0.3046 - val_loss: 1.4887 - val_accuracy: 0.3310\n",
      "Epoch 25/80\n",
      "6435/6435 [==============================] - 0s 36us/step - loss: 1.5252 - accuracy: 0.3147 - val_loss: 1.5009 - val_accuracy: 0.3310\n",
      "Epoch 26/80\n",
      "6435/6435 [==============================] - 0s 39us/step - loss: 1.5194 - accuracy: 0.3106 - val_loss: 1.4911 - val_accuracy: 0.3310\n",
      "Epoch 27/80\n",
      "6435/6435 [==============================] - 0s 41us/step - loss: 1.5185 - accuracy: 0.3071 - val_loss: 1.4857 - val_accuracy: 0.3212\n",
      "Epoch 28/80\n",
      "6435/6435 [==============================] - 0s 46us/step - loss: 1.5196 - accuracy: 0.3130 - val_loss: 1.4918 - val_accuracy: 0.3198\n",
      "Epoch 29/80\n",
      "6435/6435 [==============================] - 0s 41us/step - loss: 1.5204 - accuracy: 0.3083 - val_loss: 1.4774 - val_accuracy: 0.3128\n",
      "Epoch 30/80\n",
      "6435/6435 [==============================] - 0s 39us/step - loss: 1.5124 - accuracy: 0.3139 - val_loss: 1.4992 - val_accuracy: 0.3087\n",
      "Epoch 31/80\n",
      "6435/6435 [==============================] - 0s 39us/step - loss: 1.5096 - accuracy: 0.3214 - val_loss: 1.4704 - val_accuracy: 0.3198\n",
      "Epoch 32/80\n",
      "6435/6435 [==============================] - 0s 36us/step - loss: 1.5096 - accuracy: 0.3114 - val_loss: 1.4704 - val_accuracy: 0.3198\n",
      "Epoch 33/80\n",
      "6435/6435 [==============================] - 0s 39us/step - loss: 1.5144 - accuracy: 0.3122 - val_loss: 1.4833 - val_accuracy: 0.3268\n",
      "Epoch 34/80\n",
      "6435/6435 [==============================] - 0s 39us/step - loss: 1.5061 - accuracy: 0.3088 - val_loss: 1.4781 - val_accuracy: 0.3226\n",
      "Epoch 35/80\n",
      "6435/6435 [==============================] - 0s 36us/step - loss: 1.5060 - accuracy: 0.3110 - val_loss: 1.5082 - val_accuracy: 0.3268\n",
      "Epoch 36/80\n",
      "6435/6435 [==============================] - 0s 36us/step - loss: 1.5031 - accuracy: 0.3119 - val_loss: 1.5037 - val_accuracy: 0.3059\n",
      "Epoch 37/80\n",
      "6435/6435 [==============================] - 0s 44us/step - loss: 1.5008 - accuracy: 0.3190 - val_loss: 1.4817 - val_accuracy: 0.3142\n",
      "Epoch 38/80\n",
      "6435/6435 [==============================] - 0s 36us/step - loss: 1.5031 - accuracy: 0.3085 - val_loss: 1.4665 - val_accuracy: 0.3156\n",
      "Epoch 39/80\n",
      "6435/6435 [==============================] - 0s 41us/step - loss: 1.4996 - accuracy: 0.3071 - val_loss: 1.4899 - val_accuracy: 0.3087\n",
      "Epoch 40/80\n",
      "6435/6435 [==============================] - 0s 32us/step - loss: 1.5020 - accuracy: 0.3139 - val_loss: 1.4802 - val_accuracy: 0.3184\n",
      "Epoch 41/80\n",
      "6435/6435 [==============================] - 0s 39us/step - loss: 1.4944 - accuracy: 0.3152 - val_loss: 1.4897 - val_accuracy: 0.3198\n",
      "Epoch 42/80\n",
      "6435/6435 [==============================] - 0s 39us/step - loss: 1.4978 - accuracy: 0.3088 - val_loss: 1.4774 - val_accuracy: 0.3282\n",
      "Epoch 43/80\n",
      "6435/6435 [==============================] - 0s 39us/step - loss: 1.4986 - accuracy: 0.3153 - val_loss: 1.4761 - val_accuracy: 0.3240\n",
      "Epoch 44/80\n",
      "6435/6435 [==============================] - 0s 36us/step - loss: 1.4948 - accuracy: 0.3139 - val_loss: 1.4588 - val_accuracy: 0.3324\n",
      "Epoch 45/80\n",
      "6435/6435 [==============================] - 0s 39us/step - loss: 1.4946 - accuracy: 0.3161 - val_loss: 1.4927 - val_accuracy: 0.3198\n",
      "Epoch 46/80\n",
      "6435/6435 [==============================] - 0s 39us/step - loss: 1.4939 - accuracy: 0.3150 - val_loss: 1.4750 - val_accuracy: 0.3310\n",
      "Epoch 47/80\n",
      "6435/6435 [==============================] - 0s 39us/step - loss: 1.4889 - accuracy: 0.3162 - val_loss: 1.4620 - val_accuracy: 0.3268\n",
      "Epoch 48/80\n",
      "6435/6435 [==============================] - 0s 36us/step - loss: 1.4914 - accuracy: 0.3102 - val_loss: 1.4566 - val_accuracy: 0.3212\n",
      "Epoch 49/80\n",
      "6435/6435 [==============================] - 0s 36us/step - loss: 1.4871 - accuracy: 0.3040 - val_loss: 1.4630 - val_accuracy: 0.3184\n",
      "Epoch 50/80\n",
      "6435/6435 [==============================] - 0s 32us/step - loss: 1.4906 - accuracy: 0.3147 - val_loss: 1.4639 - val_accuracy: 0.3296\n",
      "Epoch 51/80\n",
      "6435/6435 [==============================] - 0s 39us/step - loss: 1.4911 - accuracy: 0.3206 - val_loss: 1.4676 - val_accuracy: 0.3254\n",
      "Epoch 52/80\n",
      "6435/6435 [==============================] - 0s 39us/step - loss: 1.4837 - accuracy: 0.3206 - val_loss: 1.4577 - val_accuracy: 0.3268\n",
      "Epoch 53/80\n",
      "6435/6435 [==============================] - 0s 36us/step - loss: 1.4852 - accuracy: 0.3197 - val_loss: 1.4610 - val_accuracy: 0.3142\n",
      "Epoch 54/80\n",
      "6435/6435 [==============================] - 0s 36us/step - loss: 1.4850 - accuracy: 0.3130 - val_loss: 1.4781 - val_accuracy: 0.3268\n",
      "Epoch 55/80\n",
      "6435/6435 [==============================] - 0s 41us/step - loss: 1.4867 - accuracy: 0.3100 - val_loss: 1.4476 - val_accuracy: 0.3352\n",
      "Epoch 56/80\n",
      "6435/6435 [==============================] - 0s 36us/step - loss: 1.4835 - accuracy: 0.3181 - val_loss: 1.4528 - val_accuracy: 0.3296\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 57/80\n",
      "6435/6435 [==============================] - 0s 36us/step - loss: 1.4816 - accuracy: 0.3166 - val_loss: 1.4686 - val_accuracy: 0.2989\n",
      "Epoch 58/80\n",
      "6435/6435 [==============================] - 0s 36us/step - loss: 1.4813 - accuracy: 0.3144 - val_loss: 1.4533 - val_accuracy: 0.3380\n",
      "Epoch 59/80\n",
      "6435/6435 [==============================] - 0s 41us/step - loss: 1.4776 - accuracy: 0.3240 - val_loss: 1.4577 - val_accuracy: 0.3282\n",
      "Epoch 60/80\n",
      "6435/6435 [==============================] - 0s 41us/step - loss: 1.4787 - accuracy: 0.3221 - val_loss: 1.4572 - val_accuracy: 0.3184\n",
      "Epoch 61/80\n",
      "6435/6435 [==============================] - 0s 39us/step - loss: 1.4760 - accuracy: 0.3179 - val_loss: 1.4506 - val_accuracy: 0.3422\n",
      "Epoch 62/80\n",
      "6435/6435 [==============================] - 0s 39us/step - loss: 1.4739 - accuracy: 0.3229 - val_loss: 1.4563 - val_accuracy: 0.3268\n",
      "Epoch 63/80\n",
      "6435/6435 [==============================] - 0s 39us/step - loss: 1.4775 - accuracy: 0.3235 - val_loss: 1.4698 - val_accuracy: 0.3296\n",
      "Epoch 64/80\n",
      "6435/6435 [==============================] - 0s 36us/step - loss: 1.4749 - accuracy: 0.3201 - val_loss: 1.4605 - val_accuracy: 0.3156\n",
      "Epoch 65/80\n",
      "6435/6435 [==============================] - 0s 39us/step - loss: 1.4719 - accuracy: 0.3271 - val_loss: 1.4506 - val_accuracy: 0.3310\n",
      "Epoch 00065: early stopping\n",
      "[[1.5189716e-01 1.7720935e-01 7.5700722e-04 ... 1.8682277e-01\n",
      "  1.8942389e-01 2.5685862e-01]\n",
      " [3.4376319e-02 4.2015836e-02 5.3899583e-08 ... 6.8720249e-03\n",
      "  9.8681683e-03 1.5108404e-02]\n",
      " [1.5630944e-01 1.8513547e-01 7.3608026e-05 ... 2.3204888e-01\n",
      "  1.7708208e-01 2.2764969e-01]\n",
      " ...\n",
      " [1.5747280e-01 1.8575351e-01 9.7551027e-05 ... 2.2484708e-01\n",
      "  1.7920616e-01 2.3164040e-01]\n",
      " [1.4379910e-01 1.6532591e-01 4.8923395e-03 ... 1.4913805e-01\n",
      "  1.9262339e-01 2.7260190e-01]\n",
      " [1.4762394e-01 1.7056969e-01 2.5085192e-03 ... 1.6249606e-01\n",
      "  1.9252907e-01 2.6825693e-01]]\n",
      "[13  5 11 ... 13 13 13]\n",
      "<class 'numpy.ndarray'>\n",
      "One CNN, r:  0\n",
      "Computing Time:  0:11:44.489573\n",
      "n, p1, p2 32 2 7\n",
      "Model: \"sequential_1\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv1d_1 (Conv1D)            (None, 3, 6)              12        \n",
      "_________________________________________________________________\n",
      "average_pooling1d_1 (Average (None, 1, 6)              0         \n",
      "_________________________________________________________________\n",
      "conv1d_2 (Conv1D)            (None, 1, 16)             112       \n",
      "_________________________________________________________________\n",
      "average_pooling1d_2 (Average (None, 1, 16)             0         \n",
      "_________________________________________________________________\n",
      "conv1d_3 (Conv1D)            (None, 1, 120)            2040      \n",
      "_________________________________________________________________\n",
      "flatten_1 (Flatten)          (None, 120)               0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 84)                10164     \n",
      "_________________________________________________________________\n",
      "preds (Dense)                (None, 14)                1190      \n",
      "=================================================================\n",
      "Total params: 13,518\n",
      "Trainable params: 13,518\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Train on 6435 samples, validate on 716 samples\n",
      "Epoch 1/80\n",
      "6435/6435 [==============================] - 0s 70us/step - loss: 2.6112 - accuracy: 0.1237 - val_loss: 2.5376 - val_accuracy: 0.1494\n",
      "Epoch 2/80\n",
      "6435/6435 [==============================] - 0s 39us/step - loss: 2.3305 - accuracy: 0.1655 - val_loss: 2.1193 - val_accuracy: 0.2011\n",
      "Epoch 3/80\n",
      "6435/6435 [==============================] - 0s 36us/step - loss: 1.9970 - accuracy: 0.2255 - val_loss: 1.9462 - val_accuracy: 0.2989\n",
      "Epoch 4/80\n",
      "6435/6435 [==============================] - 0s 36us/step - loss: 1.8682 - accuracy: 0.2785 - val_loss: 1.8646 - val_accuracy: 0.2751\n",
      "Epoch 5/80\n",
      "6435/6435 [==============================] - 0s 39us/step - loss: 1.7925 - accuracy: 0.2828 - val_loss: 1.8017 - val_accuracy: 0.2835\n",
      "Epoch 6/80\n",
      "6435/6435 [==============================] - 0s 36us/step - loss: 1.7332 - accuracy: 0.2928 - val_loss: 1.7366 - val_accuracy: 0.3059\n",
      "Epoch 7/80\n",
      "6435/6435 [==============================] - 0s 39us/step - loss: 1.6724 - accuracy: 0.2996 - val_loss: 1.6868 - val_accuracy: 0.3031\n",
      "Epoch 8/80\n",
      "6435/6435 [==============================] - 0s 39us/step - loss: 1.6368 - accuracy: 0.2956 - val_loss: 1.6653 - val_accuracy: 0.3003\n",
      "Epoch 9/80\n",
      "6435/6435 [==============================] - 0s 41us/step - loss: 1.6082 - accuracy: 0.3004 - val_loss: 1.6214 - val_accuracy: 0.2961\n",
      "Epoch 10/80\n",
      "6435/6435 [==============================] - 0s 39us/step - loss: 1.5778 - accuracy: 0.3055 - val_loss: 1.5961 - val_accuracy: 0.2919\n",
      "Epoch 11/80\n",
      "6435/6435 [==============================] - 0s 39us/step - loss: 1.5630 - accuracy: 0.3077 - val_loss: 1.5925 - val_accuracy: 0.3156\n",
      "Epoch 12/80\n",
      "6435/6435 [==============================] - 0s 39us/step - loss: 1.5619 - accuracy: 0.2970 - val_loss: 1.5923 - val_accuracy: 0.3073\n",
      "Epoch 13/80\n",
      "6435/6435 [==============================] - 0s 39us/step - loss: 1.5450 - accuracy: 0.3105 - val_loss: 1.5805 - val_accuracy: 0.3142\n",
      "Epoch 14/80\n",
      "6435/6435 [==============================] - 0s 36us/step - loss: 1.5407 - accuracy: 0.3082 - val_loss: 1.5666 - val_accuracy: 0.3324\n",
      "Epoch 15/80\n",
      "6435/6435 [==============================] - 0s 36us/step - loss: 1.5350 - accuracy: 0.3072 - val_loss: 1.5575 - val_accuracy: 0.3115\n",
      "Epoch 16/80\n",
      "6435/6435 [==============================] - 0s 36us/step - loss: 1.5333 - accuracy: 0.3058 - val_loss: 1.5633 - val_accuracy: 0.3101\n",
      "Epoch 17/80\n",
      "6435/6435 [==============================] - 0s 39us/step - loss: 1.5232 - accuracy: 0.3155 - val_loss: 1.5489 - val_accuracy: 0.3198\n",
      "Epoch 18/80\n",
      "6435/6435 [==============================] - 0s 36us/step - loss: 1.5183 - accuracy: 0.3170 - val_loss: 1.5571 - val_accuracy: 0.3128\n",
      "Epoch 19/80\n",
      "6435/6435 [==============================] - 0s 39us/step - loss: 1.5209 - accuracy: 0.3124 - val_loss: 1.5545 - val_accuracy: 0.3045\n",
      "Epoch 20/80\n",
      "6435/6435 [==============================] - 0s 36us/step - loss: 1.5153 - accuracy: 0.3156 - val_loss: 1.5486 - val_accuracy: 0.3282\n",
      "Epoch 21/80\n",
      "6435/6435 [==============================] - 0s 39us/step - loss: 1.5057 - accuracy: 0.3245 - val_loss: 1.5390 - val_accuracy: 0.3268\n",
      "Epoch 22/80\n",
      "6435/6435 [==============================] - 0s 42us/step - loss: 1.5063 - accuracy: 0.3234 - val_loss: 1.5439 - val_accuracy: 0.3296\n",
      "Epoch 23/80\n",
      "6435/6435 [==============================] - 0s 39us/step - loss: 1.5017 - accuracy: 0.3159 - val_loss: 1.5268 - val_accuracy: 0.3198\n",
      "Epoch 24/80\n",
      "6435/6435 [==============================] - 0s 38us/step - loss: 1.4996 - accuracy: 0.3152 - val_loss: 1.5338 - val_accuracy: 0.3366\n",
      "Epoch 25/80\n",
      "6435/6435 [==============================] - 0s 38us/step - loss: 1.4972 - accuracy: 0.3212 - val_loss: 1.5377 - val_accuracy: 0.3156\n",
      "Epoch 26/80\n",
      "6435/6435 [==============================] - 0s 39us/step - loss: 1.4948 - accuracy: 0.3198 - val_loss: 1.5241 - val_accuracy: 0.3534\n",
      "Epoch 27/80\n",
      "6435/6435 [==============================] - 0s 38us/step - loss: 1.4938 - accuracy: 0.3201 - val_loss: 1.5267 - val_accuracy: 0.3212\n",
      "Epoch 28/80\n",
      "6435/6435 [==============================] - 0s 33us/step - loss: 1.4933 - accuracy: 0.3152 - val_loss: 1.5707 - val_accuracy: 0.3184\n",
      "Epoch 29/80\n",
      "6435/6435 [==============================] - 0s 36us/step - loss: 1.4920 - accuracy: 0.3215 - val_loss: 1.5187 - val_accuracy: 0.3534\n",
      "Epoch 30/80\n",
      "6435/6435 [==============================] - 0s 41us/step - loss: 1.4829 - accuracy: 0.3218 - val_loss: 1.5194 - val_accuracy: 0.3520\n",
      "Epoch 31/80\n",
      "6435/6435 [==============================] - 0s 36us/step - loss: 1.4797 - accuracy: 0.3284 - val_loss: 1.5156 - val_accuracy: 0.3380\n",
      "Epoch 32/80\n",
      "6435/6435 [==============================] - 0s 44us/step - loss: 1.4840 - accuracy: 0.3242 - val_loss: 1.5148 - val_accuracy: 0.3128\n",
      "Epoch 33/80\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6435/6435 [==============================] - 0s 39us/step - loss: 1.4776 - accuracy: 0.3256 - val_loss: 1.5074 - val_accuracy: 0.3520\n",
      "Epoch 34/80\n",
      "6435/6435 [==============================] - 0s 40us/step - loss: 1.4750 - accuracy: 0.3218 - val_loss: 1.5173 - val_accuracy: 0.3520\n",
      "Epoch 35/80\n",
      "6435/6435 [==============================] - 0s 40us/step - loss: 1.4724 - accuracy: 0.3239 - val_loss: 1.5117 - val_accuracy: 0.3408\n",
      "Epoch 36/80\n",
      "6435/6435 [==============================] - 0s 42us/step - loss: 1.4697 - accuracy: 0.3352 - val_loss: 1.4989 - val_accuracy: 0.3659\n",
      "Epoch 37/80\n",
      "6435/6435 [==============================] - 0s 38us/step - loss: 1.4667 - accuracy: 0.3324 - val_loss: 1.5015 - val_accuracy: 0.3366\n",
      "Epoch 38/80\n",
      "6435/6435 [==============================] - 0s 37us/step - loss: 1.4609 - accuracy: 0.3335 - val_loss: 1.4931 - val_accuracy: 0.3534\n",
      "Epoch 39/80\n",
      "6435/6435 [==============================] - 0s 36us/step - loss: 1.4579 - accuracy: 0.3302 - val_loss: 1.4977 - val_accuracy: 0.3352\n",
      "Epoch 40/80\n",
      "6435/6435 [==============================] - 0s 41us/step - loss: 1.4516 - accuracy: 0.3557 - val_loss: 1.4822 - val_accuracy: 0.3855\n",
      "Epoch 41/80\n",
      "6435/6435 [==============================] - 0s 37us/step - loss: 1.4492 - accuracy: 0.3489 - val_loss: 1.4799 - val_accuracy: 0.3659\n",
      "Epoch 42/80\n",
      "6435/6435 [==============================] - 0s 36us/step - loss: 1.4422 - accuracy: 0.3481 - val_loss: 1.4854 - val_accuracy: 0.3561\n",
      "Epoch 43/80\n",
      "6435/6435 [==============================] - 0s 39us/step - loss: 1.4382 - accuracy: 0.3565 - val_loss: 1.4744 - val_accuracy: 0.3394\n",
      "Epoch 44/80\n",
      "6435/6435 [==============================] - 0s 36us/step - loss: 1.4357 - accuracy: 0.3560 - val_loss: 1.4638 - val_accuracy: 0.3701\n",
      "Epoch 45/80\n",
      "6435/6435 [==============================] - 0s 39us/step - loss: 1.4269 - accuracy: 0.3590 - val_loss: 1.4491 - val_accuracy: 0.3701\n",
      "Epoch 46/80\n",
      "6435/6435 [==============================] - 0s 36us/step - loss: 1.4114 - accuracy: 0.3714 - val_loss: 1.4295 - val_accuracy: 0.3589\n",
      "Epoch 47/80\n",
      "6435/6435 [==============================] - 0s 35us/step - loss: 1.4014 - accuracy: 0.3711 - val_loss: 1.4220 - val_accuracy: 0.3534\n",
      "Epoch 48/80\n",
      "6435/6435 [==============================] - 0s 36us/step - loss: 1.3903 - accuracy: 0.3699 - val_loss: 1.4143 - val_accuracy: 0.3645\n",
      "Epoch 49/80\n",
      "6435/6435 [==============================] - 0s 36us/step - loss: 1.3800 - accuracy: 0.3641 - val_loss: 1.3893 - val_accuracy: 0.3799\n",
      "Epoch 50/80\n",
      "6435/6435 [==============================] - 0s 36us/step - loss: 1.3560 - accuracy: 0.3737 - val_loss: 1.3729 - val_accuracy: 0.3743\n",
      "Epoch 51/80\n",
      "6435/6435 [==============================] - 0s 38us/step - loss: 1.3411 - accuracy: 0.3784 - val_loss: 1.3784 - val_accuracy: 0.4022\n",
      "Epoch 52/80\n",
      "6435/6435 [==============================] - 0s 35us/step - loss: 1.3343 - accuracy: 0.3765 - val_loss: 1.3498 - val_accuracy: 0.3715\n",
      "Epoch 53/80\n",
      "6435/6435 [==============================] - 0s 38us/step - loss: 1.3223 - accuracy: 0.3838 - val_loss: 1.3337 - val_accuracy: 0.3883\n",
      "Epoch 54/80\n",
      "6435/6435 [==============================] - 0s 38us/step - loss: 1.3139 - accuracy: 0.3832 - val_loss: 1.3408 - val_accuracy: 0.3827\n",
      "Epoch 55/80\n",
      "6435/6435 [==============================] - 0s 36us/step - loss: 1.3106 - accuracy: 0.3784 - val_loss: 1.3241 - val_accuracy: 0.3911\n",
      "Epoch 56/80\n",
      "6435/6435 [==============================] - 0s 36us/step - loss: 1.3000 - accuracy: 0.3908 - val_loss: 1.3201 - val_accuracy: 0.3771\n",
      "Epoch 57/80\n",
      "6435/6435 [==============================] - 0s 36us/step - loss: 1.2973 - accuracy: 0.3935 - val_loss: 1.3043 - val_accuracy: 0.4050\n",
      "Epoch 58/80\n",
      "6435/6435 [==============================] - 0s 36us/step - loss: 1.2983 - accuracy: 0.3910 - val_loss: 1.3111 - val_accuracy: 0.3757\n",
      "Epoch 59/80\n",
      "6435/6435 [==============================] - 0s 36us/step - loss: 1.2937 - accuracy: 0.3829 - val_loss: 1.3135 - val_accuracy: 0.4008\n",
      "Epoch 60/80\n",
      "6435/6435 [==============================] - 0s 33us/step - loss: 1.2870 - accuracy: 0.3910 - val_loss: 1.3051 - val_accuracy: 0.4050\n",
      "Epoch 61/80\n",
      "6435/6435 [==============================] - 0s 35us/step - loss: 1.2815 - accuracy: 0.3944 - val_loss: 1.3015 - val_accuracy: 0.3925\n",
      "Epoch 62/80\n",
      "6435/6435 [==============================] - 0s 35us/step - loss: 1.2847 - accuracy: 0.3848 - val_loss: 1.2997 - val_accuracy: 0.3813\n",
      "Epoch 63/80\n",
      "6435/6435 [==============================] - 0s 36us/step - loss: 1.2760 - accuracy: 0.3911 - val_loss: 1.2895 - val_accuracy: 0.3897\n",
      "Epoch 64/80\n",
      "6435/6435 [==============================] - 0s 37us/step - loss: 1.2686 - accuracy: 0.3956 - val_loss: 1.3020 - val_accuracy: 0.3939\n",
      "Epoch 65/80\n",
      "6435/6435 [==============================] - 0s 36us/step - loss: 1.2754 - accuracy: 0.3829 - val_loss: 1.2975 - val_accuracy: 0.4036\n",
      "Epoch 66/80\n",
      "6435/6435 [==============================] - 0s 41us/step - loss: 1.2705 - accuracy: 0.3902 - val_loss: 1.2972 - val_accuracy: 0.3939\n",
      "Epoch 67/80\n",
      "6435/6435 [==============================] - 0s 36us/step - loss: 1.2683 - accuracy: 0.3910 - val_loss: 1.2801 - val_accuracy: 0.4134\n",
      "Epoch 68/80\n",
      "6435/6435 [==============================] - 0s 38us/step - loss: 1.2637 - accuracy: 0.3925 - val_loss: 1.2951 - val_accuracy: 0.3799\n",
      "Epoch 69/80\n",
      "6435/6435 [==============================] - 0s 34us/step - loss: 1.2654 - accuracy: 0.3930 - val_loss: 1.2733 - val_accuracy: 0.4190\n",
      "Epoch 70/80\n",
      "6435/6435 [==============================] - 0s 37us/step - loss: 1.2655 - accuracy: 0.3854 - val_loss: 1.2737 - val_accuracy: 0.3953\n",
      "Epoch 71/80\n",
      "6435/6435 [==============================] - 0s 36us/step - loss: 1.2617 - accuracy: 0.3904 - val_loss: 1.2876 - val_accuracy: 0.3799\n",
      "Epoch 72/80\n",
      "6435/6435 [==============================] - 0s 39us/step - loss: 1.2573 - accuracy: 0.4028 - val_loss: 1.2797 - val_accuracy: 0.3925\n",
      "Epoch 73/80\n",
      "6435/6435 [==============================] - 0s 37us/step - loss: 1.2600 - accuracy: 0.3910 - val_loss: 1.2695 - val_accuracy: 0.3994\n",
      "Epoch 74/80\n",
      "6435/6435 [==============================] - 0s 33us/step - loss: 1.2510 - accuracy: 0.3989 - val_loss: 1.2801 - val_accuracy: 0.4078\n",
      "Epoch 75/80\n",
      "6435/6435 [==============================] - 0s 39us/step - loss: 1.2511 - accuracy: 0.3933 - val_loss: 1.2615 - val_accuracy: 0.3953\n",
      "Epoch 76/80\n",
      "6435/6435 [==============================] - 0s 36us/step - loss: 1.2481 - accuracy: 0.3970 - val_loss: 1.2775 - val_accuracy: 0.4008\n",
      "Epoch 77/80\n",
      "6435/6435 [==============================] - 0s 34us/step - loss: 1.2520 - accuracy: 0.3980 - val_loss: 1.2604 - val_accuracy: 0.4092\n",
      "Epoch 78/80\n",
      "6435/6435 [==============================] - 0s 39us/step - loss: 1.2450 - accuracy: 0.4048 - val_loss: 1.2764 - val_accuracy: 0.4050\n",
      "Epoch 79/80\n",
      "6435/6435 [==============================] - 0s 37us/step - loss: 1.2403 - accuracy: 0.4036 - val_loss: 1.2589 - val_accuracy: 0.4260\n",
      "Epoch 80/80\n",
      "6435/6435 [==============================] - 0s 34us/step - loss: 1.2435 - accuracy: 0.3969 - val_loss: 1.2724 - val_accuracy: 0.4232\n",
      "[[1.6731645e-01 1.1209860e-01 7.8278077e-05 ... 3.2641685e-01\n",
      "  2.2952247e-01 1.5845515e-01]\n",
      " [4.8927221e-02 3.3933256e-02 2.4382960e-08 ... 2.8884453e-03\n",
      "  1.2196563e-02 7.4136341e-03]\n",
      " [2.2665784e-01 1.7917997e-01 8.4952742e-05 ... 6.4130835e-02\n",
      "  3.0391300e-01 2.2408082e-01]\n",
      " ...\n",
      " [2.4949533e-01 2.0887008e-01 5.3956656e-04 ... 1.2176228e-02\n",
      "  2.9898423e-01 2.2935615e-01]\n",
      " [1.2976174e-01 9.5881298e-02 7.5552112e-04 ... 1.8235421e-01\n",
      "  3.4017575e-01 2.4432208e-01]\n",
      " [1.4991906e-01 1.0853834e-01 4.6778828e-04 ... 1.9014069e-01\n",
      "  3.2081938e-01 2.2606376e-01]]\n",
      "[11  9 12 ... 12 12 12]\n",
      "<class 'numpy.ndarray'>\n",
      "One CNN, r:  0\n",
      "Computing Time:  0:12:05.463303\n",
      "n, p1, p2 33 2 8\n",
      "Model: \"sequential_1\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv1d_1 (Conv1D)            (None, 3, 6)              12        \n",
      "_________________________________________________________________\n",
      "average_pooling1d_1 (Average (None, 1, 6)              0         \n",
      "_________________________________________________________________\n",
      "conv1d_2 (Conv1D)            (None, 1, 16)             112       \n",
      "_________________________________________________________________\n",
      "average_pooling1d_2 (Average (None, 1, 16)             0         \n",
      "_________________________________________________________________\n",
      "conv1d_3 (Conv1D)            (None, 1, 120)            2040      \n",
      "_________________________________________________________________\n",
      "flatten_1 (Flatten)          (None, 120)               0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 84)                10164     \n",
      "_________________________________________________________________\n",
      "preds (Dense)                (None, 14)                1190      \n",
      "=================================================================\n",
      "Total params: 13,518\n",
      "Trainable params: 13,518\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 6435 samples, validate on 716 samples\n",
      "Epoch 1/80\n",
      "6435/6435 [==============================] - 1s 80us/step - loss: 2.6093 - accuracy: 0.1709 - val_loss: 2.5324 - val_accuracy: 0.1606\n",
      "Epoch 2/80\n",
      "6435/6435 [==============================] - 0s 43us/step - loss: 2.3075 - accuracy: 0.1821 - val_loss: 2.0789 - val_accuracy: 0.2346\n",
      "Epoch 3/80\n",
      "6435/6435 [==============================] - 0s 44us/step - loss: 1.9685 - accuracy: 0.2465 - val_loss: 1.8941 - val_accuracy: 0.3073\n",
      "Epoch 4/80\n",
      "6435/6435 [==============================] - 0s 40us/step - loss: 1.8305 - accuracy: 0.2768 - val_loss: 1.7767 - val_accuracy: 0.3310\n",
      "Epoch 5/80\n",
      "6435/6435 [==============================] - 0s 37us/step - loss: 1.7512 - accuracy: 0.2786 - val_loss: 1.7286 - val_accuracy: 0.3226\n",
      "Epoch 6/80\n",
      "6435/6435 [==============================] - 0s 40us/step - loss: 1.6878 - accuracy: 0.2959 - val_loss: 1.6455 - val_accuracy: 0.3436\n",
      "Epoch 7/80\n",
      "6435/6435 [==============================] - 0s 35us/step - loss: 1.6423 - accuracy: 0.2940 - val_loss: 1.5931 - val_accuracy: 0.3506\n",
      "Epoch 8/80\n",
      "6435/6435 [==============================] - 0s 40us/step - loss: 1.6025 - accuracy: 0.2974 - val_loss: 1.5752 - val_accuracy: 0.3394\n",
      "Epoch 9/80\n",
      "6435/6435 [==============================] - 0s 36us/step - loss: 1.5797 - accuracy: 0.2998 - val_loss: 1.5472 - val_accuracy: 0.3156\n",
      "Epoch 10/80\n",
      "6435/6435 [==============================] - 0s 39us/step - loss: 1.5594 - accuracy: 0.3096 - val_loss: 1.5657 - val_accuracy: 0.3184\n",
      "Epoch 11/80\n",
      "6435/6435 [==============================] - 0s 38us/step - loss: 1.5496 - accuracy: 0.3030 - val_loss: 1.5304 - val_accuracy: 0.3059\n",
      "Epoch 12/80\n",
      "6435/6435 [==============================] - 0s 40us/step - loss: 1.5363 - accuracy: 0.3097 - val_loss: 1.5187 - val_accuracy: 0.3282\n",
      "Epoch 13/80\n",
      "6435/6435 [==============================] - 0s 40us/step - loss: 1.5332 - accuracy: 0.3024 - val_loss: 1.5060 - val_accuracy: 0.3198\n",
      "Epoch 14/80\n",
      "6435/6435 [==============================] - 0s 37us/step - loss: 1.5289 - accuracy: 0.2996 - val_loss: 1.4914 - val_accuracy: 0.3450\n",
      "Epoch 15/80\n",
      "6435/6435 [==============================] - 0s 38us/step - loss: 1.5174 - accuracy: 0.3074 - val_loss: 1.4828 - val_accuracy: 0.3338\n",
      "Epoch 16/80\n",
      "6435/6435 [==============================] - 0s 38us/step - loss: 1.5164 - accuracy: 0.3075 - val_loss: 1.4957 - val_accuracy: 0.3310\n",
      "Epoch 17/80\n",
      "6435/6435 [==============================] - 0s 34us/step - loss: 1.5090 - accuracy: 0.3125 - val_loss: 1.4905 - val_accuracy: 0.3324\n",
      "Epoch 18/80\n",
      "6435/6435 [==============================] - 0s 34us/step - loss: 1.5056 - accuracy: 0.3091 - val_loss: 1.4847 - val_accuracy: 0.3464\n",
      "Epoch 19/80\n",
      "6435/6435 [==============================] - 0s 34us/step - loss: 1.5032 - accuracy: 0.3144 - val_loss: 1.4823 - val_accuracy: 0.3254\n",
      "Epoch 20/80\n",
      "6435/6435 [==============================] - 0s 36us/step - loss: 1.4981 - accuracy: 0.3127 - val_loss: 1.4796 - val_accuracy: 0.3338\n",
      "Epoch 21/80\n",
      "6435/6435 [==============================] - 0s 41us/step - loss: 1.4989 - accuracy: 0.3108 - val_loss: 1.4823 - val_accuracy: 0.3310\n",
      "Epoch 22/80\n",
      "6435/6435 [==============================] - 0s 36us/step - loss: 1.4964 - accuracy: 0.3037 - val_loss: 1.4777 - val_accuracy: 0.3394\n",
      "Epoch 23/80\n",
      "6435/6435 [==============================] - 0s 41us/step - loss: 1.4930 - accuracy: 0.3064 - val_loss: 1.4724 - val_accuracy: 0.3380\n",
      "Epoch 24/80\n",
      "6435/6435 [==============================] - 0s 41us/step - loss: 1.4906 - accuracy: 0.3170 - val_loss: 1.4815 - val_accuracy: 0.3268\n",
      "Epoch 25/80\n",
      "6435/6435 [==============================] - 0s 36us/step - loss: 1.4877 - accuracy: 0.3105 - val_loss: 1.4753 - val_accuracy: 0.3324\n",
      "Epoch 26/80\n",
      "6435/6435 [==============================] - 0s 39us/step - loss: 1.4918 - accuracy: 0.3198 - val_loss: 1.4659 - val_accuracy: 0.3352\n",
      "Epoch 27/80\n",
      "6435/6435 [==============================] - 0s 39us/step - loss: 1.4865 - accuracy: 0.3193 - val_loss: 1.4682 - val_accuracy: 0.3464\n",
      "Epoch 28/80\n",
      "6435/6435 [==============================] - 0s 34us/step - loss: 1.4868 - accuracy: 0.3097 - val_loss: 1.4864 - val_accuracy: 0.3170\n",
      "Epoch 29/80\n",
      "6435/6435 [==============================] - 0s 36us/step - loss: 1.4826 - accuracy: 0.3206 - val_loss: 1.4670 - val_accuracy: 0.3366\n",
      "Epoch 30/80\n",
      "6435/6435 [==============================] - 0s 32us/step - loss: 1.4783 - accuracy: 0.3127 - val_loss: 1.4564 - val_accuracy: 0.3296\n",
      "Epoch 31/80\n",
      "6435/6435 [==============================] - 0s 36us/step - loss: 1.4797 - accuracy: 0.3092 - val_loss: 1.4657 - val_accuracy: 0.3212\n",
      "Epoch 32/80\n",
      "6435/6435 [==============================] - 0s 34us/step - loss: 1.4744 - accuracy: 0.3131 - val_loss: 1.4511 - val_accuracy: 0.3366\n",
      "Epoch 33/80\n",
      "6435/6435 [==============================] - 0s 36us/step - loss: 1.4769 - accuracy: 0.3183 - val_loss: 1.4699 - val_accuracy: 0.3547\n",
      "Epoch 34/80\n",
      "6435/6435 [==============================] - 0s 34us/step - loss: 1.4718 - accuracy: 0.3131 - val_loss: 1.4569 - val_accuracy: 0.3268\n",
      "Epoch 35/80\n",
      "6435/6435 [==============================] - 0s 36us/step - loss: 1.4721 - accuracy: 0.3198 - val_loss: 1.4419 - val_accuracy: 0.3561\n",
      "Epoch 36/80\n",
      "6435/6435 [==============================] - 0s 34us/step - loss: 1.4722 - accuracy: 0.3172 - val_loss: 1.4438 - val_accuracy: 0.3575\n",
      "Epoch 37/80\n",
      "6435/6435 [==============================] - 0s 39us/step - loss: 1.4725 - accuracy: 0.3128 - val_loss: 1.4517 - val_accuracy: 0.3296\n",
      "Epoch 38/80\n",
      "6435/6435 [==============================] - 0s 34us/step - loss: 1.4657 - accuracy: 0.3220 - val_loss: 1.4414 - val_accuracy: 0.3869\n",
      "Epoch 39/80\n",
      "6435/6435 [==============================] - 0s 34us/step - loss: 1.4689 - accuracy: 0.3203 - val_loss: 1.4533 - val_accuracy: 0.3799\n",
      "Epoch 40/80\n",
      "6435/6435 [==============================] - 0s 36us/step - loss: 1.4635 - accuracy: 0.3279 - val_loss: 1.4543 - val_accuracy: 0.3310\n",
      "Epoch 41/80\n",
      "6435/6435 [==============================] - 0s 36us/step - loss: 1.4696 - accuracy: 0.3299 - val_loss: 1.4542 - val_accuracy: 0.3687\n",
      "Epoch 42/80\n",
      "6435/6435 [==============================] - 0s 36us/step - loss: 1.4675 - accuracy: 0.3220 - val_loss: 1.4430 - val_accuracy: 0.3506\n",
      "Epoch 43/80\n",
      "6435/6435 [==============================] - 0s 36us/step - loss: 1.4626 - accuracy: 0.3341 - val_loss: 1.4413 - val_accuracy: 0.3422\n",
      "Epoch 44/80\n",
      "6435/6435 [==============================] - 0s 34us/step - loss: 1.4626 - accuracy: 0.3192 - val_loss: 1.4253 - val_accuracy: 0.3799\n",
      "Epoch 45/80\n",
      "6435/6435 [==============================] - 0s 36us/step - loss: 1.4534 - accuracy: 0.3343 - val_loss: 1.4447 - val_accuracy: 0.3520\n",
      "Epoch 46/80\n",
      "6435/6435 [==============================] - 0s 39us/step - loss: 1.4526 - accuracy: 0.3416 - val_loss: 1.4392 - val_accuracy: 0.3659\n",
      "Epoch 47/80\n",
      "6435/6435 [==============================] - 0s 32us/step - loss: 1.4562 - accuracy: 0.3372 - val_loss: 1.4411 - val_accuracy: 0.3324\n",
      "Epoch 48/80\n",
      "6435/6435 [==============================] - 0s 34us/step - loss: 1.4544 - accuracy: 0.3313 - val_loss: 1.4297 - val_accuracy: 0.3785\n",
      "Epoch 49/80\n",
      "6435/6435 [==============================] - 0s 32us/step - loss: 1.4462 - accuracy: 0.3400 - val_loss: 1.4327 - val_accuracy: 0.3645\n",
      "Epoch 50/80\n",
      "6435/6435 [==============================] - 0s 34us/step - loss: 1.4492 - accuracy: 0.3336 - val_loss: 1.4270 - val_accuracy: 0.3631\n",
      "Epoch 51/80\n",
      "6435/6435 [==============================] - 0s 36us/step - loss: 1.4405 - accuracy: 0.3417 - val_loss: 1.4318 - val_accuracy: 0.3268\n",
      "Epoch 52/80\n",
      "6435/6435 [==============================] - 0s 39us/step - loss: 1.4321 - accuracy: 0.3467 - val_loss: 1.4257 - val_accuracy: 0.3324\n",
      "Epoch 53/80\n",
      "6435/6435 [==============================] - 0s 34us/step - loss: 1.4312 - accuracy: 0.3469 - val_loss: 1.4329 - val_accuracy: 0.3394\n",
      "Epoch 54/80\n",
      "6435/6435 [==============================] - 0s 34us/step - loss: 1.4279 - accuracy: 0.3529 - val_loss: 1.4091 - val_accuracy: 0.3589\n",
      "Epoch 55/80\n",
      "6435/6435 [==============================] - 0s 39us/step - loss: 1.4271 - accuracy: 0.3546 - val_loss: 1.4231 - val_accuracy: 0.3715\n",
      "Epoch 56/80\n",
      "6435/6435 [==============================] - 0s 36us/step - loss: 1.4169 - accuracy: 0.3588 - val_loss: 1.4050 - val_accuracy: 0.3883\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 57/80\n",
      "6435/6435 [==============================] - 0s 34us/step - loss: 1.4102 - accuracy: 0.3582 - val_loss: 1.4082 - val_accuracy: 0.3687\n",
      "Epoch 58/80\n",
      "6435/6435 [==============================] - 0s 36us/step - loss: 1.3992 - accuracy: 0.3571 - val_loss: 1.3791 - val_accuracy: 0.3757\n",
      "Epoch 59/80\n",
      "6435/6435 [==============================] - 0s 36us/step - loss: 1.3959 - accuracy: 0.3669 - val_loss: 1.3779 - val_accuracy: 0.3813\n",
      "Epoch 60/80\n",
      "6435/6435 [==============================] - 0s 36us/step - loss: 1.3813 - accuracy: 0.3695 - val_loss: 1.3952 - val_accuracy: 0.3771\n",
      "Epoch 61/80\n",
      "6435/6435 [==============================] - 0s 36us/step - loss: 1.3714 - accuracy: 0.3731 - val_loss: 1.3560 - val_accuracy: 0.3897\n",
      "Epoch 62/80\n",
      "6435/6435 [==============================] - 0s 34us/step - loss: 1.3622 - accuracy: 0.3737 - val_loss: 1.3410 - val_accuracy: 0.3869\n",
      "Epoch 63/80\n",
      "6435/6435 [==============================] - 0s 32us/step - loss: 1.3529 - accuracy: 0.3837 - val_loss: 1.3418 - val_accuracy: 0.3631\n",
      "Epoch 64/80\n",
      "6435/6435 [==============================] - 0s 34us/step - loss: 1.3406 - accuracy: 0.3854 - val_loss: 1.3190 - val_accuracy: 0.4120\n",
      "Epoch 65/80\n",
      "6435/6435 [==============================] - 0s 36us/step - loss: 1.3294 - accuracy: 0.3916 - val_loss: 1.3111 - val_accuracy: 0.4022\n",
      "Epoch 66/80\n",
      "6435/6435 [==============================] - 0s 36us/step - loss: 1.3276 - accuracy: 0.3742 - val_loss: 1.3429 - val_accuracy: 0.3324\n",
      "Epoch 67/80\n",
      "6435/6435 [==============================] - 0s 36us/step - loss: 1.3189 - accuracy: 0.3773 - val_loss: 1.3114 - val_accuracy: 0.4120\n",
      "Epoch 68/80\n",
      "6435/6435 [==============================] - 0s 36us/step - loss: 1.3134 - accuracy: 0.3882 - val_loss: 1.3038 - val_accuracy: 0.3980\n",
      "Epoch 69/80\n",
      "6435/6435 [==============================] - 0s 34us/step - loss: 1.3079 - accuracy: 0.3815 - val_loss: 1.2826 - val_accuracy: 0.3925\n",
      "Epoch 70/80\n",
      "6435/6435 [==============================] - 0s 44us/step - loss: 1.3086 - accuracy: 0.3745 - val_loss: 1.2933 - val_accuracy: 0.4302\n",
      "Epoch 71/80\n",
      "6435/6435 [==============================] - 0s 32us/step - loss: 1.3004 - accuracy: 0.3824 - val_loss: 1.2890 - val_accuracy: 0.3869\n",
      "Epoch 72/80\n",
      "6435/6435 [==============================] - 0s 34us/step - loss: 1.2925 - accuracy: 0.3868 - val_loss: 1.2703 - val_accuracy: 0.4092\n",
      "Epoch 73/80\n",
      "6435/6435 [==============================] - 0s 34us/step - loss: 1.2862 - accuracy: 0.3919 - val_loss: 1.2833 - val_accuracy: 0.3883\n",
      "Epoch 74/80\n",
      "6435/6435 [==============================] - 0s 36us/step - loss: 1.2963 - accuracy: 0.3891 - val_loss: 1.2858 - val_accuracy: 0.3813\n",
      "Epoch 75/80\n",
      "6435/6435 [==============================] - 0s 36us/step - loss: 1.2821 - accuracy: 0.3882 - val_loss: 1.2694 - val_accuracy: 0.3897\n",
      "Epoch 76/80\n",
      "6435/6435 [==============================] - 0s 34us/step - loss: 1.2867 - accuracy: 0.3843 - val_loss: 1.2673 - val_accuracy: 0.3911\n",
      "Epoch 77/80\n",
      "6435/6435 [==============================] - 0s 34us/step - loss: 1.2778 - accuracy: 0.3964 - val_loss: 1.2536 - val_accuracy: 0.4190\n",
      "Epoch 78/80\n",
      "6435/6435 [==============================] - 0s 32us/step - loss: 1.2708 - accuracy: 0.3974 - val_loss: 1.2598 - val_accuracy: 0.4190\n",
      "Epoch 79/80\n",
      "6435/6435 [==============================] - 0s 34us/step - loss: 1.2738 - accuracy: 0.3868 - val_loss: 1.2727 - val_accuracy: 0.3785\n",
      "Epoch 80/80\n",
      "6435/6435 [==============================] - 0s 34us/step - loss: 1.2715 - accuracy: 0.3911 - val_loss: 1.2587 - val_accuracy: 0.3994\n",
      "[[1.4246336e-01 1.3447495e-01 2.9183513e-02 ... 2.6236933e-01\n",
      "  2.0949374e-01 2.2076322e-01]\n",
      " [4.3559127e-02 5.2351158e-02 8.7039268e-07 ... 3.8272985e-03\n",
      "  4.0384387e-03 4.0463456e-03]\n",
      " [2.3503032e-01 2.2372331e-01 3.3195980e-04 ... 5.4281175e-02\n",
      "  2.4106210e-01 2.4280763e-01]\n",
      " ...\n",
      " [2.6394409e-01 2.3837778e-01 3.0692976e-05 ... 1.2891737e-02\n",
      "  2.4852543e-01 2.3547728e-01]\n",
      " [1.4698794e-01 1.3745444e-01 2.4362573e-02 ... 1.4433865e-01\n",
      "  2.6874205e-01 2.7577153e-01]\n",
      " [1.6082612e-01 1.5035765e-01 1.8343432e-02 ... 1.5134911e-01\n",
      "  2.5726554e-01 2.6059306e-01]]\n",
      "[11  5 13 ...  0 13 13]\n",
      "<class 'numpy.ndarray'>\n",
      "One CNN, r:  0\n",
      "Computing Time:  0:12:25.895819\n",
      "n, p1, p2 34 2 9\n",
      "Model: \"sequential_1\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv1d_1 (Conv1D)            (None, 3, 6)              12        \n",
      "_________________________________________________________________\n",
      "average_pooling1d_1 (Average (None, 1, 6)              0         \n",
      "_________________________________________________________________\n",
      "conv1d_2 (Conv1D)            (None, 1, 16)             112       \n",
      "_________________________________________________________________\n",
      "average_pooling1d_2 (Average (None, 1, 16)             0         \n",
      "_________________________________________________________________\n",
      "conv1d_3 (Conv1D)            (None, 1, 120)            2040      \n",
      "_________________________________________________________________\n",
      "flatten_1 (Flatten)          (None, 120)               0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 84)                10164     \n",
      "_________________________________________________________________\n",
      "preds (Dense)                (None, 14)                1190      \n",
      "=================================================================\n",
      "Total params: 13,518\n",
      "Trainable params: 13,518\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Train on 6435 samples, validate on 716 samples\n",
      "Epoch 1/80\n",
      "6435/6435 [==============================] - 0s 78us/step - loss: 2.6091 - accuracy: 0.1577 - val_loss: 2.5293 - val_accuracy: 0.1508\n",
      "Epoch 2/80\n",
      "6435/6435 [==============================] - 0s 39us/step - loss: 2.3107 - accuracy: 0.1762 - val_loss: 2.0922 - val_accuracy: 0.1983\n",
      "Epoch 3/80\n",
      "6435/6435 [==============================] - 0s 39us/step - loss: 1.9820 - accuracy: 0.2640 - val_loss: 1.8750 - val_accuracy: 0.2626\n",
      "Epoch 4/80\n",
      "6435/6435 [==============================] - 0s 39us/step - loss: 1.8162 - accuracy: 0.3099 - val_loss: 1.7475 - val_accuracy: 0.3170\n",
      "Epoch 5/80\n",
      "6435/6435 [==============================] - 0s 41us/step - loss: 1.6964 - accuracy: 0.3305 - val_loss: 1.6445 - val_accuracy: 0.3059\n",
      "Epoch 6/80\n",
      "6435/6435 [==============================] - 0s 44us/step - loss: 1.6058 - accuracy: 0.3288 - val_loss: 1.5775 - val_accuracy: 0.3268\n",
      "Epoch 7/80\n",
      "6435/6435 [==============================] - 0s 36us/step - loss: 1.5478 - accuracy: 0.3451 - val_loss: 1.5202 - val_accuracy: 0.3338\n",
      "Epoch 8/80\n",
      "6435/6435 [==============================] - 0s 41us/step - loss: 1.5064 - accuracy: 0.3406 - val_loss: 1.5012 - val_accuracy: 0.3115\n",
      "Epoch 9/80\n",
      "6435/6435 [==============================] - 0s 36us/step - loss: 1.4829 - accuracy: 0.3501 - val_loss: 1.4704 - val_accuracy: 0.3422\n",
      "Epoch 10/80\n",
      "6435/6435 [==============================] - 0s 39us/step - loss: 1.4648 - accuracy: 0.3503 - val_loss: 1.4557 - val_accuracy: 0.3464\n",
      "Epoch 11/80\n",
      "6435/6435 [==============================] - 0s 36us/step - loss: 1.4504 - accuracy: 0.3504 - val_loss: 1.4394 - val_accuracy: 0.3520\n",
      "Epoch 12/80\n",
      "6435/6435 [==============================] - 0s 36us/step - loss: 1.4440 - accuracy: 0.3481 - val_loss: 1.4498 - val_accuracy: 0.3561\n",
      "Epoch 13/80\n",
      "6435/6435 [==============================] - 0s 41us/step - loss: 1.4326 - accuracy: 0.3512 - val_loss: 1.4348 - val_accuracy: 0.3296\n",
      "Epoch 14/80\n",
      "6435/6435 [==============================] - 0s 39us/step - loss: 1.4279 - accuracy: 0.3584 - val_loss: 1.4409 - val_accuracy: 0.3212\n",
      "Epoch 15/80\n",
      "6435/6435 [==============================] - 0s 36us/step - loss: 1.4227 - accuracy: 0.3549 - val_loss: 1.4454 - val_accuracy: 0.3254\n",
      "Epoch 16/80\n",
      "6435/6435 [==============================] - 0s 39us/step - loss: 1.4261 - accuracy: 0.3540 - val_loss: 1.4203 - val_accuracy: 0.3617\n",
      "Epoch 17/80\n",
      "6435/6435 [==============================] - 0s 39us/step - loss: 1.4157 - accuracy: 0.3632 - val_loss: 1.4231 - val_accuracy: 0.3492\n",
      "Epoch 18/80\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6435/6435 [==============================] - 0s 33us/step - loss: 1.4200 - accuracy: 0.3576 - val_loss: 1.4079 - val_accuracy: 0.3631\n",
      "Epoch 19/80\n",
      "6435/6435 [==============================] - 0s 34us/step - loss: 1.4155 - accuracy: 0.3514 - val_loss: 1.4212 - val_accuracy: 0.3492\n",
      "Epoch 20/80\n",
      "6435/6435 [==============================] - 0s 39us/step - loss: 1.4072 - accuracy: 0.3607 - val_loss: 1.4040 - val_accuracy: 0.3561\n",
      "Epoch 21/80\n",
      "6435/6435 [==============================] - 0s 39us/step - loss: 1.4043 - accuracy: 0.3591 - val_loss: 1.4175 - val_accuracy: 0.3394\n",
      "Epoch 22/80\n",
      "6435/6435 [==============================] - 0s 39us/step - loss: 1.4029 - accuracy: 0.3576 - val_loss: 1.4022 - val_accuracy: 0.3184\n",
      "Epoch 23/80\n",
      "6435/6435 [==============================] - 0s 41us/step - loss: 1.3968 - accuracy: 0.3610 - val_loss: 1.4043 - val_accuracy: 0.3464\n",
      "Epoch 24/80\n",
      "6435/6435 [==============================] - 0s 41us/step - loss: 1.4007 - accuracy: 0.3571 - val_loss: 1.3880 - val_accuracy: 0.3534\n",
      "Epoch 25/80\n",
      "6435/6435 [==============================] - 0s 39us/step - loss: 1.3949 - accuracy: 0.3627 - val_loss: 1.4008 - val_accuracy: 0.3506\n",
      "Epoch 26/80\n",
      "6435/6435 [==============================] - 0s 41us/step - loss: 1.3890 - accuracy: 0.3731 - val_loss: 1.3816 - val_accuracy: 0.3673\n",
      "Epoch 27/80\n",
      "6435/6435 [==============================] - 0s 38us/step - loss: 1.3845 - accuracy: 0.3708 - val_loss: 1.4087 - val_accuracy: 0.3268\n",
      "Epoch 28/80\n",
      "6435/6435 [==============================] - 0s 38us/step - loss: 1.3841 - accuracy: 0.3748 - val_loss: 1.4144 - val_accuracy: 0.3534\n",
      "Epoch 29/80\n",
      "6435/6435 [==============================] - 0s 38us/step - loss: 1.3775 - accuracy: 0.3641 - val_loss: 1.3757 - val_accuracy: 0.3631\n",
      "Epoch 30/80\n",
      "6435/6435 [==============================] - 0s 36us/step - loss: 1.3712 - accuracy: 0.3720 - val_loss: 1.3765 - val_accuracy: 0.3603\n",
      "Epoch 31/80\n",
      "6435/6435 [==============================] - 0s 36us/step - loss: 1.3714 - accuracy: 0.3699 - val_loss: 1.3639 - val_accuracy: 0.3575\n",
      "Epoch 32/80\n",
      "6435/6435 [==============================] - 0s 34us/step - loss: 1.3643 - accuracy: 0.3709 - val_loss: 1.3681 - val_accuracy: 0.3603\n",
      "Epoch 33/80\n",
      "6435/6435 [==============================] - 0s 39us/step - loss: 1.3640 - accuracy: 0.3807 - val_loss: 1.3691 - val_accuracy: 0.3589\n",
      "Epoch 34/80\n",
      "6435/6435 [==============================] - 0s 36us/step - loss: 1.3528 - accuracy: 0.3838 - val_loss: 1.3525 - val_accuracy: 0.3813\n",
      "Epoch 35/80\n",
      "6435/6435 [==============================] - 0s 36us/step - loss: 1.3444 - accuracy: 0.3832 - val_loss: 1.3411 - val_accuracy: 0.3883\n",
      "Epoch 36/80\n",
      "6435/6435 [==============================] - 0s 36us/step - loss: 1.3341 - accuracy: 0.3961 - val_loss: 1.3315 - val_accuracy: 0.3659\n",
      "Epoch 37/80\n",
      "6435/6435 [==============================] - 0s 39us/step - loss: 1.3332 - accuracy: 0.3955 - val_loss: 1.3248 - val_accuracy: 0.3785\n",
      "Epoch 38/80\n",
      "6435/6435 [==============================] - 0s 36us/step - loss: 1.3184 - accuracy: 0.3929 - val_loss: 1.3116 - val_accuracy: 0.4120\n",
      "Epoch 39/80\n",
      "6435/6435 [==============================] - 0s 41us/step - loss: 1.3064 - accuracy: 0.4019 - val_loss: 1.2913 - val_accuracy: 0.3994\n",
      "Epoch 40/80\n",
      "6435/6435 [==============================] - 0s 36us/step - loss: 1.2893 - accuracy: 0.3992 - val_loss: 1.2911 - val_accuracy: 0.4106\n",
      "Epoch 41/80\n",
      "6435/6435 [==============================] - 0s 39us/step - loss: 1.2797 - accuracy: 0.4109 - val_loss: 1.2668 - val_accuracy: 0.4218\n",
      "Epoch 42/80\n",
      "6435/6435 [==============================] - 0s 39us/step - loss: 1.2668 - accuracy: 0.4179 - val_loss: 1.2478 - val_accuracy: 0.4288\n",
      "Epoch 43/80\n",
      "6435/6435 [==============================] - 0s 41us/step - loss: 1.2463 - accuracy: 0.4227 - val_loss: 1.2690 - val_accuracy: 0.4358\n",
      "Epoch 44/80\n",
      "6435/6435 [==============================] - 0s 36us/step - loss: 1.2425 - accuracy: 0.4208 - val_loss: 1.2485 - val_accuracy: 0.4316\n",
      "Epoch 45/80\n",
      "6435/6435 [==============================] - 0s 38us/step - loss: 1.2325 - accuracy: 0.4236 - val_loss: 1.2306 - val_accuracy: 0.4078\n",
      "Epoch 46/80\n",
      "6435/6435 [==============================] - 0s 38us/step - loss: 1.2170 - accuracy: 0.4281 - val_loss: 1.2460 - val_accuracy: 0.4316\n",
      "Epoch 47/80\n",
      "6435/6435 [==============================] - 0s 40us/step - loss: 1.2198 - accuracy: 0.4291 - val_loss: 1.2232 - val_accuracy: 0.4581\n",
      "Epoch 48/80\n",
      "6435/6435 [==============================] - 0s 38us/step - loss: 1.2196 - accuracy: 0.4308 - val_loss: 1.2184 - val_accuracy: 0.4274\n",
      "Epoch 49/80\n",
      "6435/6435 [==============================] - 0s 44us/step - loss: 1.2089 - accuracy: 0.4328 - val_loss: 1.2254 - val_accuracy: 0.4218\n",
      "Epoch 50/80\n",
      "6435/6435 [==============================] - 0s 41us/step - loss: 1.2155 - accuracy: 0.4294 - val_loss: 1.2309 - val_accuracy: 0.4288\n",
      "Epoch 51/80\n",
      "6435/6435 [==============================] - 0s 36us/step - loss: 1.2050 - accuracy: 0.4350 - val_loss: 1.2175 - val_accuracy: 0.4050\n",
      "Epoch 52/80\n",
      "6435/6435 [==============================] - 0s 36us/step - loss: 1.1978 - accuracy: 0.4362 - val_loss: 1.2086 - val_accuracy: 0.4246\n",
      "Epoch 53/80\n",
      "6435/6435 [==============================] - 0s 40us/step - loss: 1.1969 - accuracy: 0.4401 - val_loss: 1.1897 - val_accuracy: 0.4581\n",
      "Epoch 54/80\n",
      "6435/6435 [==============================] - 0s 34us/step - loss: 1.1940 - accuracy: 0.4283 - val_loss: 1.1950 - val_accuracy: 0.4274\n",
      "Epoch 55/80\n",
      "6435/6435 [==============================] - 0s 41us/step - loss: 1.1898 - accuracy: 0.4357 - val_loss: 1.1875 - val_accuracy: 0.4455\n",
      "Epoch 56/80\n",
      "6435/6435 [==============================] - 0s 39us/step - loss: 1.1881 - accuracy: 0.4396 - val_loss: 1.1874 - val_accuracy: 0.4176\n",
      "Epoch 57/80\n",
      "6435/6435 [==============================] - 0s 39us/step - loss: 1.1822 - accuracy: 0.4347 - val_loss: 1.1833 - val_accuracy: 0.4344\n",
      "Epoch 58/80\n",
      "6435/6435 [==============================] - 0s 39us/step - loss: 1.1747 - accuracy: 0.4418 - val_loss: 1.1911 - val_accuracy: 0.4399\n",
      "Epoch 59/80\n",
      "6435/6435 [==============================] - 0s 39us/step - loss: 1.1703 - accuracy: 0.4514 - val_loss: 1.1758 - val_accuracy: 0.4330\n",
      "Epoch 60/80\n",
      "6435/6435 [==============================] - 0s 39us/step - loss: 1.1742 - accuracy: 0.4365 - val_loss: 1.1755 - val_accuracy: 0.4358\n",
      "Epoch 61/80\n",
      "6435/6435 [==============================] - 0s 41us/step - loss: 1.1651 - accuracy: 0.4465 - val_loss: 1.1922 - val_accuracy: 0.4344\n",
      "Epoch 62/80\n",
      "6435/6435 [==============================] - 0s 37us/step - loss: 1.1722 - accuracy: 0.4458 - val_loss: 1.1815 - val_accuracy: 0.4595\n",
      "Epoch 63/80\n",
      "6435/6435 [==============================] - 0s 38us/step - loss: 1.1687 - accuracy: 0.4451 - val_loss: 1.1717 - val_accuracy: 0.4539\n",
      "Epoch 64/80\n",
      "6435/6435 [==============================] - 0s 36us/step - loss: 1.1633 - accuracy: 0.4406 - val_loss: 1.1672 - val_accuracy: 0.4483\n",
      "Epoch 65/80\n",
      "6435/6435 [==============================] - 0s 37us/step - loss: 1.1614 - accuracy: 0.4444 - val_loss: 1.1568 - val_accuracy: 0.4651\n",
      "Epoch 66/80\n",
      "6435/6435 [==============================] - 0s 37us/step - loss: 1.1616 - accuracy: 0.4474 - val_loss: 1.1685 - val_accuracy: 0.4399\n",
      "Epoch 67/80\n",
      "1408/6435 [=====>........................] - ETA: 0s - loss: 1.1431 - accuracy: 0.4467"
     ]
    }
   ],
   "source": [
    "#====CNN combination c(20,2)======\n",
    "comb=[]\n",
    "for subset in itertools.combinations(range(NUM_region), 2):\n",
    "    comb.append(subset)\n",
    "NUM_comb=len(comb)\n",
    "display(NUM_comb)            \n",
    "\n",
    "for n in range(NUM_comb+1):\n",
    "    region=region_image.copy()\n",
    "    region=list(region)\n",
    "    selected_region = list(range(NUM_region))\n",
    "\n",
    "    if (n > 0):\n",
    "        p1=comb[n-1][0]\n",
    "        p2=comb[n-1][1]\n",
    "        region[p1]=region[p1]+region[p2]\n",
    "        region.pop(p2)\n",
    "        selected_region.pop(-1)\n",
    "    else:\n",
    "        p1=0\n",
    "        p2=0\n",
    "\n",
    "    print(\"n, p1, p2\", n, p1, p2)\n",
    "\n",
    "\n",
    "    # ===== one CNN =============\n",
    "    NUM_CLASSES = len(selected_region)\n",
    "\n",
    "    Input_img     = []\n",
    "    Input_img_len = []\n",
    "    for c,sel in enumerate(selected_region, start=0):\n",
    "        Input_img = Input_img + list(region[sel])\n",
    "        Input_img_len.append(len(region[sel]))\n",
    "\n",
    "    #1213\n",
    "    # fill up training array\n",
    "    W           = np.shape(test_array[0])[0]\n",
    "    train_array = np.zeros((len(Input_img), W), dtype=float)\n",
    "    for i in range (len(Input_img)):\n",
    "        train_array[i] = test_array[Input_img[i]].reshape(W)\n",
    "\n",
    "    train_array = np.expand_dims(train_array, axis = -1)\n",
    "\n",
    "\n",
    "    # fill up the training label to each training image\n",
    "    current_train_label = np.zeros(len(train_array), dtype=int)\n",
    "    accum_base=0\n",
    "    for label in range(1,NUM_CLASSES):\n",
    "        pre_cursor = Input_img_len[label-1]\n",
    "        accum_base = accum_base + pre_cursor\n",
    "        current_train_label[accum_base:] = label\n",
    "\n",
    "    # CNN\n",
    "    #===============================================\n",
    "    one_predicted_results  = np.zeros((TRIALS, len(test_label_answer)), dtype=int)\n",
    "    one_predict_percentage = np.zeros((TRIALS, len(test_label_answer), NUM_CLASSES), dtype=float)    \n",
    "    model_history = np.zeros(TRIALS, dtype=list)\n",
    "\n",
    "    for r in range(TRIALS):\n",
    "        one_predicted_results[r], one_predict_percentage[r], model_history[r] = ME_CNN(\n",
    "                x_train     = train_array,\n",
    "                train_label = current_train_label,\n",
    "                test_array  = test_array,\n",
    "                true_answer = test_label_answer,\n",
    "                Num_Classes = NUM_CLASSES\n",
    "                )\n",
    "        print(type(model_history))\n",
    "\n",
    "\n",
    "        # ===== delete CNN tensors =====\n",
    "        from keras import backend as K\n",
    "        K.clear_session()\n",
    "        import gc\n",
    "        gc.collect()\n",
    "\n",
    "        print(\"One CNN, r: \",r)\n",
    "        ROUND_duration = time.time() - ROUND_start\n",
    "        print(\"Computing Time: \", str(datetime.timedelta(seconds=ROUND_duration)))\n",
    "\n",
    "    # === save to file ===\n",
    "    savefile_path = './' + str(timestr) + '(classes=' + str(NUM_CLASSES)+')_n' + str(n) + '_R' + str(p1) + '+R'+ str(p2) +'.pickle'\n",
    "    with open(savefile_path, 'wb') as f:\n",
    "        pickle.dump([Input_img, Input_img_len, one_predicted_results, one_predict_percentage, model_history], f)\n",
    "\n",
    "\n",
    "\n",
    "# ==== CNN Removal =====\n",
    "for n in range(NUM_region):\n",
    "    region=region_image.copy()   #reset\n",
    "    selected_region = list(range(NUM_region))\n",
    "    selected_region.pop(n)\n",
    "\n",
    "    print(\"n=\", n)\n",
    "\n",
    "\n",
    "    # ===== one CNN =============\n",
    "    NUM_CLASSES = len(selected_region)\n",
    "\n",
    "    # input image and label\n",
    "    Input_img     = []\n",
    "    Input_img_len = []\n",
    "    for c,sel in enumerate(selected_region, start=0):\n",
    "        Input_img = Input_img + list(region[sel])\n",
    "        Input_img_len.append(len(region[sel]))\n",
    "\n",
    "    #1213\n",
    "    # fill up training array\n",
    "    W           = np.shape(test_array[0])[0]\n",
    "    train_array = np.zeros((len(Input_img), W), dtype=float)\n",
    "    for i in range (len(Input_img)):\n",
    "        train_array[i] = test_array[Input_img[i]].reshape(W)\n",
    "\n",
    "    train_array = np.expand_dims(train_array, axis = -1)\n",
    "\n",
    "\n",
    "    # fill up the training label to each training image\n",
    "    current_train_label = np.zeros(len(train_array), dtype=int)\n",
    "    accum_base=0\n",
    "    for label in range(1,NUM_CLASSES):\n",
    "        pre_cursor = Input_img_len[label-1]\n",
    "        accum_base = accum_base + pre_cursor\n",
    "        current_train_label[accum_base:] = label\n",
    "\n",
    "    # CNN\n",
    "    #===============================================\n",
    "    one_predicted_results  = np.zeros((TRIALS, len(test_label_answer)), dtype=int)\n",
    "    one_predict_percentage = np.zeros((TRIALS, len(test_label_answer), NUM_CLASSES), dtype=float)    \n",
    "    model_history = np.zeros(TRIALS, dtype=list)\n",
    "\n",
    "    for r in range(TRIALS):\n",
    "        one_predicted_results[r], one_predict_percentage[r], model_history[r] = ME_CNN(\n",
    "                x_train     = train_array,\n",
    "                train_label = current_train_label,\n",
    "                test_array  = test_array,\n",
    "                true_answer = test_label_answer,\n",
    "                Num_Classes = NUM_CLASSES\n",
    "                )\n",
    "        print(type(model_history))\n",
    "\n",
    "\n",
    "        # ===== delete CNN tensors =====\n",
    "        from keras import backend as K\n",
    "        K.clear_session()\n",
    "        import gc\n",
    "        gc.collect()\n",
    "\n",
    "        print(\"One CNN, r: \",r)\n",
    "        ROUND_duration = time.time() - ROUND_start\n",
    "        print(\"Computing Time: \", str(datetime.timedelta(seconds=ROUND_duration)))\n",
    "\n",
    "    # === save to file ===\n",
    "    savefile_path = './' + str(timestr) + '(classes=' + str(NUM_CLASSES)+')_Remove' + str(n) +'.pickle' \n",
    "    with open(savefile_path, 'wb') as f:\n",
    "        pickle.dump([Input_img, Input_img_len, one_predicted_results, one_predict_percentage, model_history], f)\n",
    "  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ====shift label=====\n",
    "#=== combination =====\n",
    "comb=[]\n",
    "for oneset in itertools.combinations(range(NUM_region), 2):\n",
    "    comb.append(oneset)\n",
    "NUM_comb=len(comb)\n",
    "\n",
    "Merged_result=[]\n",
    "Merged_prob=[]\n",
    "Merged_prob_label=[]\n",
    "\n",
    "for n in range(NUM_comb):\n",
    "    label = list(range(NUM_region))\n",
    "    p1=comb[n][0]\n",
    "    p2=comb[n][1]\n",
    "\n",
    "    with open('./' + timestr + '(classes=' + str(NUM_region-1) + ')_n'+str(n+1)+'_R'+str(p1)+'+R'+str(p2)+'.pickle', 'rb') as f:\n",
    "        Input_img, Input_img_len, one_predicted_results, one_predict_percentage, model_history = pickle.load(f)\n",
    "    label_B = one_predicted_results[0].copy()\n",
    "    label_B_prob = one_predict_percentage[0].copy()\n",
    "\n",
    "    #(1)shift label index\n",
    "    for p in reversed(range(p2,NUM_region-1)):\n",
    "        addr=np.where(label_B==p)[0]\n",
    "        label_B[addr]+=1\n",
    "    Merged_result.append(label_B)\n",
    "\n",
    "    #(2)\n",
    "    Merged_prob.append(label_B_prob)\n",
    "\n",
    "    #(3)\n",
    "    label.pop(p2)\n",
    "    Merged_prob_label.append(label)\n",
    "\n",
    "print(np.shape(Merged_result), np.shape(Merged_prob), np.shape(Merged_prob_label))\n",
    "\n",
    "# save pickle\n",
    "with open('./' + timestr + 'results_of_combination.pickle', 'wb') as f:\n",
    "    pickle.dump([comb, Merged_result, Merged_prob, Merged_prob_label], f)\n",
    "\n",
    "# save mat\n",
    "from scipy.io import savemat\n",
    "if (np.shape(Merged_prob)[0]<=300):\n",
    "    savemat('./' + timestr + 'results_of_combination.mat', {'combination_pairs':comb, 'result_for_merge':Merged_result, 'prob_for_merge':Merged_prob,'prob_label_for_merge': Merged_prob_label})\n",
    "    print(\"normal size = \", np.shape(Merged_prob))\n",
    "else:\n",
    "    savemat('./' + timestr + 'results_of_combination.mat', {'combination_pairs':comb, 'result_for_merge':Merged_result, 'prob_label_for_merge': Merged_prob_label})\n",
    "    savemat('./' + timestr + 'results_of_combination_prob1.mat', {'prob_for_merge1':Merged_prob[:200]})\n",
    "    savemat('./' + timestr + 'results_of_combination_prob2.mat', {'prob_for_merge2':Merged_prob[200:400]})\n",
    "    savemat('./' + timestr + 'results_of_combination_prob3.mat', {'prob_for_merge3':Merged_prob[400:]})\n",
    "    print(\"large size = \", np.shape(Merged_prob))\n",
    "\n",
    "    \n",
    "    \n",
    "    \n",
    "#======== removal ===========\n",
    "Removal_result=[]\n",
    "Removal_prob=[]\n",
    "Removal_prob_label=[]\n",
    "\n",
    "for n in range(NUM_region):\n",
    "    label = list(range(NUM_region))    \n",
    "    #reset\n",
    "    with open('./' + timestr + '(classes=' + str(NUM_region-1) + ')_Remove' + str(n) + '.pickle', 'rb') as f:\n",
    "        Input_img, Input_img_len, one_predicted_results, one_predict_percentage, model_history = pickle.load(f)\n",
    "    label_B = one_predicted_results[0].copy()\n",
    "    label_B_prob = one_predict_percentage[0].copy()\n",
    "\n",
    "    for p in reversed(range(n,NUM_region-1)):\n",
    "        addr=np.where(label_B==p)[0]\n",
    "        label_B[addr]+=1\n",
    "    Removal_result.append(label_B)\n",
    "\n",
    "    #(2)\n",
    "    Removal_prob.append(label_B_prob)\n",
    "\n",
    "    #(3)\n",
    "    label.pop(n)\n",
    "    Removal_prob_label.append(label)\n",
    "\n",
    "print(np.shape(Removal_result), np.shape(Removal_prob), np.shape(Removal_prob_label))\n",
    "\n",
    "# save pickle\n",
    "with open('./' + timestr + 'results_of_removal.pickle', 'wb') as f:\n",
    "    pickle.dump([Removal_result, Removal_prob, Removal_prob_label], f)\n",
    "    \n",
    "# save mat\n",
    "from scipy.io import savemat\n",
    "savemat('./' + timestr + 'results_of_removal.mat', {'result_for_removal':Removal_result,'prob_for_removal':Removal_prob, 'prob_label_for_removal':Removal_prob_label})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"done\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
