{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***\n",
    "### <span style='color:green'> ME Algorithm  &emsp;&emsp; Feb, 2024 </span>\n",
    "### <span style='color:Blue'> Phase 3 </span>\n",
    "### <p> Yan-Bin Chen (陳彥賓) &emsp; yanbin@stat.sinica.edu.tw </p>\n",
    "### <p> Institute of Statistical Science, Academia Sinica, Taipei, Taiwan.</p>  \n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Input"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "import numpy as np\n",
    "import collections\n",
    "import pandas\n",
    "import itertools\n",
    "from itertools import chain\n",
    "import random \n",
    "import time\n",
    "import datetime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "region: [15  9 11  6  7  8 10 20 14 12 19  1 13 18  4]\n",
      "region amount: 15\n"
     ]
    }
   ],
   "source": [
    "# Input\n",
    "TRIALS    = 1\n",
    "timestr   = ''\n",
    "#Region_Index_loc = 6 # column location; Others is 6\n",
    "REGION_INDEX_LOC = 4 # column location; MNIST is 4\n",
    "\n",
    "PATH1='../data/MNIST_seedinds.txt'\n",
    "PATH2='../data/MNIST_bilabels.txt'\n",
    "PATH3='../data/MNIST_seedinds_neighborregions.txt'\n",
    "PATH4='../data/MNIST_Labels_Spec20.csv'\n",
    "PATH5='../data/Small_MNIST_tSNE_embeddings.pickle'\n",
    "#PATH5='../phase3_data/MNIST_Labels_5000.csv'\n",
    "#=================================================================\n",
    "\n",
    "# (1)PATH1\n",
    "df = pandas.read_csv(PATH1, header=None, delimiter = \"\\t\")\n",
    "region = df.to_numpy().T[0]\n",
    "NUM_region = len(region)\n",
    "\n",
    "# (2)PATH2\n",
    "df = pandas.read_csv(PATH2, header=None, delimiter = \"\\t\")\n",
    "cen = df.to_numpy()\n",
    "\n",
    "print('region:', region)\n",
    "print('region amount:', len(region))\n",
    "\n",
    "\n",
    "# (4)PATH4. Have to be here. The following neighboring process needs this information\n",
    "df = pandas.read_csv(PATH4)\n",
    "#1213 add auto judge\n",
    "all_region_index = df.to_numpy().T[REGION_INDEX_LOC].astype(int)"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "# (5)PATH5     conver the embedded data into the pickle file\n",
    "df1 = pandas.read_csv(PATH5)\n",
    "test_array        = df1.iloc[:,:3].to_numpy().copy()\n",
    "test_label_answer = df1.iloc[:,3].to_numpy().copy()\n",
    "\n",
    "#save\n",
    "with open('../phase3_data/Small_MNIST_tSNE_embeddings.pickle', 'wb') as f:\n",
    "    pickle.dump([test_array, test_label_answer], f)\n",
    "print (test_label_answer, test_array)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Get neighbors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "neighbor amount:  15\n",
      "[[ 9]\n",
      " [15]\n",
      " [16]\n",
      " [ 7]\n",
      " [ 6]\n",
      " [ 8]\n",
      " [20]\n",
      " [10]\n",
      " [ 5]\n",
      " [ 6]\n",
      " [ 1]\n",
      " [19]\n",
      " [13]\n",
      " [ 4]\n",
      " [18]]\n",
      "neighbor amount:  14\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[[9],\n",
       " [15],\n",
       " [16],\n",
       " [7],\n",
       " [6],\n",
       " [8],\n",
       " [20],\n",
       " [10],\n",
       " [5],\n",
       " [],\n",
       " [1],\n",
       " [19],\n",
       " [13],\n",
       " [4],\n",
       " [18]]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "if (PATH3):\n",
    "    df = pandas.read_csv(PATH3, delim_whitespace=' ', header=None,  index_col=0)\n",
    "    neighbors = df.to_numpy()\n",
    "    NUM_NEI=df.shape[1]\n",
    "    \n",
    "    print('neighbor amount: ',len(list(chain.from_iterable(neighbors))))\n",
    "    print(neighbors)\n",
    "\n",
    "# filter out duplicated ones\n",
    "    test_list=list(chain.from_iterable(neighbors))\n",
    "    res2=[]\n",
    "    [res2.append(n) for n, i in enumerate(test_list) if i in test_list[:n]]\n",
    "\n",
    "    res2.reverse()\n",
    "    neighbors=neighbors.tolist()\n",
    "    [neighbors[x//NUM_NEI].pop(x%NUM_NEI) for x in res2]\n",
    "    print('neighbor amount: ',len(list(chain.from_iterable(neighbors))))\n",
    "    display(neighbors)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[15, 9],\n",
       " [9, 15],\n",
       " [11, 16],\n",
       " [6, 7],\n",
       " [7, 6],\n",
       " [8, 8],\n",
       " [10, 20],\n",
       " [20, 10],\n",
       " [14, 5],\n",
       " [12],\n",
       " [19, 1],\n",
       " [1, 19],\n",
       " [13, 13],\n",
       " [18, 4],\n",
       " [4, 18]]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# combine seed regions and neighbors\n",
    "if (PATH3):\n",
    "    reg_nei=[]\n",
    "    for i in range(len(neighbors)):\n",
    "        a=[region[i]]\n",
    "        b=neighbors[i]\n",
    "        if len(b):\n",
    "            c=list(np.concatenate((a,b),axis=0))\n",
    "        else:\n",
    "            c=a.copy()\n",
    "        reg_nei.append(c)\n",
    "else:\n",
    "    reg_nei=region.copy()\n",
    "\n",
    "reg_nei"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "** original duplicate at i= 5 ;region 8 ;duplicate size 491\n",
      "** same duplicate situation\n",
      "** original duplicate at i= 12 ;region 13 ;duplicate size 460\n",
      "** same duplicate situation\n"
     ]
    }
   ],
   "source": [
    "# collect images from target region and neighboring regions\n",
    "# input : region, NUM_region, cen, all_region_index, neighbors\n",
    "# output: region_image: to save image indices corresponding to seed regions.\n",
    "#         region_answer: to save answer\n",
    "\n",
    "region_image_before=[]\n",
    "region_image=[]\n",
    "region_image_pure=[]\n",
    "for i in range(NUM_region):\n",
    "    \n",
    "    \n",
    "    #(1)neighbor  nei\n",
    "    if (PATH3):\n",
    "        addr_nei=[]\n",
    "        for j in range(len(neighbors[i])):\n",
    "            addr_nei=addr_nei+list(np.where(all_region_index==neighbors[i][j])[0])\n",
    "            #check whether it has duplicates\n",
    "            if (len(addr_nei) != len(set(addr_nei))):\n",
    "                print(\"neighbor duplicate at i=\",i,\"j=\",j)\n",
    "                addr_nei=list(set(addr_nei))\n",
    "\n",
    "    #(2)original\n",
    "    addr=list(np.where(  (all_region_index==region[i])  &  (cen.T[1]==1)  )[0])\n",
    "    if (PATH3):\n",
    "        addr=addr+addr_nei\n",
    "    #check whether it has duplicates\n",
    "    if (len(addr) != len(set(addr))):\n",
    "        print(\"** original duplicate at i=\",i,\";region\",region[i],\";duplicate size\",len(addr)-len(set(addr)))\n",
    "        addr=list(set(addr))\n",
    "    region_image.append(addr)\n",
    "\n",
    "    #(3)original before centroid (this is only for check, rather than for main codes)\n",
    "    addr_before=list(np.where(all_region_index==region[i])[0])\n",
    "    if (PATH3):\n",
    "        addr_before=addr_before+addr_nei\n",
    "    #check whether it has duplicates\n",
    "    if (len(addr_before) != len(set(addr_before))):\n",
    "        print(\"** same duplicate situation\")\n",
    "        addr_before=list(set(addr_before))\n",
    "    region_image_before.append(addr_before)\n",
    "\n",
    "    #(4)pure\n",
    "    addr_pure=list(np.where(  (all_region_index==region[i])  &  (cen.T[1]==1)  )[0])\n",
    "    region_image_pure.append(addr_pure)\n",
    "\n",
    "\n",
    "with open('../data/' + timestr + 'region_for_phase5.pickle', 'wb') as f:\n",
    "    pickle.dump([region, reg_nei, region_image_pure, region_image,], f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test_array: (5000, 3)\n",
      "training size: 7151\n"
     ]
    }
   ],
   "source": [
    "# ==== test_array ====\n",
    "with open(PATH5, 'rb') as f:\n",
    "    test_array, test_label_answer = pickle.load(f)\n",
    "print(\"test_array:\",np.shape(test_array))\n",
    "\n",
    "\n",
    "# 1213 add auto judge /255\n",
    "test_array = np.expand_dims(test_array, axis = -1)\n",
    "test_array /= 255\n",
    "print(\"training size:\",len(np.array(list(chain.from_iterable(region_image)))))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# CNN original"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "n, p1, p2 0 0 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_1\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv1d_1 (Conv1D)            (None, 3, 6)              12        \n",
      "_________________________________________________________________\n",
      "average_pooling1d_1 (Average (None, 1, 6)              0         \n",
      "_________________________________________________________________\n",
      "conv1d_2 (Conv1D)            (None, 1, 16)             112       \n",
      "_________________________________________________________________\n",
      "average_pooling1d_2 (Average (None, 1, 16)             0         \n",
      "_________________________________________________________________\n",
      "conv1d_3 (Conv1D)            (None, 1, 120)            2040      \n",
      "_________________________________________________________________\n",
      "flatten_1 (Flatten)          (None, 120)               0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 84)                10164     \n",
      "_________________________________________________________________\n",
      "preds (Dense)                (None, 15)                1275      \n",
      "=================================================================\n",
      "Total params: 13,603\n",
      "Trainable params: 13,603\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Train on 6435 samples, validate on 716 samples\n",
      "Epoch 1/80\n",
      "6435/6435 [==============================] - 2s 309us/step - loss: 2.6704 - accuracy: 0.1263 - val_loss: 2.5712 - val_accuracy: 0.1830\n",
      "Epoch 2/80\n",
      "6435/6435 [==============================] - 0s 50us/step - loss: 2.3423 - accuracy: 0.2099 - val_loss: 2.1374 - val_accuracy: 0.2388\n",
      "Epoch 3/80\n",
      "6435/6435 [==============================] - 0s 50us/step - loss: 2.0076 - accuracy: 0.2605 - val_loss: 1.9461 - val_accuracy: 0.2696\n",
      "Epoch 4/80\n",
      "6435/6435 [==============================] - 0s 45us/step - loss: 1.8655 - accuracy: 0.2793 - val_loss: 1.8371 - val_accuracy: 0.2905\n",
      "Epoch 5/80\n",
      "6435/6435 [==============================] - 0s 46us/step - loss: 1.7649 - accuracy: 0.2996 - val_loss: 1.7609 - val_accuracy: 0.2765\n",
      "Epoch 6/80\n",
      "6435/6435 [==============================] - 0s 40us/step - loss: 1.7029 - accuracy: 0.2903 - val_loss: 1.6948 - val_accuracy: 0.2863\n",
      "Epoch 7/80\n",
      "6435/6435 [==============================] - 0s 34us/step - loss: 1.6539 - accuracy: 0.2977 - val_loss: 1.6754 - val_accuracy: 0.2807\n",
      "Epoch 8/80\n",
      "6435/6435 [==============================] - 0s 37us/step - loss: 1.6201 - accuracy: 0.3071 - val_loss: 1.6474 - val_accuracy: 0.3073\n",
      "Epoch 9/80\n",
      "6435/6435 [==============================] - 0s 39us/step - loss: 1.6043 - accuracy: 0.3024 - val_loss: 1.6125 - val_accuracy: 0.3142\n",
      "Epoch 10/80\n",
      "6435/6435 [==============================] - 0s 44us/step - loss: 1.5835 - accuracy: 0.3074 - val_loss: 1.6199 - val_accuracy: 0.2807\n",
      "Epoch 11/80\n",
      "6435/6435 [==============================] - 0s 37us/step - loss: 1.5788 - accuracy: 0.3064 - val_loss: 1.5886 - val_accuracy: 0.3422\n",
      "Epoch 12/80\n",
      "6435/6435 [==============================] - 0s 42us/step - loss: 1.5671 - accuracy: 0.3106 - val_loss: 1.5815 - val_accuracy: 0.3156\n",
      "Epoch 13/80\n",
      "6435/6435 [==============================] - 0s 42us/step - loss: 1.5531 - accuracy: 0.3138 - val_loss: 1.5864 - val_accuracy: 0.2975\n",
      "Epoch 14/80\n",
      "6435/6435 [==============================] - 0s 42us/step - loss: 1.5529 - accuracy: 0.3094 - val_loss: 1.5681 - val_accuracy: 0.3226\n",
      "Epoch 15/80\n",
      "6435/6435 [==============================] - 0s 42us/step - loss: 1.5546 - accuracy: 0.3024 - val_loss: 1.5557 - val_accuracy: 0.2975\n",
      "Epoch 16/80\n",
      "6435/6435 [==============================] - 0s 38us/step - loss: 1.5377 - accuracy: 0.3114 - val_loss: 1.5598 - val_accuracy: 0.3198\n",
      "Epoch 17/80\n",
      "6435/6435 [==============================] - 0s 40us/step - loss: 1.5357 - accuracy: 0.3094 - val_loss: 1.5498 - val_accuracy: 0.3087\n",
      "Epoch 18/80\n",
      "6435/6435 [==============================] - 0s 40us/step - loss: 1.5276 - accuracy: 0.3173 - val_loss: 1.5581 - val_accuracy: 0.3087\n",
      "Epoch 19/80\n",
      "6435/6435 [==============================] - 0s 45us/step - loss: 1.5265 - accuracy: 0.3144 - val_loss: 1.5510 - val_accuracy: 0.3170\n",
      "Epoch 20/80\n",
      "6435/6435 [==============================] - 0s 43us/step - loss: 1.5268 - accuracy: 0.3108 - val_loss: 1.5486 - val_accuracy: 0.3115\n",
      "Epoch 21/80\n",
      "6435/6435 [==============================] - 0s 43us/step - loss: 1.5278 - accuracy: 0.3100 - val_loss: 1.5483 - val_accuracy: 0.3031\n",
      "Epoch 22/80\n",
      "6435/6435 [==============================] - 0s 42us/step - loss: 1.5187 - accuracy: 0.3150 - val_loss: 1.5373 - val_accuracy: 0.3198\n",
      "Epoch 23/80\n",
      "6435/6435 [==============================] - 0s 43us/step - loss: 1.5125 - accuracy: 0.3187 - val_loss: 1.5366 - val_accuracy: 0.3059\n",
      "Epoch 24/80\n",
      "6435/6435 [==============================] - 0s 44us/step - loss: 1.5076 - accuracy: 0.3193 - val_loss: 1.5461 - val_accuracy: 0.3226\n",
      "Epoch 25/80\n",
      "6435/6435 [==============================] - 0s 45us/step - loss: 1.5081 - accuracy: 0.3100 - val_loss: 1.5389 - val_accuracy: 0.2989\n",
      "Epoch 26/80\n",
      "6435/6435 [==============================] - 0s 44us/step - loss: 1.5052 - accuracy: 0.3152 - val_loss: 1.5264 - val_accuracy: 0.3240\n",
      "Epoch 27/80\n",
      "6435/6435 [==============================] - 0s 41us/step - loss: 1.5001 - accuracy: 0.3256 - val_loss: 1.5224 - val_accuracy: 0.3142\n",
      "Epoch 28/80\n",
      "6435/6435 [==============================] - 0s 42us/step - loss: 1.5013 - accuracy: 0.3204 - val_loss: 1.5309 - val_accuracy: 0.3352\n",
      "Epoch 29/80\n",
      "6435/6435 [==============================] - 0s 41us/step - loss: 1.4994 - accuracy: 0.3117 - val_loss: 1.5172 - val_accuracy: 0.3436\n",
      "Epoch 30/80\n",
      "6435/6435 [==============================] - 0s 41us/step - loss: 1.4939 - accuracy: 0.3206 - val_loss: 1.5227 - val_accuracy: 0.3240\n",
      "Epoch 31/80\n",
      "6435/6435 [==============================] - 0s 41us/step - loss: 1.4892 - accuracy: 0.3142 - val_loss: 1.5205 - val_accuracy: 0.3142\n",
      "Epoch 32/80\n",
      "6435/6435 [==============================] - 0s 41us/step - loss: 1.4896 - accuracy: 0.3138 - val_loss: 1.5083 - val_accuracy: 0.3296\n",
      "Epoch 33/80\n",
      "6435/6435 [==============================] - 0s 40us/step - loss: 1.4920 - accuracy: 0.3169 - val_loss: 1.5169 - val_accuracy: 0.3198\n",
      "Epoch 34/80\n",
      "6435/6435 [==============================] - 0s 41us/step - loss: 1.4833 - accuracy: 0.3206 - val_loss: 1.5069 - val_accuracy: 0.3059\n",
      "Epoch 35/80\n",
      "6435/6435 [==============================] - 0s 43us/step - loss: 1.4823 - accuracy: 0.3192 - val_loss: 1.5016 - val_accuracy: 0.3394\n",
      "Epoch 36/80\n",
      "6435/6435 [==============================] - 0s 40us/step - loss: 1.4851 - accuracy: 0.3181 - val_loss: 1.5094 - val_accuracy: 0.3352\n",
      "Epoch 37/80\n",
      "6435/6435 [==============================] - 0s 44us/step - loss: 1.4822 - accuracy: 0.3223 - val_loss: 1.5055 - val_accuracy: 0.3198\n",
      "Epoch 38/80\n",
      "6435/6435 [==============================] - 0s 41us/step - loss: 1.4787 - accuracy: 0.3131 - val_loss: 1.5070 - val_accuracy: 0.3366\n",
      "Epoch 39/80\n",
      "6435/6435 [==============================] - 0s 43us/step - loss: 1.4776 - accuracy: 0.3232 - val_loss: 1.5128 - val_accuracy: 0.3450\n",
      "Epoch 40/80\n",
      "6435/6435 [==============================] - 0s 39us/step - loss: 1.4844 - accuracy: 0.3246 - val_loss: 1.5025 - val_accuracy: 0.3212\n",
      "Epoch 41/80\n",
      "6435/6435 [==============================] - 0s 42us/step - loss: 1.4782 - accuracy: 0.3231 - val_loss: 1.4989 - val_accuracy: 0.3380\n",
      "Epoch 42/80\n",
      "6435/6435 [==============================] - 0s 40us/step - loss: 1.4760 - accuracy: 0.3152 - val_loss: 1.5000 - val_accuracy: 0.3059\n",
      "Epoch 43/80\n",
      "6435/6435 [==============================] - 0s 39us/step - loss: 1.4756 - accuracy: 0.3200 - val_loss: 1.4957 - val_accuracy: 0.3296\n",
      "Epoch 44/80\n",
      "6435/6435 [==============================] - 0s 39us/step - loss: 1.4683 - accuracy: 0.3298 - val_loss: 1.5047 - val_accuracy: 0.3212\n",
      "Epoch 45/80\n",
      "6435/6435 [==============================] - 0s 41us/step - loss: 1.4756 - accuracy: 0.3225 - val_loss: 1.4981 - val_accuracy: 0.3324\n",
      "Epoch 46/80\n",
      "6435/6435 [==============================] - 0s 39us/step - loss: 1.4700 - accuracy: 0.3239 - val_loss: 1.4902 - val_accuracy: 0.3101\n",
      "Epoch 47/80\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6435/6435 [==============================] - 0s 46us/step - loss: 1.4661 - accuracy: 0.3284 - val_loss: 1.4780 - val_accuracy: 0.3268\n",
      "Epoch 48/80\n",
      "6435/6435 [==============================] - 0s 41us/step - loss: 1.4609 - accuracy: 0.3285 - val_loss: 1.4916 - val_accuracy: 0.3310\n",
      "Epoch 49/80\n",
      "6435/6435 [==============================] - 0s 37us/step - loss: 1.4589 - accuracy: 0.3315 - val_loss: 1.4845 - val_accuracy: 0.3198\n",
      "Epoch 50/80\n",
      "6435/6435 [==============================] - 0s 40us/step - loss: 1.4559 - accuracy: 0.3372 - val_loss: 1.4811 - val_accuracy: 0.3366\n",
      "Epoch 51/80\n",
      "6435/6435 [==============================] - 0s 38us/step - loss: 1.4576 - accuracy: 0.3279 - val_loss: 1.4990 - val_accuracy: 0.2989\n",
      "Epoch 52/80\n",
      "6435/6435 [==============================] - 0s 40us/step - loss: 1.4541 - accuracy: 0.3336 - val_loss: 1.4681 - val_accuracy: 0.3240\n",
      "Epoch 53/80\n",
      "6435/6435 [==============================] - 0s 41us/step - loss: 1.4551 - accuracy: 0.3402 - val_loss: 1.4722 - val_accuracy: 0.3017\n",
      "Epoch 54/80\n",
      "6435/6435 [==============================] - 0s 39us/step - loss: 1.4433 - accuracy: 0.3403 - val_loss: 1.4632 - val_accuracy: 0.3701\n",
      "Epoch 55/80\n",
      "6435/6435 [==============================] - 0s 38us/step - loss: 1.4400 - accuracy: 0.3517 - val_loss: 1.4659 - val_accuracy: 0.3506\n",
      "Epoch 56/80\n",
      "6435/6435 [==============================] - 0s 38us/step - loss: 1.4351 - accuracy: 0.3545 - val_loss: 1.4656 - val_accuracy: 0.3464\n",
      "Epoch 57/80\n",
      "6435/6435 [==============================] - 0s 41us/step - loss: 1.4225 - accuracy: 0.3708 - val_loss: 1.4389 - val_accuracy: 0.3799\n",
      "Epoch 58/80\n",
      "6435/6435 [==============================] - 0s 37us/step - loss: 1.4099 - accuracy: 0.3647 - val_loss: 1.4413 - val_accuracy: 0.3520\n",
      "Epoch 59/80\n",
      "6435/6435 [==============================] - 0s 43us/step - loss: 1.4007 - accuracy: 0.3750 - val_loss: 1.4133 - val_accuracy: 0.3841\n",
      "Epoch 60/80\n",
      "6435/6435 [==============================] - 0s 39us/step - loss: 1.3884 - accuracy: 0.3713 - val_loss: 1.4054 - val_accuracy: 0.4050\n",
      "Epoch 61/80\n",
      "6435/6435 [==============================] - 0s 40us/step - loss: 1.3834 - accuracy: 0.3751 - val_loss: 1.4047 - val_accuracy: 0.3701\n",
      "Epoch 62/80\n",
      "6435/6435 [==============================] - 0s 41us/step - loss: 1.3639 - accuracy: 0.3765 - val_loss: 1.3688 - val_accuracy: 0.3869\n",
      "Epoch 63/80\n",
      "6435/6435 [==============================] - 0s 41us/step - loss: 1.3468 - accuracy: 0.3814 - val_loss: 1.3510 - val_accuracy: 0.3966\n",
      "Epoch 64/80\n",
      "6435/6435 [==============================] - 0s 38us/step - loss: 1.3354 - accuracy: 0.3862 - val_loss: 1.3393 - val_accuracy: 0.3980\n",
      "Epoch 65/80\n",
      "6435/6435 [==============================] - 0s 38us/step - loss: 1.3214 - accuracy: 0.3877 - val_loss: 1.3441 - val_accuracy: 0.3771\n",
      "Epoch 66/80\n",
      "6435/6435 [==============================] - 0s 38us/step - loss: 1.3137 - accuracy: 0.3877 - val_loss: 1.3177 - val_accuracy: 0.3953\n",
      "Epoch 67/80\n",
      "6435/6435 [==============================] - 0s 39us/step - loss: 1.3039 - accuracy: 0.3851 - val_loss: 1.3139 - val_accuracy: 0.3869\n",
      "Epoch 68/80\n",
      "6435/6435 [==============================] - 0s 40us/step - loss: 1.2981 - accuracy: 0.3905 - val_loss: 1.3155 - val_accuracy: 0.3785\n",
      "Epoch 69/80\n",
      "6435/6435 [==============================] - 0s 36us/step - loss: 1.2965 - accuracy: 0.3845 - val_loss: 1.3199 - val_accuracy: 0.3883\n",
      "Epoch 70/80\n",
      "6435/6435 [==============================] - 0s 40us/step - loss: 1.2913 - accuracy: 0.3911 - val_loss: 1.3066 - val_accuracy: 0.3966\n",
      "Epoch 71/80\n",
      "6435/6435 [==============================] - 0s 40us/step - loss: 1.2883 - accuracy: 0.3935 - val_loss: 1.2975 - val_accuracy: 0.4022\n",
      "Epoch 72/80\n",
      "6435/6435 [==============================] - 0s 38us/step - loss: 1.2835 - accuracy: 0.3901 - val_loss: 1.3245 - val_accuracy: 0.3911\n",
      "Epoch 73/80\n",
      "6435/6435 [==============================] - 0s 39us/step - loss: 1.2869 - accuracy: 0.3885 - val_loss: 1.3012 - val_accuracy: 0.4092\n",
      "Epoch 74/80\n",
      "6435/6435 [==============================] - 0s 40us/step - loss: 1.2801 - accuracy: 0.3949 - val_loss: 1.2991 - val_accuracy: 0.3939\n",
      "Epoch 75/80\n",
      "6435/6435 [==============================] - 0s 39us/step - loss: 1.2722 - accuracy: 0.3943 - val_loss: 1.2805 - val_accuracy: 0.3939\n",
      "Epoch 76/80\n",
      "6435/6435 [==============================] - 0s 44us/step - loss: 1.2770 - accuracy: 0.4098 - val_loss: 1.2912 - val_accuracy: 0.3785\n",
      "Epoch 77/80\n",
      "6435/6435 [==============================] - 0s 39us/step - loss: 1.2704 - accuracy: 0.3924 - val_loss: 1.2857 - val_accuracy: 0.3911\n",
      "Epoch 78/80\n",
      "6435/6435 [==============================] - 0s 38us/step - loss: 1.2668 - accuracy: 0.3960 - val_loss: 1.2809 - val_accuracy: 0.3897\n",
      "Epoch 79/80\n",
      "6435/6435 [==============================] - 0s 43us/step - loss: 1.2627 - accuracy: 0.3974 - val_loss: 1.2752 - val_accuracy: 0.4036\n",
      "Epoch 80/80\n",
      "6435/6435 [==============================] - 0s 37us/step - loss: 1.2605 - accuracy: 0.3994 - val_loss: 1.2867 - val_accuracy: 0.3799\n",
      "[[1.10025577e-01 1.27806023e-01 8.04336822e-16 ... 2.50276029e-01\n",
      "  2.47476071e-01 2.50017673e-01]\n",
      " [5.24446070e-02 5.98056056e-02 1.55591878e-24 ... 5.52480947e-03\n",
      "  2.70127952e-02 2.58301031e-02]\n",
      " [2.05590978e-01 2.49549091e-01 1.02563197e-19 ... 4.90439758e-02\n",
      "  2.55744994e-01 2.38416478e-01]\n",
      " ...\n",
      " [2.36433685e-01 2.77230114e-01 4.36555877e-21 ... 6.60465378e-03\n",
      "  2.39764050e-01 2.39452139e-01]\n",
      " [1.03788681e-01 1.27161369e-01 1.20028905e-14 ... 1.31063089e-01\n",
      "  3.16038996e-01 3.01666319e-01]\n",
      " [1.13930322e-01 1.38068601e-01 2.25496391e-15 ... 1.39171407e-01\n",
      "  2.99306631e-01 2.96589524e-01]]\n",
      "[12 10 13 ...  1 13 13]\n",
      "<class 'numpy.ndarray'>\n",
      "One CNN, r:  0\n",
      "Computing Time:  0:00:38.576774\n",
      "n, p1, p2 1 0 0\n",
      "Model: \"sequential_1\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv1d_1 (Conv1D)            (None, 3, 6)              12        \n",
      "_________________________________________________________________\n",
      "average_pooling1d_1 (Average (None, 1, 6)              0         \n",
      "_________________________________________________________________\n",
      "conv1d_2 (Conv1D)            (None, 1, 16)             112       \n",
      "_________________________________________________________________\n",
      "average_pooling1d_2 (Average (None, 1, 16)             0         \n",
      "_________________________________________________________________\n",
      "conv1d_3 (Conv1D)            (None, 1, 120)            2040      \n",
      "_________________________________________________________________\n",
      "flatten_1 (Flatten)          (None, 120)               0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 84)                10164     \n",
      "_________________________________________________________________\n",
      "preds (Dense)                (None, 15)                1275      \n",
      "=================================================================\n",
      "Total params: 13,603\n",
      "Trainable params: 13,603\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Train on 6435 samples, validate on 716 samples\n",
      "Epoch 1/80\n",
      "6435/6435 [==============================] - 1s 83us/step - loss: 2.6635 - accuracy: 0.1548 - val_loss: 2.5412 - val_accuracy: 0.1648\n",
      "Epoch 2/80\n",
      "6435/6435 [==============================] - 0s 46us/step - loss: 2.2953 - accuracy: 0.2056 - val_loss: 2.0512 - val_accuracy: 0.2304\n",
      "Epoch 3/80\n",
      "6435/6435 [==============================] - 0s 42us/step - loss: 1.9921 - accuracy: 0.2503 - val_loss: 1.8924 - val_accuracy: 0.2821\n",
      "Epoch 4/80\n",
      "6435/6435 [==============================] - 0s 41us/step - loss: 1.8785 - accuracy: 0.2838 - val_loss: 1.7975 - val_accuracy: 0.2919\n",
      "Epoch 5/80\n",
      "6435/6435 [==============================] - 0s 41us/step - loss: 1.8049 - accuracy: 0.2897 - val_loss: 1.7352 - val_accuracy: 0.3017\n",
      "Epoch 6/80\n",
      "6435/6435 [==============================] - 0s 39us/step - loss: 1.7364 - accuracy: 0.2880 - val_loss: 1.6684 - val_accuracy: 0.2975\n",
      "Epoch 7/80\n",
      "6435/6435 [==============================] - 0s 40us/step - loss: 1.6849 - accuracy: 0.2838 - val_loss: 1.6226 - val_accuracy: 0.3212\n",
      "Epoch 8/80\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6435/6435 [==============================] - 0s 37us/step - loss: 1.6503 - accuracy: 0.2990 - val_loss: 1.6171 - val_accuracy: 0.3073\n",
      "Epoch 9/80\n",
      "6435/6435 [==============================] - 0s 41us/step - loss: 1.6292 - accuracy: 0.3049 - val_loss: 1.5737 - val_accuracy: 0.3408\n",
      "Epoch 10/80\n",
      "6435/6435 [==============================] - 0s 40us/step - loss: 1.5997 - accuracy: 0.3142 - val_loss: 1.5601 - val_accuracy: 0.3226\n",
      "Epoch 11/80\n",
      "6435/6435 [==============================] - 0s 41us/step - loss: 1.5708 - accuracy: 0.3173 - val_loss: 1.5274 - val_accuracy: 0.3310\n",
      "Epoch 12/80\n",
      "6435/6435 [==============================] - 0s 38us/step - loss: 1.5504 - accuracy: 0.3183 - val_loss: 1.5171 - val_accuracy: 0.3422\n",
      "Epoch 13/80\n",
      "6435/6435 [==============================] - 0s 39us/step - loss: 1.5412 - accuracy: 0.3100 - val_loss: 1.5046 - val_accuracy: 0.3198\n",
      "Epoch 14/80\n",
      "6435/6435 [==============================] - 0s 38us/step - loss: 1.5287 - accuracy: 0.3119 - val_loss: 1.4964 - val_accuracy: 0.3101\n",
      "Epoch 15/80\n",
      "6435/6435 [==============================] - 0s 41us/step - loss: 1.5226 - accuracy: 0.3134 - val_loss: 1.4999 - val_accuracy: 0.3142\n",
      "Epoch 16/80\n",
      "6435/6435 [==============================] - 0s 41us/step - loss: 1.5290 - accuracy: 0.3064 - val_loss: 1.4972 - val_accuracy: 0.3422\n",
      "Epoch 17/80\n",
      "6435/6435 [==============================] - 0s 38us/step - loss: 1.5175 - accuracy: 0.3119 - val_loss: 1.4911 - val_accuracy: 0.3212\n",
      "Epoch 18/80\n",
      "6435/6435 [==============================] - 0s 36us/step - loss: 1.5096 - accuracy: 0.3159 - val_loss: 1.4813 - val_accuracy: 0.3450\n",
      "Epoch 19/80\n",
      "6435/6435 [==============================] - 0s 37us/step - loss: 1.5099 - accuracy: 0.3114 - val_loss: 1.5027 - val_accuracy: 0.2877\n",
      "Epoch 20/80\n",
      "6435/6435 [==============================] - 0s 39us/step - loss: 1.5106 - accuracy: 0.3139 - val_loss: 1.4702 - val_accuracy: 0.3478\n",
      "Epoch 21/80\n",
      "6435/6435 [==============================] - 0s 40us/step - loss: 1.5071 - accuracy: 0.3103 - val_loss: 1.4733 - val_accuracy: 0.3422\n",
      "Epoch 22/80\n",
      "6435/6435 [==============================] - 0s 43us/step - loss: 1.5016 - accuracy: 0.3066 - val_loss: 1.4681 - val_accuracy: 0.3268\n",
      "Epoch 23/80\n",
      "6435/6435 [==============================] - 0s 43us/step - loss: 1.4971 - accuracy: 0.3186 - val_loss: 1.4853 - val_accuracy: 0.3184\n",
      "Epoch 24/80\n",
      "6435/6435 [==============================] - 0s 39us/step - loss: 1.5000 - accuracy: 0.3127 - val_loss: 1.4756 - val_accuracy: 0.3059\n",
      "Epoch 25/80\n",
      "6435/6435 [==============================] - 0s 40us/step - loss: 1.4958 - accuracy: 0.3114 - val_loss: 1.4658 - val_accuracy: 0.3422\n",
      "Epoch 26/80\n",
      "6435/6435 [==============================] - 0s 42us/step - loss: 1.4881 - accuracy: 0.3099 - val_loss: 1.4709 - val_accuracy: 0.3338\n",
      "Epoch 27/80\n",
      "6435/6435 [==============================] - 0s 40us/step - loss: 1.4921 - accuracy: 0.3124 - val_loss: 1.4758 - val_accuracy: 0.3059\n",
      "Epoch 28/80\n",
      "6435/6435 [==============================] - 0s 39us/step - loss: 1.4879 - accuracy: 0.3085 - val_loss: 1.4688 - val_accuracy: 0.3268\n",
      "Epoch 29/80\n",
      "6435/6435 [==============================] - 0s 38us/step - loss: 1.4808 - accuracy: 0.3105 - val_loss: 1.4522 - val_accuracy: 0.3324\n",
      "Epoch 30/80\n",
      "6435/6435 [==============================] - 0s 38us/step - loss: 1.4829 - accuracy: 0.3209 - val_loss: 1.4616 - val_accuracy: 0.3170\n",
      "Epoch 31/80\n",
      "6435/6435 [==============================] - 0s 34us/step - loss: 1.4844 - accuracy: 0.3086 - val_loss: 1.4560 - val_accuracy: 0.3450\n",
      "Epoch 32/80\n",
      "6435/6435 [==============================] - 0s 35us/step - loss: 1.4811 - accuracy: 0.3139 - val_loss: 1.4595 - val_accuracy: 0.3464\n",
      "Epoch 33/80\n",
      "6435/6435 [==============================] - 0s 37us/step - loss: 1.4825 - accuracy: 0.3064 - val_loss: 1.5004 - val_accuracy: 0.3017\n",
      "Epoch 34/80\n",
      "6435/6435 [==============================] - 0s 38us/step - loss: 1.4858 - accuracy: 0.3119 - val_loss: 1.4550 - val_accuracy: 0.3198\n",
      "Epoch 35/80\n",
      "6435/6435 [==============================] - 0s 37us/step - loss: 1.4814 - accuracy: 0.3176 - val_loss: 1.4711 - val_accuracy: 0.2933\n",
      "Epoch 36/80\n",
      "6435/6435 [==============================] - 0s 38us/step - loss: 1.4730 - accuracy: 0.3092 - val_loss: 1.4490 - val_accuracy: 0.3394\n",
      "Epoch 37/80\n",
      "6435/6435 [==============================] - 0s 39us/step - loss: 1.4768 - accuracy: 0.3085 - val_loss: 1.4605 - val_accuracy: 0.3156\n",
      "Epoch 38/80\n",
      "6435/6435 [==============================] - 0s 38us/step - loss: 1.4760 - accuracy: 0.3153 - val_loss: 1.4751 - val_accuracy: 0.2891\n",
      "Epoch 39/80\n",
      "6435/6435 [==============================] - 0s 39us/step - loss: 1.4719 - accuracy: 0.3197 - val_loss: 1.4528 - val_accuracy: 0.3394\n",
      "Epoch 40/80\n",
      "6435/6435 [==============================] - ETA: 0s - loss: 1.4709 - accuracy: 0.31 - 0s 37us/step - loss: 1.4709 - accuracy: 0.3120 - val_loss: 1.4646 - val_accuracy: 0.3115\n",
      "Epoch 41/80\n",
      "6435/6435 [==============================] - 0s 40us/step - loss: 1.4749 - accuracy: 0.3155 - val_loss: 1.4490 - val_accuracy: 0.3352\n",
      "Epoch 42/80\n",
      "6435/6435 [==============================] - 0s 40us/step - loss: 1.4704 - accuracy: 0.3204 - val_loss: 1.4639 - val_accuracy: 0.2975\n",
      "Epoch 43/80\n",
      "6435/6435 [==============================] - 0s 39us/step - loss: 1.4692 - accuracy: 0.3150 - val_loss: 1.4557 - val_accuracy: 0.2933\n",
      "Epoch 44/80\n",
      "6435/6435 [==============================] - 0s 48us/step - loss: 1.4668 - accuracy: 0.3195 - val_loss: 1.4516 - val_accuracy: 0.3352\n",
      "Epoch 45/80\n",
      "6435/6435 [==============================] - 0s 41us/step - loss: 1.4636 - accuracy: 0.3212 - val_loss: 1.4542 - val_accuracy: 0.3324\n",
      "Epoch 46/80\n",
      "6435/6435 [==============================] - 0s 41us/step - loss: 1.4651 - accuracy: 0.3234 - val_loss: 1.4526 - val_accuracy: 0.3296\n",
      "Epoch 47/80\n",
      "6435/6435 [==============================] - 0s 39us/step - loss: 1.4629 - accuracy: 0.3273 - val_loss: 1.4503 - val_accuracy: 0.2989\n",
      "Epoch 48/80\n",
      "6435/6435 [==============================] - 0s 39us/step - loss: 1.4602 - accuracy: 0.3245 - val_loss: 1.4407 - val_accuracy: 0.3492\n",
      "Epoch 49/80\n",
      "6435/6435 [==============================] - 0s 40us/step - loss: 1.4591 - accuracy: 0.3254 - val_loss: 1.4343 - val_accuracy: 0.3492\n",
      "Epoch 50/80\n",
      "6435/6435 [==============================] - 0s 39us/step - loss: 1.4553 - accuracy: 0.3249 - val_loss: 1.4537 - val_accuracy: 0.3422\n",
      "Epoch 51/80\n",
      "6435/6435 [==============================] - 0s 43us/step - loss: 1.4571 - accuracy: 0.3357 - val_loss: 1.4516 - val_accuracy: 0.3226\n",
      "Epoch 52/80\n",
      "6435/6435 [==============================] - 0s 42us/step - loss: 1.4613 - accuracy: 0.3192 - val_loss: 1.4330 - val_accuracy: 0.3394\n",
      "Epoch 53/80\n",
      "6435/6435 [==============================] - 0s 40us/step - loss: 1.4472 - accuracy: 0.3350 - val_loss: 1.4319 - val_accuracy: 0.3380\n",
      "Epoch 54/80\n",
      "6435/6435 [==============================] - 0s 37us/step - loss: 1.4451 - accuracy: 0.3341 - val_loss: 1.4325 - val_accuracy: 0.3366\n",
      "Epoch 55/80\n",
      "6435/6435 [==============================] - 0s 39us/step - loss: 1.4417 - accuracy: 0.3521 - val_loss: 1.4433 - val_accuracy: 0.3478\n",
      "Epoch 56/80\n",
      "6435/6435 [==============================] - 0s 40us/step - loss: 1.4410 - accuracy: 0.3490 - val_loss: 1.4528 - val_accuracy: 0.3589\n",
      "Epoch 57/80\n",
      "6435/6435 [==============================] - 0s 41us/step - loss: 1.4380 - accuracy: 0.3497 - val_loss: 1.4179 - val_accuracy: 0.3575\n",
      "Epoch 58/80\n",
      "6435/6435 [==============================] - 0s 40us/step - loss: 1.4234 - accuracy: 0.3577 - val_loss: 1.4075 - val_accuracy: 0.3450\n",
      "Epoch 59/80\n",
      "6435/6435 [==============================] - 0s 40us/step - loss: 1.4161 - accuracy: 0.3716 - val_loss: 1.3995 - val_accuracy: 0.3827\n",
      "Epoch 60/80\n",
      "6435/6435 [==============================] - 0s 41us/step - loss: 1.4068 - accuracy: 0.3630 - val_loss: 1.4313 - val_accuracy: 0.3436\n",
      "Epoch 61/80\n",
      "6435/6435 [==============================] - 0s 39us/step - loss: 1.4002 - accuracy: 0.3664 - val_loss: 1.3798 - val_accuracy: 0.3575\n",
      "Epoch 62/80\n",
      "6435/6435 [==============================] - 0s 38us/step - loss: 1.3940 - accuracy: 0.3588 - val_loss: 1.3735 - val_accuracy: 0.3729\n",
      "Epoch 63/80\n",
      "6435/6435 [==============================] - 0s 40us/step - loss: 1.3814 - accuracy: 0.3790 - val_loss: 1.3615 - val_accuracy: 0.3827\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 64/80\n",
      "6435/6435 [==============================] - 0s 41us/step - loss: 1.3662 - accuracy: 0.3879 - val_loss: 1.3494 - val_accuracy: 0.3883\n",
      "Epoch 65/80\n",
      "6435/6435 [==============================] - 0s 45us/step - loss: 1.3585 - accuracy: 0.3767 - val_loss: 1.3413 - val_accuracy: 0.3966\n",
      "Epoch 66/80\n",
      "6435/6435 [==============================] - 0s 37us/step - loss: 1.3509 - accuracy: 0.3809 - val_loss: 1.3495 - val_accuracy: 0.3603\n",
      "Epoch 67/80\n",
      "6435/6435 [==============================] - 0s 41us/step - loss: 1.3362 - accuracy: 0.3806 - val_loss: 1.3226 - val_accuracy: 0.3813\n",
      "Epoch 68/80\n",
      "6435/6435 [==============================] - 0s 39us/step - loss: 1.3296 - accuracy: 0.3784 - val_loss: 1.3278 - val_accuracy: 0.3911\n",
      "Epoch 69/80\n",
      "6435/6435 [==============================] - 0s 38us/step - loss: 1.3224 - accuracy: 0.3866 - val_loss: 1.3290 - val_accuracy: 0.3617\n",
      "Epoch 70/80\n",
      "6435/6435 [==============================] - 0s 38us/step - loss: 1.3198 - accuracy: 0.3832 - val_loss: 1.3098 - val_accuracy: 0.3827\n",
      "Epoch 71/80\n",
      "6435/6435 [==============================] - 0s 37us/step - loss: 1.3088 - accuracy: 0.3868 - val_loss: 1.3019 - val_accuracy: 0.3785\n",
      "Epoch 72/80\n",
      "6435/6435 [==============================] - 0s 38us/step - loss: 1.3064 - accuracy: 0.3869 - val_loss: 1.2836 - val_accuracy: 0.4232\n",
      "Epoch 73/80\n",
      "6435/6435 [==============================] - 0s 38us/step - loss: 1.3002 - accuracy: 0.3824 - val_loss: 1.2856 - val_accuracy: 0.3869\n",
      "Epoch 74/80\n",
      "6435/6435 [==============================] - 0s 39us/step - loss: 1.3008 - accuracy: 0.3902 - val_loss: 1.3039 - val_accuracy: 0.3589\n",
      "Epoch 75/80\n",
      "6435/6435 [==============================] - 0s 40us/step - loss: 1.2971 - accuracy: 0.3863 - val_loss: 1.2743 - val_accuracy: 0.4204\n",
      "Epoch 76/80\n",
      "6435/6435 [==============================] - 0s 39us/step - loss: 1.2884 - accuracy: 0.3936 - val_loss: 1.2885 - val_accuracy: 0.4148\n",
      "Epoch 77/80\n",
      "6435/6435 [==============================] - 0s 38us/step - loss: 1.2878 - accuracy: 0.3969 - val_loss: 1.2901 - val_accuracy: 0.3645\n",
      "Epoch 78/80\n",
      "6435/6435 [==============================] - 0s 40us/step - loss: 1.2865 - accuracy: 0.3863 - val_loss: 1.2798 - val_accuracy: 0.4008\n",
      "Epoch 79/80\n",
      "6435/6435 [==============================] - 0s 40us/step - loss: 1.2829 - accuracy: 0.3907 - val_loss: 1.2745 - val_accuracy: 0.4162\n",
      "Epoch 80/80\n",
      "6435/6435 [==============================] - 0s 41us/step - loss: 1.2860 - accuracy: 0.3946 - val_loss: 1.2857 - val_accuracy: 0.3994\n",
      "[[8.6320847e-02 9.2554271e-02 7.0422245e-14 ... 3.6385307e-01\n",
      "  2.2285037e-01 2.0559394e-01]\n",
      " [2.4072006e-02 3.0236902e-02 6.7891657e-21 ... 5.8193374e-03\n",
      "  7.2507891e-03 6.6217859e-03]\n",
      " [1.8208089e-01 1.9169179e-01 9.3881916e-17 ... 1.2219128e-01\n",
      "  2.5686473e-01 2.4316318e-01]\n",
      " ...\n",
      " [2.2695351e-01 2.4255572e-01 6.8609615e-18 ... 3.0265817e-02\n",
      "  2.6030871e-01 2.3891906e-01]\n",
      " [9.2397481e-02 9.8990232e-02 6.9241509e-13 ... 2.0823525e-01\n",
      "  2.9356763e-01 2.6772177e-01]\n",
      " [1.0246621e-01 1.1063171e-01 1.8461121e-13 ... 2.2246486e-01\n",
      "  2.7886346e-01 2.5813329e-01]]\n",
      "[12 10 13 ... 13 13 13]\n",
      "<class 'numpy.ndarray'>\n",
      "One CNN, r:  0\n",
      "Computing Time:  0:01:00.676639\n",
      "n, p1, p2 2 0 0\n",
      "Model: \"sequential_1\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv1d_1 (Conv1D)            (None, 3, 6)              12        \n",
      "_________________________________________________________________\n",
      "average_pooling1d_1 (Average (None, 1, 6)              0         \n",
      "_________________________________________________________________\n",
      "conv1d_2 (Conv1D)            (None, 1, 16)             112       \n",
      "_________________________________________________________________\n",
      "average_pooling1d_2 (Average (None, 1, 16)             0         \n",
      "_________________________________________________________________\n",
      "conv1d_3 (Conv1D)            (None, 1, 120)            2040      \n",
      "_________________________________________________________________\n",
      "flatten_1 (Flatten)          (None, 120)               0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 84)                10164     \n",
      "_________________________________________________________________\n",
      "preds (Dense)                (None, 15)                1275      \n",
      "=================================================================\n",
      "Total params: 13,603\n",
      "Trainable params: 13,603\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Train on 6435 samples, validate on 716 samples\n",
      "Epoch 1/80\n",
      "6435/6435 [==============================] - 1s 81us/step - loss: 2.6742 - accuracy: 0.1587 - val_loss: 2.5636 - val_accuracy: 0.1774\n",
      "Epoch 2/80\n",
      "6435/6435 [==============================] - 0s 43us/step - loss: 2.3292 - accuracy: 0.1784 - val_loss: 2.0122 - val_accuracy: 0.2388\n",
      "Epoch 3/80\n",
      "6435/6435 [==============================] - 0s 43us/step - loss: 1.9665 - accuracy: 0.2591 - val_loss: 1.7712 - val_accuracy: 0.2961\n",
      "Epoch 4/80\n",
      "6435/6435 [==============================] - 0s 41us/step - loss: 1.8208 - accuracy: 0.2609 - val_loss: 1.6744 - val_accuracy: 0.3338\n",
      "Epoch 5/80\n",
      "6435/6435 [==============================] - 0s 39us/step - loss: 1.7263 - accuracy: 0.2903 - val_loss: 1.6142 - val_accuracy: 0.2933\n",
      "Epoch 6/80\n",
      "6435/6435 [==============================] - 0s 43us/step - loss: 1.6557 - accuracy: 0.2821 - val_loss: 1.5560 - val_accuracy: 0.3268\n",
      "Epoch 7/80\n",
      "6435/6435 [==============================] - 0s 39us/step - loss: 1.6144 - accuracy: 0.2906 - val_loss: 1.5392 - val_accuracy: 0.2835\n",
      "Epoch 8/80\n",
      "6435/6435 [==============================] - 0s 40us/step - loss: 1.5868 - accuracy: 0.2931 - val_loss: 1.5068 - val_accuracy: 0.3003\n",
      "Epoch 9/80\n",
      "6435/6435 [==============================] - 0s 42us/step - loss: 1.5641 - accuracy: 0.2956 - val_loss: 1.5056 - val_accuracy: 0.2612\n",
      "Epoch 10/80\n",
      "6435/6435 [==============================] - 0s 41us/step - loss: 1.5593 - accuracy: 0.2904 - val_loss: 1.4776 - val_accuracy: 0.3534\n",
      "Epoch 11/80\n",
      "6435/6435 [==============================] - 0s 41us/step - loss: 1.5502 - accuracy: 0.3027 - val_loss: 1.4868 - val_accuracy: 0.3156\n",
      "Epoch 12/80\n",
      "6435/6435 [==============================] - 0s 40us/step - loss: 1.5411 - accuracy: 0.3027 - val_loss: 1.4764 - val_accuracy: 0.3268\n",
      "Epoch 13/80\n",
      "6435/6435 [==============================] - 0s 40us/step - loss: 1.5349 - accuracy: 0.3088 - val_loss: 1.4507 - val_accuracy: 0.3450\n",
      "Epoch 14/80\n",
      "6435/6435 [==============================] - 0s 41us/step - loss: 1.5347 - accuracy: 0.2937 - val_loss: 1.4683 - val_accuracy: 0.3003\n",
      "Epoch 15/80\n",
      "6435/6435 [==============================] - 0s 42us/step - loss: 1.5279 - accuracy: 0.3007 - val_loss: 1.4663 - val_accuracy: 0.3101\n",
      "Epoch 16/80\n",
      "6435/6435 [==============================] - 0s 40us/step - loss: 1.5299 - accuracy: 0.2959 - val_loss: 1.4661 - val_accuracy: 0.3142\n",
      "Epoch 17/80\n",
      "6435/6435 [==============================] - 0s 38us/step - loss: 1.5210 - accuracy: 0.3097 - val_loss: 1.4368 - val_accuracy: 0.3170\n",
      "Epoch 18/80\n",
      "6435/6435 [==============================] - 0s 41us/step - loss: 1.5140 - accuracy: 0.3091 - val_loss: 1.4419 - val_accuracy: 0.3101\n",
      "Epoch 19/80\n",
      "6435/6435 [==============================] - 0s 43us/step - loss: 1.5134 - accuracy: 0.3046 - val_loss: 1.4294 - val_accuracy: 0.3338\n",
      "Epoch 20/80\n",
      "6435/6435 [==============================] - 0s 41us/step - loss: 1.5179 - accuracy: 0.3068 - val_loss: 1.4398 - val_accuracy: 0.3115\n",
      "Epoch 21/80\n",
      "6435/6435 [==============================] - 0s 41us/step - loss: 1.5125 - accuracy: 0.2984 - val_loss: 1.4362 - val_accuracy: 0.3115\n",
      "Epoch 22/80\n",
      "6435/6435 [==============================] - 0s 39us/step - loss: 1.5133 - accuracy: 0.3049 - val_loss: 1.4607 - val_accuracy: 0.3212\n",
      "Epoch 23/80\n",
      "6435/6435 [==============================] - 0s 41us/step - loss: 1.5080 - accuracy: 0.3080 - val_loss: 1.4160 - val_accuracy: 0.3534\n",
      "Epoch 24/80\n",
      "6435/6435 [==============================] - 0s 38us/step - loss: 1.5046 - accuracy: 0.3077 - val_loss: 1.4382 - val_accuracy: 0.3310\n",
      "Epoch 25/80\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6435/6435 [==============================] - 0s 39us/step - loss: 1.5088 - accuracy: 0.3057 - val_loss: 1.4524 - val_accuracy: 0.3226\n",
      "Epoch 26/80\n",
      "6435/6435 [==============================] - 0s 41us/step - loss: 1.5036 - accuracy: 0.3148 - val_loss: 1.4335 - val_accuracy: 0.3520\n",
      "Epoch 27/80\n",
      "6435/6435 [==============================] - 0s 41us/step - loss: 1.5036 - accuracy: 0.3068 - val_loss: 1.4376 - val_accuracy: 0.3142\n",
      "Epoch 28/80\n",
      "6435/6435 [==============================] - 0s 38us/step - loss: 1.4992 - accuracy: 0.3184 - val_loss: 1.4243 - val_accuracy: 0.3338\n",
      "Epoch 29/80\n",
      "6435/6435 [==============================] - 0s 40us/step - loss: 1.4997 - accuracy: 0.3209 - val_loss: 1.4576 - val_accuracy: 0.3212\n",
      "Epoch 30/80\n",
      "6435/6435 [==============================] - 0s 39us/step - loss: 1.5051 - accuracy: 0.3122 - val_loss: 1.4191 - val_accuracy: 0.3478\n",
      "Epoch 31/80\n",
      "6435/6435 [==============================] - 0s 38us/step - loss: 1.5078 - accuracy: 0.3040 - val_loss: 1.4351 - val_accuracy: 0.3240\n",
      "Epoch 32/80\n",
      "6435/6435 [==============================] - 0s 39us/step - loss: 1.5031 - accuracy: 0.3161 - val_loss: 1.4268 - val_accuracy: 0.3156\n",
      "Epoch 33/80\n",
      "6435/6435 [==============================] - 0s 39us/step - loss: 1.4992 - accuracy: 0.3119 - val_loss: 1.4439 - val_accuracy: 0.2877\n",
      "Epoch 00033: early stopping\n",
      "[[1.5133397e-01 1.2810458e-01 5.7638935e-11 ... 1.9245902e-01\n",
      "  2.6648435e-01 2.2480781e-01]\n",
      " [3.8443681e-02 3.5918146e-02 9.2514442e-16 ... 8.0750268e-03\n",
      "  1.7287623e-02 1.7593643e-02]\n",
      " [1.7480825e-01 1.3066657e-01 2.9501937e-12 ... 2.3647441e-01\n",
      "  2.4560104e-01 1.9082545e-01]\n",
      " ...\n",
      " [1.7517161e-01 1.3039167e-01 3.5807314e-12 ... 2.3525314e-01\n",
      "  2.4673854e-01 1.9160378e-01]\n",
      " [1.2404957e-01 1.2274769e-01 4.4961465e-10 ... 1.4742237e-01\n",
      "  2.7695116e-01 2.5746888e-01]\n",
      " [1.3461259e-01 1.2555994e-01 2.0541190e-10 ... 1.6403832e-01\n",
      "  2.7464634e-01 2.4614890e-01]]\n",
      "[13  5 13 ... 13 13 13]\n",
      "<class 'numpy.ndarray'>\n",
      "One CNN, r:  0\n",
      "Computing Time:  0:01:10.906129\n",
      "n, p1, p2 3 0 0\n",
      "Model: \"sequential_1\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv1d_1 (Conv1D)            (None, 3, 6)              12        \n",
      "_________________________________________________________________\n",
      "average_pooling1d_1 (Average (None, 1, 6)              0         \n",
      "_________________________________________________________________\n",
      "conv1d_2 (Conv1D)            (None, 1, 16)             112       \n",
      "_________________________________________________________________\n",
      "average_pooling1d_2 (Average (None, 1, 16)             0         \n",
      "_________________________________________________________________\n",
      "conv1d_3 (Conv1D)            (None, 1, 120)            2040      \n",
      "_________________________________________________________________\n",
      "flatten_1 (Flatten)          (None, 120)               0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 84)                10164     \n",
      "_________________________________________________________________\n",
      "preds (Dense)                (None, 15)                1275      \n",
      "=================================================================\n",
      "Total params: 13,603\n",
      "Trainable params: 13,603\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Train on 6435 samples, validate on 716 samples\n",
      "Epoch 1/80\n",
      "6435/6435 [==============================] - 1s 79us/step - loss: 2.6675 - accuracy: 0.1584 - val_loss: 2.5633 - val_accuracy: 0.1927\n",
      "Epoch 2/80\n",
      "6435/6435 [==============================] - 0s 44us/step - loss: 2.3156 - accuracy: 0.1894 - val_loss: 2.1043 - val_accuracy: 0.2779\n",
      "Epoch 3/80\n",
      "6435/6435 [==============================] - 0s 40us/step - loss: 1.9729 - accuracy: 0.2657 - val_loss: 1.9040 - val_accuracy: 0.2528\n",
      "Epoch 4/80\n",
      "6435/6435 [==============================] - 0s 40us/step - loss: 1.8337 - accuracy: 0.2786 - val_loss: 1.7982 - val_accuracy: 0.2989\n",
      "Epoch 5/80\n",
      "6435/6435 [==============================] - 0s 38us/step - loss: 1.7466 - accuracy: 0.2945 - val_loss: 1.7260 - val_accuracy: 0.2709\n",
      "Epoch 6/80\n",
      "6435/6435 [==============================] - 0s 42us/step - loss: 1.6725 - accuracy: 0.2985 - val_loss: 1.6677 - val_accuracy: 0.2584\n",
      "Epoch 7/80\n",
      "6435/6435 [==============================] - 0s 42us/step - loss: 1.6252 - accuracy: 0.3026 - val_loss: 1.6464 - val_accuracy: 0.2835\n",
      "Epoch 8/80\n",
      "6435/6435 [==============================] - 0s 41us/step - loss: 1.6004 - accuracy: 0.3032 - val_loss: 1.6097 - val_accuracy: 0.3296\n",
      "Epoch 9/80\n",
      "6435/6435 [==============================] - 0s 41us/step - loss: 1.5831 - accuracy: 0.3074 - val_loss: 1.6056 - val_accuracy: 0.2723\n",
      "Epoch 10/80\n",
      "6435/6435 [==============================] - 0s 39us/step - loss: 1.5595 - accuracy: 0.3145 - val_loss: 1.5645 - val_accuracy: 0.3115\n",
      "Epoch 11/80\n",
      "6435/6435 [==============================] - 0s 41us/step - loss: 1.5490 - accuracy: 0.3089 - val_loss: 1.5663 - val_accuracy: 0.3017\n",
      "Epoch 12/80\n",
      "6435/6435 [==============================] - 0s 42us/step - loss: 1.5494 - accuracy: 0.3082 - val_loss: 1.5594 - val_accuracy: 0.3073\n",
      "Epoch 13/80\n",
      "6435/6435 [==============================] - 0s 42us/step - loss: 1.5386 - accuracy: 0.3089 - val_loss: 1.5459 - val_accuracy: 0.2933\n",
      "Epoch 14/80\n",
      "6435/6435 [==============================] - 0s 40us/step - loss: 1.5294 - accuracy: 0.3094 - val_loss: 1.5477 - val_accuracy: 0.2919\n",
      "Epoch 15/80\n",
      "6435/6435 [==============================] - 0s 40us/step - loss: 1.5261 - accuracy: 0.3097 - val_loss: 1.5346 - val_accuracy: 0.3156\n",
      "Epoch 16/80\n",
      "6435/6435 [==============================] - 0s 40us/step - loss: 1.5251 - accuracy: 0.3094 - val_loss: 1.5328 - val_accuracy: 0.3059\n",
      "Epoch 17/80\n",
      "6435/6435 [==============================] - 0s 39us/step - loss: 1.5178 - accuracy: 0.3035 - val_loss: 1.5227 - val_accuracy: 0.3254\n",
      "Epoch 18/80\n",
      "6435/6435 [==============================] - 0s 40us/step - loss: 1.5153 - accuracy: 0.3181 - val_loss: 1.5175 - val_accuracy: 0.3128\n",
      "Epoch 19/80\n",
      "6435/6435 [==============================] - 0s 41us/step - loss: 1.5085 - accuracy: 0.3136 - val_loss: 1.5352 - val_accuracy: 0.3059\n",
      "Epoch 20/80\n",
      "6435/6435 [==============================] - 0s 39us/step - loss: 1.5059 - accuracy: 0.3200 - val_loss: 1.5173 - val_accuracy: 0.3352\n",
      "Epoch 21/80\n",
      "6435/6435 [==============================] - 0s 39us/step - loss: 1.5010 - accuracy: 0.3166 - val_loss: 1.5255 - val_accuracy: 0.2891\n",
      "Epoch 22/80\n",
      "6435/6435 [==============================] - 0s 48us/step - loss: 1.5040 - accuracy: 0.3127 - val_loss: 1.5150 - val_accuracy: 0.3073\n",
      "Epoch 23/80\n",
      "6435/6435 [==============================] - 0s 39us/step - loss: 1.4950 - accuracy: 0.3159 - val_loss: 1.5078 - val_accuracy: 0.3017\n",
      "Epoch 24/80\n",
      "6435/6435 [==============================] - 0s 39us/step - loss: 1.4961 - accuracy: 0.3206 - val_loss: 1.5102 - val_accuracy: 0.2947\n",
      "Epoch 25/80\n",
      "6435/6435 [==============================] - 0s 41us/step - loss: 1.4914 - accuracy: 0.3204 - val_loss: 1.5285 - val_accuracy: 0.3017\n",
      "Epoch 26/80\n",
      "6435/6435 [==============================] - 0s 43us/step - loss: 1.4895 - accuracy: 0.3145 - val_loss: 1.5285 - val_accuracy: 0.3031\n",
      "Epoch 27/80\n",
      "6435/6435 [==============================] - 0s 38us/step - loss: 1.4899 - accuracy: 0.3184 - val_loss: 1.5077 - val_accuracy: 0.2975\n",
      "Epoch 28/80\n",
      "6435/6435 [==============================] - 0s 41us/step - loss: 1.4867 - accuracy: 0.3248 - val_loss: 1.5035 - val_accuracy: 0.3352\n",
      "Epoch 29/80\n",
      "6435/6435 [==============================] - 0s 38us/step - loss: 1.4843 - accuracy: 0.3204 - val_loss: 1.5089 - val_accuracy: 0.3212\n",
      "Epoch 30/80\n",
      "6435/6435 [==============================] - 0s 39us/step - loss: 1.4799 - accuracy: 0.3200 - val_loss: 1.5097 - val_accuracy: 0.2919\n",
      "Epoch 31/80\n",
      "6435/6435 [==============================] - 0s 38us/step - loss: 1.4768 - accuracy: 0.3175 - val_loss: 1.4963 - val_accuracy: 0.3156\n",
      "Epoch 32/80\n",
      "6435/6435 [==============================] - 0s 41us/step - loss: 1.4788 - accuracy: 0.3223 - val_loss: 1.4893 - val_accuracy: 0.3254\n",
      "Epoch 33/80\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6435/6435 [==============================] - 0s 39us/step - loss: 1.4741 - accuracy: 0.3232 - val_loss: 1.4923 - val_accuracy: 0.3352\n",
      "Epoch 34/80\n",
      "6435/6435 [==============================] - 0s 39us/step - loss: 1.4681 - accuracy: 0.3253 - val_loss: 1.5127 - val_accuracy: 0.2933\n",
      "Epoch 35/80\n",
      "6435/6435 [==============================] - 0s 41us/step - loss: 1.4702 - accuracy: 0.3271 - val_loss: 1.4882 - val_accuracy: 0.3324\n",
      "Epoch 36/80\n",
      "6435/6435 [==============================] - 0s 41us/step - loss: 1.4693 - accuracy: 0.3305 - val_loss: 1.4715 - val_accuracy: 0.3296\n",
      "Epoch 37/80\n",
      "6435/6435 [==============================] - 0s 40us/step - loss: 1.4592 - accuracy: 0.3270 - val_loss: 1.4828 - val_accuracy: 0.3282\n",
      "Epoch 38/80\n",
      "6435/6435 [==============================] - 0s 37us/step - loss: 1.4554 - accuracy: 0.3336 - val_loss: 1.4795 - val_accuracy: 0.3142\n",
      "Epoch 39/80\n",
      "6435/6435 [==============================] - 0s 39us/step - loss: 1.4532 - accuracy: 0.3444 - val_loss: 1.4733 - val_accuracy: 0.3394\n",
      "Epoch 40/80\n",
      "6435/6435 [==============================] - 0s 40us/step - loss: 1.4533 - accuracy: 0.3584 - val_loss: 1.4779 - val_accuracy: 0.3506\n",
      "Epoch 41/80\n",
      "6435/6435 [==============================] - 0s 39us/step - loss: 1.4420 - accuracy: 0.3598 - val_loss: 1.4754 - val_accuracy: 0.3408\n",
      "Epoch 42/80\n",
      "6435/6435 [==============================] - 0s 41us/step - loss: 1.4254 - accuracy: 0.3534 - val_loss: 1.4377 - val_accuracy: 0.3547\n",
      "Epoch 43/80\n",
      "6435/6435 [==============================] - 0s 41us/step - loss: 1.4122 - accuracy: 0.3643 - val_loss: 1.4269 - val_accuracy: 0.3687\n",
      "Epoch 44/80\n",
      "6435/6435 [==============================] - 0s 38us/step - loss: 1.4067 - accuracy: 0.3672 - val_loss: 1.4619 - val_accuracy: 0.3506\n",
      "Epoch 45/80\n",
      "6435/6435 [==============================] - 0s 38us/step - loss: 1.3883 - accuracy: 0.3734 - val_loss: 1.3874 - val_accuracy: 0.3561\n",
      "Epoch 46/80\n",
      "6435/6435 [==============================] - 0s 42us/step - loss: 1.3599 - accuracy: 0.3739 - val_loss: 1.3638 - val_accuracy: 0.3799\n",
      "Epoch 47/80\n",
      "6435/6435 [==============================] - 0s 38us/step - loss: 1.3435 - accuracy: 0.3812 - val_loss: 1.3618 - val_accuracy: 0.3296\n",
      "Epoch 48/80\n",
      "6435/6435 [==============================] - 0s 39us/step - loss: 1.3397 - accuracy: 0.3826 - val_loss: 1.3516 - val_accuracy: 0.3897\n",
      "Epoch 49/80\n",
      "6435/6435 [==============================] - 0s 39us/step - loss: 1.3250 - accuracy: 0.3775 - val_loss: 1.3388 - val_accuracy: 0.3785\n",
      "Epoch 50/80\n",
      "6435/6435 [==============================] - 0s 39us/step - loss: 1.3161 - accuracy: 0.3880 - val_loss: 1.3150 - val_accuracy: 0.3980\n",
      "Epoch 51/80\n",
      "6435/6435 [==============================] - 0s 41us/step - loss: 1.3067 - accuracy: 0.3887 - val_loss: 1.3144 - val_accuracy: 0.3855\n",
      "Epoch 52/80\n",
      "6435/6435 [==============================] - 0s 39us/step - loss: 1.3147 - accuracy: 0.3859 - val_loss: 1.3031 - val_accuracy: 0.3785\n",
      "Epoch 53/80\n",
      "6435/6435 [==============================] - 0s 42us/step - loss: 1.2969 - accuracy: 0.3930 - val_loss: 1.3019 - val_accuracy: 0.3687\n",
      "Epoch 54/80\n",
      "6435/6435 [==============================] - 0s 39us/step - loss: 1.3028 - accuracy: 0.3927 - val_loss: 1.2906 - val_accuracy: 0.4008\n",
      "Epoch 55/80\n",
      "6435/6435 [==============================] - 0s 40us/step - loss: 1.2913 - accuracy: 0.3913 - val_loss: 1.2987 - val_accuracy: 0.3757\n",
      "Epoch 56/80\n",
      "6435/6435 [==============================] - 0s 41us/step - loss: 1.2891 - accuracy: 0.3910 - val_loss: 1.2922 - val_accuracy: 0.3827\n",
      "Epoch 57/80\n",
      "6435/6435 [==============================] - 0s 38us/step - loss: 1.2890 - accuracy: 0.3950 - val_loss: 1.3107 - val_accuracy: 0.4106\n",
      "Epoch 58/80\n",
      "6435/6435 [==============================] - 0s 40us/step - loss: 1.2848 - accuracy: 0.3891 - val_loss: 1.2871 - val_accuracy: 0.4162\n",
      "Epoch 59/80\n",
      "6435/6435 [==============================] - 0s 40us/step - loss: 1.2797 - accuracy: 0.4002 - val_loss: 1.2729 - val_accuracy: 0.4078\n",
      "Epoch 60/80\n",
      "6435/6435 [==============================] - 0s 37us/step - loss: 1.2816 - accuracy: 0.3977 - val_loss: 1.2798 - val_accuracy: 0.3897\n",
      "Epoch 61/80\n",
      "6435/6435 [==============================] - 0s 40us/step - loss: 1.2749 - accuracy: 0.3908 - val_loss: 1.2735 - val_accuracy: 0.4092\n",
      "Epoch 62/80\n",
      "6435/6435 [==============================] - 0s 40us/step - loss: 1.2719 - accuracy: 0.3992 - val_loss: 1.2791 - val_accuracy: 0.3897\n",
      "Epoch 63/80\n",
      "6435/6435 [==============================] - 0s 46us/step - loss: 1.2665 - accuracy: 0.3977 - val_loss: 1.2728 - val_accuracy: 0.4008\n",
      "Epoch 64/80\n",
      "6435/6435 [==============================] - 0s 37us/step - loss: 1.2585 - accuracy: 0.3975 - val_loss: 1.2780 - val_accuracy: 0.4162\n",
      "Epoch 65/80\n",
      "6435/6435 [==============================] - 0s 40us/step - loss: 1.2596 - accuracy: 0.3970 - val_loss: 1.2713 - val_accuracy: 0.4036\n",
      "Epoch 66/80\n",
      "6435/6435 [==============================] - 0s 40us/step - loss: 1.2587 - accuracy: 0.3983 - val_loss: 1.2620 - val_accuracy: 0.3994\n",
      "Epoch 67/80\n",
      "6435/6435 [==============================] - 0s 38us/step - loss: 1.2569 - accuracy: 0.4023 - val_loss: 1.2532 - val_accuracy: 0.3966\n",
      "Epoch 68/80\n",
      "6435/6435 [==============================] - 0s 40us/step - loss: 1.2505 - accuracy: 0.4129 - val_loss: 1.2659 - val_accuracy: 0.4078\n",
      "Epoch 69/80\n",
      "6435/6435 [==============================] - 0s 40us/step - loss: 1.2487 - accuracy: 0.4087 - val_loss: 1.2489 - val_accuracy: 0.4120\n",
      "Epoch 70/80\n",
      "6435/6435 [==============================] - 0s 40us/step - loss: 1.2473 - accuracy: 0.3963 - val_loss: 1.2674 - val_accuracy: 0.4078\n",
      "Epoch 71/80\n",
      "6435/6435 [==============================] - 0s 39us/step - loss: 1.2443 - accuracy: 0.4042 - val_loss: 1.2472 - val_accuracy: 0.3966\n",
      "Epoch 72/80\n",
      "6435/6435 [==============================] - 0s 38us/step - loss: 1.2421 - accuracy: 0.4117 - val_loss: 1.2478 - val_accuracy: 0.3994\n",
      "Epoch 73/80\n",
      "6435/6435 [==============================] - 0s 38us/step - loss: 1.2446 - accuracy: 0.3983 - val_loss: 1.2450 - val_accuracy: 0.4120\n",
      "Epoch 74/80\n",
      "6435/6435 [==============================] - 0s 38us/step - loss: 1.2408 - accuracy: 0.3967 - val_loss: 1.2833 - val_accuracy: 0.3994\n",
      "Epoch 75/80\n",
      "6435/6435 [==============================] - 0s 39us/step - loss: 1.2421 - accuracy: 0.4019 - val_loss: 1.2380 - val_accuracy: 0.4064\n",
      "Epoch 76/80\n",
      "6435/6435 [==============================] - 0s 41us/step - loss: 1.2415 - accuracy: 0.3974 - val_loss: 1.2618 - val_accuracy: 0.3869\n",
      "Epoch 77/80\n",
      "6435/6435 [==============================] - 0s 39us/step - loss: 1.2314 - accuracy: 0.4006 - val_loss: 1.2488 - val_accuracy: 0.4050\n",
      "Epoch 78/80\n",
      "6435/6435 [==============================] - 0s 39us/step - loss: 1.2342 - accuracy: 0.4059 - val_loss: 1.2549 - val_accuracy: 0.3939\n",
      "Epoch 79/80\n",
      "6435/6435 [==============================] - 0s 39us/step - loss: 1.2345 - accuracy: 0.4068 - val_loss: 1.2404 - val_accuracy: 0.4078\n",
      "Epoch 80/80\n",
      "6435/6435 [==============================] - 0s 40us/step - loss: 1.2355 - accuracy: 0.4026 - val_loss: 1.2459 - val_accuracy: 0.4148\n",
      "[[1.2667306e-01 1.2337527e-01 3.3654167e-14 ... 4.0073055e-01\n",
      "  1.5069695e-01 1.8493024e-01]\n",
      " [4.2720858e-02 4.5502320e-02 5.5275399e-21 ... 2.2257322e-03\n",
      "  6.2988149e-03 7.4452818e-03]\n",
      " [1.6513318e-01 1.7519827e-01 1.2741690e-17 ... 6.0954571e-02\n",
      "  2.6578072e-01 3.3116335e-01]\n",
      " ...\n",
      " [1.7913032e-01 1.8487152e-01 9.3515188e-19 ... 6.2343078e-03\n",
      "  2.7863100e-01 3.5071263e-01]\n",
      " [9.4720840e-02 8.8972859e-02 2.1618766e-13 ... 2.0930582e-01\n",
      "  2.5905263e-01 3.3255765e-01]\n",
      " [1.0831990e-01 1.0541736e-01 5.9726285e-14 ... 2.2351179e-01\n",
      "  2.4384382e-01 3.0903280e-01]]\n",
      "[12 11 14 ... 14 14 14]\n",
      "<class 'numpy.ndarray'>\n",
      "One CNN, r:  0\n",
      "Computing Time:  0:01:33.117406\n",
      "n, p1, p2 4 0 0\n",
      "Model: \"sequential_1\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv1d_1 (Conv1D)            (None, 3, 6)              12        \n",
      "_________________________________________________________________\n",
      "average_pooling1d_1 (Average (None, 1, 6)              0         \n",
      "_________________________________________________________________\n",
      "conv1d_2 (Conv1D)            (None, 1, 16)             112       \n",
      "_________________________________________________________________\n",
      "average_pooling1d_2 (Average (None, 1, 16)             0         \n",
      "_________________________________________________________________\n",
      "conv1d_3 (Conv1D)            (None, 1, 120)            2040      \n",
      "_________________________________________________________________\n",
      "flatten_1 (Flatten)          (None, 120)               0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 84)                10164     \n",
      "_________________________________________________________________\n",
      "preds (Dense)                (None, 15)                1275      \n",
      "=================================================================\n",
      "Total params: 13,603\n",
      "Trainable params: 13,603\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 6435 samples, validate on 716 samples\n",
      "Epoch 1/80\n",
      "6435/6435 [==============================] - 0s 76us/step - loss: 2.6763 - accuracy: 0.1189 - val_loss: 2.5966 - val_accuracy: 0.1229\n",
      "Epoch 2/80\n",
      "6435/6435 [==============================] - 0s 47us/step - loss: 2.3913 - accuracy: 0.1360 - val_loss: 2.1923 - val_accuracy: 0.1564\n",
      "Epoch 3/80\n",
      "6435/6435 [==============================] - 0s 42us/step - loss: 2.0523 - accuracy: 0.2239 - val_loss: 1.9628 - val_accuracy: 0.2626\n",
      "Epoch 4/80\n",
      "6435/6435 [==============================] - 0s 42us/step - loss: 1.8973 - accuracy: 0.2810 - val_loss: 1.8647 - val_accuracy: 0.2654\n",
      "Epoch 5/80\n",
      "6435/6435 [==============================] - 0s 43us/step - loss: 1.8025 - accuracy: 0.2985 - val_loss: 1.8074 - val_accuracy: 0.2821\n",
      "Epoch 6/80\n",
      "6435/6435 [==============================] - 0s 38us/step - loss: 1.7286 - accuracy: 0.2960 - val_loss: 1.7062 - val_accuracy: 0.2933\n",
      "Epoch 7/80\n",
      "6435/6435 [==============================] - 0s 42us/step - loss: 1.6598 - accuracy: 0.2988 - val_loss: 1.6444 - val_accuracy: 0.2975\n",
      "Epoch 8/80\n",
      "6435/6435 [==============================] - 0s 43us/step - loss: 1.6141 - accuracy: 0.2942 - val_loss: 1.6409 - val_accuracy: 0.2640\n",
      "Epoch 9/80\n",
      "6435/6435 [==============================] - 0s 40us/step - loss: 1.5881 - accuracy: 0.3018 - val_loss: 1.5756 - val_accuracy: 0.2961\n",
      "Epoch 10/80\n",
      "6435/6435 [==============================] - 0s 40us/step - loss: 1.5611 - accuracy: 0.3019 - val_loss: 1.5614 - val_accuracy: 0.2933\n",
      "Epoch 11/80\n",
      "6435/6435 [==============================] - 0s 39us/step - loss: 1.5477 - accuracy: 0.3058 - val_loss: 1.5511 - val_accuracy: 0.2849\n",
      "Epoch 12/80\n",
      "6435/6435 [==============================] - 0s 40us/step - loss: 1.5371 - accuracy: 0.3037 - val_loss: 1.5467 - val_accuracy: 0.2919\n",
      "Epoch 13/80\n",
      "6435/6435 [==============================] - 0s 42us/step - loss: 1.5298 - accuracy: 0.3054 - val_loss: 1.5450 - val_accuracy: 0.2849\n",
      "Epoch 14/80\n",
      "6435/6435 [==============================] - 0s 41us/step - loss: 1.5252 - accuracy: 0.3106 - val_loss: 1.5337 - val_accuracy: 0.2947\n",
      "Epoch 15/80\n",
      "6435/6435 [==============================] - 0s 39us/step - loss: 1.5220 - accuracy: 0.3069 - val_loss: 1.5559 - val_accuracy: 0.3003\n",
      "Epoch 16/80\n",
      "6435/6435 [==============================] - 0s 36us/step - loss: 1.5224 - accuracy: 0.3077 - val_loss: 1.5288 - val_accuracy: 0.3073\n",
      "Epoch 17/80\n",
      "6435/6435 [==============================] - 0s 39us/step - loss: 1.5132 - accuracy: 0.3108 - val_loss: 1.5155 - val_accuracy: 0.3115\n",
      "Epoch 18/80\n",
      "6435/6435 [==============================] - 0s 42us/step - loss: 1.5120 - accuracy: 0.3176 - val_loss: 1.5412 - val_accuracy: 0.3017\n",
      "Epoch 19/80\n",
      "6435/6435 [==============================] - 0s 39us/step - loss: 1.5081 - accuracy: 0.3159 - val_loss: 1.5293 - val_accuracy: 0.2961\n",
      "Epoch 20/80\n",
      "6435/6435 [==============================] - 0s 40us/step - loss: 1.5070 - accuracy: 0.3130 - val_loss: 1.5181 - val_accuracy: 0.2961\n",
      "Epoch 21/80\n",
      "6435/6435 [==============================] - 0s 38us/step - loss: 1.5023 - accuracy: 0.3141 - val_loss: 1.5195 - val_accuracy: 0.2905\n",
      "Epoch 22/80\n",
      "6435/6435 [==============================] - 0s 39us/step - loss: 1.5055 - accuracy: 0.3103 - val_loss: 1.5082 - val_accuracy: 0.2975\n",
      "Epoch 23/80\n",
      "6435/6435 [==============================] - 0s 38us/step - loss: 1.4968 - accuracy: 0.3141 - val_loss: 1.5093 - val_accuracy: 0.2877\n",
      "Epoch 24/80\n",
      "6435/6435 [==============================] - 0s 39us/step - loss: 1.4969 - accuracy: 0.3192 - val_loss: 1.5072 - val_accuracy: 0.2947\n",
      "Epoch 25/80\n",
      "6435/6435 [==============================] - 0s 39us/step - loss: 1.4958 - accuracy: 0.3127 - val_loss: 1.5006 - val_accuracy: 0.3198\n",
      "Epoch 26/80\n",
      "6435/6435 [==============================] - 0s 40us/step - loss: 1.4992 - accuracy: 0.3082 - val_loss: 1.5188 - val_accuracy: 0.2933\n",
      "Epoch 27/80\n",
      "6435/6435 [==============================] - 0s 39us/step - loss: 1.4981 - accuracy: 0.3072 - val_loss: 1.5003 - val_accuracy: 0.3031\n",
      "Epoch 28/80\n",
      "6435/6435 [==============================] - 0s 40us/step - loss: 1.4939 - accuracy: 0.3114 - val_loss: 1.5068 - val_accuracy: 0.2975\n",
      "Epoch 29/80\n",
      "6435/6435 [==============================] - 0s 39us/step - loss: 1.4932 - accuracy: 0.3186 - val_loss: 1.4979 - val_accuracy: 0.3226\n",
      "Epoch 30/80\n",
      "6435/6435 [==============================] - 0s 40us/step - loss: 1.4932 - accuracy: 0.3092 - val_loss: 1.4965 - val_accuracy: 0.2989\n",
      "Epoch 31/80\n",
      "6435/6435 [==============================] - 0s 41us/step - loss: 1.4867 - accuracy: 0.3206 - val_loss: 1.5013 - val_accuracy: 0.2905\n",
      "Epoch 32/80\n",
      "6435/6435 [==============================] - 0s 38us/step - loss: 1.4857 - accuracy: 0.3195 - val_loss: 1.5032 - val_accuracy: 0.2863\n",
      "Epoch 33/80\n",
      "6435/6435 [==============================] - 0s 39us/step - loss: 1.4864 - accuracy: 0.3221 - val_loss: 1.4958 - val_accuracy: 0.3017\n",
      "Epoch 34/80\n",
      "6435/6435 [==============================] - 0s 39us/step - loss: 1.4873 - accuracy: 0.3125 - val_loss: 1.4937 - val_accuracy: 0.3031\n",
      "Epoch 35/80\n",
      "6435/6435 [==============================] - 0s 41us/step - loss: 1.4845 - accuracy: 0.3169 - val_loss: 1.5027 - val_accuracy: 0.2849\n",
      "Epoch 36/80\n",
      "6435/6435 [==============================] - 0s 41us/step - loss: 1.4864 - accuracy: 0.3139 - val_loss: 1.5020 - val_accuracy: 0.2919\n",
      "Epoch 37/80\n",
      "6435/6435 [==============================] - 0s 37us/step - loss: 1.4942 - accuracy: 0.3142 - val_loss: 1.4969 - val_accuracy: 0.3031\n",
      "Epoch 38/80\n",
      "6435/6435 [==============================] - 0s 42us/step - loss: 1.4850 - accuracy: 0.3198 - val_loss: 1.4837 - val_accuracy: 0.3142\n",
      "Epoch 39/80\n",
      "6435/6435 [==============================] - 0s 45us/step - loss: 1.4845 - accuracy: 0.3256 - val_loss: 1.4854 - val_accuracy: 0.2947\n",
      "Epoch 40/80\n",
      "6435/6435 [==============================] - 0s 39us/step - loss: 1.4815 - accuracy: 0.3218 - val_loss: 1.4800 - val_accuracy: 0.3142\n",
      "Epoch 41/80\n",
      "6435/6435 [==============================] - 0s 40us/step - loss: 1.4760 - accuracy: 0.3221 - val_loss: 1.4979 - val_accuracy: 0.2947\n",
      "Epoch 42/80\n",
      "6435/6435 [==============================] - 0s 43us/step - loss: 1.4787 - accuracy: 0.3221 - val_loss: 1.4938 - val_accuracy: 0.3059\n",
      "Epoch 43/80\n",
      "6435/6435 [==============================] - 0s 39us/step - loss: 1.4804 - accuracy: 0.3187 - val_loss: 1.4904 - val_accuracy: 0.2975\n",
      "Epoch 44/80\n",
      "6435/6435 [==============================] - 0s 40us/step - loss: 1.4825 - accuracy: 0.3162 - val_loss: 1.4871 - val_accuracy: 0.2947\n",
      "Epoch 45/80\n",
      "6435/6435 [==============================] - 0s 40us/step - loss: 1.4757 - accuracy: 0.3270 - val_loss: 1.4987 - val_accuracy: 0.2989\n",
      "Epoch 46/80\n",
      "6435/6435 [==============================] - 0s 40us/step - loss: 1.4761 - accuracy: 0.3254 - val_loss: 1.4993 - val_accuracy: 0.3101\n",
      "Epoch 47/80\n",
      "6435/6435 [==============================] - 0s 40us/step - loss: 1.4771 - accuracy: 0.3172 - val_loss: 1.5029 - val_accuracy: 0.3087\n",
      "Epoch 48/80\n",
      "6435/6435 [==============================] - 0s 37us/step - loss: 1.4729 - accuracy: 0.3248 - val_loss: 1.4959 - val_accuracy: 0.3003\n",
      "Epoch 49/80\n",
      "6435/6435 [==============================] - 0s 37us/step - loss: 1.4741 - accuracy: 0.3259 - val_loss: 1.4916 - val_accuracy: 0.3212\n",
      "Epoch 50/80\n",
      "6435/6435 [==============================] - 0s 41us/step - loss: 1.4762 - accuracy: 0.3152 - val_loss: 1.5003 - val_accuracy: 0.3073\n",
      "Epoch 00050: early stopping\n",
      "[[1.4715375e-01 1.4215223e-01 1.4782524e-11 ... 2.5229883e-01\n",
      "  2.0427321e-01 2.2384690e-01]\n",
      " [2.1019001e-02 2.3869243e-02 1.9301602e-16 ... 4.7953748e-03\n",
      "  3.1897554e-03 3.8371251e-03]\n",
      " [1.4802524e-01 1.5196264e-01 1.0353936e-12 ... 2.9607049e-01\n",
      "  1.8259196e-01 2.0222569e-01]\n",
      " ...\n",
      " [1.4895359e-01 1.5056643e-01 1.7644196e-12 ... 2.8352758e-01\n",
      "  1.8902919e-01 2.0950361e-01]\n",
      " [1.4158237e-01 1.3636014e-01 1.8576493e-10 ... 1.8747093e-01\n",
      "  2.3207307e-01 2.4150176e-01]\n",
      " [1.4369024e-01 1.3871489e-01 7.5800317e-11 ... 2.0581132e-01\n",
      "  2.2479904e-01 2.3873779e-01]]\n",
      "[12  5 12 ... 12 14 14]\n",
      "<class 'numpy.ndarray'>\n",
      "One CNN, r:  0\n",
      "Computing Time:  0:01:47.597389\n"
     ]
    }
   ],
   "source": [
    "#======================================================\n",
    "\n",
    "#1213 add auto judge\n",
    "from CNN_Modules_1D import ME_CNN\n",
    "\n",
    "# ==== CNN Original =====\n",
    "ROUND_start = time.time()\n",
    "\n",
    "for n in range(5):\n",
    "    region=region_image.copy()\n",
    "    region=list(region)\n",
    "    selected_region = list(range(NUM_region))\n",
    "\n",
    "    p1=0\n",
    "    p2=0\n",
    "\n",
    "    print(\"n, p1, p2\", n, p1, p2)\n",
    "\n",
    "\n",
    "    # ===== one CNN =============\n",
    "    NUM_CLASSES = len(selected_region)\n",
    "\n",
    "    # input image and label\n",
    "    Input_img     = []\n",
    "    Input_img_len = []\n",
    "    for c,sel in enumerate(selected_region, start=0):\n",
    "        Input_img = Input_img + list(region[sel])\n",
    "        Input_img_len.append(len(region[sel]))\n",
    "\n",
    "    # 1213\n",
    "    # fill up training array\n",
    "    W           = np.shape(test_array[0])[0]\n",
    "    train_array = np.zeros((len(Input_img), W), dtype=float)\n",
    "    for i in range (len(Input_img)):\n",
    "        train_array[i] = test_array[Input_img[i]].reshape(W)\n",
    "\n",
    "    train_array = np.expand_dims(train_array, axis = -1)\n",
    "\n",
    "\n",
    "    # fill up the training label to each training image\n",
    "    current_train_label = np.zeros(len(train_array), dtype=int)\n",
    "    accum_base=0\n",
    "    for label in range(1,NUM_CLASSES):\n",
    "        pre_cursor = Input_img_len[label-1]\n",
    "        accum_base = accum_base + pre_cursor\n",
    "        current_train_label[accum_base:] = label\n",
    "\n",
    "    # CNN\n",
    "    #===============================================\n",
    "    one_predicted_results  = np.zeros((TRIALS, len(test_label_answer)), dtype=int)\n",
    "    one_predict_percentage = np.zeros((TRIALS, len(test_label_answer), NUM_CLASSES), dtype=float)    \n",
    "    model_history = np.zeros(TRIALS, dtype=list)\n",
    "\n",
    "    for r in range(TRIALS):\n",
    "        one_predicted_results[r], one_predict_percentage[r], model_history[r] = ME_CNN(\n",
    "                x_train     = train_array,\n",
    "                train_label = current_train_label,\n",
    "                test_array  = test_array,\n",
    "                true_answer = test_label_answer,\n",
    "                Num_Classes = NUM_CLASSES\n",
    "                )\n",
    "        print(type(model_history))\n",
    "\n",
    "\n",
    "        # ===== delete CNN tensors =====\n",
    "        from keras import backend as K\n",
    "        K.clear_session()\n",
    "        import gc\n",
    "        gc.collect()\n",
    "\n",
    "        print(\"One CNN, r: \",r)\n",
    "        ROUND_duration = time.time() - ROUND_start\n",
    "        print(\"Computing Time: \", str(datetime.timedelta(seconds=ROUND_duration)))\n",
    "\n",
    "    # === save to file ===\n",
    "    savefile_path = './' + str(timestr) + '(classes=' + str(NUM_CLASSES)+')_n0_R' + str(p1) + '+R'+ str(p2) +'_trial' + str(n)+'.pickle'  #extra_original\n",
    "    with open(savefile_path, 'wb') as f:\n",
    "        pickle.dump([Input_img, Input_img_len, one_predicted_results, one_predict_percentage, model_history], f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(5, 5000) (5, 5000, 15)\n"
     ]
    }
   ],
   "source": [
    "#==== shift label =======\n",
    "N=5\n",
    "Original_result=[]\n",
    "Original_prob=[]\n",
    "for i in range(N):\n",
    "    with open('./' + timestr + '(classes=' + str(NUM_region) + ')_n0_R0+R0_trial' + str(i)+ '.pickle', 'rb') as f:\n",
    "        Input_img, Input_img_len, one_predicted_results, one_predict_percentage, model_history = pickle.load(f)\n",
    "    label_B = one_predicted_results[0].copy()\n",
    "    label_B_prob = one_predict_percentage[0].copy()\n",
    "\n",
    "    #(1)\n",
    "    Original_result.append(label_B)\n",
    "\n",
    "    #(2)\n",
    "    Original_prob.append(label_B_prob)\n",
    "print(np.shape(Original_result), np.shape(Original_prob))\n",
    "\n",
    "# save pickle\n",
    "with open('./' + timestr + 'results_of_original.pickle', 'wb') as f:\n",
    "    pickle.dump([Original_result, Original_prob], f)\n",
    "    \n",
    "# save mat\n",
    "from scipy.io import savemat\n",
    "savemat('./' + timestr + 'results_of_original.mat', {'result_for_original':Original_result, 'prob_for_original':Original_prob})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# CNN combination and removal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "105"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "n, p1, p2 0 0 0\n",
      "Model: \"sequential_1\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv1d_1 (Conv1D)            (None, 3, 6)              12        \n",
      "_________________________________________________________________\n",
      "average_pooling1d_1 (Average (None, 1, 6)              0         \n",
      "_________________________________________________________________\n",
      "conv1d_2 (Conv1D)            (None, 1, 16)             112       \n",
      "_________________________________________________________________\n",
      "average_pooling1d_2 (Average (None, 1, 16)             0         \n",
      "_________________________________________________________________\n",
      "conv1d_3 (Conv1D)            (None, 1, 120)            2040      \n",
      "_________________________________________________________________\n",
      "flatten_1 (Flatten)          (None, 120)               0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 84)                10164     \n",
      "_________________________________________________________________\n",
      "preds (Dense)                (None, 15)                1275      \n",
      "=================================================================\n",
      "Total params: 13,603\n",
      "Trainable params: 13,603\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Train on 6435 samples, validate on 716 samples\n",
      "Epoch 1/80\n",
      "6435/6435 [==============================] - 0s 75us/step - loss: 2.6859 - accuracy: 0.1085 - val_loss: 2.6303 - val_accuracy: 0.1760\n",
      "Epoch 2/80\n",
      "6435/6435 [==============================] - 0s 41us/step - loss: 2.4487 - accuracy: 0.1972 - val_loss: 2.2197 - val_accuracy: 0.1858\n",
      "Epoch 3/80\n",
      "6435/6435 [==============================] - 0s 42us/step - loss: 2.0868 - accuracy: 0.2301 - val_loss: 1.9503 - val_accuracy: 0.2570\n",
      "Epoch 4/80\n",
      "6435/6435 [==============================] - 0s 41us/step - loss: 1.9024 - accuracy: 0.2844 - val_loss: 1.7937 - val_accuracy: 0.2807\n",
      "Epoch 5/80\n",
      "6435/6435 [==============================] - 0s 39us/step - loss: 1.7908 - accuracy: 0.2932 - val_loss: 1.6931 - val_accuracy: 0.3003\n",
      "Epoch 6/80\n",
      "6435/6435 [==============================] - 0s 41us/step - loss: 1.7114 - accuracy: 0.2873 - val_loss: 1.6273 - val_accuracy: 0.3296\n",
      "Epoch 7/80\n",
      "6435/6435 [==============================] - 0s 41us/step - loss: 1.6456 - accuracy: 0.2973 - val_loss: 1.5872 - val_accuracy: 0.3045\n",
      "Epoch 8/80\n",
      "6435/6435 [==============================] - 0s 41us/step - loss: 1.6007 - accuracy: 0.3029 - val_loss: 1.5544 - val_accuracy: 0.2891\n",
      "Epoch 9/80\n",
      "6435/6435 [==============================] - 0s 39us/step - loss: 1.5797 - accuracy: 0.2981 - val_loss: 1.5241 - val_accuracy: 0.3212\n",
      "Epoch 10/80\n",
      "6435/6435 [==============================] - 0s 38us/step - loss: 1.5518 - accuracy: 0.3004 - val_loss: 1.5151 - val_accuracy: 0.3282\n",
      "Epoch 11/80\n",
      "6435/6435 [==============================] - 0s 38us/step - loss: 1.5415 - accuracy: 0.3113 - val_loss: 1.5008 - val_accuracy: 0.3184\n",
      "Epoch 12/80\n",
      "6435/6435 [==============================] - 0s 35us/step - loss: 1.5320 - accuracy: 0.3189 - val_loss: 1.4857 - val_accuracy: 0.3059\n",
      "Epoch 13/80\n",
      "6435/6435 [==============================] - 0s 38us/step - loss: 1.5265 - accuracy: 0.3043 - val_loss: 1.4934 - val_accuracy: 0.3296\n",
      "Epoch 14/80\n",
      "6435/6435 [==============================] - 0s 39us/step - loss: 1.5152 - accuracy: 0.3204 - val_loss: 1.4784 - val_accuracy: 0.3254\n",
      "Epoch 15/80\n",
      "6435/6435 [==============================] - 0s 39us/step - loss: 1.5122 - accuracy: 0.3125 - val_loss: 1.4750 - val_accuracy: 0.3338\n",
      "Epoch 16/80\n",
      "6435/6435 [==============================] - 0s 41us/step - loss: 1.5135 - accuracy: 0.3133 - val_loss: 1.4681 - val_accuracy: 0.3184\n",
      "Epoch 17/80\n",
      "6435/6435 [==============================] - 0s 38us/step - loss: 1.5112 - accuracy: 0.3040 - val_loss: 1.4769 - val_accuracy: 0.3212\n",
      "Epoch 18/80\n",
      "6435/6435 [==============================] - 0s 40us/step - loss: 1.5045 - accuracy: 0.3164 - val_loss: 1.4732 - val_accuracy: 0.3101\n",
      "Epoch 19/80\n",
      "6435/6435 [==============================] - 0s 42us/step - loss: 1.5052 - accuracy: 0.3021 - val_loss: 1.4600 - val_accuracy: 0.3282\n",
      "Epoch 20/80\n",
      "6435/6435 [==============================] - 0s 41us/step - loss: 1.5041 - accuracy: 0.3172 - val_loss: 1.4823 - val_accuracy: 0.3115\n",
      "Epoch 21/80\n",
      "6435/6435 [==============================] - 0s 37us/step - loss: 1.5008 - accuracy: 0.3023 - val_loss: 1.4724 - val_accuracy: 0.3045\n",
      "Epoch 22/80\n",
      "6435/6435 [==============================] - 0s 39us/step - loss: 1.4997 - accuracy: 0.3215 - val_loss: 1.4602 - val_accuracy: 0.3212\n",
      "Epoch 23/80\n",
      "6435/6435 [==============================] - 0s 42us/step - loss: 1.5039 - accuracy: 0.3044 - val_loss: 1.4687 - val_accuracy: 0.3170\n",
      "Epoch 24/80\n",
      "6435/6435 [==============================] - 0s 42us/step - loss: 1.4956 - accuracy: 0.3057 - val_loss: 1.4691 - val_accuracy: 0.3198\n",
      "Epoch 25/80\n",
      "6435/6435 [==============================] - 0s 39us/step - loss: 1.4908 - accuracy: 0.3197 - val_loss: 1.4563 - val_accuracy: 0.3045\n",
      "Epoch 26/80\n",
      "6435/6435 [==============================] - 0s 43us/step - loss: 1.4935 - accuracy: 0.3026 - val_loss: 1.4597 - val_accuracy: 0.3310\n",
      "Epoch 27/80\n",
      "6435/6435 [==============================] - 0s 40us/step - loss: 1.4938 - accuracy: 0.3204 - val_loss: 1.4535 - val_accuracy: 0.3128\n",
      "Epoch 28/80\n",
      "6435/6435 [==============================] - 0s 38us/step - loss: 1.4911 - accuracy: 0.3136 - val_loss: 1.4514 - val_accuracy: 0.3142\n",
      "Epoch 29/80\n",
      "6435/6435 [==============================] - 0s 39us/step - loss: 1.4939 - accuracy: 0.3040 - val_loss: 1.4477 - val_accuracy: 0.3184\n",
      "Epoch 30/80\n",
      "6435/6435 [==============================] - 0s 40us/step - loss: 1.4880 - accuracy: 0.3204 - val_loss: 1.4434 - val_accuracy: 0.3115\n",
      "Epoch 31/80\n",
      "6435/6435 [==============================] - 0s 40us/step - loss: 1.4879 - accuracy: 0.3184 - val_loss: 1.4426 - val_accuracy: 0.3310\n",
      "Epoch 32/80\n",
      "6435/6435 [==============================] - 0s 48us/step - loss: 1.4803 - accuracy: 0.3164 - val_loss: 1.4517 - val_accuracy: 0.3226\n",
      "Epoch 33/80\n",
      "6435/6435 [==============================] - 0s 38us/step - loss: 1.4785 - accuracy: 0.3175 - val_loss: 1.4541 - val_accuracy: 0.3212\n",
      "Epoch 34/80\n",
      "6435/6435 [==============================] - 0s 39us/step - loss: 1.4804 - accuracy: 0.3206 - val_loss: 1.4497 - val_accuracy: 0.3115\n",
      "Epoch 35/80\n",
      "6435/6435 [==============================] - 0s 38us/step - loss: 1.4807 - accuracy: 0.3138 - val_loss: 1.4488 - val_accuracy: 0.3170\n",
      "Epoch 36/80\n",
      "6435/6435 [==============================] - 0s 37us/step - loss: 1.4780 - accuracy: 0.3173 - val_loss: 1.4379 - val_accuracy: 0.3282\n",
      "Epoch 37/80\n",
      "6435/6435 [==============================] - 0s 38us/step - loss: 1.4788 - accuracy: 0.3153 - val_loss: 1.4528 - val_accuracy: 0.3254\n",
      "Epoch 38/80\n",
      "6435/6435 [==============================] - 0s 39us/step - loss: 1.4793 - accuracy: 0.3204 - val_loss: 1.4540 - val_accuracy: 0.3254\n",
      "Epoch 39/80\n",
      "6435/6435 [==============================] - 0s 39us/step - loss: 1.4848 - accuracy: 0.3110 - val_loss: 1.4455 - val_accuracy: 0.3115\n",
      "Epoch 40/80\n",
      "6435/6435 [==============================] - 0s 41us/step - loss: 1.4789 - accuracy: 0.3184 - val_loss: 1.4340 - val_accuracy: 0.3170\n",
      "Epoch 41/80\n",
      "6435/6435 [==============================] - 0s 37us/step - loss: 1.4771 - accuracy: 0.3147 - val_loss: 1.4411 - val_accuracy: 0.3156\n",
      "Epoch 42/80\n",
      "6435/6435 [==============================] - 0s 38us/step - loss: 1.4727 - accuracy: 0.3134 - val_loss: 1.4492 - val_accuracy: 0.3142\n",
      "Epoch 43/80\n",
      "6435/6435 [==============================] - 0s 39us/step - loss: 1.4719 - accuracy: 0.3195 - val_loss: 1.4459 - val_accuracy: 0.3324\n",
      "Epoch 44/80\n",
      "6435/6435 [==============================] - 0s 39us/step - loss: 1.4737 - accuracy: 0.3190 - val_loss: 1.4403 - val_accuracy: 0.3059\n",
      "Epoch 45/80\n",
      "6435/6435 [==============================] - 0s 39us/step - loss: 1.4728 - accuracy: 0.3170 - val_loss: 1.4523 - val_accuracy: 0.3128\n",
      "Epoch 46/80\n",
      "6435/6435 [==============================] - 0s 39us/step - loss: 1.4704 - accuracy: 0.3166 - val_loss: 1.4291 - val_accuracy: 0.3352\n",
      "Epoch 47/80\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6435/6435 [==============================] - 0s 39us/step - loss: 1.4703 - accuracy: 0.3175 - val_loss: 1.4391 - val_accuracy: 0.3212\n",
      "Epoch 48/80\n",
      "6435/6435 [==============================] - 0s 43us/step - loss: 1.4688 - accuracy: 0.3232 - val_loss: 1.4395 - val_accuracy: 0.3198\n",
      "Epoch 49/80\n",
      "6435/6435 [==============================] - 0s 39us/step - loss: 1.4679 - accuracy: 0.3198 - val_loss: 1.4372 - val_accuracy: 0.3073\n",
      "Epoch 50/80\n",
      "6435/6435 [==============================] - 0s 39us/step - loss: 1.4726 - accuracy: 0.3251 - val_loss: 1.4395 - val_accuracy: 0.3212\n",
      "Epoch 51/80\n",
      "6435/6435 [==============================] - 0s 41us/step - loss: 1.4704 - accuracy: 0.3153 - val_loss: 1.4383 - val_accuracy: 0.3059\n",
      "Epoch 52/80\n",
      "6435/6435 [==============================] - 0s 41us/step - loss: 1.4663 - accuracy: 0.3178 - val_loss: 1.4355 - val_accuracy: 0.3198\n",
      "Epoch 53/80\n",
      "6435/6435 [==============================] - 0s 48us/step - loss: 1.4632 - accuracy: 0.3249 - val_loss: 1.4360 - val_accuracy: 0.3296\n",
      "Epoch 54/80\n",
      "6435/6435 [==============================] - 0s 39us/step - loss: 1.4629 - accuracy: 0.3211 - val_loss: 1.4295 - val_accuracy: 0.3296\n",
      "Epoch 55/80\n",
      "6435/6435 [==============================] - 0s 41us/step - loss: 1.4620 - accuracy: 0.3277 - val_loss: 1.4295 - val_accuracy: 0.3450\n",
      "Epoch 56/80\n",
      "6435/6435 [==============================] - 0s 38us/step - loss: 1.4666 - accuracy: 0.3215 - val_loss: 1.4267 - val_accuracy: 0.3394\n",
      "Epoch 57/80\n",
      "6435/6435 [==============================] - 0s 41us/step - loss: 1.4652 - accuracy: 0.3211 - val_loss: 1.4285 - val_accuracy: 0.3059\n",
      "Epoch 58/80\n",
      "6435/6435 [==============================] - 0s 37us/step - loss: 1.4622 - accuracy: 0.3225 - val_loss: 1.4458 - val_accuracy: 0.3282\n",
      "Epoch 59/80\n",
      "6435/6435 [==============================] - 0s 40us/step - loss: 1.4623 - accuracy: 0.3198 - val_loss: 1.4302 - val_accuracy: 0.3128\n",
      "Epoch 60/80\n",
      "6435/6435 [==============================] - 0s 39us/step - loss: 1.4640 - accuracy: 0.3193 - val_loss: 1.4390 - val_accuracy: 0.3240\n",
      "Epoch 61/80\n",
      "6435/6435 [==============================] - 0s 43us/step - loss: 1.4670 - accuracy: 0.3237 - val_loss: 1.4244 - val_accuracy: 0.3073\n",
      "Epoch 62/80\n",
      "6435/6435 [==============================] - 0s 41us/step - loss: 1.4575 - accuracy: 0.3237 - val_loss: 1.4328 - val_accuracy: 0.3268\n",
      "Epoch 63/80\n",
      "6435/6435 [==============================] - 0s 39us/step - loss: 1.4557 - accuracy: 0.3287 - val_loss: 1.4432 - val_accuracy: 0.3310\n",
      "Epoch 64/80\n",
      "6435/6435 [==============================] - 0s 39us/step - loss: 1.4541 - accuracy: 0.3383 - val_loss: 1.4187 - val_accuracy: 0.3352\n",
      "Epoch 65/80\n",
      "6435/6435 [==============================] - 0s 37us/step - loss: 1.4555 - accuracy: 0.3329 - val_loss: 1.4290 - val_accuracy: 0.3450\n",
      "Epoch 66/80\n",
      "6435/6435 [==============================] - 0s 39us/step - loss: 1.4552 - accuracy: 0.3377 - val_loss: 1.4360 - val_accuracy: 0.3324\n",
      "Epoch 67/80\n",
      "6435/6435 [==============================] - 0s 39us/step - loss: 1.4523 - accuracy: 0.3360 - val_loss: 1.4388 - val_accuracy: 0.3115\n",
      "Epoch 68/80\n",
      "6435/6435 [==============================] - 0s 39us/step - loss: 1.4491 - accuracy: 0.3315 - val_loss: 1.4243 - val_accuracy: 0.3254\n",
      "Epoch 69/80\n",
      "6435/6435 [==============================] - 0s 40us/step - loss: 1.4476 - accuracy: 0.3347 - val_loss: 1.4117 - val_accuracy: 0.3436\n",
      "Epoch 70/80\n",
      "6435/6435 [==============================] - 0s 38us/step - loss: 1.4483 - accuracy: 0.3386 - val_loss: 1.4172 - val_accuracy: 0.3603\n",
      "Epoch 71/80\n",
      "6435/6435 [==============================] - 0s 42us/step - loss: 1.4481 - accuracy: 0.3394 - val_loss: 1.4183 - val_accuracy: 0.3282\n",
      "Epoch 72/80\n",
      "6435/6435 [==============================] - 0s 38us/step - loss: 1.4408 - accuracy: 0.3413 - val_loss: 1.4083 - val_accuracy: 0.3352\n",
      "Epoch 73/80\n",
      "6435/6435 [==============================] - 0s 44us/step - loss: 1.4322 - accuracy: 0.3632 - val_loss: 1.4020 - val_accuracy: 0.3603\n",
      "Epoch 74/80\n",
      "6435/6435 [==============================] - 0s 41us/step - loss: 1.4336 - accuracy: 0.3622 - val_loss: 1.3880 - val_accuracy: 0.3645\n",
      "Epoch 75/80\n",
      "6435/6435 [==============================] - 0s 40us/step - loss: 1.4184 - accuracy: 0.3618 - val_loss: 1.3917 - val_accuracy: 0.3547\n",
      "Epoch 76/80\n",
      "6435/6435 [==============================] - ETA: 0s - loss: 1.4126 - accuracy: 0.37 - 0s 36us/step - loss: 1.4126 - accuracy: 0.3731 - val_loss: 1.3780 - val_accuracy: 0.3785\n",
      "Epoch 77/80\n",
      "6435/6435 [==============================] - 0s 39us/step - loss: 1.3949 - accuracy: 0.3807 - val_loss: 1.3693 - val_accuracy: 0.3394\n",
      "Epoch 78/80\n",
      "6435/6435 [==============================] - 0s 40us/step - loss: 1.3928 - accuracy: 0.3832 - val_loss: 1.3531 - val_accuracy: 0.3897\n",
      "Epoch 79/80\n",
      "6435/6435 [==============================] - 0s 38us/step - loss: 1.3699 - accuracy: 0.3734 - val_loss: 1.3401 - val_accuracy: 0.3715\n",
      "Epoch 80/80\n",
      "6435/6435 [==============================] - 0s 40us/step - loss: 1.3569 - accuracy: 0.3837 - val_loss: 1.3278 - val_accuracy: 0.3645\n",
      "[[1.33313075e-01 1.81969300e-01 1.90049240e-14 ... 3.08988243e-01\n",
      "  1.64955437e-01 1.87830150e-01]\n",
      " [3.12064346e-02 4.55356650e-02 9.43428064e-22 ... 5.72582940e-03\n",
      "  5.79879107e-03 6.75837789e-03]\n",
      " [1.67236105e-01 2.29607925e-01 6.73579195e-17 ... 1.95423648e-01\n",
      "  1.79612130e-01 2.21182182e-01]\n",
      " ...\n",
      " [1.85142353e-01 2.52337664e-01 2.88874399e-17 ... 1.10397443e-01\n",
      "  1.90190300e-01 2.58530945e-01]\n",
      " [1.39176026e-01 1.83483779e-01 4.54810289e-13 ... 2.05190897e-01\n",
      "  1.98880792e-01 2.27063581e-01]\n",
      " [1.42174155e-01 1.91065788e-01 1.11838077e-13 ... 2.29939148e-01\n",
      "  1.88437909e-01 2.16854513e-01]]\n",
      "[12 11  1 ... 14 14 12]\n",
      "<class 'numpy.ndarray'>\n",
      "One CNN, r:  0\n",
      "Computing Time:  0:02:13.256015\n",
      "n, p1, p2 1 0 1\n",
      "Model: \"sequential_1\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv1d_1 (Conv1D)            (None, 3, 6)              12        \n",
      "_________________________________________________________________\n",
      "average_pooling1d_1 (Average (None, 1, 6)              0         \n",
      "_________________________________________________________________\n",
      "conv1d_2 (Conv1D)            (None, 1, 16)             112       \n",
      "_________________________________________________________________\n",
      "average_pooling1d_2 (Average (None, 1, 16)             0         \n",
      "_________________________________________________________________\n",
      "conv1d_3 (Conv1D)            (None, 1, 120)            2040      \n",
      "_________________________________________________________________\n",
      "flatten_1 (Flatten)          (None, 120)               0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 84)                10164     \n",
      "_________________________________________________________________\n",
      "preds (Dense)                (None, 14)                1190      \n",
      "=================================================================\n",
      "Total params: 13,518\n",
      "Trainable params: 13,518\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Train on 6435 samples, validate on 716 samples\n",
      "Epoch 1/80\n",
      "6435/6435 [==============================] - 0s 77us/step - loss: 2.5740 - accuracy: 0.1473 - val_loss: 2.4416 - val_accuracy: 0.1941\n",
      "Epoch 2/80\n",
      "6435/6435 [==============================] - 0s 40us/step - loss: 2.2204 - accuracy: 0.2617 - val_loss: 1.9781 - val_accuracy: 0.2891\n",
      "Epoch 3/80\n",
      "6435/6435 [==============================] - 0s 42us/step - loss: 1.8879 - accuracy: 0.3176 - val_loss: 1.7861 - val_accuracy: 0.2975\n",
      "Epoch 4/80\n",
      "6435/6435 [==============================] - 0s 42us/step - loss: 1.7533 - accuracy: 0.3318 - val_loss: 1.6712 - val_accuracy: 0.3268\n",
      "Epoch 5/80\n",
      "6435/6435 [==============================] - 0s 39us/step - loss: 1.6641 - accuracy: 0.3395 - val_loss: 1.5906 - val_accuracy: 0.3520\n",
      "Epoch 6/80\n",
      "6435/6435 [==============================] - 0s 40us/step - loss: 1.5804 - accuracy: 0.3489 - val_loss: 1.5364 - val_accuracy: 0.3450\n",
      "Epoch 7/80\n",
      "6435/6435 [==============================] - 0s 39us/step - loss: 1.5220 - accuracy: 0.3545 - val_loss: 1.4867 - val_accuracy: 0.3436\n",
      "Epoch 8/80\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6435/6435 [==============================] - 0s 39us/step - loss: 1.4879 - accuracy: 0.3574 - val_loss: 1.4670 - val_accuracy: 0.3659\n",
      "Epoch 9/80\n",
      "6435/6435 [==============================] - 0s 40us/step - loss: 1.4714 - accuracy: 0.3518 - val_loss: 1.4486 - val_accuracy: 0.3687\n",
      "Epoch 10/80\n",
      "6435/6435 [==============================] - 0s 41us/step - loss: 1.4536 - accuracy: 0.3543 - val_loss: 1.4397 - val_accuracy: 0.3659\n",
      "Epoch 11/80\n",
      "6435/6435 [==============================] - 0s 38us/step - loss: 1.4385 - accuracy: 0.3526 - val_loss: 1.4276 - val_accuracy: 0.3520\n",
      "Epoch 12/80\n",
      "6435/6435 [==============================] - 0s 37us/step - loss: 1.4293 - accuracy: 0.3594 - val_loss: 1.4203 - val_accuracy: 0.3506\n",
      "Epoch 13/80\n",
      "6435/6435 [==============================] - 0s 41us/step - loss: 1.4254 - accuracy: 0.3599 - val_loss: 1.4080 - val_accuracy: 0.3883\n",
      "Epoch 14/80\n",
      "6435/6435 [==============================] - 0s 37us/step - loss: 1.4144 - accuracy: 0.3616 - val_loss: 1.4098 - val_accuracy: 0.3561\n",
      "Epoch 15/80\n",
      "6435/6435 [==============================] - 0s 40us/step - loss: 1.4055 - accuracy: 0.3624 - val_loss: 1.4242 - val_accuracy: 0.3547\n",
      "Epoch 16/80\n",
      "6435/6435 [==============================] - 0s 41us/step - loss: 1.4002 - accuracy: 0.3591 - val_loss: 1.3971 - val_accuracy: 0.3785\n",
      "Epoch 17/80\n",
      "6435/6435 [==============================] - 0s 39us/step - loss: 1.3942 - accuracy: 0.3700 - val_loss: 1.3863 - val_accuracy: 0.3659\n",
      "Epoch 18/80\n",
      "6435/6435 [==============================] - 0s 38us/step - loss: 1.4014 - accuracy: 0.3627 - val_loss: 1.4005 - val_accuracy: 0.3897\n",
      "Epoch 19/80\n",
      "6435/6435 [==============================] - 0s 37us/step - loss: 1.3861 - accuracy: 0.3636 - val_loss: 1.3936 - val_accuracy: 0.3631\n",
      "Epoch 20/80\n",
      "6435/6435 [==============================] - 0s 38us/step - loss: 1.3806 - accuracy: 0.3702 - val_loss: 1.3945 - val_accuracy: 0.3436\n",
      "Epoch 21/80\n",
      "6435/6435 [==============================] - 0s 40us/step - loss: 1.3770 - accuracy: 0.3683 - val_loss: 1.3713 - val_accuracy: 0.3715\n",
      "Epoch 22/80\n",
      "6435/6435 [==============================] - 0s 37us/step - loss: 1.3770 - accuracy: 0.3758 - val_loss: 1.4056 - val_accuracy: 0.3631\n",
      "Epoch 23/80\n",
      "6435/6435 [==============================] - 0s 40us/step - loss: 1.3792 - accuracy: 0.3610 - val_loss: 1.3709 - val_accuracy: 0.3785\n",
      "Epoch 24/80\n",
      "6435/6435 [==============================] - 0s 40us/step - loss: 1.3674 - accuracy: 0.3708 - val_loss: 1.3912 - val_accuracy: 0.3687\n",
      "Epoch 25/80\n",
      "6435/6435 [==============================] - 0s 40us/step - loss: 1.3719 - accuracy: 0.3647 - val_loss: 1.3769 - val_accuracy: 0.3813\n",
      "Epoch 26/80\n",
      "6435/6435 [==============================] - 0s 38us/step - loss: 1.3606 - accuracy: 0.3751 - val_loss: 1.3573 - val_accuracy: 0.3785\n",
      "Epoch 27/80\n",
      "6435/6435 [==============================] - 0s 37us/step - loss: 1.3563 - accuracy: 0.3790 - val_loss: 1.3479 - val_accuracy: 0.3897\n",
      "Epoch 28/80\n",
      "6435/6435 [==============================] - 0s 38us/step - loss: 1.3558 - accuracy: 0.3761 - val_loss: 1.3368 - val_accuracy: 0.4008\n",
      "Epoch 29/80\n",
      "6435/6435 [==============================] - 0s 47us/step - loss: 1.3387 - accuracy: 0.3876 - val_loss: 1.3227 - val_accuracy: 0.3980\n",
      "Epoch 30/80\n",
      "6435/6435 [==============================] - 0s 41us/step - loss: 1.3230 - accuracy: 0.3956 - val_loss: 1.3043 - val_accuracy: 0.4246\n",
      "Epoch 31/80\n",
      "6435/6435 [==============================] - 0s 38us/step - loss: 1.3085 - accuracy: 0.4067 - val_loss: 1.2940 - val_accuracy: 0.4022\n",
      "Epoch 32/80\n",
      "6435/6435 [==============================] - 0s 38us/step - loss: 1.2934 - accuracy: 0.4073 - val_loss: 1.2620 - val_accuracy: 0.4330\n",
      "Epoch 33/80\n",
      "6435/6435 [==============================] - 0s 40us/step - loss: 1.2715 - accuracy: 0.4152 - val_loss: 1.2490 - val_accuracy: 0.4232\n",
      "Epoch 34/80\n",
      "6435/6435 [==============================] - 0s 38us/step - loss: 1.2536 - accuracy: 0.4207 - val_loss: 1.2255 - val_accuracy: 0.4567\n",
      "Epoch 35/80\n",
      "6435/6435 [==============================] - 0s 40us/step - loss: 1.2401 - accuracy: 0.4183 - val_loss: 1.2230 - val_accuracy: 0.4218\n",
      "Epoch 36/80\n",
      "6435/6435 [==============================] - 0s 37us/step - loss: 1.2297 - accuracy: 0.4213 - val_loss: 1.2066 - val_accuracy: 0.4218\n",
      "Epoch 37/80\n",
      "6435/6435 [==============================] - 0s 37us/step - loss: 1.2173 - accuracy: 0.4221 - val_loss: 1.2047 - val_accuracy: 0.4246\n",
      "Epoch 38/80\n",
      "6435/6435 [==============================] - 0s 40us/step - loss: 1.2194 - accuracy: 0.4176 - val_loss: 1.2127 - val_accuracy: 0.4190\n",
      "Epoch 39/80\n",
      "6435/6435 [==============================] - 0s 39us/step - loss: 1.2104 - accuracy: 0.4200 - val_loss: 1.1968 - val_accuracy: 0.4399\n",
      "Epoch 40/80\n",
      "6435/6435 [==============================] - 0s 41us/step - loss: 1.2027 - accuracy: 0.4291 - val_loss: 1.1650 - val_accuracy: 0.4846\n",
      "Epoch 41/80\n",
      "6435/6435 [==============================] - 0s 41us/step - loss: 1.2010 - accuracy: 0.4197 - val_loss: 1.1773 - val_accuracy: 0.4344\n",
      "Epoch 42/80\n",
      "6435/6435 [==============================] - 0s 38us/step - loss: 1.1934 - accuracy: 0.4197 - val_loss: 1.1842 - val_accuracy: 0.4441\n",
      "Epoch 43/80\n",
      "6435/6435 [==============================] - 0s 38us/step - loss: 1.1886 - accuracy: 0.4260 - val_loss: 1.1608 - val_accuracy: 0.4497\n",
      "Epoch 44/80\n",
      "6435/6435 [==============================] - 0s 40us/step - loss: 1.1893 - accuracy: 0.4224 - val_loss: 1.1634 - val_accuracy: 0.4637\n",
      "Epoch 45/80\n",
      "6435/6435 [==============================] - 0s 38us/step - loss: 1.1837 - accuracy: 0.4253 - val_loss: 1.1625 - val_accuracy: 0.4427\n",
      "Epoch 46/80\n",
      "6435/6435 [==============================] - 0s 38us/step - loss: 1.1795 - accuracy: 0.4284 - val_loss: 1.1539 - val_accuracy: 0.4735\n",
      "Epoch 47/80\n",
      "6435/6435 [==============================] - 0s 39us/step - loss: 1.1738 - accuracy: 0.4312 - val_loss: 1.1600 - val_accuracy: 0.4344\n",
      "Epoch 48/80\n",
      "6435/6435 [==============================] - 0s 37us/step - loss: 1.1777 - accuracy: 0.4277 - val_loss: 1.1643 - val_accuracy: 0.4134\n",
      "Epoch 49/80\n",
      "6435/6435 [==============================] - 0s 38us/step - loss: 1.1757 - accuracy: 0.4376 - val_loss: 1.1756 - val_accuracy: 0.4483\n",
      "Epoch 50/80\n",
      "6435/6435 [==============================] - 0s 49us/step - loss: 1.1720 - accuracy: 0.4202 - val_loss: 1.1503 - val_accuracy: 0.4651\n",
      "Epoch 51/80\n",
      "6435/6435 [==============================] - 0s 39us/step - loss: 1.1687 - accuracy: 0.4294 - val_loss: 1.1523 - val_accuracy: 0.4288\n",
      "Epoch 52/80\n",
      "6435/6435 [==============================] - 0s 38us/step - loss: 1.1667 - accuracy: 0.4297 - val_loss: 1.1330 - val_accuracy: 0.4330\n",
      "Epoch 53/80\n",
      "6435/6435 [==============================] - 0s 38us/step - loss: 1.1638 - accuracy: 0.4373 - val_loss: 1.1395 - val_accuracy: 0.4553\n",
      "Epoch 54/80\n",
      "6435/6435 [==============================] - 0s 39us/step - loss: 1.1567 - accuracy: 0.4435 - val_loss: 1.1350 - val_accuracy: 0.4246\n",
      "Epoch 55/80\n",
      "6435/6435 [==============================] - 0s 43us/step - loss: 1.1543 - accuracy: 0.4356 - val_loss: 1.1477 - val_accuracy: 0.4218\n",
      "Epoch 56/80\n",
      "6435/6435 [==============================] - 0s 40us/step - loss: 1.1512 - accuracy: 0.4399 - val_loss: 1.1364 - val_accuracy: 0.4707\n",
      "Epoch 57/80\n",
      "6435/6435 [==============================] - 0s 40us/step - loss: 1.1524 - accuracy: 0.4351 - val_loss: 1.1412 - val_accuracy: 0.4623\n",
      "Epoch 58/80\n",
      "6435/6435 [==============================] - 0s 39us/step - loss: 1.1464 - accuracy: 0.4449 - val_loss: 1.1337 - val_accuracy: 0.4553\n",
      "Epoch 59/80\n",
      "6435/6435 [==============================] - 0s 40us/step - loss: 1.1409 - accuracy: 0.4340 - val_loss: 1.1319 - val_accuracy: 0.4399\n",
      "Epoch 60/80\n",
      "6435/6435 [==============================] - 0s 41us/step - loss: 1.1426 - accuracy: 0.4479 - val_loss: 1.1162 - val_accuracy: 0.4609\n",
      "Epoch 61/80\n",
      "6435/6435 [==============================] - 0s 41us/step - loss: 1.1380 - accuracy: 0.4385 - val_loss: 1.1239 - val_accuracy: 0.4441\n",
      "Epoch 62/80\n",
      "6435/6435 [==============================] - 0s 38us/step - loss: 1.1359 - accuracy: 0.4441 - val_loss: 1.1285 - val_accuracy: 0.4539\n",
      "Epoch 63/80\n",
      "6435/6435 [==============================] - 0s 41us/step - loss: 1.1306 - accuracy: 0.4420 - val_loss: 1.1205 - val_accuracy: 0.4358\n",
      "Epoch 64/80\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6435/6435 [==============================] - 0s 37us/step - loss: 1.1373 - accuracy: 0.4370 - val_loss: 1.1240 - val_accuracy: 0.4525\n",
      "Epoch 65/80\n",
      "6435/6435 [==============================] - 0s 39us/step - loss: 1.1389 - accuracy: 0.4502 - val_loss: 1.1196 - val_accuracy: 0.4679\n",
      "Epoch 66/80\n",
      "6435/6435 [==============================] - 0s 42us/step - loss: 1.1398 - accuracy: 0.4427 - val_loss: 1.1084 - val_accuracy: 0.4707\n",
      "Epoch 67/80\n",
      "6435/6435 [==============================] - 0s 39us/step - loss: 1.1342 - accuracy: 0.4378 - val_loss: 1.1215 - val_accuracy: 0.4553\n",
      "Epoch 68/80\n",
      "6435/6435 [==============================] - 0s 40us/step - loss: 1.1333 - accuracy: 0.4395 - val_loss: 1.1150 - val_accuracy: 0.4441\n",
      "Epoch 69/80\n",
      "6435/6435 [==============================] - 0s 38us/step - loss: 1.1355 - accuracy: 0.4409 - val_loss: 1.1127 - val_accuracy: 0.4735\n",
      "Epoch 70/80\n",
      "6435/6435 [==============================] - 0s 38us/step - loss: 1.1296 - accuracy: 0.4432 - val_loss: 1.1117 - val_accuracy: 0.4609\n",
      "Epoch 71/80\n",
      "6435/6435 [==============================] - 0s 41us/step - loss: 1.1279 - accuracy: 0.4415 - val_loss: 1.1088 - val_accuracy: 0.4791\n",
      "Epoch 72/80\n",
      "6435/6435 [==============================] - 0s 40us/step - loss: 1.1321 - accuracy: 0.4340 - val_loss: 1.1015 - val_accuracy: 0.4595\n",
      "Epoch 73/80\n",
      "6435/6435 [==============================] - 0s 38us/step - loss: 1.1266 - accuracy: 0.4423 - val_loss: 1.0968 - val_accuracy: 0.4707\n",
      "Epoch 74/80\n",
      "6435/6435 [==============================] - 0s 38us/step - loss: 1.1263 - accuracy: 0.4342 - val_loss: 1.1097 - val_accuracy: 0.4623\n",
      "Epoch 75/80\n",
      "6435/6435 [==============================] - 0s 38us/step - loss: 1.1201 - accuracy: 0.4510 - val_loss: 1.1035 - val_accuracy: 0.4735\n",
      "Epoch 76/80\n",
      "6435/6435 [==============================] - 0s 38us/step - loss: 1.1166 - accuracy: 0.4418 - val_loss: 1.0945 - val_accuracy: 0.4707\n",
      "Epoch 77/80\n",
      "6435/6435 [==============================] - 0s 39us/step - loss: 1.1211 - accuracy: 0.4485 - val_loss: 1.1128 - val_accuracy: 0.4791\n",
      "Epoch 78/80\n",
      "6435/6435 [==============================] - 0s 40us/step - loss: 1.1191 - accuracy: 0.4471 - val_loss: 1.0944 - val_accuracy: 0.4763\n",
      "Epoch 79/80\n",
      "6435/6435 [==============================] - 0s 39us/step - loss: 1.1161 - accuracy: 0.4505 - val_loss: 1.0888 - val_accuracy: 0.4707\n",
      "Epoch 80/80\n",
      "6435/6435 [==============================] - 0s 40us/step - loss: 1.1220 - accuracy: 0.4463 - val_loss: 1.1006 - val_accuracy: 0.4539\n",
      "[[2.4783631e-01 5.5551015e-16 1.1759128e-04 ... 3.4064305e-01\n",
      "  1.6818729e-01 2.3700792e-01]\n",
      " [7.5340293e-02 1.4592131e-23 1.2272274e-03 ... 2.4779057e-04\n",
      "  6.9792094e-03 7.5116088e-03]\n",
      " [3.3221415e-01 8.5324520e-20 3.3376602e-06 ... 4.4060357e-02\n",
      "  2.6392296e-01 3.5834333e-01]\n",
      " ...\n",
      " [4.3672788e-01 5.2363546e-21 2.2439458e-07 ... 3.7216796e-03\n",
      "  2.3989575e-01 3.1941381e-01]\n",
      " [1.3845225e-01 6.5866065e-15 3.4377648e-05 ... 1.3642396e-01\n",
      "  3.0457461e-01 4.1588911e-01]\n",
      " [1.6663469e-01 1.2819695e-15 2.5867625e-05 ... 1.5287869e-01\n",
      "  2.8473651e-01 3.9309177e-01]]\n",
      "[11 10 13 ...  0 13 13]\n",
      "<class 'numpy.ndarray'>\n",
      "One CNN, r:  0\n",
      "Computing Time:  0:02:35.282332\n",
      "n, p1, p2 2 0 2\n",
      "Model: \"sequential_1\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv1d_1 (Conv1D)            (None, 3, 6)              12        \n",
      "_________________________________________________________________\n",
      "average_pooling1d_1 (Average (None, 1, 6)              0         \n",
      "_________________________________________________________________\n",
      "conv1d_2 (Conv1D)            (None, 1, 16)             112       \n",
      "_________________________________________________________________\n",
      "average_pooling1d_2 (Average (None, 1, 16)             0         \n",
      "_________________________________________________________________\n",
      "conv1d_3 (Conv1D)            (None, 1, 120)            2040      \n",
      "_________________________________________________________________\n",
      "flatten_1 (Flatten)          (None, 120)               0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 84)                10164     \n",
      "_________________________________________________________________\n",
      "preds (Dense)                (None, 14)                1190      \n",
      "=================================================================\n",
      "Total params: 13,518\n",
      "Trainable params: 13,518\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Train on 6435 samples, validate on 716 samples\n",
      "Epoch 1/80\n",
      "6435/6435 [==============================] - 1s 84us/step - loss: 2.5898 - accuracy: 0.1319 - val_loss: 2.4695 - val_accuracy: 0.1648\n",
      "Epoch 2/80\n",
      "6435/6435 [==============================] - 0s 41us/step - loss: 2.2562 - accuracy: 0.1840 - val_loss: 2.0619 - val_accuracy: 0.2067\n",
      "Epoch 3/80\n",
      "6435/6435 [==============================] - 0s 40us/step - loss: 1.9732 - accuracy: 0.2232 - val_loss: 1.8721 - val_accuracy: 0.2598\n",
      "Epoch 4/80\n",
      "6435/6435 [==============================] - 0s 42us/step - loss: 1.8369 - accuracy: 0.2508 - val_loss: 1.7899 - val_accuracy: 0.2821\n",
      "Epoch 5/80\n",
      "6435/6435 [==============================] - 0s 46us/step - loss: 1.7339 - accuracy: 0.2741 - val_loss: 1.6787 - val_accuracy: 0.2723\n",
      "Epoch 6/80\n",
      "6435/6435 [==============================] - 0s 42us/step - loss: 1.6552 - accuracy: 0.2807 - val_loss: 1.6092 - val_accuracy: 0.3087\n",
      "Epoch 7/80\n",
      "6435/6435 [==============================] - 0s 40us/step - loss: 1.6016 - accuracy: 0.3015 - val_loss: 1.5890 - val_accuracy: 0.3045\n",
      "Epoch 8/80\n",
      "6435/6435 [==============================] - 0s 39us/step - loss: 1.5776 - accuracy: 0.3009 - val_loss: 1.5543 - val_accuracy: 0.3087\n",
      "Epoch 9/80\n",
      "6435/6435 [==============================] - 0s 39us/step - loss: 1.5598 - accuracy: 0.2967 - val_loss: 1.5350 - val_accuracy: 0.3059\n",
      "Epoch 10/80\n",
      "6435/6435 [==============================] - 0s 39us/step - loss: 1.5383 - accuracy: 0.3108 - val_loss: 1.5210 - val_accuracy: 0.3059\n",
      "Epoch 11/80\n",
      "6435/6435 [==============================] - 0s 37us/step - loss: 1.5294 - accuracy: 0.3064 - val_loss: 1.5144 - val_accuracy: 0.3198\n",
      "Epoch 12/80\n",
      "6435/6435 [==============================] - 0s 39us/step - loss: 1.5224 - accuracy: 0.3001 - val_loss: 1.5572 - val_accuracy: 0.3073\n",
      "Epoch 13/80\n",
      "6435/6435 [==============================] - 0s 37us/step - loss: 1.5251 - accuracy: 0.2982 - val_loss: 1.5200 - val_accuracy: 0.3156\n",
      "Epoch 14/80\n",
      "6435/6435 [==============================] - 0s 42us/step - loss: 1.5126 - accuracy: 0.3061 - val_loss: 1.4983 - val_accuracy: 0.2751\n",
      "Epoch 15/80\n",
      "6435/6435 [==============================] - 0s 39us/step - loss: 1.5103 - accuracy: 0.3052 - val_loss: 1.4894 - val_accuracy: 0.3212\n",
      "Epoch 16/80\n",
      "6435/6435 [==============================] - 0s 41us/step - loss: 1.5003 - accuracy: 0.3089 - val_loss: 1.4980 - val_accuracy: 0.3087\n",
      "Epoch 17/80\n",
      "6435/6435 [==============================] - 0s 42us/step - loss: 1.5024 - accuracy: 0.3061 - val_loss: 1.4891 - val_accuracy: 0.3296\n",
      "Epoch 18/80\n",
      "6435/6435 [==============================] - 0s 40us/step - loss: 1.4967 - accuracy: 0.3075 - val_loss: 1.4977 - val_accuracy: 0.3115\n",
      "Epoch 19/80\n",
      "6435/6435 [==============================] - 0s 40us/step - loss: 1.4953 - accuracy: 0.3116 - val_loss: 1.4874 - val_accuracy: 0.3394\n",
      "Epoch 20/80\n",
      "6435/6435 [==============================] - 0s 41us/step - loss: 1.4901 - accuracy: 0.3214 - val_loss: 1.4825 - val_accuracy: 0.3338\n",
      "Epoch 21/80\n",
      "6435/6435 [==============================] - 0s 41us/step - loss: 1.4846 - accuracy: 0.3103 - val_loss: 1.4748 - val_accuracy: 0.3226\n",
      "Epoch 22/80\n",
      "6435/6435 [==============================] - 0s 39us/step - loss: 1.4918 - accuracy: 0.3005 - val_loss: 1.4751 - val_accuracy: 0.3184\n",
      "Epoch 23/80\n",
      "6435/6435 [==============================] - 0s 38us/step - loss: 1.4829 - accuracy: 0.3069 - val_loss: 1.4682 - val_accuracy: 0.3226\n",
      "Epoch 24/80\n",
      "6435/6435 [==============================] - 0s 38us/step - loss: 1.4813 - accuracy: 0.3082 - val_loss: 1.4667 - val_accuracy: 0.3296\n",
      "Epoch 25/80\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6435/6435 [==============================] - 0s 40us/step - loss: 1.4806 - accuracy: 0.3077 - val_loss: 1.4815 - val_accuracy: 0.2919\n",
      "Epoch 26/80\n",
      "6435/6435 [==============================] - 0s 45us/step - loss: 1.4930 - accuracy: 0.3080 - val_loss: 1.4688 - val_accuracy: 0.3338\n",
      "Epoch 27/80\n",
      "6435/6435 [==============================] - 0s 40us/step - loss: 1.4792 - accuracy: 0.3161 - val_loss: 1.4805 - val_accuracy: 0.2863\n",
      "Epoch 28/80\n",
      "6435/6435 [==============================] - 0s 37us/step - loss: 1.4787 - accuracy: 0.3136 - val_loss: 1.4553 - val_accuracy: 0.3366\n",
      "Epoch 29/80\n",
      "6435/6435 [==============================] - 0s 39us/step - loss: 1.4732 - accuracy: 0.3164 - val_loss: 1.4600 - val_accuracy: 0.3324\n",
      "Epoch 30/80\n",
      "6435/6435 [==============================] - 0s 40us/step - loss: 1.4758 - accuracy: 0.3187 - val_loss: 1.5061 - val_accuracy: 0.3003\n",
      "Epoch 31/80\n",
      "6435/6435 [==============================] - 0s 38us/step - loss: 1.4822 - accuracy: 0.3223 - val_loss: 1.4618 - val_accuracy: 0.3045\n",
      "Epoch 32/80\n",
      "6435/6435 [==============================] - 0s 38us/step - loss: 1.4704 - accuracy: 0.3229 - val_loss: 1.4531 - val_accuracy: 0.3240\n",
      "Epoch 33/80\n",
      "6435/6435 [==============================] - 0s 38us/step - loss: 1.4682 - accuracy: 0.3200 - val_loss: 1.4681 - val_accuracy: 0.3547\n",
      "Epoch 34/80\n",
      "6435/6435 [==============================] - 0s 38us/step - loss: 1.4726 - accuracy: 0.3173 - val_loss: 1.4562 - val_accuracy: 0.3492\n",
      "Epoch 35/80\n",
      "6435/6435 [==============================] - 0s 38us/step - loss: 1.4654 - accuracy: 0.3201 - val_loss: 1.4546 - val_accuracy: 0.3589\n",
      "Epoch 36/80\n",
      "6435/6435 [==============================] - 0s 38us/step - loss: 1.4561 - accuracy: 0.3343 - val_loss: 1.4604 - val_accuracy: 0.3226\n",
      "Epoch 37/80\n",
      "6435/6435 [==============================] - 0s 38us/step - loss: 1.4568 - accuracy: 0.3336 - val_loss: 1.4395 - val_accuracy: 0.3603\n",
      "Epoch 38/80\n",
      "6435/6435 [==============================] - 0s 42us/step - loss: 1.4452 - accuracy: 0.3484 - val_loss: 1.4240 - val_accuracy: 0.3841\n",
      "Epoch 39/80\n",
      "6435/6435 [==============================] - 0s 40us/step - loss: 1.4372 - accuracy: 0.3450 - val_loss: 1.4280 - val_accuracy: 0.3729\n",
      "Epoch 40/80\n",
      "6435/6435 [==============================] - 0s 38us/step - loss: 1.4320 - accuracy: 0.3591 - val_loss: 1.4267 - val_accuracy: 0.3757\n",
      "Epoch 41/80\n",
      "6435/6435 [==============================] - 0s 40us/step - loss: 1.4244 - accuracy: 0.3638 - val_loss: 1.3985 - val_accuracy: 0.3715\n",
      "Epoch 42/80\n",
      "6435/6435 [==============================] - 0s 37us/step - loss: 1.4108 - accuracy: 0.3650 - val_loss: 1.4136 - val_accuracy: 0.3631\n",
      "Epoch 43/80\n",
      "6435/6435 [==============================] - 0s 39us/step - loss: 1.3940 - accuracy: 0.3694 - val_loss: 1.3587 - val_accuracy: 0.3883\n",
      "Epoch 44/80\n",
      "6435/6435 [==============================] - 0s 37us/step - loss: 1.3690 - accuracy: 0.3885 - val_loss: 1.3405 - val_accuracy: 0.3953\n",
      "Epoch 45/80\n",
      "6435/6435 [==============================] - 0s 40us/step - loss: 1.3577 - accuracy: 0.3818 - val_loss: 1.3360 - val_accuracy: 0.4022\n",
      "Epoch 46/80\n",
      "6435/6435 [==============================] - 0s 44us/step - loss: 1.3434 - accuracy: 0.3717 - val_loss: 1.3368 - val_accuracy: 0.3729\n",
      "Epoch 47/80\n",
      "6435/6435 [==============================] - 0s 50us/step - loss: 1.3209 - accuracy: 0.3852 - val_loss: 1.2975 - val_accuracy: 0.3869\n",
      "Epoch 48/80\n",
      "6435/6435 [==============================] - 0s 39us/step - loss: 1.3143 - accuracy: 0.3846 - val_loss: 1.2973 - val_accuracy: 0.3687\n",
      "Epoch 49/80\n",
      "6435/6435 [==============================] - 0s 38us/step - loss: 1.3042 - accuracy: 0.3869 - val_loss: 1.2674 - val_accuracy: 0.4120\n",
      "Epoch 50/80\n",
      "6435/6435 [==============================] - 0s 43us/step - loss: 1.3020 - accuracy: 0.3859 - val_loss: 1.2605 - val_accuracy: 0.4064\n",
      "Epoch 51/80\n",
      "6435/6435 [==============================] - ETA: 0s - loss: 1.2731 - accuracy: 0.40 - 0s 43us/step - loss: 1.2806 - accuracy: 0.4006 - val_loss: 1.2491 - val_accuracy: 0.4036\n",
      "Epoch 52/80\n",
      "6435/6435 [==============================] - 0s 39us/step - loss: 1.2758 - accuracy: 0.3915 - val_loss: 1.2539 - val_accuracy: 0.3939\n",
      "Epoch 53/80\n",
      "6435/6435 [==============================] - 0s 38us/step - loss: 1.2711 - accuracy: 0.3949 - val_loss: 1.2475 - val_accuracy: 0.4162\n",
      "Epoch 54/80\n",
      "6435/6435 [==============================] - 0s 37us/step - loss: 1.2694 - accuracy: 0.3958 - val_loss: 1.2335 - val_accuracy: 0.4274\n",
      "Epoch 55/80\n",
      "6435/6435 [==============================] - 0s 42us/step - loss: 1.2604 - accuracy: 0.4034 - val_loss: 1.2391 - val_accuracy: 0.4078\n",
      "Epoch 56/80\n",
      "6435/6435 [==============================] - 0s 46us/step - loss: 1.2580 - accuracy: 0.4034 - val_loss: 1.2280 - val_accuracy: 0.4190\n",
      "Epoch 57/80\n",
      "6435/6435 [==============================] - 0s 43us/step - loss: 1.2478 - accuracy: 0.4026 - val_loss: 1.2269 - val_accuracy: 0.3897\n",
      "Epoch 58/80\n",
      "6435/6435 [==============================] - 0s 43us/step - loss: 1.2527 - accuracy: 0.4033 - val_loss: 1.2124 - val_accuracy: 0.4204\n",
      "Epoch 59/80\n",
      "6435/6435 [==============================] - 0s 41us/step - loss: 1.2457 - accuracy: 0.4022 - val_loss: 1.2173 - val_accuracy: 0.4106\n",
      "Epoch 60/80\n",
      "6435/6435 [==============================] - 0s 46us/step - loss: 1.2431 - accuracy: 0.3991 - val_loss: 1.2078 - val_accuracy: 0.4148\n",
      "Epoch 61/80\n",
      "6435/6435 [==============================] - 0s 40us/step - loss: 1.2341 - accuracy: 0.4103 - val_loss: 1.2058 - val_accuracy: 0.4274\n",
      "Epoch 62/80\n",
      "6435/6435 [==============================] - 0s 41us/step - loss: 1.2381 - accuracy: 0.4022 - val_loss: 1.2134 - val_accuracy: 0.4274\n",
      "Epoch 63/80\n",
      "6435/6435 [==============================] - 0s 41us/step - loss: 1.2375 - accuracy: 0.4070 - val_loss: 1.2205 - val_accuracy: 0.4148\n",
      "Epoch 64/80\n",
      "6435/6435 [==============================] - 0s 39us/step - loss: 1.2307 - accuracy: 0.4112 - val_loss: 1.2061 - val_accuracy: 0.4162\n",
      "Epoch 65/80\n",
      "6435/6435 [==============================] - 0s 43us/step - loss: 1.2313 - accuracy: 0.4044 - val_loss: 1.1982 - val_accuracy: 0.4344\n",
      "Epoch 66/80\n",
      "6435/6435 [==============================] - 0s 42us/step - loss: 1.2317 - accuracy: 0.4053 - val_loss: 1.2161 - val_accuracy: 0.3939\n",
      "Epoch 67/80\n",
      "6435/6435 [==============================] - 0s 41us/step - loss: 1.2283 - accuracy: 0.4101 - val_loss: 1.2116 - val_accuracy: 0.4078\n",
      "Epoch 68/80\n",
      "6435/6435 [==============================] - 0s 38us/step - loss: 1.2252 - accuracy: 0.4103 - val_loss: 1.1918 - val_accuracy: 0.4120\n",
      "Epoch 69/80\n",
      "6435/6435 [==============================] - 0s 43us/step - loss: 1.2306 - accuracy: 0.4099 - val_loss: 1.2130 - val_accuracy: 0.4274\n",
      "Epoch 70/80\n",
      "6435/6435 [==============================] - 0s 40us/step - loss: 1.2207 - accuracy: 0.4089 - val_loss: 1.2087 - val_accuracy: 0.3953\n",
      "Epoch 71/80\n",
      "6435/6435 [==============================] - 0s 36us/step - loss: 1.2225 - accuracy: 0.4109 - val_loss: 1.1887 - val_accuracy: 0.4232\n",
      "Epoch 72/80\n",
      "6435/6435 [==============================] - 0s 41us/step - loss: 1.2224 - accuracy: 0.4071 - val_loss: 1.2026 - val_accuracy: 0.4372\n",
      "Epoch 73/80\n",
      "6435/6435 [==============================] - 0s 40us/step - loss: 1.2226 - accuracy: 0.4098 - val_loss: 1.1935 - val_accuracy: 0.4232\n",
      "Epoch 74/80\n",
      "6435/6435 [==============================] - 0s 42us/step - loss: 1.2155 - accuracy: 0.4103 - val_loss: 1.2091 - val_accuracy: 0.4106\n",
      "Epoch 75/80\n",
      "6435/6435 [==============================] - 0s 40us/step - loss: 1.2148 - accuracy: 0.4104 - val_loss: 1.1924 - val_accuracy: 0.4302\n",
      "Epoch 76/80\n",
      "6435/6435 [==============================] - 0s 39us/step - loss: 1.2187 - accuracy: 0.4078 - val_loss: 1.1865 - val_accuracy: 0.4344\n",
      "Epoch 77/80\n",
      "6435/6435 [==============================] - 0s 39us/step - loss: 1.2159 - accuracy: 0.4064 - val_loss: 1.2143 - val_accuracy: 0.4218\n",
      "Epoch 78/80\n",
      "6435/6435 [==============================] - 0s 39us/step - loss: 1.2150 - accuracy: 0.4145 - val_loss: 1.1861 - val_accuracy: 0.4302\n",
      "Epoch 79/80\n",
      "6435/6435 [==============================] - 0s 38us/step - loss: 1.2121 - accuracy: 0.4057 - val_loss: 1.1839 - val_accuracy: 0.4399\n",
      "Epoch 80/80\n",
      "6435/6435 [==============================] - 0s 39us/step - loss: 1.2114 - accuracy: 0.4109 - val_loss: 1.1786 - val_accuracy: 0.4427\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[1.01451874e-01 1.16868123e-01 5.72749006e-04 ... 2.84525573e-01\n",
      "  2.61457443e-01 2.30131641e-01]\n",
      " [4.42953072e-02 4.74934541e-02 5.48468612e-04 ... 2.86411698e-04\n",
      "  6.15194021e-03 6.09785970e-03]\n",
      " [1.34617925e-01 1.54514417e-01 3.56365163e-05 ... 4.93679605e-02\n",
      "  3.59291762e-01 3.00710380e-01]\n",
      " ...\n",
      " [1.90906346e-01 1.92300007e-01 4.49125628e-06 ... 8.71777162e-03\n",
      "  3.47667813e-01 2.60094702e-01]\n",
      " [6.39788583e-02 7.99457952e-02 2.75685365e-04 ... 1.22425452e-01\n",
      "  3.90726984e-01 3.39292914e-01]\n",
      " [7.78489783e-02 9.34988782e-02 2.27882105e-04 ... 1.40268639e-01\n",
      "  3.62826765e-01 3.23215008e-01]]\n",
      "[11 10 12 ... 12 12 12]\n",
      "<class 'numpy.ndarray'>\n",
      "One CNN, r:  0\n",
      "Computing Time:  0:02:57.860542\n",
      "n, p1, p2 3 0 3\n",
      "Model: \"sequential_1\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv1d_1 (Conv1D)            (None, 3, 6)              12        \n",
      "_________________________________________________________________\n",
      "average_pooling1d_1 (Average (None, 1, 6)              0         \n",
      "_________________________________________________________________\n",
      "conv1d_2 (Conv1D)            (None, 1, 16)             112       \n",
      "_________________________________________________________________\n",
      "average_pooling1d_2 (Average (None, 1, 16)             0         \n",
      "_________________________________________________________________\n",
      "conv1d_3 (Conv1D)            (None, 1, 120)            2040      \n",
      "_________________________________________________________________\n",
      "flatten_1 (Flatten)          (None, 120)               0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 84)                10164     \n",
      "_________________________________________________________________\n",
      "preds (Dense)                (None, 14)                1190      \n",
      "=================================================================\n",
      "Total params: 13,518\n",
      "Trainable params: 13,518\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Train on 6435 samples, validate on 716 samples\n",
      "Epoch 1/80\n",
      "6435/6435 [==============================] - 0s 78us/step - loss: 2.5864 - accuracy: 0.1580 - val_loss: 2.4734 - val_accuracy: 0.1899\n",
      "Epoch 2/80\n",
      "6435/6435 [==============================] - 0s 40us/step - loss: 2.2578 - accuracy: 0.2110 - val_loss: 2.0910 - val_accuracy: 0.2165\n",
      "Epoch 3/80\n",
      "6435/6435 [==============================] - 0s 40us/step - loss: 1.9887 - accuracy: 0.2357 - val_loss: 1.9240 - val_accuracy: 0.2556\n",
      "Epoch 4/80\n",
      "6435/6435 [==============================] - 0s 41us/step - loss: 1.8743 - accuracy: 0.2485 - val_loss: 1.8301 - val_accuracy: 0.2444\n",
      "Epoch 5/80\n",
      "6435/6435 [==============================] - 0s 40us/step - loss: 1.7819 - accuracy: 0.2580 - val_loss: 1.7377 - val_accuracy: 0.2542\n",
      "Epoch 6/80\n",
      "6435/6435 [==============================] - 0s 41us/step - loss: 1.7014 - accuracy: 0.2862 - val_loss: 1.6878 - val_accuracy: 0.2668\n",
      "Epoch 7/80\n",
      "6435/6435 [==============================] - 0s 39us/step - loss: 1.6488 - accuracy: 0.2906 - val_loss: 1.6422 - val_accuracy: 0.3142\n",
      "Epoch 8/80\n",
      "6435/6435 [==============================] - 0s 39us/step - loss: 1.6178 - accuracy: 0.3043 - val_loss: 1.6148 - val_accuracy: 0.3017\n",
      "Epoch 9/80\n",
      "6435/6435 [==============================] - 0s 38us/step - loss: 1.5951 - accuracy: 0.2974 - val_loss: 1.5969 - val_accuracy: 0.3101\n",
      "Epoch 10/80\n",
      "6435/6435 [==============================] - 0s 39us/step - loss: 1.5757 - accuracy: 0.3046 - val_loss: 1.5891 - val_accuracy: 0.3045\n",
      "Epoch 11/80\n",
      "6435/6435 [==============================] - 0s 40us/step - loss: 1.5678 - accuracy: 0.2962 - val_loss: 1.5707 - val_accuracy: 0.3128\n",
      "Epoch 12/80\n",
      "6435/6435 [==============================] - 0s 38us/step - loss: 1.5586 - accuracy: 0.3110 - val_loss: 1.5890 - val_accuracy: 0.3031\n",
      "Epoch 13/80\n",
      "6435/6435 [==============================] - 0s 40us/step - loss: 1.5464 - accuracy: 0.3099 - val_loss: 1.5524 - val_accuracy: 0.3254\n",
      "Epoch 14/80\n",
      "6435/6435 [==============================] - 0s 39us/step - loss: 1.5347 - accuracy: 0.3110 - val_loss: 1.5610 - val_accuracy: 0.3212\n",
      "Epoch 15/80\n",
      "6435/6435 [==============================] - 0s 38us/step - loss: 1.5314 - accuracy: 0.3096 - val_loss: 1.5556 - val_accuracy: 0.2933\n",
      "Epoch 16/80\n",
      "6435/6435 [==============================] - 0s 36us/step - loss: 1.5288 - accuracy: 0.3071 - val_loss: 1.5404 - val_accuracy: 0.3324\n",
      "Epoch 17/80\n",
      "6435/6435 [==============================] - 0s 40us/step - loss: 1.5189 - accuracy: 0.3057 - val_loss: 1.5328 - val_accuracy: 0.3184\n",
      "Epoch 18/80\n",
      "6435/6435 [==============================] - 0s 39us/step - loss: 1.5147 - accuracy: 0.2998 - val_loss: 1.5287 - val_accuracy: 0.3310\n",
      "Epoch 19/80\n",
      "6435/6435 [==============================] - 0s 39us/step - loss: 1.5112 - accuracy: 0.3086 - val_loss: 1.5417 - val_accuracy: 0.3017\n",
      "Epoch 20/80\n",
      "6435/6435 [==============================] - 0s 37us/step - loss: 1.5094 - accuracy: 0.3064 - val_loss: 1.5303 - val_accuracy: 0.3031\n",
      "Epoch 21/80\n",
      "6435/6435 [==============================] - 0s 34us/step - loss: 1.5037 - accuracy: 0.3060 - val_loss: 1.5186 - val_accuracy: 0.3073\n",
      "Epoch 22/80\n",
      "6435/6435 [==============================] - 0s 38us/step - loss: 1.5082 - accuracy: 0.3023 - val_loss: 1.5244 - val_accuracy: 0.3128\n",
      "Epoch 23/80\n",
      "6435/6435 [==============================] - 0s 36us/step - loss: 1.5014 - accuracy: 0.3060 - val_loss: 1.5189 - val_accuracy: 0.2891\n",
      "Epoch 24/80\n",
      "6435/6435 [==============================] - 0s 40us/step - loss: 1.4971 - accuracy: 0.2998 - val_loss: 1.5236 - val_accuracy: 0.3324\n",
      "Epoch 25/80\n",
      "6435/6435 [==============================] - 0s 41us/step - loss: 1.4940 - accuracy: 0.3136 - val_loss: 1.5051 - val_accuracy: 0.3226\n",
      "Epoch 26/80\n",
      "6435/6435 [==============================] - 0s 41us/step - loss: 1.4865 - accuracy: 0.3026 - val_loss: 1.5408 - val_accuracy: 0.2989\n",
      "Epoch 27/80\n",
      "6435/6435 [==============================] - 0s 40us/step - loss: 1.4910 - accuracy: 0.3110 - val_loss: 1.5221 - val_accuracy: 0.3142\n",
      "Epoch 28/80\n",
      "6435/6435 [==============================] - 0s 40us/step - loss: 1.4868 - accuracy: 0.3094 - val_loss: 1.5223 - val_accuracy: 0.3073\n",
      "Epoch 29/80\n",
      "6435/6435 [==============================] - 0s 39us/step - loss: 1.4812 - accuracy: 0.3117 - val_loss: 1.5208 - val_accuracy: 0.3059\n",
      "Epoch 30/80\n",
      "6435/6435 [==============================] - 0s 40us/step - loss: 1.4896 - accuracy: 0.3072 - val_loss: 1.5127 - val_accuracy: 0.3198\n",
      "Epoch 31/80\n",
      "6435/6435 [==============================] - 0s 41us/step - loss: 1.4774 - accuracy: 0.3105 - val_loss: 1.5141 - val_accuracy: 0.2961\n",
      "Epoch 32/80\n",
      "6435/6435 [==============================] - 0s 37us/step - loss: 1.4846 - accuracy: 0.3080 - val_loss: 1.5045 - val_accuracy: 0.2947\n",
      "Epoch 33/80\n",
      "6435/6435 [==============================] - 0s 41us/step - loss: 1.4730 - accuracy: 0.3044 - val_loss: 1.4996 - val_accuracy: 0.3184\n",
      "Epoch 34/80\n",
      "6435/6435 [==============================] - 0s 41us/step - loss: 1.4792 - accuracy: 0.3136 - val_loss: 1.4903 - val_accuracy: 0.3534\n",
      "Epoch 35/80\n",
      "6435/6435 [==============================] - 0s 40us/step - loss: 1.4789 - accuracy: 0.3220 - val_loss: 1.4929 - val_accuracy: 0.3128\n",
      "Epoch 36/80\n",
      "6435/6435 [==============================] - 0s 38us/step - loss: 1.4720 - accuracy: 0.3110 - val_loss: 1.5024 - val_accuracy: 0.3226\n",
      "Epoch 37/80\n",
      "6435/6435 [==============================] - 0s 39us/step - loss: 1.4809 - accuracy: 0.2963 - val_loss: 1.4957 - val_accuracy: 0.3240\n",
      "Epoch 38/80\n",
      "6435/6435 [==============================] - 0s 39us/step - loss: 1.4706 - accuracy: 0.3060 - val_loss: 1.4878 - val_accuracy: 0.3282\n",
      "Epoch 39/80\n",
      "6435/6435 [==============================] - 0s 38us/step - loss: 1.4705 - accuracy: 0.3068 - val_loss: 1.4982 - val_accuracy: 0.3128\n",
      "Epoch 40/80\n",
      "6435/6435 [==============================] - 0s 38us/step - loss: 1.4735 - accuracy: 0.3175 - val_loss: 1.4892 - val_accuracy: 0.3101\n",
      "Epoch 41/80\n",
      "6435/6435 [==============================] - 0s 36us/step - loss: 1.4682 - accuracy: 0.3128 - val_loss: 1.5059 - val_accuracy: 0.3310\n",
      "Epoch 42/80\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6435/6435 [==============================] - 0s 38us/step - loss: 1.4709 - accuracy: 0.3127 - val_loss: 1.5039 - val_accuracy: 0.2933\n",
      "Epoch 43/80\n",
      "6435/6435 [==============================] - 0s 47us/step - loss: 1.4692 - accuracy: 0.3128 - val_loss: 1.4926 - val_accuracy: 0.3101\n",
      "Epoch 44/80\n",
      "6435/6435 [==============================] - 0s 37us/step - loss: 1.4675 - accuracy: 0.3207 - val_loss: 1.4948 - val_accuracy: 0.3324\n",
      "Epoch 45/80\n",
      "6435/6435 [==============================] - 0s 34us/step - loss: 1.4674 - accuracy: 0.3148 - val_loss: 1.5255 - val_accuracy: 0.2975\n",
      "Epoch 46/80\n",
      "6435/6435 [==============================] - 0s 40us/step - loss: 1.4617 - accuracy: 0.3175 - val_loss: 1.4866 - val_accuracy: 0.3128\n",
      "Epoch 47/80\n",
      "6435/6435 [==============================] - 0s 40us/step - loss: 1.4669 - accuracy: 0.3173 - val_loss: 1.4895 - val_accuracy: 0.3045\n",
      "Epoch 48/80\n",
      "6435/6435 [==============================] - 0s 40us/step - loss: 1.4704 - accuracy: 0.3207 - val_loss: 1.4989 - val_accuracy: 0.3003\n",
      "Epoch 49/80\n",
      "6435/6435 [==============================] - 0s 39us/step - loss: 1.4600 - accuracy: 0.3148 - val_loss: 1.5198 - val_accuracy: 0.3198\n",
      "Epoch 50/80\n",
      "6435/6435 [==============================] - 0s 37us/step - loss: 1.4661 - accuracy: 0.3178 - val_loss: 1.4909 - val_accuracy: 0.3170\n",
      "Epoch 51/80\n",
      "6435/6435 [==============================] - 0s 37us/step - loss: 1.4671 - accuracy: 0.3176 - val_loss: 1.4787 - val_accuracy: 0.3156\n",
      "Epoch 52/80\n",
      "6435/6435 [==============================] - 0s 38us/step - loss: 1.4604 - accuracy: 0.3153 - val_loss: 1.4841 - val_accuracy: 0.3338\n",
      "Epoch 53/80\n",
      "6435/6435 [==============================] - 0s 37us/step - loss: 1.4575 - accuracy: 0.3229 - val_loss: 1.4807 - val_accuracy: 0.3128\n",
      "Epoch 54/80\n",
      "6435/6435 [==============================] - 0s 40us/step - loss: 1.4643 - accuracy: 0.3100 - val_loss: 1.4891 - val_accuracy: 0.3087\n",
      "Epoch 55/80\n",
      "6435/6435 [==============================] - 0s 40us/step - loss: 1.4608 - accuracy: 0.3128 - val_loss: 1.4788 - val_accuracy: 0.3212\n",
      "Epoch 56/80\n",
      "6435/6435 [==============================] - 0s 39us/step - loss: 1.4573 - accuracy: 0.3131 - val_loss: 1.4799 - val_accuracy: 0.3310\n",
      "Epoch 57/80\n",
      "6435/6435 [==============================] - 0s 32us/step - loss: 1.4541 - accuracy: 0.3263 - val_loss: 1.4787 - val_accuracy: 0.3101\n",
      "Epoch 58/80\n",
      "6435/6435 [==============================] - 0s 37us/step - loss: 1.4510 - accuracy: 0.3206 - val_loss: 1.4769 - val_accuracy: 0.3115\n",
      "Epoch 59/80\n",
      "6435/6435 [==============================] - 0s 39us/step - loss: 1.4561 - accuracy: 0.3158 - val_loss: 1.4753 - val_accuracy: 0.3170\n",
      "Epoch 60/80\n",
      "6435/6435 [==============================] - 0s 40us/step - loss: 1.4529 - accuracy: 0.3195 - val_loss: 1.4840 - val_accuracy: 0.3240\n",
      "Epoch 61/80\n",
      "6435/6435 [==============================] - 0s 36us/step - loss: 1.4546 - accuracy: 0.3256 - val_loss: 1.4785 - val_accuracy: 0.3212\n",
      "Epoch 62/80\n",
      "6435/6435 [==============================] - 0s 39us/step - loss: 1.4551 - accuracy: 0.3186 - val_loss: 1.4825 - val_accuracy: 0.3087\n",
      "Epoch 63/80\n",
      "6435/6435 [==============================] - 0s 35us/step - loss: 1.4541 - accuracy: 0.3211 - val_loss: 1.4860 - val_accuracy: 0.2961\n",
      "Epoch 64/80\n",
      "6435/6435 [==============================] - 0s 37us/step - loss: 1.4517 - accuracy: 0.3305 - val_loss: 1.4832 - val_accuracy: 0.3184\n",
      "Epoch 65/80\n",
      "6435/6435 [==============================] - 0s 39us/step - loss: 1.4559 - accuracy: 0.3239 - val_loss: 1.4699 - val_accuracy: 0.3198\n",
      "Epoch 66/80\n",
      "6435/6435 [==============================] - 0s 40us/step - loss: 1.4545 - accuracy: 0.3189 - val_loss: 1.4748 - val_accuracy: 0.3198\n",
      "Epoch 67/80\n",
      "6435/6435 [==============================] - 0s 41us/step - loss: 1.4449 - accuracy: 0.3240 - val_loss: 1.4683 - val_accuracy: 0.3366\n",
      "Epoch 68/80\n",
      "6435/6435 [==============================] - 0s 41us/step - loss: 1.4521 - accuracy: 0.3234 - val_loss: 1.4748 - val_accuracy: 0.3422\n",
      "Epoch 69/80\n",
      "6435/6435 [==============================] - 0s 37us/step - loss: 1.4529 - accuracy: 0.3242 - val_loss: 1.4695 - val_accuracy: 0.3212\n",
      "Epoch 70/80\n",
      "6435/6435 [==============================] - 0s 33us/step - loss: 1.4467 - accuracy: 0.3288 - val_loss: 1.4745 - val_accuracy: 0.3240\n",
      "Epoch 71/80\n",
      "6435/6435 [==============================] - 0s 38us/step - loss: 1.4461 - accuracy: 0.3341 - val_loss: 1.4642 - val_accuracy: 0.3282\n",
      "Epoch 72/80\n",
      "6435/6435 [==============================] - 0s 39us/step - loss: 1.4442 - accuracy: 0.3340 - val_loss: 1.4685 - val_accuracy: 0.3506\n",
      "Epoch 73/80\n",
      "6435/6435 [==============================] - 0s 39us/step - loss: 1.4441 - accuracy: 0.3305 - val_loss: 1.4639 - val_accuracy: 0.3170\n",
      "Epoch 74/80\n",
      "6435/6435 [==============================] - 0s 39us/step - loss: 1.4487 - accuracy: 0.3195 - val_loss: 1.4610 - val_accuracy: 0.3310\n",
      "Epoch 75/80\n",
      "6435/6435 [==============================] - 0s 42us/step - loss: 1.4397 - accuracy: 0.3315 - val_loss: 1.4617 - val_accuracy: 0.3394\n",
      "Epoch 76/80\n",
      "6435/6435 [==============================] - 0s 38us/step - loss: 1.4391 - accuracy: 0.3285 - val_loss: 1.4604 - val_accuracy: 0.3352\n",
      "Epoch 77/80\n",
      "6435/6435 [==============================] - 0s 33us/step - loss: 1.4435 - accuracy: 0.3382 - val_loss: 1.4760 - val_accuracy: 0.3408\n",
      "Epoch 78/80\n",
      "6435/6435 [==============================] - 0s 37us/step - loss: 1.4374 - accuracy: 0.3350 - val_loss: 1.4710 - val_accuracy: 0.3575\n",
      "Epoch 79/80\n",
      "6435/6435 [==============================] - 0s 38us/step - loss: 1.4356 - accuracy: 0.3423 - val_loss: 1.4580 - val_accuracy: 0.3575\n",
      "Epoch 80/80\n",
      "6435/6435 [==============================] - 0s 36us/step - loss: 1.4318 - accuracy: 0.3447 - val_loss: 1.4545 - val_accuracy: 0.3575\n",
      "[[1.8185894e-01 1.5113516e-01 1.7135764e-13 ... 2.5162241e-01\n",
      "  1.9593942e-01 1.6303463e-01]\n",
      " [3.7834954e-02 2.9887775e-02 6.7452754e-21 ... 1.0610336e-02\n",
      "  8.7019242e-03 7.6737860e-03]\n",
      " [2.1385729e-01 1.8486160e-01 1.1657853e-15 ... 2.3589510e-01\n",
      "  1.9135472e-01 1.6044775e-01]\n",
      " ...\n",
      " [2.2121294e-01 1.9657333e-01 9.6030793e-16 ... 2.1622650e-01\n",
      "  1.9309887e-01 1.6154198e-01]\n",
      " [1.6543119e-01 1.4268734e-01 3.4607720e-12 ... 1.8260913e-01\n",
      "  2.2203927e-01 1.8836330e-01]\n",
      " [1.7381063e-01 1.4838882e-01 1.0416067e-12 ... 2.0539638e-01\n",
      "  2.1385263e-01 1.7988744e-01]]\n",
      "[11  4 11 ...  0 12 12]\n",
      "<class 'numpy.ndarray'>\n",
      "One CNN, r:  0\n",
      "Computing Time:  0:03:19.439252\n",
      "n, p1, p2 4 0 4\n",
      "Model: \"sequential_1\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv1d_1 (Conv1D)            (None, 3, 6)              12        \n",
      "_________________________________________________________________\n",
      "average_pooling1d_1 (Average (None, 1, 6)              0         \n",
      "_________________________________________________________________\n",
      "conv1d_2 (Conv1D)            (None, 1, 16)             112       \n",
      "_________________________________________________________________\n",
      "average_pooling1d_2 (Average (None, 1, 16)             0         \n",
      "_________________________________________________________________\n",
      "conv1d_3 (Conv1D)            (None, 1, 120)            2040      \n",
      "_________________________________________________________________\n",
      "flatten_1 (Flatten)          (None, 120)               0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 84)                10164     \n",
      "_________________________________________________________________\n",
      "preds (Dense)                (None, 14)                1190      \n",
      "=================================================================\n",
      "Total params: 13,518\n",
      "Trainable params: 13,518\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Train on 6435 samples, validate on 716 samples\n",
      "Epoch 1/80\n",
      "6435/6435 [==============================] - 0s 76us/step - loss: 2.6027 - accuracy: 0.1423 - val_loss: 2.5254 - val_accuracy: 0.1578\n",
      "Epoch 2/80\n",
      "6435/6435 [==============================] - 0s 46us/step - loss: 2.3628 - accuracy: 0.2048 - val_loss: 2.1746 - val_accuracy: 0.2542\n",
      "Epoch 3/80\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6435/6435 [==============================] - 0s 40us/step - loss: 2.0406 - accuracy: 0.2384 - val_loss: 1.9770 - val_accuracy: 0.2514\n",
      "Epoch 4/80\n",
      "6435/6435 [==============================] - 0s 37us/step - loss: 1.9067 - accuracy: 0.2446 - val_loss: 1.9074 - val_accuracy: 0.2081\n",
      "Epoch 5/80\n",
      "6435/6435 [==============================] - 0s 40us/step - loss: 1.8364 - accuracy: 0.2458 - val_loss: 1.8472 - val_accuracy: 0.2360\n",
      "Epoch 6/80\n",
      "6435/6435 [==============================] - 0s 41us/step - loss: 1.7807 - accuracy: 0.2679 - val_loss: 1.8111 - val_accuracy: 0.2486\n",
      "Epoch 7/80\n",
      "6435/6435 [==============================] - 0s 41us/step - loss: 1.7496 - accuracy: 0.2808 - val_loss: 1.7614 - val_accuracy: 0.2668\n",
      "Epoch 8/80\n",
      "6435/6435 [==============================] - 0s 39us/step - loss: 1.7220 - accuracy: 0.2827 - val_loss: 1.7563 - val_accuracy: 0.2835\n",
      "Epoch 9/80\n",
      "6435/6435 [==============================] - 0s 42us/step - loss: 1.7026 - accuracy: 0.2942 - val_loss: 1.7387 - val_accuracy: 0.2612\n",
      "Epoch 10/80\n",
      "6435/6435 [==============================] - 0s 39us/step - loss: 1.6903 - accuracy: 0.2929 - val_loss: 1.7115 - val_accuracy: 0.2821\n",
      "Epoch 11/80\n",
      "6435/6435 [==============================] - 0s 41us/step - loss: 1.6818 - accuracy: 0.2973 - val_loss: 1.7045 - val_accuracy: 0.2723\n",
      "Epoch 12/80\n",
      "6435/6435 [==============================] - 0s 37us/step - loss: 1.6750 - accuracy: 0.2987 - val_loss: 1.6984 - val_accuracy: 0.2793\n",
      "Epoch 13/80\n",
      "6435/6435 [==============================] - 0s 42us/step - loss: 1.6654 - accuracy: 0.2988 - val_loss: 1.7130 - val_accuracy: 0.2626\n",
      "Epoch 14/80\n",
      "6435/6435 [==============================] - 0s 39us/step - loss: 1.6644 - accuracy: 0.3007 - val_loss: 1.6887 - val_accuracy: 0.2919\n",
      "Epoch 15/80\n",
      "6435/6435 [==============================] - 0s 37us/step - loss: 1.6623 - accuracy: 0.3007 - val_loss: 1.7103 - val_accuracy: 0.2765\n",
      "Epoch 16/80\n",
      "6435/6435 [==============================] - 0s 39us/step - loss: 1.6578 - accuracy: 0.2960 - val_loss: 1.6818 - val_accuracy: 0.2947\n",
      "Epoch 17/80\n",
      "6435/6435 [==============================] - 0s 39us/step - loss: 1.6578 - accuracy: 0.3001 - val_loss: 1.7012 - val_accuracy: 0.2542\n",
      "Epoch 18/80\n",
      "6435/6435 [==============================] - 0s 40us/step - loss: 1.6497 - accuracy: 0.2991 - val_loss: 1.6979 - val_accuracy: 0.2626\n",
      "Epoch 19/80\n",
      "6435/6435 [==============================] - 0s 40us/step - loss: 1.6509 - accuracy: 0.3043 - val_loss: 1.6830 - val_accuracy: 0.2793\n",
      "Epoch 20/80\n",
      "6435/6435 [==============================] - 0s 40us/step - loss: 1.6491 - accuracy: 0.3026 - val_loss: 1.6790 - val_accuracy: 0.2975\n",
      "Epoch 21/80\n",
      "6435/6435 [==============================] - 0s 50us/step - loss: 1.6498 - accuracy: 0.3021 - val_loss: 1.6729 - val_accuracy: 0.2905\n",
      "Epoch 22/80\n",
      "6435/6435 [==============================] - 0s 39us/step - loss: 1.6481 - accuracy: 0.2982 - val_loss: 1.6769 - val_accuracy: 0.2849\n",
      "Epoch 23/80\n",
      "6435/6435 [==============================] - 0s 40us/step - loss: 1.6420 - accuracy: 0.3072 - val_loss: 1.6834 - val_accuracy: 0.2500\n",
      "Epoch 24/80\n",
      "6435/6435 [==============================] - 0s 40us/step - loss: 1.6452 - accuracy: 0.3024 - val_loss: 1.6943 - val_accuracy: 0.2835\n",
      "Epoch 25/80\n",
      "6435/6435 [==============================] - 0s 38us/step - loss: 1.6434 - accuracy: 0.3052 - val_loss: 1.6846 - val_accuracy: 0.2584\n",
      "Epoch 26/80\n",
      "6435/6435 [==============================] - 0s 39us/step - loss: 1.6467 - accuracy: 0.3043 - val_loss: 1.6783 - val_accuracy: 0.2737\n",
      "Epoch 27/80\n",
      "6435/6435 [==============================] - 0s 37us/step - loss: 1.6442 - accuracy: 0.2985 - val_loss: 1.6831 - val_accuracy: 0.2765\n",
      "Epoch 28/80\n",
      "6435/6435 [==============================] - 0s 40us/step - loss: 1.6415 - accuracy: 0.3058 - val_loss: 1.6673 - val_accuracy: 0.2933\n",
      "Epoch 29/80\n",
      "6435/6435 [==============================] - 0s 40us/step - loss: 1.6396 - accuracy: 0.3029 - val_loss: 1.6915 - val_accuracy: 0.2472\n",
      "Epoch 30/80\n",
      "6435/6435 [==============================] - 0s 38us/step - loss: 1.6417 - accuracy: 0.3024 - val_loss: 1.6773 - val_accuracy: 0.2849\n",
      "Epoch 31/80\n",
      "6435/6435 [==============================] - 0s 39us/step - loss: 1.6423 - accuracy: 0.3043 - val_loss: 1.6894 - val_accuracy: 0.2486\n",
      "Epoch 32/80\n",
      "6435/6435 [==============================] - 0s 40us/step - loss: 1.6359 - accuracy: 0.3058 - val_loss: 1.6777 - val_accuracy: 0.2709\n",
      "Epoch 33/80\n",
      "6435/6435 [==============================] - 0s 42us/step - loss: 1.6335 - accuracy: 0.3047 - val_loss: 1.6956 - val_accuracy: 0.2737\n",
      "Epoch 34/80\n",
      "6435/6435 [==============================] - 0s 39us/step - loss: 1.6342 - accuracy: 0.3029 - val_loss: 1.6837 - val_accuracy: 0.2626\n",
      "Epoch 35/80\n",
      "6435/6435 [==============================] - 0s 40us/step - loss: 1.6355 - accuracy: 0.3023 - val_loss: 1.6905 - val_accuracy: 0.2556\n",
      "Epoch 36/80\n",
      "6435/6435 [==============================] - 0s 39us/step - loss: 1.6350 - accuracy: 0.3102 - val_loss: 1.6942 - val_accuracy: 0.2612\n",
      "Epoch 37/80\n",
      "6435/6435 [==============================] - 0s 40us/step - loss: 1.6365 - accuracy: 0.3044 - val_loss: 1.6790 - val_accuracy: 0.2863\n",
      "Epoch 38/80\n",
      "6435/6435 [==============================] - 0s 39us/step - loss: 1.6354 - accuracy: 0.3037 - val_loss: 1.6704 - val_accuracy: 0.3045\n",
      "Epoch 00038: early stopping\n",
      "[[1.64721400e-01 1.66670367e-01 8.54949965e-12 ... 2.73456514e-01\n",
      "  1.29648238e-01 1.23658046e-01]\n",
      " [8.84509981e-02 7.36164674e-02 4.06078317e-19 ... 4.66323632e-04\n",
      "  7.45722577e-02 6.99845701e-02]\n",
      " [1.37167349e-01 1.60115033e-01 1.94294667e-16 ... 1.37782209e-02\n",
      "  1.09419860e-01 1.04160428e-01]\n",
      " ...\n",
      " [9.57671776e-02 8.44372138e-02 1.05452200e-18 ... 7.93210056e-04\n",
      "  8.03537071e-02 7.52846673e-02]\n",
      " [1.64628804e-01 1.65101305e-01 9.22461968e-11 ... 2.15983555e-01\n",
      "  1.32570729e-01 1.27807707e-01]\n",
      " [1.65649801e-01 1.67180777e-01 1.70604936e-11 ... 2.56971806e-01\n",
      "  1.31240040e-01 1.25563264e-01]]\n",
      "[11  9  4 ...  4 11 11]\n",
      "<class 'numpy.ndarray'>\n",
      "One CNN, r:  0\n",
      "Computing Time:  0:03:30.905984\n",
      "n, p1, p2 5 0 5\n",
      "Model: \"sequential_1\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv1d_1 (Conv1D)            (None, 3, 6)              12        \n",
      "_________________________________________________________________\n",
      "average_pooling1d_1 (Average (None, 1, 6)              0         \n",
      "_________________________________________________________________\n",
      "conv1d_2 (Conv1D)            (None, 1, 16)             112       \n",
      "_________________________________________________________________\n",
      "average_pooling1d_2 (Average (None, 1, 16)             0         \n",
      "_________________________________________________________________\n",
      "conv1d_3 (Conv1D)            (None, 1, 120)            2040      \n",
      "_________________________________________________________________\n",
      "flatten_1 (Flatten)          (None, 120)               0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 84)                10164     \n",
      "_________________________________________________________________\n",
      "preds (Dense)                (None, 14)                1190      \n",
      "=================================================================\n",
      "Total params: 13,518\n",
      "Trainable params: 13,518\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Train on 6435 samples, validate on 716 samples\n",
      "Epoch 1/80\n",
      "6435/6435 [==============================] - 0s 75us/step - loss: 2.6153 - accuracy: 0.1299 - val_loss: 2.5558 - val_accuracy: 0.1564\n",
      "Epoch 2/80\n",
      "6435/6435 [==============================] - 0s 42us/step - loss: 2.4246 - accuracy: 0.1650 - val_loss: 2.2118 - val_accuracy: 0.2542\n",
      "Epoch 3/80\n",
      "6435/6435 [==============================] - 0s 41us/step - loss: 2.0499 - accuracy: 0.3007 - val_loss: 1.9409 - val_accuracy: 0.2989\n",
      "Epoch 4/80\n",
      "6435/6435 [==============================] - 0s 39us/step - loss: 1.8772 - accuracy: 0.3072 - val_loss: 1.8633 - val_accuracy: 0.3170\n",
      "Epoch 5/80\n",
      "6435/6435 [==============================] - 0s 42us/step - loss: 1.7990 - accuracy: 0.3108 - val_loss: 1.7735 - val_accuracy: 0.3184\n",
      "Epoch 6/80\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6435/6435 [==============================] - 0s 40us/step - loss: 1.7342 - accuracy: 0.3178 - val_loss: 1.7226 - val_accuracy: 0.3226\n",
      "Epoch 7/80\n",
      "6435/6435 [==============================] - 0s 41us/step - loss: 1.6778 - accuracy: 0.3170 - val_loss: 1.6535 - val_accuracy: 0.3226\n",
      "Epoch 8/80\n",
      "6435/6435 [==============================] - 0s 40us/step - loss: 1.6247 - accuracy: 0.3263 - val_loss: 1.6174 - val_accuracy: 0.3212\n",
      "Epoch 9/80\n",
      "6435/6435 [==============================] - 0s 39us/step - loss: 1.5872 - accuracy: 0.3139 - val_loss: 1.5838 - val_accuracy: 0.3212\n",
      "Epoch 10/80\n",
      "6435/6435 [==============================] - 0s 40us/step - loss: 1.5609 - accuracy: 0.3212 - val_loss: 1.5586 - val_accuracy: 0.3268\n",
      "Epoch 11/80\n",
      "6435/6435 [==============================] - 0s 38us/step - loss: 1.5480 - accuracy: 0.3274 - val_loss: 1.5491 - val_accuracy: 0.3296\n",
      "Epoch 12/80\n",
      "6435/6435 [==============================] - 0s 40us/step - loss: 1.5327 - accuracy: 0.3279 - val_loss: 1.5352 - val_accuracy: 0.3436\n",
      "Epoch 13/80\n",
      "6435/6435 [==============================] - 0s 39us/step - loss: 1.5275 - accuracy: 0.3212 - val_loss: 1.5362 - val_accuracy: 0.3352\n",
      "Epoch 14/80\n",
      "6435/6435 [==============================] - 0s 45us/step - loss: 1.5173 - accuracy: 0.3288 - val_loss: 1.5287 - val_accuracy: 0.3352\n",
      "Epoch 15/80\n",
      "6435/6435 [==============================] - 0s 41us/step - loss: 1.5123 - accuracy: 0.3271 - val_loss: 1.5171 - val_accuracy: 0.3338\n",
      "Epoch 16/80\n",
      "6435/6435 [==============================] - 0s 41us/step - loss: 1.5056 - accuracy: 0.3277 - val_loss: 1.5245 - val_accuracy: 0.3282\n",
      "Epoch 17/80\n",
      "6435/6435 [==============================] - 0s 46us/step - loss: 1.5015 - accuracy: 0.3282 - val_loss: 1.5156 - val_accuracy: 0.3366\n",
      "Epoch 18/80\n",
      "6435/6435 [==============================] - 0s 47us/step - loss: 1.4984 - accuracy: 0.3096 - val_loss: 1.5234 - val_accuracy: 0.3310\n",
      "Epoch 19/80\n",
      "6435/6435 [==============================] - 0s 39us/step - loss: 1.4973 - accuracy: 0.3239 - val_loss: 1.5007 - val_accuracy: 0.3394\n",
      "Epoch 20/80\n",
      "6435/6435 [==============================] - 0s 39us/step - loss: 1.4901 - accuracy: 0.3284 - val_loss: 1.5162 - val_accuracy: 0.3296\n",
      "Epoch 21/80\n",
      "6435/6435 [==============================] - 0s 41us/step - loss: 1.4874 - accuracy: 0.3267 - val_loss: 1.5017 - val_accuracy: 0.3212\n",
      "Epoch 22/80\n",
      "6435/6435 [==============================] - 0s 37us/step - loss: 1.4880 - accuracy: 0.3263 - val_loss: 1.4968 - val_accuracy: 0.3464\n",
      "Epoch 23/80\n",
      "6435/6435 [==============================] - 0s 40us/step - loss: 1.4832 - accuracy: 0.3190 - val_loss: 1.5000 - val_accuracy: 0.3059\n",
      "Epoch 24/80\n",
      "6435/6435 [==============================] - 0s 42us/step - loss: 1.4867 - accuracy: 0.3179 - val_loss: 1.5144 - val_accuracy: 0.3338\n",
      "Epoch 25/80\n",
      "6435/6435 [==============================] - 0s 40us/step - loss: 1.4816 - accuracy: 0.3305 - val_loss: 1.4869 - val_accuracy: 0.3282\n",
      "Epoch 26/80\n",
      "6435/6435 [==============================] - 0s 41us/step - loss: 1.4770 - accuracy: 0.3256 - val_loss: 1.5132 - val_accuracy: 0.3366\n",
      "Epoch 27/80\n",
      "6435/6435 [==============================] - 0s 40us/step - loss: 1.4795 - accuracy: 0.3260 - val_loss: 1.4947 - val_accuracy: 0.3394\n",
      "Epoch 28/80\n",
      "6435/6435 [==============================] - 0s 40us/step - loss: 1.4716 - accuracy: 0.3254 - val_loss: 1.4845 - val_accuracy: 0.3338\n",
      "Epoch 29/80\n",
      "6435/6435 [==============================] - 0s 40us/step - loss: 1.4674 - accuracy: 0.3318 - val_loss: 1.4942 - val_accuracy: 0.3128\n",
      "Epoch 30/80\n",
      "6435/6435 [==============================] - 0s 39us/step - loss: 1.4677 - accuracy: 0.3280 - val_loss: 1.4804 - val_accuracy: 0.3282\n",
      "Epoch 31/80\n",
      "6435/6435 [==============================] - 0s 37us/step - loss: 1.4661 - accuracy: 0.3399 - val_loss: 1.4844 - val_accuracy: 0.3296\n",
      "Epoch 32/80\n",
      "6435/6435 [==============================] - 0s 41us/step - loss: 1.4615 - accuracy: 0.3223 - val_loss: 1.4832 - val_accuracy: 0.3324\n",
      "Epoch 33/80\n",
      "6435/6435 [==============================] - 0s 41us/step - loss: 1.4626 - accuracy: 0.3232 - val_loss: 1.4796 - val_accuracy: 0.3352\n",
      "Epoch 34/80\n",
      "6435/6435 [==============================] - 0s 38us/step - loss: 1.4632 - accuracy: 0.3268 - val_loss: 1.4740 - val_accuracy: 0.3282\n",
      "Epoch 35/80\n",
      "6435/6435 [==============================] - 0s 44us/step - loss: 1.4592 - accuracy: 0.3262 - val_loss: 1.4707 - val_accuracy: 0.3352\n",
      "Epoch 36/80\n",
      "6435/6435 [==============================] - 0s 38us/step - loss: 1.4564 - accuracy: 0.3290 - val_loss: 1.4716 - val_accuracy: 0.3338\n",
      "Epoch 37/80\n",
      "6435/6435 [==============================] - 0s 43us/step - loss: 1.4531 - accuracy: 0.3290 - val_loss: 1.4718 - val_accuracy: 0.3226\n",
      "Epoch 38/80\n",
      "6435/6435 [==============================] - 0s 45us/step - loss: 1.4548 - accuracy: 0.3402 - val_loss: 1.4697 - val_accuracy: 0.3492\n",
      "Epoch 39/80\n",
      "6435/6435 [==============================] - 0s 40us/step - loss: 1.4521 - accuracy: 0.3340 - val_loss: 1.4705 - val_accuracy: 0.3520\n",
      "Epoch 40/80\n",
      "6435/6435 [==============================] - 0s 38us/step - loss: 1.4503 - accuracy: 0.3355 - val_loss: 1.4625 - val_accuracy: 0.3324\n",
      "Epoch 41/80\n",
      "6435/6435 [==============================] - 0s 38us/step - loss: 1.4538 - accuracy: 0.3270 - val_loss: 1.4662 - val_accuracy: 0.3380\n",
      "Epoch 42/80\n",
      "6435/6435 [==============================] - 0s 39us/step - loss: 1.4487 - accuracy: 0.3431 - val_loss: 1.4581 - val_accuracy: 0.3422\n",
      "Epoch 43/80\n",
      "6435/6435 [==============================] - 0s 39us/step - loss: 1.4509 - accuracy: 0.3368 - val_loss: 1.4574 - val_accuracy: 0.3450\n",
      "Epoch 44/80\n",
      "6435/6435 [==============================] - 0s 39us/step - loss: 1.4476 - accuracy: 0.3197 - val_loss: 1.4704 - val_accuracy: 0.3394\n",
      "Epoch 45/80\n",
      "6435/6435 [==============================] - 0s 39us/step - loss: 1.4503 - accuracy: 0.3372 - val_loss: 1.4750 - val_accuracy: 0.3436\n",
      "Epoch 46/80\n",
      "6435/6435 [==============================] - 0s 39us/step - loss: 1.4478 - accuracy: 0.3326 - val_loss: 1.4725 - val_accuracy: 0.3422\n",
      "Epoch 47/80\n",
      "6435/6435 [==============================] - 0s 42us/step - loss: 1.4502 - accuracy: 0.3397 - val_loss: 1.4506 - val_accuracy: 0.3659\n",
      "Epoch 48/80\n",
      "6435/6435 [==============================] - 0s 39us/step - loss: 1.4370 - accuracy: 0.3464 - val_loss: 1.4422 - val_accuracy: 0.3645\n",
      "Epoch 49/80\n",
      "6435/6435 [==============================] - 0s 38us/step - loss: 1.4377 - accuracy: 0.3465 - val_loss: 1.4515 - val_accuracy: 0.3520\n",
      "Epoch 50/80\n",
      "6435/6435 [==============================] - 0s 38us/step - loss: 1.4372 - accuracy: 0.3392 - val_loss: 1.4463 - val_accuracy: 0.3589\n",
      "Epoch 51/80\n",
      "6435/6435 [==============================] - 0s 38us/step - loss: 1.4370 - accuracy: 0.3514 - val_loss: 1.4455 - val_accuracy: 0.3645\n",
      "Epoch 52/80\n",
      "6435/6435 [==============================] - 0s 40us/step - loss: 1.4334 - accuracy: 0.3492 - val_loss: 1.4357 - val_accuracy: 0.3603\n",
      "Epoch 53/80\n",
      "6435/6435 [==============================] - 0s 47us/step - loss: 1.4327 - accuracy: 0.3560 - val_loss: 1.4368 - val_accuracy: 0.3394\n",
      "Epoch 54/80\n",
      "6435/6435 [==============================] - 0s 39us/step - loss: 1.4217 - accuracy: 0.3528 - val_loss: 1.4307 - val_accuracy: 0.3743\n",
      "Epoch 55/80\n",
      "6435/6435 [==============================] - 0s 39us/step - loss: 1.4216 - accuracy: 0.3543 - val_loss: 1.4232 - val_accuracy: 0.3659\n",
      "Epoch 56/80\n",
      "6435/6435 [==============================] - 0s 41us/step - loss: 1.4198 - accuracy: 0.3579 - val_loss: 1.4260 - val_accuracy: 0.3380\n",
      "Epoch 57/80\n",
      "6435/6435 [==============================] - 0s 38us/step - loss: 1.4087 - accuracy: 0.3677 - val_loss: 1.4180 - val_accuracy: 0.3687\n",
      "Epoch 58/80\n",
      "6435/6435 [==============================] - 0s 42us/step - loss: 1.3946 - accuracy: 0.3694 - val_loss: 1.4014 - val_accuracy: 0.3631\n",
      "Epoch 59/80\n",
      "6435/6435 [==============================] - 0s 41us/step - loss: 1.3864 - accuracy: 0.3644 - val_loss: 1.3945 - val_accuracy: 0.3869\n",
      "Epoch 60/80\n",
      "6435/6435 [==============================] - 0s 38us/step - loss: 1.3783 - accuracy: 0.3809 - val_loss: 1.3727 - val_accuracy: 0.3743\n",
      "Epoch 61/80\n",
      "6435/6435 [==============================] - 0s 40us/step - loss: 1.3613 - accuracy: 0.3790 - val_loss: 1.3673 - val_accuracy: 0.3953\n",
      "Epoch 62/80\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6435/6435 [==============================] - 0s 37us/step - loss: 1.3456 - accuracy: 0.3935 - val_loss: 1.3591 - val_accuracy: 0.3827\n",
      "Epoch 63/80\n",
      "6435/6435 [==============================] - 0s 40us/step - loss: 1.3342 - accuracy: 0.3826 - val_loss: 1.3506 - val_accuracy: 0.3757\n",
      "Epoch 64/80\n",
      "6435/6435 [==============================] - 0s 39us/step - loss: 1.3176 - accuracy: 0.3960 - val_loss: 1.3457 - val_accuracy: 0.3785\n",
      "Epoch 65/80\n",
      "6435/6435 [==============================] - 0s 38us/step - loss: 1.3162 - accuracy: 0.3891 - val_loss: 1.3302 - val_accuracy: 0.3771\n",
      "Epoch 66/80\n",
      "6435/6435 [==============================] - 0s 40us/step - loss: 1.3039 - accuracy: 0.3944 - val_loss: 1.3493 - val_accuracy: 0.3953\n",
      "Epoch 67/80\n",
      "6435/6435 [==============================] - 0s 38us/step - loss: 1.3026 - accuracy: 0.3882 - val_loss: 1.3139 - val_accuracy: 0.3687\n",
      "Epoch 68/80\n",
      "6435/6435 [==============================] - 0s 40us/step - loss: 1.2904 - accuracy: 0.3943 - val_loss: 1.3135 - val_accuracy: 0.3939\n",
      "Epoch 69/80\n",
      "6435/6435 [==============================] - 0s 40us/step - loss: 1.2923 - accuracy: 0.3997 - val_loss: 1.3083 - val_accuracy: 0.3966\n",
      "Epoch 70/80\n",
      "6435/6435 [==============================] - 0s 39us/step - loss: 1.2855 - accuracy: 0.3936 - val_loss: 1.3119 - val_accuracy: 0.3701\n",
      "Epoch 71/80\n",
      "6435/6435 [==============================] - 0s 39us/step - loss: 1.2834 - accuracy: 0.4003 - val_loss: 1.3094 - val_accuracy: 0.3939\n",
      "Epoch 72/80\n",
      "6435/6435 [==============================] - 0s 39us/step - loss: 1.2765 - accuracy: 0.4028 - val_loss: 1.3011 - val_accuracy: 0.3827\n",
      "Epoch 73/80\n",
      "6435/6435 [==============================] - 0s 41us/step - loss: 1.2772 - accuracy: 0.4034 - val_loss: 1.3095 - val_accuracy: 0.3980\n",
      "Epoch 74/80\n",
      "6435/6435 [==============================] - 0s 39us/step - loss: 1.2734 - accuracy: 0.4003 - val_loss: 1.2933 - val_accuracy: 0.3994\n",
      "Epoch 75/80\n",
      "6435/6435 [==============================] - 0s 41us/step - loss: 1.2725 - accuracy: 0.3960 - val_loss: 1.2955 - val_accuracy: 0.3953\n",
      "Epoch 76/80\n",
      "6435/6435 [==============================] - 0s 41us/step - loss: 1.2675 - accuracy: 0.4062 - val_loss: 1.3021 - val_accuracy: 0.3953\n",
      "Epoch 77/80\n",
      "6435/6435 [==============================] - 0s 42us/step - loss: 1.2689 - accuracy: 0.4068 - val_loss: 1.2962 - val_accuracy: 0.3883\n",
      "Epoch 78/80\n",
      "6435/6435 [==============================] - 0s 40us/step - loss: 1.2659 - accuracy: 0.4003 - val_loss: 1.2945 - val_accuracy: 0.4022\n",
      "Epoch 79/80\n",
      "6435/6435 [==============================] - 0s 43us/step - loss: 1.2646 - accuracy: 0.3991 - val_loss: 1.3196 - val_accuracy: 0.3883\n",
      "Epoch 80/80\n",
      "6435/6435 [==============================] - 0s 42us/step - loss: 1.2597 - accuracy: 0.3953 - val_loss: 1.2974 - val_accuracy: 0.4008\n",
      "[[1.51470259e-01 1.03029542e-01 6.27041127e-16 ... 2.18839958e-01\n",
      "  2.57321209e-01 2.58947194e-01]\n",
      " [3.82840425e-01 4.58749570e-02 2.86341737e-24 ... 2.46887957e-03\n",
      "  2.96680797e-02 3.51691060e-02]\n",
      " [2.13041350e-01 1.88104376e-01 6.08586051e-20 ... 4.07700464e-02\n",
      "  2.72871792e-01 2.81530172e-01]\n",
      " ...\n",
      " [2.36625850e-01 2.31074005e-01 2.38481482e-21 ... 4.67417901e-03\n",
      "  2.59109050e-01 2.64453351e-01]\n",
      " [1.11973807e-01 9.22053382e-02 1.03237316e-14 ... 1.12446427e-01\n",
      "  3.20690632e-01 3.37252200e-01]\n",
      " [1.30187988e-01 1.06819876e-01 1.84641176e-15 ... 1.20425113e-01\n",
      "  3.09879571e-01 3.17118943e-01]]\n",
      "[13  0 13 ... 13 13 13]\n",
      "<class 'numpy.ndarray'>\n",
      "One CNN, r:  0\n",
      "Computing Time:  0:03:53.465255\n",
      "n, p1, p2 6 0 6\n",
      "Model: \"sequential_1\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv1d_1 (Conv1D)            (None, 3, 6)              12        \n",
      "_________________________________________________________________\n",
      "average_pooling1d_1 (Average (None, 1, 6)              0         \n",
      "_________________________________________________________________\n",
      "conv1d_2 (Conv1D)            (None, 1, 16)             112       \n",
      "_________________________________________________________________\n",
      "average_pooling1d_2 (Average (None, 1, 16)             0         \n",
      "_________________________________________________________________\n",
      "conv1d_3 (Conv1D)            (None, 1, 120)            2040      \n",
      "_________________________________________________________________\n",
      "flatten_1 (Flatten)          (None, 120)               0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 84)                10164     \n",
      "_________________________________________________________________\n",
      "preds (Dense)                (None, 14)                1190      \n",
      "=================================================================\n",
      "Total params: 13,518\n",
      "Trainable params: 13,518\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Train on 6435 samples, validate on 716 samples\n",
      "Epoch 1/80\n",
      "6435/6435 [==============================] - 1s 80us/step - loss: 2.6092 - accuracy: 0.1540 - val_loss: 2.5402 - val_accuracy: 0.1802\n",
      "Epoch 2/80\n",
      "6435/6435 [==============================] - 0s 47us/step - loss: 2.3650 - accuracy: 0.1958 - val_loss: 2.1703 - val_accuracy: 0.2332\n",
      "Epoch 3/80\n",
      "6435/6435 [==============================] - 0s 41us/step - loss: 2.0368 - accuracy: 0.2547 - val_loss: 1.9542 - val_accuracy: 0.2933\n",
      "Epoch 4/80\n",
      "6435/6435 [==============================] - 0s 42us/step - loss: 1.8826 - accuracy: 0.2864 - val_loss: 1.8521 - val_accuracy: 0.3087\n",
      "Epoch 5/80\n",
      "6435/6435 [==============================] - 0s 38us/step - loss: 1.7934 - accuracy: 0.2982 - val_loss: 1.7719 - val_accuracy: 0.3282\n",
      "Epoch 6/80\n",
      "6435/6435 [==============================] - 0s 41us/step - loss: 1.7179 - accuracy: 0.3004 - val_loss: 1.6934 - val_accuracy: 0.3254\n",
      "Epoch 7/80\n",
      "6435/6435 [==============================] - 0s 38us/step - loss: 1.6547 - accuracy: 0.3063 - val_loss: 1.6561 - val_accuracy: 0.3184\n",
      "Epoch 8/80\n",
      "6435/6435 [==============================] - 0s 38us/step - loss: 1.6078 - accuracy: 0.3162 - val_loss: 1.6117 - val_accuracy: 0.3352\n",
      "Epoch 9/80\n",
      "6435/6435 [==============================] - 0s 42us/step - loss: 1.5649 - accuracy: 0.3253 - val_loss: 1.5509 - val_accuracy: 0.3268\n",
      "Epoch 10/80\n",
      "6435/6435 [==============================] - 0s 38us/step - loss: 1.5374 - accuracy: 0.3183 - val_loss: 1.5270 - val_accuracy: 0.3226\n",
      "Epoch 11/80\n",
      "6435/6435 [==============================] - 0s 37us/step - loss: 1.5227 - accuracy: 0.3245 - val_loss: 1.5132 - val_accuracy: 0.2989\n",
      "Epoch 12/80\n",
      "6435/6435 [==============================] - 0s 43us/step - loss: 1.5037 - accuracy: 0.3218 - val_loss: 1.4859 - val_accuracy: 0.3422\n",
      "Epoch 13/80\n",
      "6435/6435 [==============================] - 0s 43us/step - loss: 1.5003 - accuracy: 0.3161 - val_loss: 1.4810 - val_accuracy: 0.3324\n",
      "Epoch 14/80\n",
      "6435/6435 [==============================] - 0s 35us/step - loss: 1.4855 - accuracy: 0.3214 - val_loss: 1.4773 - val_accuracy: 0.3589\n",
      "Epoch 15/80\n",
      "6435/6435 [==============================] - 0s 39us/step - loss: 1.4772 - accuracy: 0.3285 - val_loss: 1.4718 - val_accuracy: 0.3408\n",
      "Epoch 16/80\n",
      "6435/6435 [==============================] - 0s 36us/step - loss: 1.4774 - accuracy: 0.3218 - val_loss: 1.4550 - val_accuracy: 0.3394\n",
      "Epoch 17/80\n",
      "6435/6435 [==============================] - 0s 39us/step - loss: 1.4720 - accuracy: 0.3212 - val_loss: 1.4514 - val_accuracy: 0.3282\n",
      "Epoch 18/80\n",
      "6435/6435 [==============================] - 0s 40us/step - loss: 1.4657 - accuracy: 0.3302 - val_loss: 1.4828 - val_accuracy: 0.3296\n",
      "Epoch 19/80\n",
      "6435/6435 [==============================] - 0s 40us/step - loss: 1.4763 - accuracy: 0.3260 - val_loss: 1.4557 - val_accuracy: 0.3338\n",
      "Epoch 20/80\n",
      "6435/6435 [==============================] - 0s 40us/step - loss: 1.4599 - accuracy: 0.3217 - val_loss: 1.4443 - val_accuracy: 0.3561\n",
      "Epoch 21/80\n",
      "6435/6435 [==============================] - 0s 40us/step - loss: 1.4554 - accuracy: 0.3254 - val_loss: 1.4405 - val_accuracy: 0.3394\n",
      "Epoch 22/80\n",
      "6435/6435 [==============================] - 0s 39us/step - loss: 1.4588 - accuracy: 0.3229 - val_loss: 1.4550 - val_accuracy: 0.3296\n",
      "Epoch 23/80\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6435/6435 [==============================] - 0s 39us/step - loss: 1.4552 - accuracy: 0.3277 - val_loss: 1.4499 - val_accuracy: 0.3324\n",
      "Epoch 24/80\n",
      "6435/6435 [==============================] - 0s 40us/step - loss: 1.4550 - accuracy: 0.3260 - val_loss: 1.4417 - val_accuracy: 0.3128\n",
      "Epoch 25/80\n",
      "6435/6435 [==============================] - 0s 38us/step - loss: 1.4581 - accuracy: 0.3211 - val_loss: 1.4611 - val_accuracy: 0.3226\n",
      "Epoch 26/80\n",
      "6435/6435 [==============================] - 0s 40us/step - loss: 1.4505 - accuracy: 0.3262 - val_loss: 1.4350 - val_accuracy: 0.3282\n",
      "Epoch 27/80\n",
      "6435/6435 [==============================] - 0s 41us/step - loss: 1.4442 - accuracy: 0.3321 - val_loss: 1.4281 - val_accuracy: 0.3296\n",
      "Epoch 28/80\n",
      "6435/6435 [==============================] - 0s 38us/step - loss: 1.4403 - accuracy: 0.3340 - val_loss: 1.4530 - val_accuracy: 0.3338\n",
      "Epoch 29/80\n",
      "6435/6435 [==============================] - 0s 41us/step - loss: 1.4425 - accuracy: 0.3319 - val_loss: 1.4511 - val_accuracy: 0.3366\n",
      "Epoch 30/80\n",
      "6435/6435 [==============================] - 0s 41us/step - loss: 1.4478 - accuracy: 0.3383 - val_loss: 1.4603 - val_accuracy: 0.3156\n",
      "Epoch 31/80\n",
      "6435/6435 [==============================] - 0s 32us/step - loss: 1.4415 - accuracy: 0.3290 - val_loss: 1.4281 - val_accuracy: 0.3380\n",
      "Epoch 32/80\n",
      "6435/6435 [==============================] - 0s 39us/step - loss: 1.4382 - accuracy: 0.3333 - val_loss: 1.4349 - val_accuracy: 0.3394\n",
      "Epoch 33/80\n",
      "6435/6435 [==============================] - 0s 39us/step - loss: 1.4408 - accuracy: 0.3341 - val_loss: 1.4315 - val_accuracy: 0.3380\n",
      "Epoch 34/80\n",
      "6435/6435 [==============================] - 0s 43us/step - loss: 1.4363 - accuracy: 0.3308 - val_loss: 1.4217 - val_accuracy: 0.3366\n",
      "Epoch 35/80\n",
      "6435/6435 [==============================] - 0s 41us/step - loss: 1.4348 - accuracy: 0.3375 - val_loss: 1.4348 - val_accuracy: 0.3366\n",
      "Epoch 36/80\n",
      "6435/6435 [==============================] - 0s 41us/step - loss: 1.4408 - accuracy: 0.3273 - val_loss: 1.4317 - val_accuracy: 0.3240\n",
      "Epoch 37/80\n",
      "6435/6435 [==============================] - 0s 39us/step - loss: 1.4331 - accuracy: 0.3329 - val_loss: 1.4166 - val_accuracy: 0.3492\n",
      "Epoch 38/80\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-9-8b27f107b0f8>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     63\u001b[0m                 \u001b[0mtest_array\u001b[0m  \u001b[1;33m=\u001b[0m \u001b[0mtest_array\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     64\u001b[0m                 \u001b[0mtrue_answer\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtest_label_answer\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 65\u001b[1;33m                 \u001b[0mNum_Classes\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mNUM_CLASSES\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     66\u001b[0m                 )\n\u001b[0;32m     67\u001b[0m         \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtype\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmodel_history\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\Yanbin\\2024\\Python_codes\\20240314_Toy_embedded_MNIST\\phase3\\codes\\CNN_Modules_1D.py\u001b[0m in \u001b[0;36mME_CNN\u001b[1;34m(x_train, train_label, test_array, true_answer, Num_Classes)\u001b[0m\n\u001b[0;32m    155\u001b[0m               \u001b[0mshuffle\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    156\u001b[0m               \u001b[0mvalidation_split\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m0.10\u001b[0m\u001b[1;33m,\u001b[0m             \u001b[1;31m#Get 0.1 as validatin data. Validation data is never shuffled.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 157\u001b[1;33m               callbacks = [earlystop])\n\u001b[0m\u001b[0;32m    158\u001b[0m               \u001b[1;31m#validation_data=(test_array, true_answer))\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    159\u001b[0m               \u001b[1;31m#callbacks=[tensorboard_callback]) # 1112 TensorBoard\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\envs\\myenv3\\lib\\site-packages\\keras\\engine\\training.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_freq, max_queue_size, workers, use_multiprocessing, **kwargs)\u001b[0m\n\u001b[0;32m   1237\u001b[0m                                         \u001b[0msteps_per_epoch\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0msteps_per_epoch\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1238\u001b[0m                                         \u001b[0mvalidation_steps\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mvalidation_steps\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1239\u001b[1;33m                                         validation_freq=validation_freq)\n\u001b[0m\u001b[0;32m   1240\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1241\u001b[0m     def evaluate(self,\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\envs\\myenv3\\lib\\site-packages\\keras\\engine\\training_arrays.py\u001b[0m in \u001b[0;36mfit_loop\u001b[1;34m(model, fit_function, fit_inputs, out_labels, batch_size, epochs, verbose, callbacks, val_function, val_inputs, shuffle, initial_epoch, steps_per_epoch, validation_steps, validation_freq)\u001b[0m\n\u001b[0;32m    194\u001b[0m                     \u001b[0mins_batch\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mins_batch\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtoarray\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    195\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 196\u001b[1;33m                 \u001b[0mouts\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mfit_function\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mins_batch\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    197\u001b[0m                 \u001b[0mouts\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mto_list\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mouts\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    198\u001b[0m                 \u001b[1;32mfor\u001b[0m \u001b[0ml\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mo\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mzip\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mout_labels\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mouts\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\envs\\myenv3\\lib\\site-packages\\tensorflow_core\\python\\keras\\backend.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, inputs)\u001b[0m\n\u001b[0;32m   3725\u001b[0m         \u001b[0mvalue\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmath_ops\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcast\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mvalue\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtensor\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdtype\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3726\u001b[0m       \u001b[0mconverted_inputs\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mvalue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 3727\u001b[1;33m     \u001b[0moutputs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_graph_fn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0mconverted_inputs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   3728\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3729\u001b[0m     \u001b[1;31m# EagerTensor.numpy() will often make a copy to ensure memory safety.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\envs\\myenv3\\lib\\site-packages\\tensorflow_core\\python\\eager\\function.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1549\u001b[0m       \u001b[0mTypeError\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mFor\u001b[0m \u001b[0minvalid\u001b[0m \u001b[0mpositional\u001b[0m\u001b[1;33m/\u001b[0m\u001b[0mkeyword\u001b[0m \u001b[0margument\u001b[0m \u001b[0mcombinations\u001b[0m\u001b[1;33m.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1550\u001b[0m     \"\"\"\n\u001b[1;32m-> 1551\u001b[1;33m     \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_call_impl\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1552\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1553\u001b[0m   \u001b[1;32mdef\u001b[0m \u001b[0m_call_impl\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcancellation_manager\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\envs\\myenv3\\lib\\site-packages\\tensorflow_core\\python\\eager\\function.py\u001b[0m in \u001b[0;36m_call_impl\u001b[1;34m(self, args, kwargs, cancellation_manager)\u001b[0m\n\u001b[0;32m   1589\u001b[0m       raise TypeError(\"Keyword arguments {} unknown. Expected {}.\".format(\n\u001b[0;32m   1590\u001b[0m           list(kwargs.keys()), list(self._arg_keywords)))\n\u001b[1;32m-> 1591\u001b[1;33m     \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_call_flat\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcaptured_inputs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcancellation_manager\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1592\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1593\u001b[0m   \u001b[1;32mdef\u001b[0m \u001b[0m_filtered_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\envs\\myenv3\\lib\\site-packages\\tensorflow_core\\python\\eager\\function.py\u001b[0m in \u001b[0;36m_call_flat\u001b[1;34m(self, args, captured_inputs, cancellation_manager)\u001b[0m\n\u001b[0;32m   1690\u001b[0m       \u001b[1;31m# No tape is watching; skip to running the function.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1691\u001b[0m       return self._build_call_outputs(self._inference_function.call(\n\u001b[1;32m-> 1692\u001b[1;33m           ctx, args, cancellation_manager=cancellation_manager))\n\u001b[0m\u001b[0;32m   1693\u001b[0m     forward_backward = self._select_forward_and_backward_functions(\n\u001b[0;32m   1694\u001b[0m         \u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\envs\\myenv3\\lib\\site-packages\\tensorflow_core\\python\\eager\\function.py\u001b[0m in \u001b[0;36mcall\u001b[1;34m(self, ctx, args, cancellation_manager)\u001b[0m\n\u001b[0;32m    543\u001b[0m               \u001b[0minputs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    544\u001b[0m               \u001b[0mattrs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"executor_type\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mexecutor_type\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m\"config_proto\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mconfig\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 545\u001b[1;33m               ctx=ctx)\n\u001b[0m\u001b[0;32m    546\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    547\u001b[0m           outputs = execute.execute_with_cancellation(\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\envs\\myenv3\\lib\\site-packages\\tensorflow_core\\python\\eager\\execute.py\u001b[0m in \u001b[0;36mquick_execute\u001b[1;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[0;32m     59\u001b[0m     tensors = pywrap_tensorflow.TFE_Py_Execute(ctx._handle, device_name,\n\u001b[0;32m     60\u001b[0m                                                \u001b[0mop_name\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mattrs\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 61\u001b[1;33m                                                num_outputs)\n\u001b[0m\u001b[0;32m     62\u001b[0m   \u001b[1;32mexcept\u001b[0m \u001b[0mcore\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_NotOkStatusException\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     63\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mname\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "#====CNN combination c(20,2)======\n",
    "comb=[]\n",
    "for subset in itertools.combinations(range(NUM_region), 2):\n",
    "    comb.append(subset)\n",
    "NUM_comb=len(comb)\n",
    "display(NUM_comb)            \n",
    "\n",
    "for n in range(NUM_comb+1):\n",
    "    region=region_image.copy()\n",
    "    region=list(region)\n",
    "    selected_region = list(range(NUM_region))\n",
    "\n",
    "    if (n > 0):\n",
    "        p1=comb[n-1][0]\n",
    "        p2=comb[n-1][1]\n",
    "        region[p1]=region[p1]+region[p2]\n",
    "        region.pop(p2)\n",
    "        selected_region.pop(-1)\n",
    "    else:\n",
    "        p1=0\n",
    "        p2=0\n",
    "\n",
    "    print(\"n, p1, p2\", n, p1, p2)\n",
    "\n",
    "\n",
    "    # ===== one CNN =============\n",
    "    NUM_CLASSES = len(selected_region)\n",
    "\n",
    "    Input_img     = []\n",
    "    Input_img_len = []\n",
    "    for c,sel in enumerate(selected_region, start=0):\n",
    "        Input_img = Input_img + list(region[sel])\n",
    "        Input_img_len.append(len(region[sel]))\n",
    "\n",
    "    #1213\n",
    "    # fill up training array\n",
    "    W           = np.shape(test_array[0])[0]\n",
    "    train_array = np.zeros((len(Input_img), W), dtype=float)\n",
    "    for i in range (len(Input_img)):\n",
    "        train_array[i] = test_array[Input_img[i]].reshape(W)\n",
    "\n",
    "    train_array = np.expand_dims(train_array, axis = -1)\n",
    "\n",
    "\n",
    "    # fill up the training label to each training image\n",
    "    current_train_label = np.zeros(len(train_array), dtype=int)\n",
    "    accum_base=0\n",
    "    for label in range(1,NUM_CLASSES):\n",
    "        pre_cursor = Input_img_len[label-1]\n",
    "        accum_base = accum_base + pre_cursor\n",
    "        current_train_label[accum_base:] = label\n",
    "\n",
    "    # CNN\n",
    "    #===============================================\n",
    "    one_predicted_results  = np.zeros((TRIALS, len(test_label_answer)), dtype=int)\n",
    "    one_predict_percentage = np.zeros((TRIALS, len(test_label_answer), NUM_CLASSES), dtype=float)    \n",
    "    model_history = np.zeros(TRIALS, dtype=list)\n",
    "\n",
    "    for r in range(TRIALS):\n",
    "        one_predicted_results[r], one_predict_percentage[r], model_history[r] = ME_CNN(\n",
    "                x_train     = train_array,\n",
    "                train_label = current_train_label,\n",
    "                test_array  = test_array,\n",
    "                true_answer = test_label_answer,\n",
    "                Num_Classes = NUM_CLASSES\n",
    "                )\n",
    "        print(type(model_history))\n",
    "\n",
    "\n",
    "        # ===== delete CNN tensors =====\n",
    "        from keras import backend as K\n",
    "        K.clear_session()\n",
    "        import gc\n",
    "        gc.collect()\n",
    "\n",
    "        print(\"One CNN, r: \",r)\n",
    "        ROUND_duration = time.time() - ROUND_start\n",
    "        print(\"Computing Time: \", str(datetime.timedelta(seconds=ROUND_duration)))\n",
    "\n",
    "    # === save to file ===\n",
    "    savefile_path = './' + str(timestr) + '(classes=' + str(NUM_CLASSES)+')_n' + str(n) + '_R' + str(p1) + '+R'+ str(p2) +'.pickle'\n",
    "    with open(savefile_path, 'wb') as f:\n",
    "        pickle.dump([Input_img, Input_img_len, one_predicted_results, one_predict_percentage, model_history], f)\n",
    "\n",
    "\n",
    "\n",
    "# ==== CNN Removal =====\n",
    "for n in range(NUM_region):\n",
    "    region=region_image.copy()   #reset\n",
    "    selected_region = list(range(NUM_region))\n",
    "    selected_region.pop(n)\n",
    "\n",
    "    print(\"n=\", n)\n",
    "\n",
    "\n",
    "    # ===== one CNN =============\n",
    "    NUM_CLASSES = len(selected_region)\n",
    "\n",
    "    # input image and label\n",
    "    Input_img     = []\n",
    "    Input_img_len = []\n",
    "    for c,sel in enumerate(selected_region, start=0):\n",
    "        Input_img = Input_img + list(region[sel])\n",
    "        Input_img_len.append(len(region[sel]))\n",
    "\n",
    "    #1213\n",
    "    # fill up training array\n",
    "    W           = np.shape(test_array[0])[0]\n",
    "    train_array = np.zeros((len(Input_img), W), dtype=float)\n",
    "    for i in range (len(Input_img)):\n",
    "        train_array[i] = test_array[Input_img[i]].reshape(W)\n",
    "\n",
    "    train_array = np.expand_dims(train_array, axis = -1)\n",
    "\n",
    "\n",
    "    # fill up the training label to each training image\n",
    "    current_train_label = np.zeros(len(train_array), dtype=int)\n",
    "    accum_base=0\n",
    "    for label in range(1,NUM_CLASSES):\n",
    "        pre_cursor = Input_img_len[label-1]\n",
    "        accum_base = accum_base + pre_cursor\n",
    "        current_train_label[accum_base:] = label\n",
    "\n",
    "    # CNN\n",
    "    #===============================================\n",
    "    one_predicted_results  = np.zeros((TRIALS, len(test_label_answer)), dtype=int)\n",
    "    one_predict_percentage = np.zeros((TRIALS, len(test_label_answer), NUM_CLASSES), dtype=float)    \n",
    "    model_history = np.zeros(TRIALS, dtype=list)\n",
    "\n",
    "    for r in range(TRIALS):\n",
    "        one_predicted_results[r], one_predict_percentage[r], model_history[r] = ME_CNN(\n",
    "                x_train     = train_array,\n",
    "                train_label = current_train_label,\n",
    "                test_array  = test_array,\n",
    "                true_answer = test_label_answer,\n",
    "                Num_Classes = NUM_CLASSES\n",
    "                )\n",
    "        print(type(model_history))\n",
    "\n",
    "\n",
    "        # ===== delete CNN tensors =====\n",
    "        from keras import backend as K\n",
    "        K.clear_session()\n",
    "        import gc\n",
    "        gc.collect()\n",
    "\n",
    "        print(\"One CNN, r: \",r)\n",
    "        ROUND_duration = time.time() - ROUND_start\n",
    "        print(\"Computing Time: \", str(datetime.timedelta(seconds=ROUND_duration)))\n",
    "\n",
    "    # === save to file ===\n",
    "    savefile_path = './' + str(timestr) + '(classes=' + str(NUM_CLASSES)+')_Remove' + str(n) +'.pickle' \n",
    "    with open(savefile_path, 'wb') as f:\n",
    "        pickle.dump([Input_img, Input_img_len, one_predicted_results, one_predict_percentage, model_history], f)\n",
    "  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ====shift label=====\n",
    "#=== combination =====\n",
    "comb=[]\n",
    "for oneset in itertools.combinations(range(NUM_region), 2):\n",
    "    comb.append(oneset)\n",
    "NUM_comb=len(comb)\n",
    "\n",
    "Merged_result=[]\n",
    "Merged_prob=[]\n",
    "Merged_prob_label=[]\n",
    "\n",
    "for n in range(NUM_comb):\n",
    "    label = list(range(NUM_region))\n",
    "    p1=comb[n][0]\n",
    "    p2=comb[n][1]\n",
    "\n",
    "    with open('./' + timestr + '(classes=' + str(NUM_region-1) + ')_n'+str(n+1)+'_R'+str(p1)+'+R'+str(p2)+'.pickle', 'rb') as f:\n",
    "        Input_img, Input_img_len, one_predicted_results, one_predict_percentage, model_history = pickle.load(f)\n",
    "    label_B = one_predicted_results[0].copy()\n",
    "    label_B_prob = one_predict_percentage[0].copy()\n",
    "\n",
    "    #(1)shift label index\n",
    "    for p in reversed(range(p2,NUM_region-1)):\n",
    "        addr=np.where(label_B==p)[0]\n",
    "        label_B[addr]+=1\n",
    "    Merged_result.append(label_B)\n",
    "\n",
    "    #(2)\n",
    "    Merged_prob.append(label_B_prob)\n",
    "\n",
    "    #(3)\n",
    "    label.pop(p2)\n",
    "    Merged_prob_label.append(label)\n",
    "\n",
    "print(np.shape(Merged_result), np.shape(Merged_prob), np.shape(Merged_prob_label))\n",
    "\n",
    "# save pickle\n",
    "with open('./' + timestr + 'results_of_combination.pickle', 'wb') as f:\n",
    "    pickle.dump([comb, Merged_result, Merged_prob, Merged_prob_label], f)\n",
    "\n",
    "# save mat\n",
    "from scipy.io import savemat\n",
    "if (np.shape(Merged_prob)[0]<=300):\n",
    "    savemat('./' + timestr + 'results_of_combination.mat', {'combination_pairs':comb, 'result_for_merge':Merged_result, 'prob_for_merge':Merged_prob,'prob_label_for_merge': Merged_prob_label})\n",
    "    print(\"normal size = \", np.shape(Merged_prob))\n",
    "else:\n",
    "    savemat('./' + timestr + 'results_of_combination.mat', {'combination_pairs':comb, 'result_for_merge':Merged_result, 'prob_label_for_merge': Merged_prob_label})\n",
    "    savemat('./' + timestr + 'results_of_combination_prob1.mat', {'prob_for_merge1':Merged_prob[:200]})\n",
    "    savemat('./' + timestr + 'results_of_combination_prob2.mat', {'prob_for_merge2':Merged_prob[200:400]})\n",
    "    savemat('./' + timestr + 'results_of_combination_prob3.mat', {'prob_for_merge3':Merged_prob[400:]})\n",
    "    print(\"large size = \", np.shape(Merged_prob))\n",
    "\n",
    "    \n",
    "    \n",
    "    \n",
    "#======== removal ===========\n",
    "Removal_result=[]\n",
    "Removal_prob=[]\n",
    "Removal_prob_label=[]\n",
    "\n",
    "for n in range(NUM_region):\n",
    "    label = list(range(NUM_region))    \n",
    "    #reset\n",
    "    with open('./' + timestr + '(classes=' + str(NUM_region-1) + ')_Remove' + str(n) + '.pickle', 'rb') as f:\n",
    "        Input_img, Input_img_len, one_predicted_results, one_predict_percentage, model_history = pickle.load(f)\n",
    "    label_B = one_predicted_results[0].copy()\n",
    "    label_B_prob = one_predict_percentage[0].copy()\n",
    "\n",
    "    for p in reversed(range(n,NUM_region-1)):\n",
    "        addr=np.where(label_B==p)[0]\n",
    "        label_B[addr]+=1\n",
    "    Removal_result.append(label_B)\n",
    "\n",
    "    #(2)\n",
    "    Removal_prob.append(label_B_prob)\n",
    "\n",
    "    #(3)\n",
    "    label.pop(n)\n",
    "    Removal_prob_label.append(label)\n",
    "\n",
    "print(np.shape(Removal_result), np.shape(Removal_prob), np.shape(Removal_prob_label))\n",
    "\n",
    "# save pickle\n",
    "with open('./' + timestr + 'results_of_removal.pickle', 'wb') as f:\n",
    "    pickle.dump([Removal_result, Removal_prob, Removal_prob_label], f)\n",
    "    \n",
    "# save mat\n",
    "from scipy.io import savemat\n",
    "savemat('./' + timestr + 'results_of_removal.mat', {'result_for_removal':Removal_result,'prob_for_removal':Removal_prob, 'prob_label_for_removal':Removal_prob_label})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"done\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
