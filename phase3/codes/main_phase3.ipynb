{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***\n",
    "### <span style='color:green'> ME Algorithm  &emsp;&emsp; Jun, 2024 </span>\n",
    "### <span style='color:Blue'> Phase 3 </span>\n",
    "### <p> Yan-Bin Chen (陳彥賓) &emsp; yanbin@ntu.edu.tw </p>\n",
    "### <p> Master Program in Statistics, CGE, National Taiwan University (NTU), Taipei, Taiwan.</p>\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Input"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "import numpy as np\n",
    "import collections\n",
    "import pandas\n",
    "import itertools\n",
    "from itertools import chain\n",
    "import random \n",
    "import time\n",
    "import datetime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1)region: [ 26 182 169 124  29   1  57  76  53  52 183  59  24 164]\n",
      "NUM_region: 14\n",
      "(3)original spec table:\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>X1</th>\n",
       "      <th>X2</th>\n",
       "      <th>X3</th>\n",
       "      <th>Class</th>\n",
       "      <th>Label</th>\n",
       "      <th>Spec200</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1.230895</td>\n",
       "      <td>-11.513212</td>\n",
       "      <td>18.781408</td>\n",
       "      <td>Cherry</td>\n",
       "      <td>2</td>\n",
       "      <td>177</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>3.190353</td>\n",
       "      <td>-14.243707</td>\n",
       "      <td>14.359673</td>\n",
       "      <td>Cherry</td>\n",
       "      <td>2</td>\n",
       "      <td>177</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1.832576</td>\n",
       "      <td>-12.109021</td>\n",
       "      <td>15.785449</td>\n",
       "      <td>Cherry</td>\n",
       "      <td>2</td>\n",
       "      <td>177</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1.880559</td>\n",
       "      <td>-12.113366</td>\n",
       "      <td>15.720321</td>\n",
       "      <td>Cherry</td>\n",
       "      <td>2</td>\n",
       "      <td>177</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5.759654</td>\n",
       "      <td>-13.821998</td>\n",
       "      <td>15.943708</td>\n",
       "      <td>Cherry</td>\n",
       "      <td>2</td>\n",
       "      <td>177</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         X1         X2         X3   Class  Label  Spec200\n",
       "0  1.230895 -11.513212  18.781408  Cherry      2      177\n",
       "1  3.190353 -14.243707  14.359673  Cherry      2      177\n",
       "2  1.832576 -12.109021  15.785449  Cherry      2      177\n",
       "3  1.880559 -12.113366  15.720321  Cherry      2      177\n",
       "4  5.759654 -13.821998  15.943708  Cherry      2      177"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "all_region_index = [177 177 177 ...  53  29 144]\n",
      "len(all_region_index) = 13076\n",
      "(4)original labels\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0      147\n",
       "2      434\n",
       "3     4375\n",
       "4     2708\n",
       "6     1410\n",
       "7     1172\n",
       "8      746\n",
       "12     826\n",
       "13    1258\n",
       "Name: Label, dtype: int64"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "original labels and sorted:  [ 0  2  3  4  6  7  8 12 13]\n",
      "reset labels:\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0     147\n",
       "1     434\n",
       "2    4375\n",
       "3    2708\n",
       "4    1410\n",
       "5    1172\n",
       "6     746\n",
       "7     826\n",
       "8    1258\n",
       "Name: Label, dtype: int64"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test_label_answer and test_array [1 1 1 ... 8 8 8] \n",
      " [[-1.7  -0.2  -1.07 ...  0.46  3.43  0.45]\n",
      " [-1.58 -2.04 -1.33 ...  0.03  1.79  0.56]\n",
      " [-1.55 -0.9  -1.15 ...  0.51  2.4   1.41]\n",
      " ...\n",
      " [ 1.39 -0.22 -1.5  ...  1.48  1.93  0.72]\n",
      " [ 0.34 -1.75 -3.64 ... -0.76  3.19  1.24]\n",
      " [ 0.79 -0.65 -1.39 ... -1.37  4.82 -0.03]]\n"
     ]
    }
   ],
   "source": [
    "# Input\n",
    "PATH1='../data/seedinds.txt'\n",
    "PATH2='../data/bilabels.txt'\n",
    "PATH3='../data/seedinds_neighborregions.txt'\n",
    "PATH4='../data/ResNet18_PlantDisease_45K_Spec200_sampling.csv'\n",
    "PATH5='../data/ResNet18_PlantDisease_45K_Values_sampling.csv'\n",
    "\n",
    "\n",
    "#===  parameters ========================================================\n",
    "TRIALS    = 1\n",
    "timestr   = ''\n",
    "REG_COLUMN = \"Spec200\"\n",
    "RAW_2D_DATA = False\n",
    "\n",
    "if RAW_2D_DATA: # 2D\n",
    "    from CNN_Modules import ME_CNN\n",
    "else: # 1D\n",
    "    from CNN_Modules_1D import ME_CNN\n",
    "\n",
    "\n",
    "# (1)PATH1\n",
    "df1 = pandas.read_csv(PATH1, header=None, delimiter = \"\\t\")\n",
    "region = df1.to_numpy().T[0]\n",
    "NUM_region = len(region)\n",
    "\n",
    "print('(1)region:', region)\n",
    "print('NUM_region:', NUM_region)\n",
    "\n",
    "\n",
    "# (2)PATH2\n",
    "df2 = pandas.read_csv(PATH2, header=None, delimiter = \"\\t\")\n",
    "cen = df2.to_numpy()\n",
    "\n",
    "\n",
    "# (3)PATH4. Have to be here. The following neighboring process needs this information\n",
    "df4 = pandas.read_csv(PATH4)\n",
    "print(\"(3)original spec table:\")\n",
    "display(df4.head())\n",
    "#all_region_index  = df.iloc[:,REGION_INDEX_LOC].to_numpy().astype(int)\n",
    "all_region_index  = df4[REG_COLUMN].to_numpy().astype(int)\n",
    "print(\"all_region_index =\", all_region_index)\n",
    "print(\"len(all_region_index) =\",len(all_region_index))\n",
    "\n",
    "\n",
    "# (4)PATH4 reset label\n",
    "print(\"(4)original labels\")\n",
    "display(df4['Label'].value_counts().sort_index(ascending=True))\n",
    "label=df4['Label'].sort_values().unique() # have to sort it to avoid reusing the previous keys\n",
    "print(\"original labels and sorted: \",label)\n",
    "[df4['Label'].replace(to_replace=label[i], value=i, inplace=True) for i in range(len(label))]  #reset labels\n",
    "print(\"reset labels:\")\n",
    "display(df4['Label'].value_counts().sort_index(ascending=True))\n",
    "test_label_answer = df4[\"Label\"].to_numpy()\n",
    "\n",
    "# (5)PATH5     convert the embedded data into the pickle file\n",
    "df5 = pandas.read_csv(PATH5)\n",
    "test_array = df5.to_numpy()\n",
    "\n",
    "#save\n",
    "PATH5='../data/embedded_data.pickle'   #replace original PATH 5\n",
    "with open(PATH5, 'wb') as f:\n",
    "    pickle.dump([test_array, test_label_answer], f)\n",
    "print(\"test_label_answer and test_array\",test_label_answer, \"\\n\", test_array)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Get neighbors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "neighbor amount:  70\n",
      "[[ 3  4  5  6  8]\n",
      " [ 3  4  5  6  8]\n",
      " [ 3  4  5  6  8]\n",
      " [ 3  4  5  6  8]\n",
      " [ 3  4  5  6  8]\n",
      " [11 12 14 15 17]\n",
      " [ 3  4  5  6  8]\n",
      " [ 3  4  5  6  8]\n",
      " [ 3  4  5  6  8]\n",
      " [ 3  4  5  6  8]\n",
      " [ 3  4  5  6  8]\n",
      " [ 3  4  5  6  8]\n",
      " [ 3  4  5  6  8]\n",
      " [ 3  4  5  6  8]]\n",
      "neighbor amount:  10\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[[3, 4, 5, 6, 8],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [11, 12, 14, 15, 17],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " []]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "if (PATH3):\n",
    "    df = pandas.read_csv(PATH3, delim_whitespace=' ', header=None,  index_col=0)\n",
    "    neighbors = df.to_numpy()\n",
    "    NUM_NEI=df.shape[1]\n",
    "    \n",
    "    print('neighbor amount: ',len(list(chain.from_iterable(neighbors))))\n",
    "    print(neighbors)\n",
    "\n",
    "# filter out duplicated ones\n",
    "    test_list=list(chain.from_iterable(neighbors))\n",
    "    res2=[]\n",
    "    [res2.append(n) for n, i in enumerate(test_list) if i in test_list[:n]]\n",
    "\n",
    "    res2.reverse()\n",
    "    neighbors=neighbors.tolist()\n",
    "    [neighbors[x//NUM_NEI].pop(x%NUM_NEI) for x in res2]\n",
    "    print('neighbor amount: ',len(list(chain.from_iterable(neighbors))))\n",
    "    display(neighbors)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[26, 3, 4, 5, 6, 8],\n",
       " [182],\n",
       " [169],\n",
       " [124],\n",
       " [29],\n",
       " [1, 11, 12, 14, 15, 17],\n",
       " [57],\n",
       " [76],\n",
       " [53],\n",
       " [52],\n",
       " [183],\n",
       " [59],\n",
       " [24],\n",
       " [164]]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# combine seed regions and neighbors\n",
    "if (PATH3):\n",
    "    reg_nei=[]\n",
    "    for i in range(len(neighbors)):\n",
    "        a=[region[i]]\n",
    "        b=neighbors[i]\n",
    "        if len(b):\n",
    "            c=list(np.concatenate((a,b),axis=0))\n",
    "        else:\n",
    "            c=a.copy()\n",
    "        reg_nei.append(c)\n",
    "else:\n",
    "    reg_nei=region.copy()\n",
    "\n",
    "reg_nei"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# collect images from target region and neighboring regions\n",
    "# input : region, NUM_region, cen, all_region_index, neighbors\n",
    "# output: region_image: to save image indices corresponding to seed regions.\n",
    "#         region_answer: to save answer\n",
    "\n",
    "region_image_before=[]\n",
    "region_image=[]\n",
    "region_image_pure=[]\n",
    "for i in range(NUM_region):\n",
    "    \n",
    "    \n",
    "    #(1)neighbor  nei\n",
    "    if (PATH3):\n",
    "        addr_nei=[]\n",
    "        for j in range(len(neighbors[i])):\n",
    "            addr_nei=addr_nei+list(np.where(all_region_index==neighbors[i][j])[0])\n",
    "            #check whether it has duplicates\n",
    "            if (len(addr_nei) != len(set(addr_nei))):\n",
    "                print(\"neighbor duplicate at i=\",i,\"j=\",j)\n",
    "                addr_nei=list(set(addr_nei))\n",
    "\n",
    "    #(2)original\n",
    "    addr=list(np.where(  (all_region_index==region[i])  &  (cen.T[1]==1)  )[0])\n",
    "    if (PATH3):\n",
    "        addr=addr+addr_nei\n",
    "    #check whether it has duplicates\n",
    "    if (len(addr) != len(set(addr))):\n",
    "        print(\"** original duplicate at i=\",i,\";region\",region[i],\";duplicate size\",len(addr)-len(set(addr)))\n",
    "        addr=list(set(addr))\n",
    "    region_image.append(addr)\n",
    "\n",
    "    #(3)original before centroid (this is only for check, rather than for main codes)\n",
    "    addr_before=list(np.where(all_region_index==region[i])[0])\n",
    "    if (PATH3):\n",
    "        addr_before=addr_before+addr_nei\n",
    "    #check whether it has duplicates\n",
    "    if (len(addr_before) != len(set(addr_before))):\n",
    "        print(\"** same duplicate situation\")\n",
    "        addr_before=list(set(addr_before))\n",
    "    region_image_before.append(addr_before)\n",
    "\n",
    "    #(4)pure\n",
    "    addr_pure=list(np.where(  (all_region_index==region[i])  &  (cen.T[1]==1)  )[0])\n",
    "    region_image_pure.append(addr_pure)\n",
    "\n",
    "\n",
    "with open('../data/' + timestr + 'region_for_phase5.pickle', 'wb') as f:\n",
    "    pickle.dump([region, reg_nei, region_image_pure, region_image,], f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test_array: (13076, 1000)\n",
      "training size: 3601\n"
     ]
    }
   ],
   "source": [
    "# ==== test_array ====\n",
    "with open(PATH5, 'rb') as f:\n",
    "    test_array, test_label_answer = pickle.load(f)\n",
    "print(\"test_array:\",np.shape(test_array))\n",
    "\n",
    "\n",
    "# 1213 add auto judge /255\n",
    "# 20240319\n",
    "if RAW_2D_DATA: # 2D\n",
    "    print(\"\")\n",
    "else: # 1D\n",
    "    test_array = np.expand_dims(test_array, axis = -1)\n",
    "test_array /= 255\n",
    "print(\"training size:\",len(np.array(list(chain.from_iterable(region_image)))))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# CNN original"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ==== CNN Original =====\n",
    "ROUND_start = time.time()\n",
    "\n",
    "for n in range(5):\n",
    "    region=region_image.copy()\n",
    "    region=list(region)\n",
    "    selected_region = list(range(NUM_region))\n",
    "\n",
    "    p1=0\n",
    "    p2=0\n",
    "\n",
    "    print(\"n, p1, p2\", n, p1, p2)\n",
    "\n",
    "\n",
    "    # ===== one CNN =============\n",
    "    NUM_CLASSES = len(selected_region)\n",
    "\n",
    "    # input image and label\n",
    "    Input_img     = []\n",
    "    Input_img_len = []\n",
    "    for c,sel in enumerate(selected_region, start=0):\n",
    "        Input_img = Input_img + list(region[sel])\n",
    "        Input_img_len.append(len(region[sel]))\n",
    "\n",
    "\n",
    "    # fill up training array\n",
    "        \n",
    "    # 20240319\n",
    "    if RAW_2D_DATA: # 2D\n",
    "        W           = np.shape(test_array[0])[0]\n",
    "        H           = np.shape(test_array[0])[1]\n",
    "        train_array = np.zeros((len(Input_img), W, H), dtype=float)\n",
    "        for i in range (len(Input_img)):\n",
    "            train_array[i] = test_array[Input_img[i]].reshape(W,H)\n",
    "    else: # 1D\n",
    "        W           = np.shape(test_array[0])[0]\n",
    "        train_array = np.zeros((len(Input_img), W), dtype=float)\n",
    "        for i in range (len(Input_img)):\n",
    "            train_array[i] = test_array[Input_img[i]].reshape(W)\n",
    "        \n",
    "\n",
    "\n",
    "    train_array = np.expand_dims(train_array, axis = -1)\n",
    "\n",
    "\n",
    "    # fill up the training label to each training image\n",
    "    current_train_label = np.zeros(len(train_array), dtype=int)\n",
    "    accum_base=0\n",
    "    for label in range(1,NUM_CLASSES):\n",
    "        pre_cursor = Input_img_len[label-1]\n",
    "        accum_base = accum_base + pre_cursor\n",
    "        current_train_label[accum_base:] = label\n",
    "\n",
    "    # CNN\n",
    "    #===============================================\n",
    "    one_predicted_results  = np.zeros((TRIALS, len(test_label_answer)), dtype=int)\n",
    "    one_predict_percentage = np.zeros((TRIALS, len(test_label_answer), NUM_CLASSES), dtype=float)    \n",
    "    model_history = np.zeros(TRIALS, dtype=list)\n",
    "\n",
    "    for r in range(TRIALS):\n",
    "        one_predicted_results[r], one_predict_percentage[r], model_history[r] = ME_CNN(\n",
    "                x_train     = train_array,\n",
    "                train_label = current_train_label,\n",
    "                test_array  = test_array,\n",
    "                true_answer = test_label_answer,\n",
    "                Num_Classes = NUM_CLASSES\n",
    "                )\n",
    "        print(type(model_history))\n",
    "\n",
    "\n",
    "        # ===== delete CNN tensors =====\n",
    "        from keras import backend as K\n",
    "        K.clear_session()\n",
    "        import gc\n",
    "        gc.collect()\n",
    "\n",
    "        print(\"One CNN, r: \",r)\n",
    "        ROUND_duration = time.time() - ROUND_start\n",
    "        print(\"Computing Time: \", str(datetime.timedelta(seconds=ROUND_duration)))\n",
    "\n",
    "    # === save to file ===\n",
    "    savefile_path = './' + str(timestr) + '(classes=' + str(NUM_CLASSES)+')_n0_R' + str(p1) + '+R'+ str(p2) +'_trial' + str(n)+'.pickle'  #extra_original\n",
    "    with open(savefile_path, 'wb') as f:\n",
    "        pickle.dump([Input_img, Input_img_len, one_predicted_results, one_predict_percentage, model_history], f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(5, 13076) (5, 13076, 14)\n"
     ]
    }
   ],
   "source": [
    "#==== shift label =======\n",
    "N=5\n",
    "Original_result=[]\n",
    "Original_prob=[]\n",
    "for i in range(N):\n",
    "    with open('./' + timestr + '(classes=' + str(NUM_region) + ')_n0_R0+R0_trial' + str(i)+ '.pickle', 'rb') as f:\n",
    "        Input_img, Input_img_len, one_predicted_results, one_predict_percentage, model_history = pickle.load(f)\n",
    "    label_B = one_predicted_results[0].copy()\n",
    "    label_B_prob = one_predict_percentage[0].copy()\n",
    "\n",
    "    #(1)\n",
    "    Original_result.append(label_B)\n",
    "\n",
    "    #(2)\n",
    "    Original_prob.append(label_B_prob)\n",
    "print(np.shape(Original_result), np.shape(Original_prob))\n",
    "\n",
    "# save pickle\n",
    "with open('./' + timestr + 'results_of_original.pickle', 'wb') as f:\n",
    "    pickle.dump([Original_result, Original_prob], f)\n",
    "    \n",
    "# save mat\n",
    "from scipy.io import savemat\n",
    "savemat('./' + timestr + 'results_of_original.mat', {'result_for_original':Original_result, 'prob_for_original':Original_prob})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# CNN combination and removal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#====CNN combination c(20,2)======\n",
    "comb=[]\n",
    "for subset in itertools.combinations(range(NUM_region), 2):\n",
    "    comb.append(subset)\n",
    "NUM_comb=len(comb)\n",
    "display(NUM_comb)            \n",
    "\n",
    "for n in range(NUM_comb+1):\n",
    "    region=region_image.copy()\n",
    "    region=list(region)\n",
    "    selected_region = list(range(NUM_region))\n",
    "\n",
    "    if (n > 0):\n",
    "        p1=comb[n-1][0]\n",
    "        p2=comb[n-1][1]\n",
    "        region[p1]=region[p1]+region[p2]\n",
    "        region.pop(p2)\n",
    "        selected_region.pop(-1)\n",
    "    else:\n",
    "        p1=0\n",
    "        p2=0\n",
    "\n",
    "    print(\"n, p1, p2\", n, p1, p2)\n",
    "\n",
    "\n",
    "    # ===== one CNN =============\n",
    "    NUM_CLASSES = len(selected_region)\n",
    "\n",
    "    Input_img     = []\n",
    "    Input_img_len = []\n",
    "    for c,sel in enumerate(selected_region, start=0):\n",
    "        Input_img = Input_img + list(region[sel])\n",
    "        Input_img_len.append(len(region[sel]))\n",
    "\n",
    "    # 20240319\n",
    "    if RAW_2D_DATA: # 2D\n",
    "        W           = np.shape(test_array[0])[0]\n",
    "        H           = np.shape(test_array[0])[1]\n",
    "        train_array = np.zeros((len(Input_img), W, H), dtype=float)\n",
    "        for i in range (len(Input_img)):\n",
    "            train_array[i] = test_array[Input_img[i]].reshape(W,H)\n",
    "    else: # 1D\n",
    "        W           = np.shape(test_array[0])[0]\n",
    "        train_array = np.zeros((len(Input_img), W), dtype=float)\n",
    "        for i in range (len(Input_img)):\n",
    "            train_array[i] = test_array[Input_img[i]].reshape(W)\n",
    "\n",
    "    train_array = np.expand_dims(train_array, axis = -1)\n",
    "\n",
    "\n",
    "    # fill up the training label to each training image\n",
    "    current_train_label = np.zeros(len(train_array), dtype=int)\n",
    "    accum_base=0\n",
    "    for label in range(1,NUM_CLASSES):\n",
    "        pre_cursor = Input_img_len[label-1]\n",
    "        accum_base = accum_base + pre_cursor\n",
    "        current_train_label[accum_base:] = label\n",
    "\n",
    "    # CNN\n",
    "    #===============================================\n",
    "    one_predicted_results  = np.zeros((TRIALS, len(test_label_answer)), dtype=int)\n",
    "    one_predict_percentage = np.zeros((TRIALS, len(test_label_answer), NUM_CLASSES), dtype=float)    \n",
    "    model_history = np.zeros(TRIALS, dtype=list)\n",
    "\n",
    "    for r in range(TRIALS):\n",
    "        one_predicted_results[r], one_predict_percentage[r], model_history[r] = ME_CNN(\n",
    "                x_train     = train_array,\n",
    "                train_label = current_train_label,\n",
    "                test_array  = test_array,\n",
    "                true_answer = test_label_answer,\n",
    "                Num_Classes = NUM_CLASSES\n",
    "                )\n",
    "        print(type(model_history))\n",
    "\n",
    "\n",
    "        # ===== delete CNN tensors =====\n",
    "        from keras import backend as K\n",
    "        K.clear_session()\n",
    "        import gc\n",
    "        gc.collect()\n",
    "\n",
    "        print(\"One CNN, r: \",r)\n",
    "        ROUND_duration = time.time() - ROUND_start\n",
    "        print(\"Computing Time: \", str(datetime.timedelta(seconds=ROUND_duration)))\n",
    "\n",
    "    # === save to file ===\n",
    "    savefile_path = './' + str(timestr) + '(classes=' + str(NUM_CLASSES)+')_n' + str(n) + '_R' + str(p1) + '+R'+ str(p2) +'.pickle'\n",
    "    with open(savefile_path, 'wb') as f:\n",
    "        pickle.dump([Input_img, Input_img_len, one_predicted_results, one_predict_percentage, model_history], f)\n",
    "\n",
    "\n",
    "\n",
    "# ==== CNN Removal =====\n",
    "for n in range(NUM_region):\n",
    "    region=region_image.copy()   #reset\n",
    "    selected_region = list(range(NUM_region))\n",
    "    selected_region.pop(n)\n",
    "\n",
    "    print(\"n=\", n)\n",
    "\n",
    "\n",
    "    # ===== one CNN =============\n",
    "    NUM_CLASSES = len(selected_region)\n",
    "\n",
    "    # input image and label\n",
    "    Input_img     = []\n",
    "    Input_img_len = []\n",
    "    for c,sel in enumerate(selected_region, start=0):\n",
    "        Input_img = Input_img + list(region[sel])\n",
    "        Input_img_len.append(len(region[sel]))\n",
    "\n",
    "\n",
    "    # 20240319\n",
    "    if RAW_2D_DATA: # 2D\n",
    "        W           = np.shape(test_array[0])[0]\n",
    "        H           = np.shape(test_array[0])[1]\n",
    "        train_array = np.zeros((len(Input_img), W, H), dtype=float)\n",
    "        for i in range (len(Input_img)):\n",
    "            train_array[i] = test_array[Input_img[i]].reshape(W,H)\n",
    "    else: # 1D\n",
    "        W           = np.shape(test_array[0])[0]\n",
    "        train_array = np.zeros((len(Input_img), W), dtype=float)\n",
    "        for i in range (len(Input_img)):\n",
    "            train_array[i] = test_array[Input_img[i]].reshape(W)\n",
    "\n",
    "    train_array = np.expand_dims(train_array, axis = -1)\n",
    "    \n",
    "    \n",
    "    # fill up the training label to each training image\n",
    "    current_train_label = np.zeros(len(train_array), dtype=int)\n",
    "    accum_base=0\n",
    "    for label in range(1,NUM_CLASSES):\n",
    "        pre_cursor = Input_img_len[label-1]\n",
    "        accum_base = accum_base + pre_cursor\n",
    "        current_train_label[accum_base:] = label\n",
    "\n",
    "    # CNN\n",
    "    #===============================================\n",
    "    one_predicted_results  = np.zeros((TRIALS, len(test_label_answer)), dtype=int)\n",
    "    one_predict_percentage = np.zeros((TRIALS, len(test_label_answer), NUM_CLASSES), dtype=float)    \n",
    "    model_history = np.zeros(TRIALS, dtype=list)\n",
    "\n",
    "    for r in range(TRIALS):\n",
    "        one_predicted_results[r], one_predict_percentage[r], model_history[r] = ME_CNN(\n",
    "                x_train     = train_array,\n",
    "                train_label = current_train_label,\n",
    "                test_array  = test_array,\n",
    "                true_answer = test_label_answer,\n",
    "                Num_Classes = NUM_CLASSES\n",
    "                )\n",
    "        print(type(model_history))\n",
    "\n",
    "\n",
    "        # ===== delete CNN tensors =====\n",
    "        from keras import backend as K\n",
    "        K.clear_session()\n",
    "        import gc\n",
    "        gc.collect()\n",
    "\n",
    "        print(\"One CNN, r: \",r)\n",
    "        ROUND_duration = time.time() - ROUND_start\n",
    "        print(\"Computing Time: \", str(datetime.timedelta(seconds=ROUND_duration)))\n",
    "\n",
    "    # === save to file ===\n",
    "    savefile_path = './' + str(timestr) + '(classes=' + str(NUM_CLASSES)+')_Remove' + str(n) +'.pickle' \n",
    "    with open(savefile_path, 'wb') as f:\n",
    "        pickle.dump([Input_img, Input_img_len, one_predicted_results, one_predict_percentage, model_history], f)\n",
    "  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# ==== CNN Removal =====\n",
    "for n in range(NUM_region):\n",
    "    region=region_image.copy()   #reset\n",
    "    selected_region = list(range(NUM_region))\n",
    "    selected_region.pop(n)\n",
    "\n",
    "    print(\"n=\", n)\n",
    "\n",
    "\n",
    "    # ===== one CNN =============\n",
    "    NUM_CLASSES = len(selected_region)\n",
    "\n",
    "    # input image and label\n",
    "    Input_img     = []\n",
    "    Input_img_len = []\n",
    "    for c,sel in enumerate(selected_region, start=0):\n",
    "        Input_img = Input_img + list(region[sel])\n",
    "        Input_img_len.append(len(region[sel]))\n",
    "\n",
    "    # 20240319\n",
    "    if RAW_2D_DATA: # 2D\n",
    "        W           = np.shape(test_array[0])[0]\n",
    "        H           = np.shape(test_array[0])[1]\n",
    "        train_array = np.zeros((len(Input_img), W, H), dtype=float)\n",
    "        for i in range (len(Input_img)):\n",
    "            train_array[i] = test_array[Input_img[i]].reshape(W,H)\n",
    "    else: # 1D\n",
    "        W           = np.shape(test_array[0])[0]\n",
    "        train_array = np.zeros((len(Input_img), W), dtype=float)\n",
    "        for i in range (len(Input_img)):\n",
    "            train_array[i] = test_array[Input_img[i]].reshape(W)\n",
    "            \n",
    "    train_array = np.expand_dims(train_array, axis = -1)\n",
    "    \n",
    "    \n",
    "    # fill up the training label to each training image\n",
    "    current_train_label = np.zeros(len(train_array), dtype=int)\n",
    "    accum_base=0\n",
    "    for label in range(1,NUM_CLASSES):\n",
    "        pre_cursor = Input_img_len[label-1]\n",
    "        accum_base = accum_base + pre_cursor\n",
    "        current_train_label[accum_base:] = label\n",
    "\n",
    "    # CNN\n",
    "    #===============================================\n",
    "    one_predicted_results  = np.zeros((TRIALS, len(test_label_answer)), dtype=int)\n",
    "    one_predict_percentage = np.zeros((TRIALS, len(test_label_answer), NUM_CLASSES), dtype=float)    \n",
    "    model_history = np.zeros(TRIALS, dtype=list)\n",
    "\n",
    "    for r in range(TRIALS):\n",
    "        one_predicted_results[r], one_predict_percentage[r], model_history[r] = ME_CNN(\n",
    "                x_train     = train_array,\n",
    "                train_label = current_train_label,\n",
    "                test_array  = test_array,\n",
    "                true_answer = test_label_answer,\n",
    "                Num_Classes = NUM_CLASSES\n",
    "                )\n",
    "        print(type(model_history))\n",
    "\n",
    "\n",
    "        # ===== delete CNN tensors =====\n",
    "        from keras import backend as K\n",
    "        K.clear_session()\n",
    "        import gc\n",
    "        gc.collect()\n",
    "\n",
    "        print(\"One CNN, r: \",r)\n",
    "        ROUND_duration = time.time() - ROUND_start\n",
    "        print(\"Computing Time: \", str(datetime.timedelta(seconds=ROUND_duration)))\n",
    "\n",
    "    # === save to file ===\n",
    "    savefile_path = './' + str(timestr) + '(classes=' + str(NUM_CLASSES)+')_Remove' + str(n) +'.pickle' \n",
    "    with open(savefile_path, 'wb') as f:\n",
    "        pickle.dump([Input_img, Input_img_len, one_predicted_results, one_predict_percentage, model_history], f)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(91, 13076) (91, 13076, 13) (91, 13)\n",
      "normal size =  (91, 13076, 13)\n",
      "(14, 13076) (14, 13076, 13) (14, 13)\n"
     ]
    }
   ],
   "source": [
    "# ====shift label=====\n",
    "#=== combination =====\n",
    "comb=[]\n",
    "for oneset in itertools.combinations(range(NUM_region), 2):\n",
    "    comb.append(oneset)\n",
    "NUM_comb=len(comb)\n",
    "\n",
    "Merged_result=[]\n",
    "Merged_prob=[]\n",
    "Merged_prob_label=[]\n",
    "\n",
    "for n in range(NUM_comb):\n",
    "    label = list(range(NUM_region))\n",
    "    p1=comb[n][0]\n",
    "    p2=comb[n][1]\n",
    "\n",
    "    with open('./' + timestr + '(classes=' + str(NUM_region-1) + ')_n'+str(n+1)+'_R'+str(p1)+'+R'+str(p2)+'.pickle', 'rb') as f:\n",
    "        Input_img, Input_img_len, one_predicted_results, one_predict_percentage, model_history = pickle.load(f)\n",
    "    label_B = one_predicted_results[0].copy()\n",
    "    label_B_prob = one_predict_percentage[0].copy()\n",
    "\n",
    "    #(1)shift label index\n",
    "    for p in reversed(range(p2,NUM_region-1)):\n",
    "        addr=np.where(label_B==p)[0]\n",
    "        label_B[addr]+=1\n",
    "    Merged_result.append(label_B)\n",
    "\n",
    "    #(2)\n",
    "    Merged_prob.append(label_B_prob)\n",
    "\n",
    "    #(3)\n",
    "    label.pop(p2)\n",
    "    Merged_prob_label.append(label)\n",
    "\n",
    "print(np.shape(Merged_result), np.shape(Merged_prob), np.shape(Merged_prob_label))\n",
    "\n",
    "# save pickle\n",
    "with open('./' + timestr + 'results_of_combination.pickle', 'wb') as f:\n",
    "    pickle.dump([comb, Merged_result, Merged_prob, Merged_prob_label], f)\n",
    "\n",
    "# save mat\n",
    "from scipy.io import savemat\n",
    "if (np.shape(Merged_prob)[0]<=300):\n",
    "    savemat('./' + timestr + 'results_of_combination.mat', {'combination_pairs':comb, 'result_for_merge':Merged_result, 'prob_for_merge':Merged_prob,'prob_label_for_merge': Merged_prob_label})\n",
    "    print(\"normal size = \", np.shape(Merged_prob))\n",
    "else:\n",
    "    savemat('./' + timestr + 'results_of_combination.mat', {'combination_pairs':comb, 'result_for_merge':Merged_result, 'prob_label_for_merge': Merged_prob_label})\n",
    "    savemat('./' + timestr + 'results_of_combination_prob1.mat', {'prob_for_merge1':Merged_prob[:200]})\n",
    "    savemat('./' + timestr + 'results_of_combination_prob2.mat', {'prob_for_merge2':Merged_prob[200:400]})\n",
    "    savemat('./' + timestr + 'results_of_combination_prob3.mat', {'prob_for_merge3':Merged_prob[400:]})\n",
    "    print(\"large size = \", np.shape(Merged_prob))\n",
    "\n",
    "    \n",
    "    \n",
    "    \n",
    "#======== removal ===========\n",
    "Removal_result=[]\n",
    "Removal_prob=[]\n",
    "Removal_prob_label=[]\n",
    "\n",
    "for n in range(NUM_region):\n",
    "    label = list(range(NUM_region))    \n",
    "    #reset\n",
    "    with open('./' + timestr + '(classes=' + str(NUM_region-1) + ')_Remove' + str(n) + '.pickle', 'rb') as f:\n",
    "        Input_img, Input_img_len, one_predicted_results, one_predict_percentage, model_history = pickle.load(f)\n",
    "    label_B = one_predicted_results[0].copy()\n",
    "    label_B_prob = one_predict_percentage[0].copy()\n",
    "\n",
    "    for p in reversed(range(n,NUM_region-1)):\n",
    "        addr=np.where(label_B==p)[0]\n",
    "        label_B[addr]+=1\n",
    "    Removal_result.append(label_B)\n",
    "\n",
    "    #(2)\n",
    "    Removal_prob.append(label_B_prob)\n",
    "\n",
    "    #(3)\n",
    "    label.pop(n)\n",
    "    Removal_prob_label.append(label)\n",
    "\n",
    "print(np.shape(Removal_result), np.shape(Removal_prob), np.shape(Removal_prob_label))\n",
    "\n",
    "# save pickle\n",
    "with open('./' + timestr + 'results_of_removal.pickle', 'wb') as f:\n",
    "    pickle.dump([Removal_result, Removal_prob, Removal_prob_label], f)\n",
    "    \n",
    "# save mat\n",
    "from scipy.io import savemat\n",
    "savemat('./' + timestr + 'results_of_removal.mat', {'result_for_removal':Removal_result,'prob_for_removal':Removal_prob, 'prob_label_for_removal':Removal_prob_label})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "done\n"
     ]
    }
   ],
   "source": [
    "print(\"done\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
