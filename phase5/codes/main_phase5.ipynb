{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***\n",
    "### <span style='color:green'> ME Algorithm  &emsp;&emsp; Feb, 2024 </span>\n",
    "### <span style='color:Blue'> Phase 5 </span>\n",
    "### <p> Yan-Bin Chen (陳彥賓) &emsp; yanbin@stat.sinica.edu.tw </p>\n",
    "### <p> Institute of Statistical Science, Academia Sinica, Taipei, Taiwan.</p>  \n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas\n",
    "import numpy as np\n",
    "import pickle\n",
    "import os\n",
    "import csv\n",
    "import time\n",
    "import datetime\n",
    "import collections\n",
    "from itertools import chain\n",
    "from scipy.spatial.distance import squareform, pdist"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Input"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# input\n",
    "PATH4='../../phase3/data/ResNet18_PlantDisease_45K_Spec200_sampling.csv'\n",
    "PATH5='../../phase3/data/embedded_data.pickle'\n",
    "PATH6='../data/mergedseedclasslabels.txt'\n",
    "PATH7='../../phase3/data/region_for_phase5.pickle'\n",
    "\n",
    "\n",
    "# === parameters ===================================================\n",
    "MNIST     = False\n",
    "NUM_CASE  = 1\n",
    "INTE_bool = False  #True: Integrate two networks VGG+ResNet    False: single network\n",
    "SAVE_bool = True\n",
    "ITE_FROM  = 5 # This setting is ONLY for Integration\n",
    "REG_COLUMN = \"Spec200\"\n",
    "RAW_2D_DATA = False\n",
    "interpret_path='./case1/accu_history.csv'  #interprete the accuracy results\n",
    "AMOUNT_ITE=3\n",
    "\n",
    "\n",
    "if RAW_2D_DATA: # 2D\n",
    "    from CNN_Modules import ME_CNN\n",
    "else: # 1D\n",
    "    from CNN_Modules_1D import ME_CNN\n",
    "    \n",
    "\n",
    "if (INTE_bool):\n",
    "    ITE_START=ITE_FROM\n",
    "    ITE_END=ITE_FROM+4\n",
    "else:\n",
    "    ITE_START=0\n",
    "    ITE_END=5"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Define functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def append_csv(x, path):\n",
    "    with open(path,'a+', newline='') as f:\n",
    "        csv_file = csv.writer(f)#   = f.write()\n",
    "        csv_file.writerow(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Only for single network. No necessary in Integrated networks\n",
    "if (not INTE_bool):\n",
    "    def create_image_0(PATH6, case_i):\n",
    "        # ===================\n",
    "        #\n",
    "        #  prepare  merged_region_image_0\n",
    "        #\n",
    "        #====================\n",
    "        # (A)\n",
    "        #get \"(1)merged_region\"      only seed regions, no neighboring regions\n",
    "        df = pandas.read_csv(PATH6, delim_whitespace=' ', header=0,  index_col=None)\n",
    "        table = df.to_numpy()\n",
    "        print(\"mergedseedclasslabels table\")\n",
    "        display(table)\n",
    "\n",
    "        merged_region=[]\n",
    "        for i in range(min(table.T[case_i+1]), max(table.T[case_i+1])+1):  #18 ---merge to --> 10\n",
    "            addr=np.where(table.T[case_i+1]==i)[0] # 2nd column equal to 0(min),1,2,3...10(max); DO NOT consider 3rd column, which is hidden\n",
    "            if(len(addr) and i>0): #if not empty and i=0 is the invalid seed region.\n",
    "                merged_region.append(table[addr][:,0].tolist())\n",
    "        print(\"merged_region\")\n",
    "        display(merged_region)\n",
    "\n",
    "\n",
    "        # (B)\n",
    "        #get \"merged_reg_and_nei\"\n",
    "        #get \"merged_reg_and_nei_image\"\n",
    "        #generate \"merged_region_image_0.pickle\"\n",
    "\n",
    "        # (B_a)=== without neighbors ====\n",
    "        #if ((DATASET == 2) or (DATASET == 4)): \n",
    "        ##20240105\n",
    "        if (not True): \n",
    "            # ==== collect regions. No neighbors, just use merged regions ====\n",
    "            merged_reg_and_nei=merged_region.copy()\n",
    "\n",
    "            # ==== collect images ====\n",
    "            img_temp=[]\n",
    "            for i in range(len(merged_region)):\n",
    "                addr=[]\n",
    "                for j in range(len(merged_region[i])):\n",
    "                    temp=np.where(all_region_index==merged_region[i][j])[0].tolist()   #tolist(): convert temp into list\n",
    "                    addr=addr+temp\n",
    "                    print(len(temp),end=' ')\n",
    "                img_temp.append(addr)\n",
    "                print(\"=\",len(img_temp[i]))\n",
    "            merged_reg_and_nei_image = img_temp.copy()\n",
    "\n",
    "\n",
    "        # (B_b)=== with neighbors ==== \n",
    "        else: \n",
    "            with open(PATH7, 'rb') as f:\n",
    "                pre_region, pre_reg_nei, pre_region_image_pure, pre_region_image= pickle.load(f)\n",
    "            #    1reg         2reg+nei        1's img            2's img\n",
    "\n",
    "            # ==== collect regions with neighbors====\n",
    "            # remove duplicate  -->  https://stackoverflow.com/questions/9835762/how-do-i-find-the-duplicates-in-a-list-and-create-another-list-with-them\n",
    "            merged_reg_and_nei=[]\n",
    "            NUM_region=len(merged_region)\n",
    "            for i in range(NUM_region):\n",
    "                temp=[]\n",
    "                for j in range(len(merged_region[i])):\n",
    "                    idx=np.where(pre_region==merged_region[i][j])[0][0] \n",
    "                    temp=temp+pre_reg_nei[idx]\n",
    "                    print(idx,pre_region[idx])\n",
    "                merged_reg_and_nei.append(temp)\n",
    "\n",
    "\n",
    "                #check whether it has duplicates\n",
    "                if (len(merged_reg_and_nei[i]) != len(set(merged_reg_and_nei[i]))):\n",
    "                    a=merged_reg_and_nei[i].copy()\n",
    "\n",
    "                    # find the duplicate.\n",
    "                    seen = set()\n",
    "                    dupli                 = [x for x in a if (x in seen or seen.add(x))]\n",
    "                    print(\"***duplicates:\",dupli)\n",
    "\n",
    "                    # keep fisrt one, remove succeeding duplicates.\n",
    "                    seen = set()\n",
    "                    merged_reg_and_nei[i] = [x for x in a if not (x in seen or seen.add(x))]  # a is the data to process; x is a working varialbe\n",
    "                    print(\"unique:\",merged_reg_and_nei[i])\n",
    "\n",
    "                print(\"total\",len(merged_reg_and_nei[i]),end=\"\\n\\n\")\n",
    "\n",
    "\n",
    "            print(\"\\nmerged_reg_and_nei\")\n",
    "            for i in range(len(merged_reg_and_nei)):\n",
    "                print(merged_reg_and_nei[i])\n",
    "\n",
    "\n",
    "            # Collect images\n",
    "            merged_reg_and_nei_image=[]\n",
    "            for i in range(NUM_region):\n",
    "                #search and add\n",
    "                img=[]\n",
    "                for j in range(len(merged_region[i])):\n",
    "                    idx=np.where(pre_region==merged_region[i][j])[0][0]\n",
    "                    print(len(pre_region_image[idx]),\"(\",idx,\")\",end=' ')\n",
    "                    img=img+pre_region_image[idx] \n",
    "                print(\"=\",len(img),end=\" \")\n",
    "\n",
    "                #check whether it has duplicates\n",
    "                if (len(img) != len(set(img))):\n",
    "                    img=list(set(img)) #remove duplicates\n",
    "                    print(\"     **duplicate, shrink to\",len(img),end=\"\\n\")  \n",
    "                else:\n",
    "                    print(end=\"\\n\")\n",
    "\n",
    "                #append\n",
    "                merged_reg_and_nei_image.append(img)\n",
    "\n",
    "            print(\"\\nmerged_reg_and_nei_image\")\n",
    "            for i in range(len(merged_reg_and_nei_image)):\n",
    "                print(len(merged_reg_and_nei_image[i]),merged_reg_and_nei_image[i][:5],\"...\")\n",
    "\n",
    "        # save\n",
    "        if (SAVE_bool):\n",
    "            with open(newpath+'/merged_region_image_0.pickle', 'wb') as f:\n",
    "                pickle.dump([merged_reg_and_nei, merged_reg_and_nei_image], f)     "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def CNN_part(PATH5,ITE):\n",
    "    TRIALS          = 5\n",
    "\n",
    "    savelog_path = newpath+'/' + 'log.txt'\n",
    "\n",
    "    # ==== test_array ====\n",
    "    with open(PATH5, 'rb') as f:\n",
    "        test_array, test_label_answer = pickle.load(f)\n",
    "        \n",
    "    if RAW_2D_DATA: # 2D\n",
    "        print(\"\")\n",
    "    else: # 1D\n",
    "        test_array = np.expand_dims(test_array, axis = -1)\n",
    "\n",
    "    \n",
    "    #if((DATASET==2) or (DATASET==4)):\n",
    "    #    test_array = np.expand_dims(test_array, axis = -1)\n",
    "    #elif(DATASET==1):\n",
    "    #    test_array = np.expand_dims(test_array, axis = -1)\n",
    "    #    test_array /= 255\n",
    "    #elif(DATASET==0):\n",
    "    #    test_array /= 255\n",
    "    #display(np.shape(test_array))\n",
    "\n",
    "\n",
    "    with open(newpath+'/merged_region_image_'+str(ITE)+'.pickle', 'rb') as f:\n",
    "        merged_reg_and_nei, merged_region_image = pickle.load(f)\n",
    "    region_image=merged_region_image.copy()\n",
    "    del merged_reg_and_nei\n",
    "\n",
    "\n",
    "    NUM_region=len(region_image)\n",
    "    print(\"NUM_region\",NUM_region)\n",
    "\n",
    "\n",
    "    from itertools import chain\n",
    "    region_image_flatten=list(chain.from_iterable(region_image))\n",
    "    print(\"number of clean images\",len(region_image_flatten))\n",
    "\n",
    "\n",
    "    ROUND_start = time.time()\n",
    "    #========  merge ==========\n",
    "    #prepare selected_region, region\n",
    "    for n in range(1): #extra_original\n",
    "    #   #reset\n",
    "        region=region_image.copy()\n",
    "        region=list(region)\n",
    "        selected_region = list(range(NUM_region))  #[0,1,2, ... ,29]\n",
    "\n",
    "        #merge\n",
    "        if (n > 4):\n",
    "            p1=comb[n-1][0]\n",
    "            p2=comb[n-1][1]\n",
    "            region[p1]=region[p1]+region[p2]\n",
    "            region.pop(p2)\n",
    "            selected_region.pop(-1)  # remove last region index\n",
    "        #original\n",
    "        else:  #n=0\n",
    "            p1=0\n",
    "            p2=0\n",
    "\n",
    "        print(\"n, p1, p2\", n, p1, p2)\n",
    "\n",
    "\n",
    "        # ===== one CNN =============\n",
    "        NUM_CLASSES = len(selected_region)  #NUM_CLASSES should be here to update for each loop\n",
    "\n",
    "        # input image and label\n",
    "        Input_img     = []\n",
    "        Input_img_len = []\n",
    "        for c,sel in enumerate(selected_region, start=0):\n",
    "            Input_img = Input_img + list(region[sel])\n",
    "            Input_img_len.append(len(region[sel])) #can only concatenate list (not \"int\") to list    \n",
    "            \n",
    "        # 20240319\n",
    "        if RAW_2D_DATA: # 2D\n",
    "            W           = np.shape(test_array[0])[0]\n",
    "            H           = np.shape(test_array[0])[1]\n",
    "            train_array = np.zeros((len(Input_img), W, H), dtype=float)\n",
    "            for i in range (len(Input_img)):\n",
    "                train_array[i] = test_array[Input_img[i]].reshape(W,H)\n",
    "        else: # 1D\n",
    "            W           = np.shape(test_array[0])[0]\n",
    "            train_array = np.zeros((len(Input_img), W), dtype=float)\n",
    "            for i in range (len(Input_img)):\n",
    "                train_array[i] = test_array[Input_img[i]].reshape(W)\n",
    "                  \n",
    "        train_array = np.expand_dims(train_array, axis = -1)\n",
    "\n",
    "\n",
    "        # fill up the training label to each training image\n",
    "        current_train_label = np.zeros(len(train_array), dtype=int)  # Assign 0 to the label\n",
    "        accum_base=0  #accumulate\n",
    "        for label in range(1,NUM_CLASSES):\n",
    "            sector = Input_img_len[label-1]\n",
    "            accum_base = accum_base + sector  # sector is the sector length\n",
    "            current_train_label[accum_base:] = label  # fill the label\n",
    "\n",
    "\n",
    "        # CNN\n",
    "        #===============================================\n",
    "        one_predicted_results  = np.zeros((TRIALS, len(test_label_answer)), dtype=int)\n",
    "        one_predict_percentage = np.zeros((TRIALS, len(test_label_answer), NUM_CLASSES), dtype=float)    \n",
    "        model_history = np.zeros(TRIALS, dtype=list)\n",
    "        print(\"NUM_CLASSES\",NUM_CLASSES)\n",
    "        print(\"current_train_label: \",list(set(current_train_label)))\n",
    "        for r in range(TRIALS):  #10\n",
    "            one_predicted_results[r], one_predict_percentage[r], model_history[r] = ME_CNN(\n",
    "                    x_train     = train_array,\n",
    "                    train_label = current_train_label,\n",
    "                    test_array  = test_array,\n",
    "                    true_answer = test_label_answer,\n",
    "                    Num_Classes = NUM_CLASSES\n",
    "                    )\n",
    "            print(type(model_history))\n",
    "\n",
    "\n",
    "            # ===== delete CNN tensors =====\n",
    "            from keras import backend as K\n",
    "            K.clear_session()\n",
    "            import gc\n",
    "            gc.collect()\n",
    "\n",
    "            print(\"One CNN, r: \",r)\n",
    "            ROUND_duration = time.time() - ROUND_start\n",
    "            print(\"Computing Time: \", str(datetime.timedelta(seconds=ROUND_duration)))\n",
    "\n",
    "\n",
    "        # === save to file ===\n",
    "        #This is useless in phase IV. Prepare for further checking in the future.\n",
    "        savefile_path = str(newpath) +  '/(classes=' + str(NUM_CLASSES)+')_n0_R' + str(p1) + '+R'+ str(p2) +'_trial' + str(n)+'_'+str(ITE)+'.pickle'  #extra_original\n",
    "        with open(savefile_path, 'wb') as f:\n",
    "            pickle.dump([Input_img, Input_img_len, one_predicted_results, one_predict_percentage, model_history], f)\n",
    "\n",
    "        savefile_path2 = str(newpath) +  '/(classes=' + str(NUM_CLASSES)+')_5_tests_simple_ITE'+str(ITE)+'.pickle'  #extra_original\n",
    "        with open(savefile_path2, 'wb') as f:\n",
    "            pickle.dump([one_predicted_results, one_predict_percentage], f)\n",
    "\n",
    "        # === save to log ===    \n",
    "        savelog = open(savelog_path, 'a+')\n",
    "        print(\"\\n\", savefile_path, file = savelog)\n",
    "        print(\"Saved parameters: Input_img, Input_img_len, one_predicted_results, one_predict_percentage\", file = savelog) #0722\n",
    "\n",
    "        # total time\n",
    "        ROUND_duration = time.time() - ROUND_start\n",
    "        print(\"Completion time: \", datetime.datetime.now(), file = savelog)\n",
    "        print(\"Total Computing Time: \", str(datetime.timedelta(seconds=ROUND_duration)), file = savelog)\n",
    "\n",
    "        savelog.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def statistic_method(PATH5,NUM_region,region_label,table_1D):\n",
    "    with open(PATH5, 'rb') as f:\n",
    "        test_array, test_label_answer = pickle.load(f)\n",
    "    del test_array\n",
    "    \n",
    "    dist_table_truth=np.zeros((NUM_region,NUM_region),dtype=int)\n",
    "    region_correct=[]\n",
    "    region_amount=[]\n",
    "    overall_correct=0\n",
    "    overall_amount=0\n",
    "\n",
    "    for i in range(NUM_region):\n",
    "        #(1) input\n",
    "        region_image=np.where(table_1D==i)[0]\n",
    "        #region_image=merged_region_image[i].copy()\n",
    "        \n",
    "        #(2) establish confusion matrix\n",
    "        for j in range(NUM_region):\n",
    "            dist_table_truth[i][j]=len(np.where(test_label_answer[region_image]==j)[0]) #the number of images which equals to true answer \n",
    "        \n",
    "        #(3) statisitc\n",
    "        region_correct.append(dist_table_truth[i][region_label[i]])\n",
    "        region_amount.append(len(region_image))\n",
    "      \n",
    "    #(4) statistic for overall\n",
    "    overall_correct=sum(region_correct)\n",
    "    overall_amount=sum(region_amount)\n",
    "\n",
    "    return region_correct,region_amount,overall_correct,overall_amount,dist_table_truth"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def statistic(PATH5,ITE):\n",
    "    # input 1:\n",
    "    # (1)merged_region_image_(ITE)\n",
    "    with open(newpath+'/merged_region_image_'+str(ITE)+'.pickle', 'rb') as f:\n",
    "        merged_reg_and_nei, merged_region_image = pickle.load(f)\n",
    "    del merged_reg_and_nei\n",
    "    NUM_region=len(merged_region_image)\n",
    "    \n",
    "    # (2)test_label_answer\n",
    "    with open(PATH5, 'rb') as f:\n",
    "        test_array, test_label_answer = pickle.load(f)\n",
    "    del test_array\n",
    "\n",
    "    # (3)get consistent result table\n",
    "    with open(newpath+'/(classes=' + str(NUM_region) + ')_5_tests_simple_ITE'+str(ITE)+'.pickle', 'rb') as f:\n",
    "        one_predicted_results, one_predict_percentage = pickle.load(f)\n",
    "    del one_predict_percentage\n",
    "    LENGTH=np.shape(one_predicted_results)[1]\n",
    "    Original_result=np.zeros(LENGTH,dtype=int)\n",
    "    for i in range(LENGTH):\n",
    "        if (len(set(one_predicted_results.T[i])) == 1):  # (***)\n",
    "            Original_result[i]=one_predicted_results[0][i]\n",
    "        else:\n",
    "            Original_result[i]=-1\n",
    " \n",
    "    # (4) get region_label \n",
    "    region_label=[] #true label by selecting dominate ones\n",
    "    for i in range(NUM_region):\n",
    "        region_image=merged_region_image[i].copy()\n",
    "        region_label.append(collections.Counter(test_label_answer[region_image]).most_common()[0][0])  #images --> true label --> most_common label\n",
    "\n",
    "\n",
    "   #========================================     \n",
    "   # (1)train + test\n",
    "    a2,b2,c2,d2,e2=statistic_method(PATH5,NUM_region,region_label,Original_result)\n",
    "    na2=np.asarray(a2)\n",
    "    nb2=np.asarray(b2)\n",
    "    nc2=np.asarray(c2)\n",
    "    nd2=np.asarray(d2)\n",
    "    all_num=len(Original_result)\n",
    "    append_csv([ITE, c2, d2,      round(nc2/nd2    ,3), \"5con over all, but 5-consensus\"], csv_path1)\n",
    "    append_csv([ITE, c2, all_num, round(nc2/all_num,3), \"5con over all\"], csv_path1)\n",
    " \n",
    "\n",
    "        \n",
    "    # (2)train\n",
    "    train_results=-1*np.ones(LENGTH,dtype=int)\n",
    "    for i in range(NUM_region):\n",
    "        images=merged_region_image[i]\n",
    "        train_results[images]=i\n",
    "        print(\"num of merged_region_image\",i,len(merged_region_image[i]))\n",
    "    print(collections.Counter(train_results))\n",
    "        \n",
    "    a1,b1,c1,d1,e1=statistic_method(PATH5,NUM_region,region_label,train_results)\n",
    "    na1=np.asarray(a1)  #region_correct\n",
    "    nb1=np.asarray(b1)  #region_amount\n",
    "    nc1=np.asarray(c1)  #overall_correct\n",
    "    nd1=np.asarray(d1)  #overall_amount\n",
    "    all_num=len(Original_result)\n",
    "    append_csv([ITE, c1, d1, round(nc1/nd1,3), \"5con over trained\"], csv_path1)\n",
    "    append_csv([ITE, c1, all_num, round(nc1/all_num,3), \"5con over all\"], csv_path1)\n",
    "    \n",
    "        \n",
    "    # (3)test\n",
    "    # remove training data(good images), only check test data(bad images)\n",
    "    from itertools import chain\n",
    "    used_image=merged_region_image.copy()\n",
    "    used_image=list(chain.from_iterable(used_image))\n",
    "    Original_result2=Original_result.copy()\n",
    "    Original_result2[used_image]=-2\n",
    "\n",
    "        \n",
    "    a4,b4,c4,d4,e4=statistic_method(PATH5,NUM_region,region_label, Original_result2)\n",
    "    na4=np.asarray(a4)\n",
    "    nb4=np.asarray(b4)\n",
    "    nc4=np.asarray(c4)\n",
    "    nd4=np.asarray(d4) #this is len(Original_result)-len(used_image)-len(unconsistent)\n",
    "    untrain=len(Original_result)-len(used_image)\n",
    "    all_num=len(Original_result)\n",
    "    append_csv([ITE, c4, untrain, round(nc4/untrain, 3), \"5con over untrained, but 5-consensus\"], csv_path1)\n",
    "    append_csv([ITE, c4, all_num, round(nc4/all_num, 3), \"5con over untrained (unclean)\"], csv_path1)\n",
    "\n",
    "        \n",
    "    # (4)set majority as label for each image        \n",
    "    # set majority from 5 trias as label for each image\n",
    "    predicted_results_major=np.zeros(LENGTH,dtype=int)\n",
    "    for i in range(LENGTH):\n",
    "        predicted_results_major[i]=collections.Counter(one_predicted_results.T[i]).most_common()[0][0]\n",
    "    \n",
    "\n",
    "    a3,b3,c3,d3,e3=statistic_method(PATH5,NUM_region,region_label,predicted_results_major)\n",
    "    na3=np.asarray(a3)\n",
    "    nb3=np.asarray(b3)\n",
    "    nc3=np.asarray(c3)\n",
    "    nd3=np.asarray(d3) #this is all in majority criterion\n",
    "    append_csv([ITE, c3, d3, round(nc3/nd3    ,3), \"majo over all\"], csv_path1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def merged_and_expand(PATH5,ITE):\n",
    "# all4.     \n",
    "    # load\n",
    "    with open('./region_initials.pickle', 'rb') as f:\n",
    "        all_region_index, all_region_image = pickle.load(f)\n",
    "    MAX_region = max(all_region_index)\n",
    "\n",
    "    with open(newpath+'/merged_region_image_'+str(ITE)+'.pickle', 'rb') as f:\n",
    "        merged_reg_and_nei, merged_region_image = pickle.load(f)\n",
    "    NUM_region = len(merged_reg_and_nei) # NUM_region is the number of clusters\n",
    "\n",
    "    with open(newpath+'/(classes='+str(NUM_region)+')_5_tests_simple_ITE'+str(ITE)+'.pickle', 'rb') as f:\n",
    "        one_predicted_results, one_predict_percentage = pickle.load(f)\n",
    "    del one_predict_percentage\n",
    "\n",
    "    with open(PATH5, 'rb') as f:\n",
    "        test_array, test_label_answer = pickle.load(f)\n",
    "    del test_array\n",
    "\n",
    "\n",
    "    # choose absolutely consistent images\n",
    "    NUM_test=np.shape(one_predicted_results)[1]\n",
    "    Original_result=np.zeros(NUM_test,dtype=int)\n",
    "\n",
    "    # (***)\n",
    "    # As set contains only unique elements, so convert the list to set.\n",
    "    # If set size is 1 then it means all elements in given list are same\n",
    "    for i in range(NUM_test):\n",
    "        if (len(set(one_predicted_results.T[i])) == 1):  # (***)\n",
    "            Original_result[i]=one_predicted_results[0][i]\n",
    "        else:\n",
    "            Original_result[i]=-1\n",
    "    \n",
    "    used_img=list(chain.from_iterable(merged_region_image))\n",
    "    used_img=np.sort(used_img)\n",
    "    working_img = np.asarray(list(  set(range(NUM_test))-set(used_img)  ))  #working_img means the unclean ones for working on the further adding process\n",
    "    print(\"===========  ITE =\",ITE, \"  ===========\")    \n",
    "    print(\"used_img\",len(used_img), len(set(used_img)))    \n",
    "    print(\"working_img(=other images=unclean images)\",len(working_img), len(set(working_img)))\n",
    "\n",
    "    # save clean and unclean images\n",
    "    if (SAVE_bool):\n",
    "        with open(newpath + '/clean_and_unclean_image_ITE='+str(ITE)+'.pickle', 'wb') as f:\n",
    "            pickle.dump([used_img, working_img], f) #used_img is clean, working_img is others\n",
    "\n",
    "    # other_regions\n",
    "    # ==== Process of other regions. Generate \"other_regions\" ====\n",
    "    merged_reg_and_nei_flatten=list(chain.from_iterable(merged_reg_and_nei))\n",
    "    print(\"merged regions\", len(merged_reg_and_nei_flatten), len(set(merged_reg_and_nei_flatten)))\n",
    "    other_regions       = list(  set(range(1,MAX_region+1))-set(merged_reg_and_nei_flatten)  ) #region index exclude used regions. 1 to 200.\n",
    "    print(\"other_regions\",len(other_regions), len(set(other_regions)))\n",
    "    \n",
    "    dmn_img             = [] # Index of dmn_img is consistent with other_regions\n",
    "    NUM_other_regions   = len(other_regions) # number of clusters in other regions\n",
    "    dist_table_truth    = np.zeros((NUM_other_regions,NUM_region),dtype=int)\n",
    "    p_reg_label_dmn     = np.zeros(NUM_other_regions,dtype=int)   #one value. dominate label in predicted lagels.\n",
    "    grd_reg_answer_dmn  = np.zeros(NUM_other_regions,dtype=int)   #one value. dominate label in true answers.\n",
    "    p_reg_dmn_rate      = np.zeros(NUM_other_regions,dtype=float) #one value. dominate ratio in a region\n",
    "\n",
    "    #(1) other_regions      --> establish all other region table \n",
    "    for i,region_name in enumerate(other_regions): #check all other regions\n",
    "\n",
    "        #(a)===== predicted images (multiple values) =====\n",
    "        p_img        = all_region_image[region_name-1] # In this region, get their images. \"region_name-1\" is due to region index starts from 1 to 200\n",
    "        p_img_label  = Original_result[p_img]   # Predicted labels in the region.\n",
    "        p_img_total  = len(p_img)\n",
    "        # the value of predicted labels is the index of trainning region. These indices are the labels\n",
    "        # but these p_img_answer are predicted, may not always be the truth.\n",
    "        if not p_img: # if p_img is empty, skip this loop\n",
    "            dmn_img.append([])\n",
    "            continue\n",
    "\n",
    "        #(b)===== region dominate; one value =====\n",
    "        #region label\n",
    "        p_reg_label_dmn[i] = collections.Counter(p_img_label).most_common()[0][0] # one value\n",
    "        # region dominate rate\n",
    "        if(p_reg_label_dmn[i]>=0):\n",
    "            p_reg_dmn_rate[i] = collections.Counter(p_img_label).most_common()[0][1]/p_img_total\n",
    "        else:              # means invalid label\n",
    "            p_reg_dmn_rate[i] = 0\n",
    "\n",
    "\n",
    "        #(c)==== ground truth =====\n",
    "        grd_label                 = test_label_answer[p_img]  #multiple values\n",
    "        grd_reg_answer_dmn[i]     = collections.Counter(grd_label).most_common()[0][0] #one value\n",
    "\n",
    "\n",
    "        #(d)==== establish confusion table=====\n",
    "        for j in range(NUM_region):\n",
    "            dist_table_truth[i][j]=len(np.where(grd_label==j)[0])\n",
    "\n",
    "\n",
    "        #(e)=== collect dominated images =============\n",
    "        addr2=np.where( (p_img_label==p_reg_label_dmn[i]) & (p_img_label>=0) )[0] # ignore -1 which are non-consistency\n",
    "        #         the labels which  == 7               the labels which >= 0\n",
    "        temp=[]\n",
    "        for k in range(len(addr2)):\n",
    "            temp.append(p_img[addr2[k]])\n",
    "        dmn_img.append(temp)\n",
    "        #=============================================\n",
    "\n",
    "\n",
    "    df1 = pandas.DataFrame({\"other index\":other_regions}) # 1 to 200   other region index\n",
    "    df2 = pandas.DataFrame({\"pred label\":p_reg_label_dmn})      \n",
    "    df4 = pandas.DataFrame({\"truth\":grd_reg_answer_dmn})\n",
    "    df6 = pandas.DataFrame({\"rate\":np.round(p_reg_dmn_rate,2)})\n",
    "    df7 = pandas.DataFrame(dist_table_truth)\n",
    "    entire_table=pandas.concat([df1, df2, df4, df6, df7], axis=1)\n",
    "    print(\"All other regions\")\n",
    "    display(entire_table)\n",
    "\n",
    "\n",
    "\n",
    "    #(2)get regions according to conditions\n",
    "    NN=5 #choose top 5 regions\n",
    "    RATE=0.7\n",
    "    candidate_reg_by_top_NN=[]\n",
    "\n",
    "    # === get candidate regions by the order of dmn label 0 to 9 ====\n",
    "    for i in range(NUM_region):\n",
    "        # (2-1) ==== select region by rate > 0.7 and top 5 ====\n",
    "        index     = np.where(p_reg_label_dmn==i)[0] # index is the index of other_regions(0~183), rather than original entire region index 1 to 200        \n",
    "        working_table = entire_table.iloc[index]\n",
    "        working_table = working_table.sort_values(by=['rate'], ascending=False)\n",
    "        working_table = working_table.loc[working_table['rate'] > RATE]  #rate > 0.7\n",
    "        NUM_region_in_one_class = len(working_table.iloc[:NN])  #top 5\n",
    "               \n",
    "        # (2-2) ==== get candidate regions ====\n",
    "        # get top N records; save only the column 'other_reg', and transfer it to list from DataFrame by \"tolist()\"\n",
    "        candidate_reg_by_top_NN.append(working_table[:NN]['other index'].tolist())\n",
    "         \n",
    "    #(3) add regions and images\n",
    "    for i in range(NUM_region):\n",
    "        added_img=[]\n",
    "        if (len(candidate_reg_by_top_NN[i])>0):\n",
    "            for j in range(len(candidate_reg_by_top_NN[i])):\n",
    "                reg_addr  = np.where( np.array(other_regions)==candidate_reg_by_top_NN[i][j] )[0][0].tolist()\n",
    "                added_img = added_img + dmn_img[reg_addr]\n",
    "            # (3-1) add image\n",
    "            temp=len(merged_region_image[i])\n",
    "            merged_region_image[i] = merged_region_image[i] + added_img\n",
    "            merged_region_image[i] = list(set(merged_region_image[i]))\n",
    "            img_amount=len(merged_region_image[i])-temp\n",
    "            \n",
    "            # (3-2) add region\n",
    "            merged_reg_and_nei[i]  = merged_reg_and_nei[i] + candidate_reg_by_top_NN[i]\n",
    "            \n",
    "            # (3-3) print out\n",
    "            print(\"added label, regions, img amount:\", set(Original_result[added_img]), candidate_reg_by_top_NN[i], img_amount)\n",
    "\n",
    "            \n",
    "    # (4) collect residual images\n",
    "    # This works only for CIFAR10. All images in the MNIST and MNIST-TRAN are clean. No this issue.        \n",
    "    #20240105\n",
    "    if (not MNIST):\n",
    "    #if ((DATASET==2) or (DATASET==4)):\n",
    "        if (len(list(chain.from_iterable(candidate_reg_by_top_NN))) == 0):  #if no extra regions\n",
    "            #20240105\n",
    "            if (True):\n",
    "            #if(DATASET==4):\n",
    "                df = pandas.read_csv(PATH4)\n",
    "                tSNE_table = df.to_numpy()[:,:3]\n",
    "            else:\n",
    "                df = pandas.read_csv(PATH8)\n",
    "                tSNE_table = df.to_numpy()\n",
    "            print(\"tSNE_table\",np.shape(tSNE_table))\n",
    "\n",
    "            working_table=tSNE_table[working_img]\n",
    "            pairwise_dist=squareform(pdist(working_table, 'euclidean'))\n",
    "            print(\"pairwise_dist\",np.shape(pairwise_dist)) #value of data point, rather than image index\n",
    "\n",
    "            TopN=10\n",
    "            M=len(working_img)\n",
    "            nei_table_images  = np.zeros((M,TopN),dtype=int)  #contain top 10 images\n",
    "            nei_table_label   = np.zeros((M,TopN),dtype=int)\n",
    "            working_img_label = np.zeros(M,dtype=int)\n",
    "            for i in range(M):   \n",
    "                # fill up top 10 \n",
    "                addr=np.argsort(pairwise_dist[i])\n",
    "                for j in range(TopN):\n",
    "                    nei_table_images[i][j]=working_img[ addr[j+1] ] #Ignore first one. First one is itself\n",
    "                    nei_table_label[i][j] =Original_result[nei_table_images[i][j]]\n",
    "                # consistent\n",
    "                if (len(set(nei_table_label[i])) == 1): #only get the one which is entire consistent\n",
    "                    working_img_label[i]=nei_table_label[i][0]\n",
    "                else:\n",
    "                    working_img_label[i]=-1\n",
    "\n",
    "            print(\"nei_table_images\",np.shape(nei_table_images))\n",
    "            print(\"working_img_label\",working_img_label)\n",
    "\n",
    "            new_img=[] # just  for monitoring\n",
    "            for i in range(NUM_region):\n",
    "                addr=np.where(working_img_label==i)[0].tolist()\n",
    "                new_img.append(working_img[addr])\n",
    "                merged_region_image[i].extend(working_img[addr])\n",
    "            print(\"add residuals \",len(list(chain.from_iterable(new_img))))\n",
    "            print(\"number of next merged_region_image\", len(list(chain.from_iterable(merged_region_image))))\n",
    "        else:\n",
    "            print(\"Not getting into residuals\")\n",
    "\n",
    "    #save\n",
    "    if (SAVE_bool):\n",
    "        with open(newpath + '/merged_region_image_'+str(ITE+1)+'.pickle', 'wb') as f:\n",
    "            pickle.dump([merged_reg_and_nei, merged_region_image], f)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Makeup region_initials.pickle\n",
    "#### For both single network and integrate network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>X1</th>\n",
       "      <th>X2</th>\n",
       "      <th>X3</th>\n",
       "      <th>Class</th>\n",
       "      <th>Label</th>\n",
       "      <th>Spec200</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1.230895</td>\n",
       "      <td>-11.513212</td>\n",
       "      <td>18.781408</td>\n",
       "      <td>Cherry</td>\n",
       "      <td>2</td>\n",
       "      <td>177</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>3.190353</td>\n",
       "      <td>-14.243707</td>\n",
       "      <td>14.359673</td>\n",
       "      <td>Cherry</td>\n",
       "      <td>2</td>\n",
       "      <td>177</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1.832576</td>\n",
       "      <td>-12.109021</td>\n",
       "      <td>15.785449</td>\n",
       "      <td>Cherry</td>\n",
       "      <td>2</td>\n",
       "      <td>177</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1.880559</td>\n",
       "      <td>-12.113366</td>\n",
       "      <td>15.720321</td>\n",
       "      <td>Cherry</td>\n",
       "      <td>2</td>\n",
       "      <td>177</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5.759654</td>\n",
       "      <td>-13.821998</td>\n",
       "      <td>15.943708</td>\n",
       "      <td>Cherry</td>\n",
       "      <td>2</td>\n",
       "      <td>177</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         X1         X2         X3   Class  Label  Spec200\n",
       "0  1.230895 -11.513212  18.781408  Cherry      2      177\n",
       "1  3.190353 -14.243707  14.359673  Cherry      2      177\n",
       "2  1.832576 -12.109021  15.785449  Cherry      2      177\n",
       "3  1.880559 -12.113366  15.720321  Cherry      2      177\n",
       "4  5.759654 -13.821998  15.943708  Cherry      2      177"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "13076\n",
      "all_region_index\n",
      " [177 177 177 177 177]\n"
     ]
    }
   ],
   "source": [
    "df = pandas.read_csv(PATH4)\n",
    "display(df.head())\n",
    "#all_region_index = df.to_numpy().T[REGION_INDEX_LOC].astype(int)\n",
    "#print(len(all_region_index))\n",
    "all_region_index  = df[REG_COLUMN].to_numpy().astype(int)\n",
    "print(len(all_region_index))\n",
    "print(\"all_region_index\\n\",all_region_index[:5])\n",
    "\n",
    "all_region_image=[]\n",
    "MAX_region=max(all_region_index)\n",
    "for i in range(MAX_region):\n",
    "    addr=list(np.where(all_region_index==i+1)[0])\n",
    "    all_region_image.append(addr)    \n",
    "\n",
    "#save\n",
    "if (SAVE_bool):\n",
    "    with open('./region_initials.pickle', 'wb') as f:\n",
    "        pickle.dump([all_region_index, all_region_image], f)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Main function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def interpret_accu_results(path, AMOUNT_ITE):\n",
    "    df = pandas.read_csv(path)\n",
    "    label_table = df.to_numpy()\n",
    "    NUM_CRI=7  #number of our accuracy criteriors, now is 7\n",
    "    \n",
    "    criterion_string=\\\n",
    "    [ \"correct in 5-consensus\\n------------------------------------\\n5-consensus\\n\",\n",
    "     \"correct in 5-consensus\\n------------------------------------\\nall\\n\",\n",
    "     \"correct in train in 5-consensus\\n------------------------------------\\ntrain in 5-consensus\\n\",\n",
    "     \"correct in train in 5-consensus \\n------------------------------------\\nall\\n\",\n",
    "     \"correct in test in 5-consensus\\n------------------------------------\\ntest in 5-consensus\\n\",\n",
    "     \"correct in test in 5-consensus\\n------------------------------------\\nall\\n\",\n",
    "      \"correct\\n------------------\\nall\\n\",\n",
    "    ]\n",
    "    for SHIFT in range (NUM_CRI):\n",
    "        if (SHIFT+1==1):\n",
    "            print(\"(overall 5-consensus)\")\n",
    "        elif (SHIFT+1==3):\n",
    "            print(\"(clean)\")\n",
    "        elif (SHIFT+1==5):\n",
    "            print(\"(unclean)\")\n",
    "        elif (SHIFT+1==7):\n",
    "            print(\"(majority)\")\n",
    "        print(\"criterion\", SHIFT+1)\n",
    "        print(criterion_string[SHIFT])\n",
    "        for i in range(AMOUNT_ITE):\n",
    "            print(\"ITE\",label_table[NUM_CRI*i+SHIFT].T[0], \"   \",label_table[NUM_CRI*i+SHIFT].T[1],\"/\", label_table[NUM_CRI*i+SHIFT].T[2], \"=\",label_table[NUM_CRI*i+SHIFT].T[3])\n",
    "        print(\"\\n\\n\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "case= 1\n",
      "mergedseedclasslabels table\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[ 26,   6,   6],\n",
       "       [182,   1,   1],\n",
       "       [169,   7,   7],\n",
       "       [124,   2,   2],\n",
       "       [ 29,   4,   4],\n",
       "       [  1,   3,   3],\n",
       "       [ 57,   5,   5],\n",
       "       [ 76,   7,   8],\n",
       "       [ 53,   8,   9],\n",
       "       [ 52,   2,   2],\n",
       "       [183,   1,   1],\n",
       "       [ 59,   8,   9],\n",
       "       [ 24,   4,   4],\n",
       "       [164,   9,   7]], dtype=int64)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "merged_region\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[[182, 183], [124, 52], [1], [29, 24], [57], [26], [169, 76], [53, 59], [164]]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 182\n",
      "10 183\n",
      "total 2\n",
      "\n",
      "3 124\n",
      "9 52\n",
      "total 2\n",
      "\n",
      "5 1\n",
      "total 6\n",
      "\n",
      "4 29\n",
      "12 24\n",
      "total 2\n",
      "\n",
      "6 57\n",
      "total 1\n",
      "\n",
      "0 26\n",
      "total 6\n",
      "\n",
      "2 169\n",
      "7 76\n",
      "total 2\n",
      "\n",
      "8 53\n",
      "11 59\n",
      "total 2\n",
      "\n",
      "13 164\n",
      "total 1\n",
      "\n",
      "\n",
      "merged_reg_and_nei\n",
      "[182, 183]\n",
      "[124, 52]\n",
      "[1, 11, 12, 14, 15, 17]\n",
      "[29, 24]\n",
      "[57]\n",
      "[26, 3, 4, 5, 6, 8]\n",
      "[169, 76]\n",
      "[53, 59]\n",
      "[164]\n",
      "286 ( 1 ) 177 ( 10 ) = 463 \n",
      "282 ( 3 ) 524 ( 9 ) = 806 \n",
      "216 ( 5 ) = 216 \n",
      "169 ( 4 ) 183 ( 12 ) = 352 \n",
      "143 ( 6 ) = 143 \n",
      "96 ( 0 ) = 96 \n",
      "166 ( 2 ) 177 ( 7 ) = 343 \n",
      "472 ( 8 ) 501 ( 11 ) = 973 \n",
      "209 ( 13 ) = 209 \n",
      "\n",
      "merged_reg_and_nei_image\n",
      "463 [7306, 7307, 7316, 7317, 7338] ...\n",
      "806 [7309, 7373, 7390, 7430, 7433] ...\n",
      "216 [1247, 1254, 1255, 1257, 1258] ...\n",
      "352 [11820, 11829, 11831, 11837, 11838] ...\n",
      "143 [11671, 11672, 11673, 11674, 11675] ...\n",
      "96 [1246, 1253, 1256, 1264, 1269] ...\n",
      "343 [4616, 4694, 4700, 4761, 4763] ...\n",
      "973 [11793, 11821, 11822, 11827, 11828] ...\n",
      "209 [1844, 1845, 1846, 1847, 1848] ...\n",
      "NUM_region 9\n",
      "number of clean images 3601\n",
      "n, p1, p2 0 0 0\n",
      "NUM_CLASSES 9\n",
      "current_train_label:  [0, 1, 2, 3, 4, 5, 6, 7, 8]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_1\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv1d_1 (Conv1D)            (None, 1000, 6)           36        \n",
      "_________________________________________________________________\n",
      "average_pooling1d_1 (Average (None, 500, 6)            0         \n",
      "_________________________________________________________________\n",
      "conv1d_2 (Conv1D)            (None, 496, 16)           496       \n",
      "_________________________________________________________________\n",
      "average_pooling1d_2 (Average (None, 248, 16)           0         \n",
      "_________________________________________________________________\n",
      "conv1d_3 (Conv1D)            (None, 244, 120)          9720      \n",
      "_________________________________________________________________\n",
      "flatten_1 (Flatten)          (None, 29280)             0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 84)                2459604   \n",
      "_________________________________________________________________\n",
      "preds (Dense)                (None, 9)                 765       \n",
      "=================================================================\n",
      "Total params: 2,470,621\n",
      "Trainable params: 2,470,621\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Train on 3240 samples, validate on 361 samples\n",
      "Epoch 1/80\n",
      "3240/3240 [==============================] - 2s 661us/step - loss: 0.8263 - accuracy: 0.7704 - val_loss: 0.0833 - val_accuracy: 0.9751\n",
      "Epoch 2/80\n",
      "3240/3240 [==============================] - 0s 96us/step - loss: 0.0150 - accuracy: 0.9957 - val_loss: 0.0193 - val_accuracy: 0.9945\n",
      "Epoch 3/80\n",
      "3240/3240 [==============================] - 0s 94us/step - loss: 0.0027 - accuracy: 0.9997 - val_loss: 0.0092 - val_accuracy: 1.0000\n",
      "Epoch 4/80\n",
      "3240/3240 [==============================] - 0s 90us/step - loss: 9.2662e-04 - accuracy: 1.0000 - val_loss: 0.0055 - val_accuracy: 1.0000\n",
      "Epoch 5/80\n",
      "3240/3240 [==============================] - 0s 89us/step - loss: 6.3575e-04 - accuracy: 1.0000 - val_loss: 0.0044 - val_accuracy: 1.0000\n",
      "Epoch 6/80\n",
      "3240/3240 [==============================] - 0s 93us/step - loss: 4.2576e-04 - accuracy: 1.0000 - val_loss: 0.0042 - val_accuracy: 1.0000\n",
      "Epoch 7/80\n",
      "3240/3240 [==============================] - 0s 92us/step - loss: 3.3778e-04 - accuracy: 1.0000 - val_loss: 0.0038 - val_accuracy: 1.0000\n",
      "Epoch 8/80\n",
      "3240/3240 [==============================] - 0s 90us/step - loss: 2.8280e-04 - accuracy: 1.0000 - val_loss: 0.0036 - val_accuracy: 1.0000\n",
      "Epoch 9/80\n",
      "3240/3240 [==============================] - 0s 88us/step - loss: 2.3654e-04 - accuracy: 1.0000 - val_loss: 0.0034 - val_accuracy: 1.0000\n",
      "Epoch 10/80\n",
      "3240/3240 [==============================] - 0s 92us/step - loss: 2.0521e-04 - accuracy: 1.0000 - val_loss: 0.0032 - val_accuracy: 1.0000\n",
      "Epoch 11/80\n",
      "3240/3240 [==============================] - 0s 86us/step - loss: 1.7492e-04 - accuracy: 1.0000 - val_loss: 0.0032 - val_accuracy: 1.0000\n",
      "Epoch 12/80\n",
      "3240/3240 [==============================] - 0s 91us/step - loss: 1.5492e-04 - accuracy: 1.0000 - val_loss: 0.0031 - val_accuracy: 1.0000\n",
      "Epoch 13/80\n",
      "3240/3240 [==============================] - 0s 95us/step - loss: 1.3208e-04 - accuracy: 1.0000 - val_loss: 0.0030 - val_accuracy: 1.0000\n",
      "Epoch 14/80\n",
      "3240/3240 [==============================] - 0s 84us/step - loss: 1.2604e-04 - accuracy: 1.0000 - val_loss: 0.0027 - val_accuracy: 1.0000\n",
      "Epoch 15/80\n",
      "3240/3240 [==============================] - 0s 91us/step - loss: 1.0422e-04 - accuracy: 1.0000 - val_loss: 0.0029 - val_accuracy: 1.0000\n",
      "Epoch 16/80\n",
      "3240/3240 [==============================] - 0s 91us/step - loss: 8.9456e-05 - accuracy: 1.0000 - val_loss: 0.0028 - val_accuracy: 1.0000\n",
      "Epoch 17/80\n",
      "3240/3240 [==============================] - 0s 92us/step - loss: 7.9670e-05 - accuracy: 1.0000 - val_loss: 0.0028 - val_accuracy: 1.0000\n",
      "Epoch 18/80\n",
      "3240/3240 [==============================] - 0s 88us/step - loss: 7.2024e-05 - accuracy: 1.0000 - val_loss: 0.0027 - val_accuracy: 1.0000\n",
      "Epoch 19/80\n",
      "3240/3240 [==============================] - 0s 90us/step - loss: 6.5468e-05 - accuracy: 1.0000 - val_loss: 0.0027 - val_accuracy: 1.0000\n",
      "Epoch 20/80\n",
      "3240/3240 [==============================] - 0s 92us/step - loss: 5.9683e-05 - accuracy: 1.0000 - val_loss: 0.0029 - val_accuracy: 1.0000\n",
      "Epoch 21/80\n",
      "3240/3240 [==============================] - 0s 94us/step - loss: 5.2407e-05 - accuracy: 1.0000 - val_loss: 0.0027 - val_accuracy: 1.0000\n",
      "Epoch 22/80\n",
      "3240/3240 [==============================] - 0s 91us/step - loss: 4.9058e-05 - accuracy: 1.0000 - val_loss: 0.0025 - val_accuracy: 1.0000\n",
      "Epoch 23/80\n",
      "3240/3240 [==============================] - 0s 91us/step - loss: 4.3886e-05 - accuracy: 1.0000 - val_loss: 0.0027 - val_accuracy: 1.0000\n",
      "Epoch 24/80\n",
      "3240/3240 [==============================] - 0s 93us/step - loss: 4.0054e-05 - accuracy: 1.0000 - val_loss: 0.0025 - val_accuracy: 1.0000\n",
      "Epoch 25/80\n",
      "3240/3240 [==============================] - 0s 93us/step - loss: 3.6103e-05 - accuracy: 1.0000 - val_loss: 0.0027 - val_accuracy: 1.0000\n",
      "Epoch 26/80\n",
      "3240/3240 [==============================] - 0s 89us/step - loss: 3.3383e-05 - accuracy: 1.0000 - val_loss: 0.0026 - val_accuracy: 1.0000\n",
      "Epoch 27/80\n",
      "3240/3240 [==============================] - 0s 88us/step - loss: 3.0900e-05 - accuracy: 1.0000 - val_loss: 0.0027 - val_accuracy: 1.0000\n",
      "Epoch 28/80\n",
      "3240/3240 [==============================] - 0s 96us/step - loss: 2.9134e-05 - accuracy: 1.0000 - val_loss: 0.0029 - val_accuracy: 0.9972\n",
      "Epoch 29/80\n",
      "3240/3240 [==============================] - 0s 90us/step - loss: 2.6890e-05 - accuracy: 1.0000 - val_loss: 0.0025 - val_accuracy: 1.0000\n",
      "Epoch 30/80\n",
      "3240/3240 [==============================] - 0s 91us/step - loss: 2.4855e-05 - accuracy: 1.0000 - val_loss: 0.0027 - val_accuracy: 1.0000\n",
      "Epoch 31/80\n",
      "3240/3240 [==============================] - 0s 86us/step - loss: 2.3218e-05 - accuracy: 1.0000 - val_loss: 0.0025 - val_accuracy: 1.0000\n",
      "Epoch 32/80\n",
      "3240/3240 [==============================] - 0s 90us/step - loss: 2.1610e-05 - accuracy: 1.0000 - val_loss: 0.0027 - val_accuracy: 1.0000\n",
      "Epoch 33/80\n",
      "3240/3240 [==============================] - 0s 89us/step - loss: 2.0385e-05 - accuracy: 1.0000 - val_loss: 0.0027 - val_accuracy: 0.9972\n",
      "Epoch 34/80\n",
      "3240/3240 [==============================] - 0s 96us/step - loss: 1.9186e-05 - accuracy: 1.0000 - val_loss: 0.0025 - val_accuracy: 1.0000\n",
      "Epoch 00034: early stopping\n",
      "[[3.9694138e-02 4.7292633e-04 5.3611840e-04 ... 5.1383162e-01\n",
      "  1.8666670e-01 4.5233201e-03]\n",
      " [2.2050135e-07 1.7061941e-08 1.5706075e-06 ... 3.8246275e-04\n",
      "  9.9929452e-01 1.9604439e-04]\n",
      " [1.6215177e-03 2.9791586e-04 1.8455937e-04 ... 2.1902761e-01\n",
      "  5.8798832e-01 3.1158322e-02]\n",
      " ...\n",
      " [6.8084101e-16 1.4937343e-11 9.9050273e-12 ... 6.5096489e-10\n",
      "  9.9999964e-01 1.9329529e-09]\n",
      " [1.0122941e-10 3.2740968e-09 2.1000499e-10 ... 1.7191547e-06\n",
      "  4.3489990e-08 6.9336323e-08]\n",
      " [4.0348494e-17 5.2916027e-10 1.9224407e-10 ... 5.7742398e-11\n",
      "  1.0000000e+00 1.3528672e-13]]\n",
      "[6 7 7 ... 7 3 7]\n",
      "<class 'numpy.ndarray'>\n",
      "One CNN, r:  0\n",
      "Computing Time:  0:00:19.844612\n",
      "Model: \"sequential_1\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv1d_1 (Conv1D)            (None, 1000, 6)           36        \n",
      "_________________________________________________________________\n",
      "average_pooling1d_1 (Average (None, 500, 6)            0         \n",
      "_________________________________________________________________\n",
      "conv1d_2 (Conv1D)            (None, 496, 16)           496       \n",
      "_________________________________________________________________\n",
      "average_pooling1d_2 (Average (None, 248, 16)           0         \n",
      "_________________________________________________________________\n",
      "conv1d_3 (Conv1D)            (None, 244, 120)          9720      \n",
      "_________________________________________________________________\n",
      "flatten_1 (Flatten)          (None, 29280)             0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 84)                2459604   \n",
      "_________________________________________________________________\n",
      "preds (Dense)                (None, 9)                 765       \n",
      "=================================================================\n",
      "Total params: 2,470,621\n",
      "Trainable params: 2,470,621\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 3240 samples, validate on 361 samples\n",
      "Epoch 1/80\n",
      "3240/3240 [==============================] - 0s 149us/step - loss: 0.7034 - accuracy: 0.7941 - val_loss: 0.0164 - val_accuracy: 1.0000\n",
      "Epoch 2/80\n",
      "3240/3240 [==============================] - 0s 91us/step - loss: 0.0098 - accuracy: 0.9978 - val_loss: 0.0055 - val_accuracy: 0.9972\n",
      "Epoch 3/80\n",
      "3240/3240 [==============================] - 0s 88us/step - loss: 0.0026 - accuracy: 0.9997 - val_loss: 0.0058 - val_accuracy: 0.9972\n",
      "Epoch 4/80\n",
      "3240/3240 [==============================] - 0s 86us/step - loss: 0.0014 - accuracy: 1.0000 - val_loss: 0.0026 - val_accuracy: 1.0000\n",
      "Epoch 5/80\n",
      "3240/3240 [==============================] - 0s 90us/step - loss: 6.2271e-04 - accuracy: 1.0000 - val_loss: 0.0039 - val_accuracy: 0.9972\n",
      "Epoch 6/80\n",
      "3240/3240 [==============================] - 0s 87us/step - loss: 3.5910e-04 - accuracy: 1.0000 - val_loss: 0.0033 - val_accuracy: 0.9972\n",
      "Epoch 7/80\n",
      "3240/3240 [==============================] - 0s 87us/step - loss: 2.9115e-04 - accuracy: 1.0000 - val_loss: 0.0032 - val_accuracy: 0.9972\n",
      "Epoch 8/80\n",
      "3240/3240 [==============================] - 0s 87us/step - loss: 2.4960e-04 - accuracy: 1.0000 - val_loss: 0.0030 - val_accuracy: 0.9972\n",
      "Epoch 9/80\n",
      "3240/3240 [==============================] - 0s 92us/step - loss: 2.1915e-04 - accuracy: 1.0000 - val_loss: 0.0030 - val_accuracy: 0.9972\n",
      "Epoch 10/80\n",
      "3240/3240 [==============================] - 0s 91us/step - loss: 1.7429e-04 - accuracy: 1.0000 - val_loss: 0.0029 - val_accuracy: 0.9972\n",
      "Epoch 11/80\n",
      "3240/3240 [==============================] - 0s 88us/step - loss: 1.5069e-04 - accuracy: 1.0000 - val_loss: 0.0029 - val_accuracy: 0.9972\n",
      "Epoch 12/80\n",
      "3240/3240 [==============================] - 0s 86us/step - loss: 1.3413e-04 - accuracy: 1.0000 - val_loss: 0.0033 - val_accuracy: 0.9972\n",
      "Epoch 13/80\n",
      "3240/3240 [==============================] - 0s 89us/step - loss: 1.1740e-04 - accuracy: 1.0000 - val_loss: 0.0031 - val_accuracy: 0.9972\n",
      "Epoch 14/80\n",
      "3240/3240 [==============================] - 0s 83us/step - loss: 1.0625e-04 - accuracy: 1.0000 - val_loss: 0.0029 - val_accuracy: 0.9972\n",
      "Epoch 00014: early stopping\n",
      "[[1.8081220e-02 4.9143968e-05 5.5679097e-04 ... 2.1274927e-01\n",
      "  7.2990876e-01 2.1567484e-02]\n",
      " [1.3672495e-06 2.1232328e-08 5.5065038e-07 ... 4.1452772e-03\n",
      "  9.9426669e-01 1.3499468e-03]\n",
      " [2.2495294e-04 1.1978676e-05 1.8246166e-05 ... 3.0382031e-01\n",
      "  6.8331611e-01 9.9528199e-03]\n",
      " ...\n",
      " [1.3120616e-12 4.8536166e-12 7.4673163e-11 ... 1.8196518e-08\n",
      "  9.9997830e-01 2.9848636e-07]\n",
      " [1.6657569e-11 8.3664721e-11 7.2027127e-11 ... 1.5178293e-07\n",
      "  2.0994430e-06 4.5080028e-06]\n",
      " [7.5452396e-12 1.5004026e-09 1.4271093e-08 ... 3.2083618e-09\n",
      "  9.9999928e-01 3.2492889e-10]]\n",
      "[7 7 7 ... 7 3 7]\n",
      "<class 'numpy.ndarray'>\n",
      "One CNN, r:  1\n",
      "Computing Time:  0:00:26.732763\n",
      "Model: \"sequential_1\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv1d_1 (Conv1D)            (None, 1000, 6)           36        \n",
      "_________________________________________________________________\n",
      "average_pooling1d_1 (Average (None, 500, 6)            0         \n",
      "_________________________________________________________________\n",
      "conv1d_2 (Conv1D)            (None, 496, 16)           496       \n",
      "_________________________________________________________________\n",
      "average_pooling1d_2 (Average (None, 248, 16)           0         \n",
      "_________________________________________________________________\n",
      "conv1d_3 (Conv1D)            (None, 244, 120)          9720      \n",
      "_________________________________________________________________\n",
      "flatten_1 (Flatten)          (None, 29280)             0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 84)                2459604   \n",
      "_________________________________________________________________\n",
      "preds (Dense)                (None, 9)                 765       \n",
      "=================================================================\n",
      "Total params: 2,470,621\n",
      "Trainable params: 2,470,621\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Train on 3240 samples, validate on 361 samples\n",
      "Epoch 1/80\n",
      "3240/3240 [==============================] - 0s 149us/step - loss: 0.5535 - accuracy: 0.8293 - val_loss: 0.0099 - val_accuracy: 0.9945\n",
      "Epoch 2/80\n",
      "3240/3240 [==============================] - 0s 92us/step - loss: 0.0205 - accuracy: 0.9941 - val_loss: 0.0092 - val_accuracy: 0.9945\n",
      "Epoch 3/80\n",
      "3240/3240 [==============================] - 0s 85us/step - loss: 0.0035 - accuracy: 0.9988 - val_loss: 0.0059 - val_accuracy: 0.9972\n",
      "Epoch 4/80\n",
      "3240/3240 [==============================] - 0s 88us/step - loss: 0.0013 - accuracy: 0.9997 - val_loss: 0.0015 - val_accuracy: 1.0000\n",
      "Epoch 5/80\n",
      "3240/3240 [==============================] - 0s 87us/step - loss: 6.1607e-04 - accuracy: 1.0000 - val_loss: 0.0015 - val_accuracy: 1.0000\n",
      "Epoch 6/80\n",
      "3240/3240 [==============================] - 0s 87us/step - loss: 4.2021e-04 - accuracy: 1.0000 - val_loss: 0.0027 - val_accuracy: 1.0000\n",
      "Epoch 7/80\n",
      "3240/3240 [==============================] - 0s 92us/step - loss: 2.1261e-04 - accuracy: 1.0000 - val_loss: 0.0015 - val_accuracy: 1.0000\n",
      "Epoch 8/80\n",
      "3240/3240 [==============================] - 0s 90us/step - loss: 1.4884e-04 - accuracy: 1.0000 - val_loss: 0.0017 - val_accuracy: 1.0000\n",
      "Epoch 9/80\n",
      "3240/3240 [==============================] - 0s 87us/step - loss: 1.2613e-04 - accuracy: 1.0000 - val_loss: 0.0014 - val_accuracy: 1.0000\n",
      "Epoch 10/80\n",
      "3240/3240 [==============================] - 0s 90us/step - loss: 1.0953e-04 - accuracy: 1.0000 - val_loss: 0.0016 - val_accuracy: 1.0000\n",
      "Epoch 11/80\n",
      "3240/3240 [==============================] - 0s 89us/step - loss: 9.8750e-05 - accuracy: 1.0000 - val_loss: 0.0012 - val_accuracy: 1.0000\n",
      "Epoch 12/80\n",
      "3240/3240 [==============================] - 0s 87us/step - loss: 8.9182e-05 - accuracy: 1.0000 - val_loss: 0.0012 - val_accuracy: 1.0000\n",
      "Epoch 13/80\n",
      "3240/3240 [==============================] - 0s 90us/step - loss: 7.6229e-05 - accuracy: 1.0000 - val_loss: 0.0016 - val_accuracy: 1.0000\n",
      "Epoch 14/80\n",
      "3240/3240 [==============================] - 0s 87us/step - loss: 6.8841e-05 - accuracy: 1.0000 - val_loss: 0.0016 - val_accuracy: 1.0000\n",
      "Epoch 15/80\n",
      "3240/3240 [==============================] - 0s 90us/step - loss: 6.2496e-05 - accuracy: 1.0000 - val_loss: 0.0016 - val_accuracy: 1.0000\n",
      "Epoch 16/80\n",
      "3240/3240 [==============================] - 0s 88us/step - loss: 5.6843e-05 - accuracy: 1.0000 - val_loss: 0.0014 - val_accuracy: 1.0000\n",
      "Epoch 17/80\n",
      "3240/3240 [==============================] - 0s 87us/step - loss: 5.2716e-05 - accuracy: 1.0000 - val_loss: 0.0016 - val_accuracy: 1.0000\n",
      "Epoch 18/80\n",
      "3240/3240 [==============================] - 0s 87us/step - loss: 4.7740e-05 - accuracy: 1.0000 - val_loss: 0.0016 - val_accuracy: 1.0000\n",
      "Epoch 19/80\n",
      "3240/3240 [==============================] - 0s 90us/step - loss: 4.4084e-05 - accuracy: 1.0000 - val_loss: 0.0014 - val_accuracy: 1.0000\n",
      "Epoch 20/80\n",
      "3240/3240 [==============================] - 0s 85us/step - loss: 4.3176e-05 - accuracy: 1.0000 - val_loss: 0.0013 - val_accuracy: 1.0000\n",
      "Epoch 21/80\n",
      "3240/3240 [==============================] - 0s 92us/step - loss: 3.8643e-05 - accuracy: 1.0000 - val_loss: 0.0015 - val_accuracy: 1.0000\n",
      "Epoch 00021: early stopping\n",
      "[[2.2149413e-04 9.7479724e-04 5.1050303e-03 ... 7.1093774e-01\n",
      "  2.3462982e-01 1.7298642e-03]\n",
      " [2.3103280e-07 1.9126772e-05 1.3590109e-04 ... 1.3139703e-02\n",
      "  9.8642147e-01 9.2284543e-05]\n",
      " [3.7497239e-06 1.5520763e-04 4.0558996e-04 ... 6.2854993e-01\n",
      "  3.6715266e-01 5.5271707e-04]\n",
      " ...\n",
      " [1.1686404e-13 3.8725729e-09 2.1335562e-10 ... 1.1655018e-09\n",
      "  1.0000000e+00 2.7851510e-10]\n",
      " [3.1854437e-12 3.4546849e-10 3.2282255e-10 ... 4.0413174e-06\n",
      "  1.6882693e-08 7.3639344e-09]\n",
      " [1.5755221e-13 6.6645619e-08 2.0327473e-08 ... 7.2098422e-10\n",
      "  9.9999976e-01 8.7642364e-14]]\n",
      "[6 7 6 ... 7 3 7]\n",
      "<class 'numpy.ndarray'>\n",
      "One CNN, r:  2\n",
      "Computing Time:  0:00:35.664638\n",
      "Model: \"sequential_1\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv1d_1 (Conv1D)            (None, 1000, 6)           36        \n",
      "_________________________________________________________________\n",
      "average_pooling1d_1 (Average (None, 500, 6)            0         \n",
      "_________________________________________________________________\n",
      "conv1d_2 (Conv1D)            (None, 496, 16)           496       \n",
      "_________________________________________________________________\n",
      "average_pooling1d_2 (Average (None, 248, 16)           0         \n",
      "_________________________________________________________________\n",
      "conv1d_3 (Conv1D)            (None, 244, 120)          9720      \n",
      "_________________________________________________________________\n",
      "flatten_1 (Flatten)          (None, 29280)             0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 84)                2459604   \n",
      "_________________________________________________________________\n",
      "preds (Dense)                (None, 9)                 765       \n",
      "=================================================================\n",
      "Total params: 2,470,621\n",
      "Trainable params: 2,470,621\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 3240 samples, validate on 361 samples\n",
      "Epoch 1/80\n",
      "3240/3240 [==============================] - 1s 165us/step - loss: 0.4647 - accuracy: 0.8778 - val_loss: 0.0153 - val_accuracy: 0.9972\n",
      "Epoch 2/80\n",
      "3240/3240 [==============================] - 0s 90us/step - loss: 0.0057 - accuracy: 0.9985 - val_loss: 0.0114 - val_accuracy: 0.9972\n",
      "Epoch 3/80\n",
      "3240/3240 [==============================] - 0s 86us/step - loss: 0.0035 - accuracy: 0.9994 - val_loss: 0.0013 - val_accuracy: 1.0000\n",
      "Epoch 4/80\n",
      "3240/3240 [==============================] - 0s 87us/step - loss: 0.0011 - accuracy: 1.0000 - val_loss: 9.5536e-04 - val_accuracy: 1.0000\n",
      "Epoch 5/80\n",
      "3240/3240 [==============================] - 0s 88us/step - loss: 6.1729e-04 - accuracy: 1.0000 - val_loss: 7.5916e-04 - val_accuracy: 1.0000\n",
      "Epoch 6/80\n",
      "3240/3240 [==============================] - 0s 88us/step - loss: 1.8190e-04 - accuracy: 1.0000 - val_loss: 4.4452e-04 - val_accuracy: 1.0000\n",
      "Epoch 7/80\n",
      "3240/3240 [==============================] - 0s 87us/step - loss: 1.3773e-04 - accuracy: 1.0000 - val_loss: 4.6736e-04 - val_accuracy: 1.0000\n",
      "Epoch 8/80\n",
      "3240/3240 [==============================] - 0s 88us/step - loss: 1.1452e-04 - accuracy: 1.0000 - val_loss: 4.0796e-04 - val_accuracy: 1.0000\n",
      "Epoch 9/80\n",
      "3240/3240 [==============================] - 0s 86us/step - loss: 1.0211e-04 - accuracy: 1.0000 - val_loss: 3.7941e-04 - val_accuracy: 1.0000\n",
      "Epoch 10/80\n",
      "3240/3240 [==============================] - 0s 88us/step - loss: 9.1702e-05 - accuracy: 1.0000 - val_loss: 3.7003e-04 - val_accuracy: 1.0000\n",
      "Epoch 11/80\n",
      "3240/3240 [==============================] - 0s 86us/step - loss: 8.1740e-05 - accuracy: 1.0000 - val_loss: 3.3664e-04 - val_accuracy: 1.0000\n",
      "Epoch 12/80\n",
      "3240/3240 [==============================] - 0s 87us/step - loss: 7.5510e-05 - accuracy: 1.0000 - val_loss: 3.2540e-04 - val_accuracy: 1.0000\n",
      "Epoch 13/80\n",
      "3240/3240 [==============================] - 0s 87us/step - loss: 6.7225e-05 - accuracy: 1.0000 - val_loss: 3.0635e-04 - val_accuracy: 1.0000\n",
      "Epoch 14/80\n",
      "3240/3240 [==============================] - 0s 87us/step - loss: 6.0571e-05 - accuracy: 1.0000 - val_loss: 2.9051e-04 - val_accuracy: 1.0000\n",
      "Epoch 15/80\n",
      "3240/3240 [==============================] - 0s 88us/step - loss: 5.4656e-05 - accuracy: 1.0000 - val_loss: 2.6516e-04 - val_accuracy: 1.0000\n",
      "Epoch 16/80\n",
      "3240/3240 [==============================] - 0s 85us/step - loss: 5.0528e-05 - accuracy: 1.0000 - val_loss: 2.5575e-04 - val_accuracy: 1.0000\n",
      "Epoch 17/80\n",
      "3240/3240 [==============================] - 0s 89us/step - loss: 4.6378e-05 - accuracy: 1.0000 - val_loss: 2.3990e-04 - val_accuracy: 1.0000\n",
      "Epoch 18/80\n",
      "3240/3240 [==============================] - 0s 87us/step - loss: 4.2739e-05 - accuracy: 1.0000 - val_loss: 2.2589e-04 - val_accuracy: 1.0000\n",
      "Epoch 19/80\n",
      "3240/3240 [==============================] - 0s 84us/step - loss: 3.9276e-05 - accuracy: 1.0000 - val_loss: 2.3315e-04 - val_accuracy: 1.0000\n",
      "Epoch 20/80\n",
      "3240/3240 [==============================] - 0s 89us/step - loss: 3.6393e-05 - accuracy: 1.0000 - val_loss: 2.1134e-04 - val_accuracy: 1.0000\n",
      "Epoch 21/80\n",
      "3240/3240 [==============================] - 0s 86us/step - loss: 3.4602e-05 - accuracy: 1.0000 - val_loss: 2.1480e-04 - val_accuracy: 1.0000\n",
      "Epoch 22/80\n",
      "3240/3240 [==============================] - 0s 86us/step - loss: 3.1446e-05 - accuracy: 1.0000 - val_loss: 1.9862e-04 - val_accuracy: 1.0000\n",
      "Epoch 23/80\n",
      "3240/3240 [==============================] - 0s 83us/step - loss: 2.9110e-05 - accuracy: 1.0000 - val_loss: 1.7584e-04 - val_accuracy: 1.0000\n",
      "Epoch 24/80\n",
      "3240/3240 [==============================] - 0s 86us/step - loss: 2.7333e-05 - accuracy: 1.0000 - val_loss: 1.8497e-04 - val_accuracy: 1.0000\n",
      "Epoch 25/80\n",
      "3240/3240 [==============================] - 0s 85us/step - loss: 2.5473e-05 - accuracy: 1.0000 - val_loss: 1.7316e-04 - val_accuracy: 1.0000\n",
      "Epoch 26/80\n",
      "3240/3240 [==============================] - 0s 86us/step - loss: 2.4187e-05 - accuracy: 1.0000 - val_loss: 1.6610e-04 - val_accuracy: 1.0000\n",
      "Epoch 27/80\n",
      "3240/3240 [==============================] - 0s 88us/step - loss: 2.2769e-05 - accuracy: 1.0000 - val_loss: 1.6235e-04 - val_accuracy: 1.0000\n",
      "Epoch 28/80\n",
      "3240/3240 [==============================] - ETA: 0s - loss: 2.2090e-05 - accuracy: 1.00 - 0s 81us/step - loss: 2.1433e-05 - accuracy: 1.0000 - val_loss: 1.5472e-04 - val_accuracy: 1.0000\n",
      "Epoch 29/80\n",
      "3240/3240 [==============================] - 0s 89us/step - loss: 2.0090e-05 - accuracy: 1.0000 - val_loss: 1.5452e-04 - val_accuracy: 1.0000\n",
      "Epoch 30/80\n",
      "3240/3240 [==============================] - 0s 83us/step - loss: 1.9036e-05 - accuracy: 1.0000 - val_loss: 1.4589e-04 - val_accuracy: 1.0000\n",
      "Epoch 31/80\n",
      "3240/3240 [==============================] - 0s 87us/step - loss: 1.7991e-05 - accuracy: 1.0000 - val_loss: 1.4172e-04 - val_accuracy: 1.0000\n",
      "Epoch 32/80\n",
      "3240/3240 [==============================] - 0s 87us/step - loss: 1.6810e-05 - accuracy: 1.0000 - val_loss: 1.3420e-04 - val_accuracy: 1.0000\n",
      "Epoch 33/80\n",
      "3240/3240 [==============================] - 0s 85us/step - loss: 1.6045e-05 - accuracy: 1.0000 - val_loss: 1.3014e-04 - val_accuracy: 1.0000\n",
      "Epoch 34/80\n",
      "3240/3240 [==============================] - 0s 90us/step - loss: 1.5422e-05 - accuracy: 1.0000 - val_loss: 1.2748e-04 - val_accuracy: 1.0000\n",
      "Epoch 35/80\n",
      "3240/3240 [==============================] - 0s 80us/step - loss: 1.4447e-05 - accuracy: 1.0000 - val_loss: 1.2302e-04 - val_accuracy: 1.0000\n",
      "Epoch 36/80\n",
      "3240/3240 [==============================] - 0s 85us/step - loss: 1.3739e-05 - accuracy: 1.0000 - val_loss: 1.2696e-04 - val_accuracy: 1.0000\n",
      "Epoch 37/80\n",
      "3240/3240 [==============================] - 0s 86us/step - loss: 1.3108e-05 - accuracy: 1.0000 - val_loss: 1.2109e-04 - val_accuracy: 1.0000\n",
      "Epoch 38/80\n",
      "3240/3240 [==============================] - 0s 83us/step - loss: 1.2502e-05 - accuracy: 1.0000 - val_loss: 1.1795e-04 - val_accuracy: 1.0000\n",
      "Epoch 39/80\n",
      "3240/3240 [==============================] - 0s 87us/step - loss: 1.1905e-05 - accuracy: 1.0000 - val_loss: 1.2027e-04 - val_accuracy: 1.0000\n",
      "Epoch 40/80\n",
      "3240/3240 [==============================] - 0s 86us/step - loss: 1.1293e-05 - accuracy: 1.0000 - val_loss: 1.1558e-04 - val_accuracy: 1.0000\n",
      "Epoch 41/80\n",
      "3240/3240 [==============================] - 0s 87us/step - loss: 1.0787e-05 - accuracy: 1.0000 - val_loss: 1.1612e-04 - val_accuracy: 1.0000\n",
      "Epoch 42/80\n",
      "3240/3240 [==============================] - 0s 85us/step - loss: 1.0387e-05 - accuracy: 1.0000 - val_loss: 1.1116e-04 - val_accuracy: 1.0000\n",
      "Epoch 43/80\n",
      "3240/3240 [==============================] - 0s 85us/step - loss: 9.8511e-06 - accuracy: 1.0000 - val_loss: 1.0555e-04 - val_accuracy: 1.0000\n",
      "Epoch 44/80\n",
      "3240/3240 [==============================] - 0s 85us/step - loss: 9.4697e-06 - accuracy: 1.0000 - val_loss: 1.0476e-04 - val_accuracy: 1.0000\n",
      "Epoch 45/80\n",
      "3240/3240 [==============================] - 0s 87us/step - loss: 9.0836e-06 - accuracy: 1.0000 - val_loss: 1.0758e-04 - val_accuracy: 1.0000\n",
      "Epoch 46/80\n",
      "3240/3240 [==============================] - 0s 88us/step - loss: 8.6766e-06 - accuracy: 1.0000 - val_loss: 1.0269e-04 - val_accuracy: 1.0000\n",
      "Epoch 47/80\n",
      "3240/3240 [==============================] - 0s 85us/step - loss: 8.3523e-06 - accuracy: 1.0000 - val_loss: 1.0234e-04 - val_accuracy: 1.0000\n",
      "Epoch 48/80\n",
      "3240/3240 [==============================] - 0s 86us/step - loss: 7.8862e-06 - accuracy: 1.0000 - val_loss: 9.6257e-05 - val_accuracy: 1.0000\n",
      "Epoch 49/80\n",
      "3240/3240 [==============================] - 0s 87us/step - loss: 7.6635e-06 - accuracy: 1.0000 - val_loss: 9.8419e-05 - val_accuracy: 1.0000\n",
      "Epoch 50/80\n",
      "3240/3240 [==============================] - 0s 87us/step - loss: 7.2439e-06 - accuracy: 1.0000 - val_loss: 9.6069e-05 - val_accuracy: 1.0000\n",
      "Epoch 51/80\n",
      "3240/3240 [==============================] - 0s 88us/step - loss: 6.9286e-06 - accuracy: 1.0000 - val_loss: 9.6150e-05 - val_accuracy: 1.0000\n",
      "Epoch 52/80\n",
      "3240/3240 [==============================] - 0s 85us/step - loss: 6.6692e-06 - accuracy: 1.0000 - val_loss: 9.2225e-05 - val_accuracy: 1.0000\n",
      "Epoch 53/80\n",
      "3240/3240 [==============================] - 0s 87us/step - loss: 6.4359e-06 - accuracy: 1.0000 - val_loss: 8.8797e-05 - val_accuracy: 1.0000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 54/80\n",
      "3240/3240 [==============================] - 0s 87us/step - loss: 6.1507e-06 - accuracy: 1.0000 - val_loss: 9.1332e-05 - val_accuracy: 1.0000\n",
      "Epoch 55/80\n",
      "3240/3240 [==============================] - 0s 86us/step - loss: 5.9003e-06 - accuracy: 1.0000 - val_loss: 8.6908e-05 - val_accuracy: 1.0000\n",
      "Epoch 56/80\n",
      "3240/3240 [==============================] - 0s 88us/step - loss: 5.6577e-06 - accuracy: 1.0000 - val_loss: 8.5709e-05 - val_accuracy: 1.0000\n",
      "Epoch 57/80\n",
      "3240/3240 [==============================] - 0s 89us/step - loss: 5.4115e-06 - accuracy: 1.0000 - val_loss: 8.8178e-05 - val_accuracy: 1.0000\n",
      "Epoch 58/80\n",
      "3240/3240 [==============================] - 0s 90us/step - loss: 5.2014e-06 - accuracy: 1.0000 - val_loss: 8.4061e-05 - val_accuracy: 1.0000\n",
      "Epoch 59/80\n",
      "3240/3240 [==============================] - 0s 90us/step - loss: 4.9959e-06 - accuracy: 1.0000 - val_loss: 8.0999e-05 - val_accuracy: 1.0000\n",
      "Epoch 60/80\n",
      "3240/3240 [==============================] - 0s 85us/step - loss: 4.8102e-06 - accuracy: 1.0000 - val_loss: 7.8559e-05 - val_accuracy: 1.0000\n",
      "Epoch 61/80\n",
      "3240/3240 [==============================] - 0s 92us/step - loss: 4.6416e-06 - accuracy: 1.0000 - val_loss: 7.8386e-05 - val_accuracy: 1.0000\n",
      "Epoch 62/80\n",
      "3240/3240 [==============================] - 0s 86us/step - loss: 4.4324e-06 - accuracy: 1.0000 - val_loss: 7.5774e-05 - val_accuracy: 1.0000\n",
      "Epoch 63/80\n",
      "3240/3240 [==============================] - 0s 87us/step - loss: 4.2605e-06 - accuracy: 1.0000 - val_loss: 7.5477e-05 - val_accuracy: 1.0000\n",
      "Epoch 64/80\n",
      "3240/3240 [==============================] - 0s 90us/step - loss: 4.0812e-06 - accuracy: 1.0000 - val_loss: 7.3416e-05 - val_accuracy: 1.0000\n",
      "Epoch 65/80\n",
      "3240/3240 [==============================] - 0s 88us/step - loss: 3.9246e-06 - accuracy: 1.0000 - val_loss: 7.7750e-05 - val_accuracy: 1.0000\n",
      "Epoch 66/80\n",
      "3240/3240 [==============================] - 0s 89us/step - loss: 3.7867e-06 - accuracy: 1.0000 - val_loss: 7.5920e-05 - val_accuracy: 1.0000\n",
      "Epoch 67/80\n",
      "3240/3240 [==============================] - 0s 80us/step - loss: 3.6075e-06 - accuracy: 1.0000 - val_loss: 7.4106e-05 - val_accuracy: 1.0000\n",
      "Epoch 68/80\n",
      "3240/3240 [==============================] - 0s 87us/step - loss: 3.4663e-06 - accuracy: 1.0000 - val_loss: 7.0344e-05 - val_accuracy: 1.0000\n",
      "Epoch 69/80\n",
      "3240/3240 [==============================] - 0s 88us/step - loss: 3.3558e-06 - accuracy: 1.0000 - val_loss: 7.0605e-05 - val_accuracy: 1.0000\n",
      "Epoch 70/80\n",
      "3240/3240 [==============================] - 0s 86us/step - loss: 3.2119e-06 - accuracy: 1.0000 - val_loss: 6.9459e-05 - val_accuracy: 1.0000\n",
      "Epoch 71/80\n",
      "3240/3240 [==============================] - 0s 86us/step - loss: 3.1054e-06 - accuracy: 1.0000 - val_loss: 6.9544e-05 - val_accuracy: 1.0000\n",
      "Epoch 72/80\n",
      "3240/3240 [==============================] - 0s 87us/step - loss: 3.0081e-06 - accuracy: 1.0000 - val_loss: 6.8806e-05 - val_accuracy: 1.0000\n",
      "Epoch 73/80\n",
      "3240/3240 [==============================] - 0s 91us/step - loss: 2.8762e-06 - accuracy: 1.0000 - val_loss: 6.6766e-05 - val_accuracy: 1.0000\n",
      "Epoch 74/80\n",
      "3240/3240 [==============================] - 0s 87us/step - loss: 2.7850e-06 - accuracy: 1.0000 - val_loss: 6.6671e-05 - val_accuracy: 1.0000\n",
      "Epoch 75/80\n",
      "3240/3240 [==============================] - 0s 82us/step - loss: 2.6723e-06 - accuracy: 1.0000 - val_loss: 6.0976e-05 - val_accuracy: 1.0000\n",
      "Epoch 76/80\n",
      "3240/3240 [==============================] - 0s 91us/step - loss: 2.6166e-06 - accuracy: 1.0000 - val_loss: 6.4741e-05 - val_accuracy: 1.0000\n",
      "Epoch 77/80\n",
      "3240/3240 [==============================] - 0s 82us/step - loss: 2.4883e-06 - accuracy: 1.0000 - val_loss: 6.5046e-05 - val_accuracy: 1.0000\n",
      "Epoch 78/80\n",
      "3240/3240 [==============================] - 0s 86us/step - loss: 2.4063e-06 - accuracy: 1.0000 - val_loss: 6.1358e-05 - val_accuracy: 1.0000\n",
      "Epoch 79/80\n",
      "3240/3240 [==============================] - 0s 86us/step - loss: 2.3271e-06 - accuracy: 1.0000 - val_loss: 6.1409e-05 - val_accuracy: 1.0000\n",
      "Epoch 80/80\n",
      "3240/3240 [==============================] - 0s 83us/step - loss: 2.2346e-06 - accuracy: 1.0000 - val_loss: 5.8117e-05 - val_accuracy: 1.0000\n",
      "[[3.8981497e-02 8.2738632e-07 6.8460332e-07 ... 4.3465877e-01\n",
      "  4.7535697e-01 4.3406701e-03]\n",
      " [2.1127232e-06 1.8699096e-10 1.0387506e-10 ... 5.3750714e-03\n",
      "  9.9424380e-01 2.1584630e-04]\n",
      " [9.8922494e-05 1.8520117e-07 8.7714866e-09 ... 2.9510856e-01\n",
      "  7.0246571e-01 4.7059797e-04]\n",
      " ...\n",
      " [5.4562313e-15 4.0178504e-15 1.1673486e-16 ... 3.2118877e-11\n",
      "  1.0000000e+00 4.2057816e-12]\n",
      " [8.0727020e-16 7.7229711e-17 2.1858036e-19 ... 2.4156963e-08\n",
      "  4.3396567e-12 7.1433527e-07]\n",
      " [1.2089177e-12 1.3862360e-10 3.1902905e-12 ... 1.5879925e-12\n",
      "  1.0000000e+00 2.1250009e-16]]\n",
      "[7 7 7 ... 7 3 7]\n",
      "<class 'numpy.ndarray'>\n",
      "One CNN, r:  3\n",
      "Computing Time:  0:01:01.352118\n",
      "Model: \"sequential_1\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv1d_1 (Conv1D)            (None, 1000, 6)           36        \n",
      "_________________________________________________________________\n",
      "average_pooling1d_1 (Average (None, 500, 6)            0         \n",
      "_________________________________________________________________\n",
      "conv1d_2 (Conv1D)            (None, 496, 16)           496       \n",
      "_________________________________________________________________\n",
      "average_pooling1d_2 (Average (None, 248, 16)           0         \n",
      "_________________________________________________________________\n",
      "conv1d_3 (Conv1D)            (None, 244, 120)          9720      \n",
      "_________________________________________________________________\n",
      "flatten_1 (Flatten)          (None, 29280)             0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 84)                2459604   \n",
      "_________________________________________________________________\n",
      "preds (Dense)                (None, 9)                 765       \n",
      "=================================================================\n",
      "Total params: 2,470,621\n",
      "Trainable params: 2,470,621\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Train on 3240 samples, validate on 361 samples\n",
      "Epoch 1/80\n",
      "3240/3240 [==============================] - 1s 159us/step - loss: 0.4689 - accuracy: 0.8463 - val_loss: 0.0179 - val_accuracy: 0.9917\n",
      "Epoch 2/80\n",
      "3240/3240 [==============================] - 0s 89us/step - loss: 0.0051 - accuracy: 0.9988 - val_loss: 0.0153 - val_accuracy: 0.9945\n",
      "Epoch 3/80\n",
      "3240/3240 [==============================] - 0s 87us/step - loss: 0.0019 - accuracy: 0.9997 - val_loss: 0.0193 - val_accuracy: 0.9917\n",
      "Epoch 4/80\n",
      "3240/3240 [==============================] - 0s 86us/step - loss: 5.1340e-04 - accuracy: 1.0000 - val_loss: 0.0034 - val_accuracy: 0.9972\n",
      "Epoch 5/80\n",
      "3240/3240 [==============================] - 0s 86us/step - loss: 1.8585e-04 - accuracy: 1.0000 - val_loss: 0.0016 - val_accuracy: 1.0000\n",
      "Epoch 6/80\n",
      "3240/3240 [==============================] - 0s 88us/step - loss: 1.0193e-04 - accuracy: 1.0000 - val_loss: 0.0012 - val_accuracy: 1.0000\n",
      "Epoch 7/80\n",
      "3240/3240 [==============================] - 0s 86us/step - loss: 9.0214e-05 - accuracy: 1.0000 - val_loss: 0.0015 - val_accuracy: 1.0000\n",
      "Epoch 8/80\n",
      "3240/3240 [==============================] - 0s 87us/step - loss: 7.0207e-05 - accuracy: 1.0000 - val_loss: 0.0011 - val_accuracy: 1.0000\n",
      "Epoch 9/80\n",
      "3240/3240 [==============================] - 0s 87us/step - loss: 6.2317e-05 - accuracy: 1.0000 - val_loss: 0.0011 - val_accuracy: 1.0000\n",
      "Epoch 10/80\n",
      "3240/3240 [==============================] - 0s 85us/step - loss: 5.6626e-05 - accuracy: 1.0000 - val_loss: 0.0010 - val_accuracy: 1.0000\n",
      "Epoch 11/80\n",
      "3240/3240 [==============================] - 0s 83us/step - loss: 5.2129e-05 - accuracy: 1.0000 - val_loss: 0.0011 - val_accuracy: 1.0000\n",
      "Epoch 12/80\n",
      "3240/3240 [==============================] - 0s 86us/step - loss: 4.7048e-05 - accuracy: 1.0000 - val_loss: 0.0010 - val_accuracy: 1.0000\n",
      "Epoch 13/80\n",
      "3240/3240 [==============================] - 0s 87us/step - loss: 4.3782e-05 - accuracy: 1.0000 - val_loss: 9.7868e-04 - val_accuracy: 1.0000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 14/80\n",
      "3240/3240 [==============================] - 0s 91us/step - loss: 4.0736e-05 - accuracy: 1.0000 - val_loss: 9.3472e-04 - val_accuracy: 1.0000\n",
      "Epoch 15/80\n",
      "3240/3240 [==============================] - 0s 83us/step - loss: 3.7795e-05 - accuracy: 1.0000 - val_loss: 9.1536e-04 - val_accuracy: 1.0000\n",
      "Epoch 16/80\n",
      "3240/3240 [==============================] - 0s 81us/step - loss: 3.5257e-05 - accuracy: 1.0000 - val_loss: 8.3966e-04 - val_accuracy: 1.0000\n",
      "Epoch 17/80\n",
      "3240/3240 [==============================] - 0s 92us/step - loss: 3.2434e-05 - accuracy: 1.0000 - val_loss: 9.0201e-04 - val_accuracy: 1.0000\n",
      "Epoch 18/80\n",
      "3240/3240 [==============================] - 0s 87us/step - loss: 3.0375e-05 - accuracy: 1.0000 - val_loss: 8.5784e-04 - val_accuracy: 1.0000\n",
      "Epoch 19/80\n",
      "3240/3240 [==============================] - 0s 87us/step - loss: 2.8582e-05 - accuracy: 1.0000 - val_loss: 8.3916e-04 - val_accuracy: 1.0000\n",
      "Epoch 20/80\n",
      "3240/3240 [==============================] - 0s 90us/step - loss: 2.6817e-05 - accuracy: 1.0000 - val_loss: 8.5264e-04 - val_accuracy: 1.0000\n",
      "Epoch 21/80\n",
      "3240/3240 [==============================] - 0s 86us/step - loss: 2.5238e-05 - accuracy: 1.0000 - val_loss: 8.4016e-04 - val_accuracy: 1.0000\n",
      "Epoch 22/80\n",
      "3240/3240 [==============================] - 0s 87us/step - loss: 2.3295e-05 - accuracy: 1.0000 - val_loss: 7.8800e-04 - val_accuracy: 1.0000\n",
      "Epoch 23/80\n",
      "3240/3240 [==============================] - 0s 87us/step - loss: 2.2016e-05 - accuracy: 1.0000 - val_loss: 7.6679e-04 - val_accuracy: 1.0000\n",
      "Epoch 24/80\n",
      "3240/3240 [==============================] - 0s 90us/step - loss: 2.1050e-05 - accuracy: 1.0000 - val_loss: 7.9334e-04 - val_accuracy: 1.0000\n",
      "Epoch 25/80\n",
      "3240/3240 [==============================] - 0s 87us/step - loss: 1.9925e-05 - accuracy: 1.0000 - val_loss: 7.5684e-04 - val_accuracy: 1.0000\n",
      "Epoch 26/80\n",
      "3240/3240 [==============================] - 0s 83us/step - loss: 1.8862e-05 - accuracy: 1.0000 - val_loss: 7.5963e-04 - val_accuracy: 1.0000\n",
      "Epoch 27/80\n",
      "3240/3240 [==============================] - 0s 87us/step - loss: 1.7866e-05 - accuracy: 1.0000 - val_loss: 7.1235e-04 - val_accuracy: 1.0000\n",
      "Epoch 28/80\n",
      "3240/3240 [==============================] - 0s 89us/step - loss: 1.6934e-05 - accuracy: 1.0000 - val_loss: 6.9252e-04 - val_accuracy: 1.0000\n",
      "Epoch 29/80\n",
      "3240/3240 [==============================] - 0s 85us/step - loss: 1.6217e-05 - accuracy: 1.0000 - val_loss: 7.3599e-04 - val_accuracy: 1.0000\n",
      "Epoch 30/80\n",
      "3240/3240 [==============================] - 0s 89us/step - loss: 1.5360e-05 - accuracy: 1.0000 - val_loss: 6.7701e-04 - val_accuracy: 1.0000\n",
      "Epoch 31/80\n",
      "3240/3240 [==============================] - 0s 84us/step - loss: 1.4649e-05 - accuracy: 1.0000 - val_loss: 6.9119e-04 - val_accuracy: 1.0000\n",
      "Epoch 32/80\n",
      "3240/3240 [==============================] - 0s 87us/step - loss: 1.4077e-05 - accuracy: 1.0000 - val_loss: 6.7275e-04 - val_accuracy: 1.0000\n",
      "Epoch 33/80\n",
      "3240/3240 [==============================] - 0s 89us/step - loss: 1.3261e-05 - accuracy: 1.0000 - val_loss: 6.8494e-04 - val_accuracy: 1.0000\n",
      "Epoch 34/80\n",
      "3240/3240 [==============================] - 0s 84us/step - loss: 1.2754e-05 - accuracy: 1.0000 - val_loss: 6.6401e-04 - val_accuracy: 1.0000\n",
      "Epoch 35/80\n",
      "3240/3240 [==============================] - 0s 91us/step - loss: 1.2257e-05 - accuracy: 1.0000 - val_loss: 6.5938e-04 - val_accuracy: 1.0000\n",
      "Epoch 36/80\n",
      "3240/3240 [==============================] - 0s 87us/step - loss: 1.1653e-05 - accuracy: 1.0000 - val_loss: 6.4230e-04 - val_accuracy: 1.0000\n",
      "Epoch 37/80\n",
      "3240/3240 [==============================] - 0s 86us/step - loss: 1.1194e-05 - accuracy: 1.0000 - val_loss: 6.5873e-04 - val_accuracy: 1.0000\n",
      "Epoch 38/80\n",
      "3240/3240 [==============================] - 0s 85us/step - loss: 1.0691e-05 - accuracy: 1.0000 - val_loss: 6.1265e-04 - val_accuracy: 1.0000\n",
      "Epoch 39/80\n",
      "3240/3240 [==============================] - 0s 83us/step - loss: 1.0290e-05 - accuracy: 1.0000 - val_loss: 6.1973e-04 - val_accuracy: 1.0000\n",
      "Epoch 40/80\n",
      "3240/3240 [==============================] - 0s 88us/step - loss: 9.8537e-06 - accuracy: 1.0000 - val_loss: 6.2921e-04 - val_accuracy: 1.0000\n",
      "Epoch 41/80\n",
      "3240/3240 [==============================] - 0s 84us/step - loss: 9.4441e-06 - accuracy: 1.0000 - val_loss: 5.9761e-04 - val_accuracy: 1.0000\n",
      "Epoch 42/80\n",
      "3240/3240 [==============================] - 0s 87us/step - loss: 8.9996e-06 - accuracy: 1.0000 - val_loss: 5.9141e-04 - val_accuracy: 1.0000\n",
      "Epoch 43/80\n",
      "3240/3240 [==============================] - 0s 87us/step - loss: 8.7196e-06 - accuracy: 1.0000 - val_loss: 6.0586e-04 - val_accuracy: 1.0000\n",
      "Epoch 44/80\n",
      "3240/3240 [==============================] - 0s 86us/step - loss: 8.5572e-06 - accuracy: 1.0000 - val_loss: 6.3091e-04 - val_accuracy: 1.0000\n",
      "Epoch 45/80\n",
      "3240/3240 [==============================] - 0s 87us/step - loss: 8.0271e-06 - accuracy: 1.0000 - val_loss: 5.6338e-04 - val_accuracy: 1.0000\n",
      "Epoch 46/80\n",
      "3240/3240 [==============================] - 0s 90us/step - loss: 7.7889e-06 - accuracy: 1.0000 - val_loss: 5.6221e-04 - val_accuracy: 1.0000\n",
      "Epoch 47/80\n",
      "3240/3240 [==============================] - 0s 86us/step - loss: 7.4688e-06 - accuracy: 1.0000 - val_loss: 5.7445e-04 - val_accuracy: 1.0000\n",
      "Epoch 48/80\n",
      "3240/3240 [==============================] - 0s 86us/step - loss: 7.2356e-06 - accuracy: 1.0000 - val_loss: 5.3707e-04 - val_accuracy: 1.0000\n",
      "Epoch 49/80\n",
      "3240/3240 [==============================] - 0s 84us/step - loss: 6.9716e-06 - accuracy: 1.0000 - val_loss: 5.5178e-04 - val_accuracy: 1.0000\n",
      "Epoch 50/80\n",
      "3240/3240 [==============================] - 0s 90us/step - loss: 6.7021e-06 - accuracy: 1.0000 - val_loss: 5.5690e-04 - val_accuracy: 1.0000\n",
      "Epoch 51/80\n",
      "3240/3240 [==============================] - 0s 87us/step - loss: 6.4643e-06 - accuracy: 1.0000 - val_loss: 5.4958e-04 - val_accuracy: 1.0000\n",
      "Epoch 52/80\n",
      "3240/3240 [==============================] - 0s 88us/step - loss: 6.2847e-06 - accuracy: 1.0000 - val_loss: 5.4012e-04 - val_accuracy: 1.0000\n",
      "Epoch 53/80\n",
      "3240/3240 [==============================] - 0s 88us/step - loss: 6.0457e-06 - accuracy: 1.0000 - val_loss: 5.3644e-04 - val_accuracy: 1.0000\n",
      "Epoch 54/80\n",
      "3240/3240 [==============================] - 0s 86us/step - loss: 5.8423e-06 - accuracy: 1.0000 - val_loss: 5.3419e-04 - val_accuracy: 1.0000\n",
      "Epoch 55/80\n",
      "3240/3240 [==============================] - 0s 87us/step - loss: 5.6816e-06 - accuracy: 1.0000 - val_loss: 5.1120e-04 - val_accuracy: 1.0000\n",
      "Epoch 56/80\n",
      "3240/3240 [==============================] - 0s 86us/step - loss: 5.4676e-06 - accuracy: 1.0000 - val_loss: 5.0580e-04 - val_accuracy: 1.0000\n",
      "Epoch 57/80\n",
      "3240/3240 [==============================] - 0s 86us/step - loss: 5.2938e-06 - accuracy: 1.0000 - val_loss: 5.2355e-04 - val_accuracy: 1.0000\n",
      "Epoch 58/80\n",
      "3240/3240 [==============================] - 0s 85us/step - loss: 5.1359e-06 - accuracy: 1.0000 - val_loss: 5.2189e-04 - val_accuracy: 1.0000\n",
      "Epoch 59/80\n",
      "3240/3240 [==============================] - 0s 87us/step - loss: 5.0132e-06 - accuracy: 1.0000 - val_loss: 5.0208e-04 - val_accuracy: 1.0000\n",
      "Epoch 60/80\n",
      "3240/3240 [==============================] - 0s 88us/step - loss: 4.8125e-06 - accuracy: 1.0000 - val_loss: 5.0337e-04 - val_accuracy: 1.0000\n",
      "Epoch 61/80\n",
      "3240/3240 [==============================] - 0s 87us/step - loss: 4.6799e-06 - accuracy: 1.0000 - val_loss: 4.8360e-04 - val_accuracy: 1.0000\n",
      "Epoch 62/80\n",
      "3240/3240 [==============================] - 0s 88us/step - loss: 4.5463e-06 - accuracy: 1.0000 - val_loss: 4.9212e-04 - val_accuracy: 1.0000\n",
      "Epoch 63/80\n",
      "3240/3240 [==============================] - 0s 85us/step - loss: 4.5127e-06 - accuracy: 1.0000 - val_loss: 5.1099e-04 - val_accuracy: 1.0000\n",
      "Epoch 64/80\n",
      "3240/3240 [==============================] - 0s 87us/step - loss: 4.2791e-06 - accuracy: 1.0000 - val_loss: 4.6423e-04 - val_accuracy: 1.0000\n",
      "Epoch 65/80\n",
      "3240/3240 [==============================] - 0s 87us/step - loss: 4.1510e-06 - accuracy: 1.0000 - val_loss: 4.5702e-04 - val_accuracy: 1.0000\n",
      "Epoch 66/80\n",
      "3240/3240 [==============================] - 0s 85us/step - loss: 4.0325e-06 - accuracy: 1.0000 - val_loss: 4.7910e-04 - val_accuracy: 1.0000\n",
      "Epoch 67/80\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3240/3240 [==============================] - 0s 83us/step - loss: 3.9066e-06 - accuracy: 1.0000 - val_loss: 4.6120e-04 - val_accuracy: 1.0000\n",
      "Epoch 68/80\n",
      "3240/3240 [==============================] - 0s 91us/step - loss: 3.8049e-06 - accuracy: 1.0000 - val_loss: 4.4726e-04 - val_accuracy: 1.0000\n",
      "Epoch 69/80\n",
      "3240/3240 [==============================] - 0s 87us/step - loss: 3.7088e-06 - accuracy: 1.0000 - val_loss: 4.8548e-04 - val_accuracy: 1.0000\n",
      "Epoch 70/80\n",
      "3240/3240 [==============================] - 0s 86us/step - loss: 3.6054e-06 - accuracy: 1.0000 - val_loss: 4.4977e-04 - val_accuracy: 1.0000\n",
      "Epoch 71/80\n",
      "3240/3240 [==============================] - 0s 89us/step - loss: 3.4849e-06 - accuracy: 1.0000 - val_loss: 4.4809e-04 - val_accuracy: 1.0000\n",
      "Epoch 72/80\n",
      "3240/3240 [==============================] - 0s 88us/step - loss: 3.4033e-06 - accuracy: 1.0000 - val_loss: 4.3872e-04 - val_accuracy: 1.0000\n",
      "Epoch 73/80\n",
      "3240/3240 [==============================] - 0s 87us/step - loss: 3.2980e-06 - accuracy: 1.0000 - val_loss: 4.6468e-04 - val_accuracy: 1.0000\n",
      "Epoch 74/80\n",
      "3240/3240 [==============================] - 0s 87us/step - loss: 3.2278e-06 - accuracy: 1.0000 - val_loss: 4.4701e-04 - val_accuracy: 1.0000\n",
      "Epoch 75/80\n",
      "3240/3240 [==============================] - 0s 86us/step - loss: 3.1341e-06 - accuracy: 1.0000 - val_loss: 4.2067e-04 - val_accuracy: 1.0000\n",
      "Epoch 76/80\n",
      "3240/3240 [==============================] - 0s 87us/step - loss: 3.0404e-06 - accuracy: 1.0000 - val_loss: 4.3665e-04 - val_accuracy: 1.0000\n",
      "Epoch 77/80\n",
      "3240/3240 [==============================] - 0s 87us/step - loss: 2.9620e-06 - accuracy: 1.0000 - val_loss: 4.3774e-04 - val_accuracy: 1.0000\n",
      "Epoch 78/80\n",
      "3240/3240 [==============================] - 0s 87us/step - loss: 2.9086e-06 - accuracy: 1.0000 - val_loss: 4.2400e-04 - val_accuracy: 1.0000\n",
      "Epoch 79/80\n",
      "3240/3240 [==============================] - 0s 86us/step - loss: 2.8141e-06 - accuracy: 1.0000 - val_loss: 4.3615e-04 - val_accuracy: 1.0000\n",
      "Epoch 80/80\n",
      "3240/3240 [==============================] - 0s 92us/step - loss: 2.7360e-06 - accuracy: 1.0000 - val_loss: 4.2934e-04 - val_accuracy: 1.0000\n",
      "[[4.76599187e-02 3.54300864e-05 1.44698948e-04 ... 5.11068881e-01\n",
      "  3.75214785e-01 8.43689137e-04]\n",
      " [3.51662425e-06 1.11858206e-07 1.19221639e-07 ... 9.15124640e-03\n",
      "  9.90740180e-01 1.78656555e-05]\n",
      " [4.15913237e-05 3.83794850e-06 2.26190537e-06 ... 4.47270244e-01\n",
      "  5.52003860e-01 1.98734037e-04]\n",
      " ...\n",
      " [1.35684344e-14 4.77479818e-13 2.88832163e-13 ... 3.86937054e-12\n",
      "  1.00000000e+00 1.23739755e-12]\n",
      " [3.81878773e-12 1.22888559e-12 1.93488736e-12 ... 2.66785136e-08\n",
      "  1.85698978e-09 1.54232807e-10]\n",
      " [1.49959732e-12 1.26321537e-10 5.49492535e-11 ... 5.24023675e-14\n",
      "  9.99999881e-01 1.13147614e-16]]\n",
      "[6 7 7 ... 7 3 7]\n",
      "<class 'numpy.ndarray'>\n",
      "One CNN, r:  4\n",
      "Computing Time:  0:01:26.883417\n",
      "num of merged_region_image 0 463\n",
      "num of merged_region_image 1 806\n",
      "num of merged_region_image 2 216\n",
      "num of merged_region_image 3 352\n",
      "num of merged_region_image 4 143\n",
      "num of merged_region_image 5 96\n",
      "num of merged_region_image 6 343\n",
      "num of merged_region_image 7 973\n",
      "num of merged_region_image 8 209\n",
      "Counter({-1: 9475, 7: 973, 1: 806, 0: 463, 3: 352, 6: 343, 2: 216, 8: 209, 4: 143, 5: 96})\n",
      "===========  ITE = 0   ===========\n",
      "used_img 3601 3601\n",
      "working_img(=other images=unclean images) 9475 9475\n",
      "merged regions 24 24\n",
      "other_regions 175 175\n",
      "All other regions\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>other index</th>\n",
       "      <th>pred label</th>\n",
       "      <th>truth</th>\n",
       "      <th>rate</th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>7</td>\n",
       "      <td>1</td>\n",
       "      <td>8</td>\n",
       "      <td>0.52</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>65</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>9</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>10</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>13</td>\n",
       "      <td>6</td>\n",
       "      <td>4</td>\n",
       "      <td>0.65</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>373</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>170</th>\n",
       "      <td>195</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>171</th>\n",
       "      <td>196</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>172</th>\n",
       "      <td>197</td>\n",
       "      <td>6</td>\n",
       "      <td>4</td>\n",
       "      <td>0.99</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>107</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>173</th>\n",
       "      <td>198</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>174</th>\n",
       "      <td>199</td>\n",
       "      <td>6</td>\n",
       "      <td>4</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>43</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>175 rows × 13 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     other index  pred label  truth  rate  0  1  2  3    4  5  6  7   8\n",
       "0              2           0      0  0.00  0  0  0  0    0  0  0  0   0\n",
       "1              7           1      8  0.52  0  0  0  0    0  0  0  0  65\n",
       "2              9           0      0  0.00  0  0  0  0    0  0  0  0   0\n",
       "3             10           0      0  0.00  0  0  0  0    0  0  0  0   0\n",
       "4             13           6      4  0.65  0  0  0  0  373  0  0  0   0\n",
       "..           ...         ...    ...   ... .. .. .. ..  ... .. .. ..  ..\n",
       "170          195           0      0  0.00  0  0  0  0    0  0  0  0   0\n",
       "171          196           0      0  0.00  0  0  0  0    0  0  0  0   0\n",
       "172          197           6      4  0.99  0  0  0  0  107  0  0  0   0\n",
       "173          198           0      0  0.00  0  0  0  0    0  0  0  0   0\n",
       "174          199           6      4  1.00  0  0  0  0   43  0  0  0   0\n",
       "\n",
       "[175 rows x 13 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "added label, regions, img amount: {0} [143, 101, 22, 60] 1271\n",
      "added label, regions, img amount: {1} [132, 159, 151, 16, 178] 925\n",
      "added label, regions, img amount: {3} [90, 102, 19, 171] 376\n",
      "added label, regions, img amount: {6} [199, 194, 58, 27, 134] 627\n",
      "added label, regions, img amount: {7} [55, 88, 133, 144, 47] 1024\n",
      "Not getting into residuals\n",
      "NUM_region 9\n",
      "number of clean images 7824\n",
      "n, p1, p2 0 0 0\n",
      "NUM_CLASSES 9\n",
      "current_train_label:  [0, 1, 2, 3, 4, 5, 6, 7, 8]\n",
      "Model: \"sequential_1\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv1d_1 (Conv1D)            (None, 1000, 6)           36        \n",
      "_________________________________________________________________\n",
      "average_pooling1d_1 (Average (None, 500, 6)            0         \n",
      "_________________________________________________________________\n",
      "conv1d_2 (Conv1D)            (None, 496, 16)           496       \n",
      "_________________________________________________________________\n",
      "average_pooling1d_2 (Average (None, 248, 16)           0         \n",
      "_________________________________________________________________\n",
      "conv1d_3 (Conv1D)            (None, 244, 120)          9720      \n",
      "_________________________________________________________________\n",
      "flatten_1 (Flatten)          (None, 29280)             0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 84)                2459604   \n",
      "_________________________________________________________________\n",
      "preds (Dense)                (None, 9)                 765       \n",
      "=================================================================\n",
      "Total params: 2,470,621\n",
      "Trainable params: 2,470,621\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Train on 7041 samples, validate on 783 samples\n",
      "Epoch 1/80\n",
      "7041/7041 [==============================] - 1s 173us/step - loss: 0.4526 - accuracy: 0.8830 - val_loss: 0.0091 - val_accuracy: 0.9974\n",
      "Epoch 2/80\n",
      "7041/7041 [==============================] - 1s 87us/step - loss: 0.0049 - accuracy: 0.9991 - val_loss: 0.0058 - val_accuracy: 0.9974\n",
      "Epoch 3/80\n",
      "7041/7041 [==============================] - 1s 86us/step - loss: 0.0013 - accuracy: 1.0000 - val_loss: 0.0014 - val_accuracy: 1.0000\n",
      "Epoch 4/80\n",
      "7041/7041 [==============================] - 1s 89us/step - loss: 5.7887e-04 - accuracy: 1.0000 - val_loss: 0.0017 - val_accuracy: 1.0000\n",
      "Epoch 5/80\n",
      "7041/7041 [==============================] - 1s 89us/step - loss: 6.2978e-04 - accuracy: 1.0000 - val_loss: 0.0013 - val_accuracy: 1.0000\n",
      "Epoch 6/80\n",
      "7041/7041 [==============================] - 1s 88us/step - loss: 2.6630e-04 - accuracy: 1.0000 - val_loss: 6.6710e-04 - val_accuracy: 1.0000\n",
      "Epoch 7/80\n",
      "7041/7041 [==============================] - 1s 88us/step - loss: 1.7426e-04 - accuracy: 1.0000 - val_loss: 5.6301e-04 - val_accuracy: 1.0000\n",
      "Epoch 8/80\n",
      "7041/7041 [==============================] - 1s 86us/step - loss: 1.1906e-04 - accuracy: 1.0000 - val_loss: 6.9527e-04 - val_accuracy: 1.0000\n",
      "Epoch 9/80\n",
      "7041/7041 [==============================] - 1s 89us/step - loss: 1.0082e-04 - accuracy: 1.0000 - val_loss: 4.6902e-04 - val_accuracy: 1.0000\n",
      "Epoch 10/80\n",
      "7041/7041 [==============================] - 1s 87us/step - loss: 7.6852e-05 - accuracy: 1.0000 - val_loss: 3.8778e-04 - val_accuracy: 1.0000\n",
      "Epoch 11/80\n",
      "7041/7041 [==============================] - 1s 87us/step - loss: 6.4828e-05 - accuracy: 1.0000 - val_loss: 3.7412e-04 - val_accuracy: 1.0000\n",
      "Epoch 12/80\n",
      "7041/7041 [==============================] - 1s 87us/step - loss: 5.3524e-05 - accuracy: 1.0000 - val_loss: 3.8485e-04 - val_accuracy: 1.0000\n",
      "Epoch 13/80\n",
      "7041/7041 [==============================] - 1s 86us/step - loss: 4.6026e-05 - accuracy: 1.0000 - val_loss: 3.1382e-04 - val_accuracy: 1.0000\n",
      "Epoch 14/80\n",
      "7041/7041 [==============================] - 1s 88us/step - loss: 3.8390e-05 - accuracy: 1.0000 - val_loss: 2.6930e-04 - val_accuracy: 1.0000\n",
      "Epoch 15/80\n",
      "7041/7041 [==============================] - 1s 84us/step - loss: 3.3453e-05 - accuracy: 1.0000 - val_loss: 3.2041e-04 - val_accuracy: 1.0000\n",
      "Epoch 16/80\n",
      "7041/7041 [==============================] - 1s 87us/step - loss: 2.9207e-05 - accuracy: 1.0000 - val_loss: 2.6206e-04 - val_accuracy: 1.0000\n",
      "Epoch 17/80\n",
      "7041/7041 [==============================] - 1s 88us/step - loss: 2.5899e-05 - accuracy: 1.0000 - val_loss: 2.6903e-04 - val_accuracy: 1.0000\n",
      "Epoch 18/80\n",
      "7041/7041 [==============================] - 1s 87us/step - loss: 2.2214e-05 - accuracy: 1.0000 - val_loss: 2.2775e-04 - val_accuracy: 1.0000\n",
      "Epoch 19/80\n",
      "7041/7041 [==============================] - 1s 87us/step - loss: 1.9485e-05 - accuracy: 1.0000 - val_loss: 2.5704e-04 - val_accuracy: 1.0000\n",
      "Epoch 20/80\n",
      "7041/7041 [==============================] - 1s 86us/step - loss: 1.7523e-05 - accuracy: 1.0000 - val_loss: 1.9442e-04 - val_accuracy: 1.0000\n",
      "Epoch 21/80\n",
      "7041/7041 [==============================] - 1s 87us/step - loss: 1.5816e-05 - accuracy: 1.0000 - val_loss: 2.2056e-04 - val_accuracy: 1.0000\n",
      "Epoch 22/80\n",
      "7041/7041 [==============================] - 1s 88us/step - loss: 1.4228e-05 - accuracy: 1.0000 - val_loss: 1.8075e-04 - val_accuracy: 1.0000\n",
      "Epoch 23/80\n",
      "7041/7041 [==============================] - 1s 91us/step - loss: 1.2822e-05 - accuracy: 1.0000 - val_loss: 1.4567e-04 - val_accuracy: 1.0000\n",
      "Epoch 24/80\n",
      "7041/7041 [==============================] - 1s 87us/step - loss: 1.1806e-05 - accuracy: 1.0000 - val_loss: 1.9720e-04 - val_accuracy: 1.0000\n",
      "Epoch 25/80\n",
      "7041/7041 [==============================] - 1s 86us/step - loss: 1.0614e-05 - accuracy: 1.0000 - val_loss: 2.0541e-04 - val_accuracy: 1.0000\n",
      "Epoch 26/80\n",
      "7041/7041 [==============================] - 1s 86us/step - loss: 9.7335e-06 - accuracy: 1.0000 - val_loss: 1.5185e-04 - val_accuracy: 1.0000\n",
      "Epoch 27/80\n",
      "7041/7041 [==============================] - 1s 89us/step - loss: 8.9228e-06 - accuracy: 1.0000 - val_loss: 1.5329e-04 - val_accuracy: 1.0000\n",
      "Epoch 28/80\n",
      "7041/7041 [==============================] - 1s 86us/step - loss: 8.3851e-06 - accuracy: 1.0000 - val_loss: 1.5412e-04 - val_accuracy: 1.0000\n",
      "Epoch 29/80\n",
      "7041/7041 [==============================] - 1s 86us/step - loss: 7.5247e-06 - accuracy: 1.0000 - val_loss: 2.4315e-04 - val_accuracy: 1.0000\n",
      "Epoch 30/80\n",
      "7041/7041 [==============================] - 1s 89us/step - loss: 9.8333e-06 - accuracy: 1.0000 - val_loss: 1.4714e-04 - val_accuracy: 1.0000\n",
      "Epoch 31/80\n",
      "7041/7041 [==============================] - ETA: 0s - loss: 6.5022e-06 - accuracy: 1.00 - 1s 88us/step - loss: 6.6087e-06 - accuracy: 1.0000 - val_loss: 1.9877e-04 - val_accuracy: 1.0000\n",
      "Epoch 32/80\n",
      "7041/7041 [==============================] - 1s 88us/step - loss: 6.0247e-06 - accuracy: 1.0000 - val_loss: 1.7637e-04 - val_accuracy: 1.0000\n",
      "Epoch 33/80\n",
      "7041/7041 [==============================] - 1s 86us/step - loss: 5.6766e-06 - accuracy: 1.0000 - val_loss: 1.3793e-04 - val_accuracy: 1.0000\n",
      "Epoch 34/80\n",
      "7041/7041 [==============================] - 1s 86us/step - loss: 5.2107e-06 - accuracy: 1.0000 - val_loss: 1.5031e-04 - val_accuracy: 1.0000\n",
      "Epoch 35/80\n",
      "7041/7041 [==============================] - 1s 87us/step - loss: 4.7753e-06 - accuracy: 1.0000 - val_loss: 1.4197e-04 - val_accuracy: 1.0000\n",
      "Epoch 36/80\n",
      "7041/7041 [==============================] - 1s 86us/step - loss: 4.6241e-06 - accuracy: 1.0000 - val_loss: 1.1913e-04 - val_accuracy: 1.0000\n",
      "Epoch 37/80\n",
      "7041/7041 [==============================] - 1s 86us/step - loss: 4.3136e-06 - accuracy: 1.0000 - val_loss: 1.6099e-04 - val_accuracy: 1.0000\n",
      "Epoch 38/80\n",
      "7041/7041 [==============================] - 1s 86us/step - loss: 3.9639e-06 - accuracy: 1.0000 - val_loss: 1.9976e-04 - val_accuracy: 1.0000\n",
      "Epoch 39/80\n",
      "7041/7041 [==============================] - 1s 86us/step - loss: 3.9016e-06 - accuracy: 1.0000 - val_loss: 1.8316e-04 - val_accuracy: 1.0000\n",
      "Epoch 40/80\n",
      "7041/7041 [==============================] - 1s 88us/step - loss: 3.5881e-06 - accuracy: 1.0000 - val_loss: 1.4866e-04 - val_accuracy: 1.0000\n",
      "Epoch 41/80\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7041/7041 [==============================] - 1s 84us/step - loss: 3.3194e-06 - accuracy: 1.0000 - val_loss: 1.2894e-04 - val_accuracy: 1.0000\n",
      "Epoch 42/80\n",
      "7041/7041 [==============================] - 1s 88us/step - loss: 3.0371e-06 - accuracy: 1.0000 - val_loss: 1.1651e-04 - val_accuracy: 1.0000\n",
      "Epoch 43/80\n",
      "7041/7041 [==============================] - 1s 85us/step - loss: 3.1444e-06 - accuracy: 1.0000 - val_loss: 1.2023e-04 - val_accuracy: 1.0000\n",
      "Epoch 44/80\n",
      "7041/7041 [==============================] - 1s 89us/step - loss: 2.8012e-06 - accuracy: 1.0000 - val_loss: 9.3988e-05 - val_accuracy: 1.0000\n",
      "Epoch 45/80\n",
      "7041/7041 [==============================] - 1s 87us/step - loss: 2.6677e-06 - accuracy: 1.0000 - val_loss: 1.3596e-04 - val_accuracy: 1.0000\n",
      "Epoch 46/80\n",
      "7041/7041 [==============================] - 1s 87us/step - loss: 2.5538e-06 - accuracy: 1.0000 - val_loss: 1.5372e-04 - val_accuracy: 1.0000\n",
      "Epoch 47/80\n",
      "7041/7041 [==============================] - 1s 86us/step - loss: 2.4712e-06 - accuracy: 1.0000 - val_loss: 1.1670e-04 - val_accuracy: 1.0000\n",
      "Epoch 48/80\n",
      "7041/7041 [==============================] - 1s 89us/step - loss: 2.2914e-06 - accuracy: 1.0000 - val_loss: 1.4007e-04 - val_accuracy: 1.0000\n",
      "Epoch 49/80\n",
      "7041/7041 [==============================] - 1s 88us/step - loss: 2.1584e-06 - accuracy: 1.0000 - val_loss: 1.0975e-04 - val_accuracy: 1.0000\n",
      "Epoch 50/80\n",
      "7041/7041 [==============================] - 1s 86us/step - loss: 2.1193e-06 - accuracy: 1.0000 - val_loss: 1.0433e-04 - val_accuracy: 1.0000\n",
      "Epoch 51/80\n",
      "7041/7041 [==============================] - 1s 85us/step - loss: 1.9780e-06 - accuracy: 1.0000 - val_loss: 1.1125e-04 - val_accuracy: 1.0000\n",
      "Epoch 52/80\n",
      "7041/7041 [==============================] - 1s 87us/step - loss: 1.9082e-06 - accuracy: 1.0000 - val_loss: 1.0547e-04 - val_accuracy: 1.0000\n",
      "Epoch 53/80\n",
      "7041/7041 [==============================] - 1s 87us/step - loss: 1.8193e-06 - accuracy: 1.0000 - val_loss: 1.1680e-04 - val_accuracy: 1.0000\n",
      "Epoch 54/80\n",
      "7041/7041 [==============================] - 1s 86us/step - loss: 1.6743e-06 - accuracy: 1.0000 - val_loss: 1.1510e-04 - val_accuracy: 1.0000\n",
      "Epoch 00054: early stopping\n",
      "[[1.6358291e-04 3.6592755e-08 2.8082971e-07 ... 7.4164130e-02\n",
      "  9.2555606e-01 9.3114068e-05]\n",
      " [2.2580624e-09 2.1578074e-10 1.1864111e-10 ... 2.2879169e-04\n",
      "  9.9976104e-01 1.0169600e-05]\n",
      " [1.0859565e-07 1.5925302e-09 2.5396385e-09 ... 1.7028297e-01\n",
      "  8.2964009e-01 7.6571698e-05]\n",
      " ...\n",
      " [1.9389858e-18 1.9263060e-17 4.5201312e-15 ... 1.3774598e-13\n",
      "  1.0000000e+00 1.1786140e-11]\n",
      " [7.8809267e-15 5.4870360e-16 6.9916911e-20 ... 1.3898689e-09\n",
      "  8.4650058e-11 8.8806410e-12]\n",
      " [1.8501192e-14 8.4461303e-16 1.7254782e-10 ... 1.2570729e-16\n",
      "  1.0000000e+00 8.3188022e-16]]\n",
      "[7 7 7 ... 7 3 7]\n",
      "<class 'numpy.ndarray'>\n",
      "One CNN, r:  0\n",
      "Computing Time:  0:00:36.609354\n",
      "Model: \"sequential_1\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv1d_1 (Conv1D)            (None, 1000, 6)           36        \n",
      "_________________________________________________________________\n",
      "average_pooling1d_1 (Average (None, 500, 6)            0         \n",
      "_________________________________________________________________\n",
      "conv1d_2 (Conv1D)            (None, 496, 16)           496       \n",
      "_________________________________________________________________\n",
      "average_pooling1d_2 (Average (None, 248, 16)           0         \n",
      "_________________________________________________________________\n",
      "conv1d_3 (Conv1D)            (None, 244, 120)          9720      \n",
      "_________________________________________________________________\n",
      "flatten_1 (Flatten)          (None, 29280)             0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 84)                2459604   \n",
      "_________________________________________________________________\n",
      "preds (Dense)                (None, 9)                 765       \n",
      "=================================================================\n",
      "Total params: 2,470,621\n",
      "Trainable params: 2,470,621\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Train on 7041 samples, validate on 783 samples\n",
      "Epoch 1/80\n",
      "7041/7041 [==============================] - 1s 118us/step - loss: 0.2699 - accuracy: 0.9176 - val_loss: 0.0043 - val_accuracy: 0.9987\n",
      "Epoch 2/80\n",
      "7041/7041 [==============================] - 1s 87us/step - loss: 0.0038 - accuracy: 0.9994 - val_loss: 0.0041 - val_accuracy: 1.0000\n",
      "Epoch 3/80\n",
      "7041/7041 [==============================] - 1s 87us/step - loss: 0.0012 - accuracy: 1.0000 - val_loss: 0.0013 - val_accuracy: 1.0000\n",
      "Epoch 4/80\n",
      "7041/7041 [==============================] - 1s 89us/step - loss: 4.1850e-04 - accuracy: 1.0000 - val_loss: 0.0010 - val_accuracy: 1.0000\n",
      "Epoch 5/80\n",
      "7041/7041 [==============================] - 1s 86us/step - loss: 7.9589e-04 - accuracy: 0.9999 - val_loss: 0.0019 - val_accuracy: 0.9987\n",
      "Epoch 6/80\n",
      "7041/7041 [==============================] - 1s 89us/step - loss: 2.1827e-04 - accuracy: 1.0000 - val_loss: 0.0018 - val_accuracy: 0.9987\n",
      "Epoch 7/80\n",
      "7041/7041 [==============================] - 1s 83us/step - loss: 1.2403e-04 - accuracy: 1.0000 - val_loss: 5.7449e-04 - val_accuracy: 1.0000\n",
      "Epoch 8/80\n",
      "7041/7041 [==============================] - 1s 89us/step - loss: 8.6958e-05 - accuracy: 1.0000 - val_loss: 5.2109e-04 - val_accuracy: 1.0000\n",
      "Epoch 9/80\n",
      "7041/7041 [==============================] - 1s 86us/step - loss: 7.0675e-05 - accuracy: 1.0000 - val_loss: 4.9779e-04 - val_accuracy: 1.0000\n",
      "Epoch 10/80\n",
      "7041/7041 [==============================] - 1s 90us/step - loss: 5.8771e-05 - accuracy: 1.0000 - val_loss: 3.6630e-04 - val_accuracy: 1.0000\n",
      "Epoch 11/80\n",
      "7041/7041 [==============================] - 1s 87us/step - loss: 5.0140e-05 - accuracy: 1.0000 - val_loss: 3.5920e-04 - val_accuracy: 1.0000\n",
      "Epoch 12/80\n",
      "7041/7041 [==============================] - 1s 89us/step - loss: 4.5167e-05 - accuracy: 1.0000 - val_loss: 3.5872e-04 - val_accuracy: 1.0000\n",
      "Epoch 13/80\n",
      "7041/7041 [==============================] - 1s 89us/step - loss: 3.8368e-05 - accuracy: 1.0000 - val_loss: 2.8945e-04 - val_accuracy: 1.0000\n",
      "Epoch 14/80\n",
      "7041/7041 [==============================] - 1s 88us/step - loss: 3.3512e-05 - accuracy: 1.0000 - val_loss: 4.0296e-04 - val_accuracy: 1.0000\n",
      "Epoch 15/80\n",
      "7041/7041 [==============================] - 1s 86us/step - loss: 2.9196e-05 - accuracy: 1.0000 - val_loss: 3.0499e-04 - val_accuracy: 1.0000\n",
      "Epoch 16/80\n",
      "7041/7041 [==============================] - 1s 91us/step - loss: 2.6077e-05 - accuracy: 1.0000 - val_loss: 2.8492e-04 - val_accuracy: 1.0000\n",
      "Epoch 17/80\n",
      "7041/7041 [==============================] - 1s 86us/step - loss: 2.3062e-05 - accuracy: 1.0000 - val_loss: 3.0141e-04 - val_accuracy: 1.0000\n",
      "Epoch 18/80\n",
      "7041/7041 [==============================] - 1s 91us/step - loss: 2.1048e-05 - accuracy: 1.0000 - val_loss: 2.5954e-04 - val_accuracy: 1.0000\n",
      "Epoch 19/80\n",
      "7041/7041 [==============================] - 1s 87us/step - loss: 1.9585e-05 - accuracy: 1.0000 - val_loss: 3.9926e-04 - val_accuracy: 1.0000\n",
      "Epoch 20/80\n",
      "7041/7041 [==============================] - 1s 92us/step - loss: 1.7733e-05 - accuracy: 1.0000 - val_loss: 2.8974e-04 - val_accuracy: 1.0000\n",
      "Epoch 21/80\n",
      "7041/7041 [==============================] - 1s 86us/step - loss: 1.5908e-05 - accuracy: 1.0000 - val_loss: 2.2855e-04 - val_accuracy: 1.0000\n",
      "Epoch 22/80\n",
      "7041/7041 [==============================] - 1s 92us/step - loss: 1.4108e-05 - accuracy: 1.0000 - val_loss: 2.0764e-04 - val_accuracy: 1.0000\n",
      "Epoch 23/80\n",
      "7041/7041 [==============================] - 1s 89us/step - loss: 1.3239e-05 - accuracy: 1.0000 - val_loss: 2.5338e-04 - val_accuracy: 1.0000\n",
      "Epoch 24/80\n",
      "7041/7041 [==============================] - 1s 92us/step - loss: 1.2054e-05 - accuracy: 1.0000 - val_loss: 2.4250e-04 - val_accuracy: 1.0000\n",
      "Epoch 25/80\n",
      "7041/7041 [==============================] - 1s 86us/step - loss: 1.1225e-05 - accuracy: 1.0000 - val_loss: 2.9692e-04 - val_accuracy: 1.0000\n",
      "Epoch 26/80\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7041/7041 [==============================] - 1s 91us/step - loss: 1.0299e-05 - accuracy: 1.0000 - val_loss: 1.9175e-04 - val_accuracy: 1.0000\n",
      "Epoch 27/80\n",
      "7041/7041 [==============================] - 1s 87us/step - loss: 9.5992e-06 - accuracy: 1.0000 - val_loss: 2.2890e-04 - val_accuracy: 1.0000\n",
      "Epoch 28/80\n",
      "7041/7041 [==============================] - 1s 92us/step - loss: 8.9753e-06 - accuracy: 1.0000 - val_loss: 1.6016e-04 - val_accuracy: 1.0000\n",
      "Epoch 29/80\n",
      "7041/7041 [==============================] - 1s 87us/step - loss: 8.3392e-06 - accuracy: 1.0000 - val_loss: 1.5316e-04 - val_accuracy: 1.0000\n",
      "Epoch 30/80\n",
      "7041/7041 [==============================] - 1s 91us/step - loss: 7.7979e-06 - accuracy: 1.0000 - val_loss: 1.9540e-04 - val_accuracy: 1.0000\n",
      "Epoch 31/80\n",
      "7041/7041 [==============================] - 1s 88us/step - loss: 7.3643e-06 - accuracy: 1.0000 - val_loss: 1.8550e-04 - val_accuracy: 1.0000\n",
      "Epoch 32/80\n",
      "7041/7041 [==============================] - 1s 87us/step - loss: 6.9093e-06 - accuracy: 1.0000 - val_loss: 1.9225e-04 - val_accuracy: 1.0000\n",
      "Epoch 33/80\n",
      "7041/7041 [==============================] - 1s 89us/step - loss: 6.5016e-06 - accuracy: 1.0000 - val_loss: 1.6482e-04 - val_accuracy: 1.0000\n",
      "Epoch 34/80\n",
      "7041/7041 [==============================] - 1s 88us/step - loss: 6.0175e-06 - accuracy: 1.0000 - val_loss: 1.7942e-04 - val_accuracy: 1.0000\n",
      "Epoch 35/80\n",
      "7041/7041 [==============================] - 1s 89us/step - loss: 5.7157e-06 - accuracy: 1.0000 - val_loss: 1.6448e-04 - val_accuracy: 1.0000\n",
      "Epoch 36/80\n",
      "7041/7041 [==============================] - 1s 91us/step - loss: 5.3476e-06 - accuracy: 1.0000 - val_loss: 1.5416e-04 - val_accuracy: 1.0000\n",
      "Epoch 37/80\n",
      "7041/7041 [==============================] - 1s 89us/step - loss: 5.0128e-06 - accuracy: 1.0000 - val_loss: 1.8078e-04 - val_accuracy: 1.0000\n",
      "Epoch 38/80\n",
      "7041/7041 [==============================] - 1s 89us/step - loss: 4.8294e-06 - accuracy: 1.0000 - val_loss: 1.5503e-04 - val_accuracy: 1.0000\n",
      "Epoch 39/80\n",
      "7041/7041 [==============================] - 1s 89us/step - loss: 4.5298e-06 - accuracy: 1.0000 - val_loss: 1.3915e-04 - val_accuracy: 1.0000\n",
      "Epoch 40/80\n",
      "7041/7041 [==============================] - 1s 86us/step - loss: 4.2667e-06 - accuracy: 1.0000 - val_loss: 1.3758e-04 - val_accuracy: 1.0000\n",
      "Epoch 41/80\n",
      "7041/7041 [==============================] - 1s 90us/step - loss: 4.0358e-06 - accuracy: 1.0000 - val_loss: 1.3615e-04 - val_accuracy: 1.0000\n",
      "Epoch 42/80\n",
      "7041/7041 [==============================] - 1s 87us/step - loss: 3.8310e-06 - accuracy: 1.0000 - val_loss: 1.5992e-04 - val_accuracy: 1.0000\n",
      "Epoch 43/80\n",
      "7041/7041 [==============================] - 1s 87us/step - loss: 3.6652e-06 - accuracy: 1.0000 - val_loss: 1.6023e-04 - val_accuracy: 1.0000\n",
      "Epoch 44/80\n",
      "7041/7041 [==============================] - 1s 89us/step - loss: 3.5154e-06 - accuracy: 1.0000 - val_loss: 1.4252e-04 - val_accuracy: 1.0000\n",
      "Epoch 45/80\n",
      "7041/7041 [==============================] - 1s 89us/step - loss: 3.2770e-06 - accuracy: 1.0000 - val_loss: 1.2984e-04 - val_accuracy: 1.0000\n",
      "Epoch 46/80\n",
      "7041/7041 [==============================] - 1s 86us/step - loss: 3.1576e-06 - accuracy: 1.0000 - val_loss: 1.4475e-04 - val_accuracy: 1.0000\n",
      "Epoch 47/80\n",
      "7041/7041 [==============================] - 1s 86us/step - loss: 3.0221e-06 - accuracy: 1.0000 - val_loss: 1.1602e-04 - val_accuracy: 1.0000\n",
      "Epoch 48/80\n",
      "7041/7041 [==============================] - 1s 88us/step - loss: 2.8492e-06 - accuracy: 1.0000 - val_loss: 1.2570e-04 - val_accuracy: 1.0000\n",
      "Epoch 49/80\n",
      "7041/7041 [==============================] - 1s 87us/step - loss: 2.6824e-06 - accuracy: 1.0000 - val_loss: 1.0653e-04 - val_accuracy: 1.0000\n",
      "Epoch 50/80\n",
      "7041/7041 [==============================] - 1s 90us/step - loss: 2.5744e-06 - accuracy: 1.0000 - val_loss: 1.2305e-04 - val_accuracy: 1.0000\n",
      "Epoch 51/80\n",
      "7041/7041 [==============================] - 1s 88us/step - loss: 2.4593e-06 - accuracy: 1.0000 - val_loss: 1.1120e-04 - val_accuracy: 1.0000\n",
      "Epoch 52/80\n",
      "7041/7041 [==============================] - 1s 88us/step - loss: 2.3415e-06 - accuracy: 1.0000 - val_loss: 1.2411e-04 - val_accuracy: 1.0000\n",
      "Epoch 53/80\n",
      "7041/7041 [==============================] - 1s 89us/step - loss: 2.2315e-06 - accuracy: 1.0000 - val_loss: 1.0485e-04 - val_accuracy: 1.0000\n",
      "Epoch 54/80\n",
      "7041/7041 [==============================] - 1s 89us/step - loss: 2.1267e-06 - accuracy: 1.0000 - val_loss: 8.6676e-05 - val_accuracy: 1.0000\n",
      "Epoch 55/80\n",
      "7041/7041 [==============================] - 1s 87us/step - loss: 2.1065e-06 - accuracy: 1.0000 - val_loss: 1.0019e-04 - val_accuracy: 1.0000\n",
      "Epoch 56/80\n",
      "7041/7041 [==============================] - 1s 86us/step - loss: 1.9548e-06 - accuracy: 1.0000 - val_loss: 9.5723e-05 - val_accuracy: 1.0000\n",
      "Epoch 57/80\n",
      "7041/7041 [==============================] - 1s 88us/step - loss: 1.8617e-06 - accuracy: 1.0000 - val_loss: 1.2318e-04 - val_accuracy: 1.0000\n",
      "Epoch 58/80\n",
      "7041/7041 [==============================] - 1s 87us/step - loss: 1.7995e-06 - accuracy: 1.0000 - val_loss: 1.0534e-04 - val_accuracy: 1.0000\n",
      "Epoch 59/80\n",
      "7041/7041 [==============================] - 1s 88us/step - loss: 1.7344e-06 - accuracy: 1.0000 - val_loss: 1.1422e-04 - val_accuracy: 1.0000\n",
      "Epoch 60/80\n",
      "7041/7041 [==============================] - 1s 88us/step - loss: 1.6537e-06 - accuracy: 1.0000 - val_loss: 1.0269e-04 - val_accuracy: 1.0000\n",
      "Epoch 61/80\n",
      "7041/7041 [==============================] - 1s 91us/step - loss: 1.5810e-06 - accuracy: 1.0000 - val_loss: 1.0528e-04 - val_accuracy: 1.0000\n",
      "Epoch 62/80\n",
      "7041/7041 [==============================] - 1s 87us/step - loss: 1.5132e-06 - accuracy: 1.0000 - val_loss: 9.7537e-05 - val_accuracy: 1.0000\n",
      "Epoch 63/80\n",
      "7041/7041 [==============================] - 1s 91us/step - loss: 1.4330e-06 - accuracy: 1.0000 - val_loss: 9.2199e-05 - val_accuracy: 1.0000\n",
      "Epoch 64/80\n",
      "7041/7041 [==============================] - 1s 88us/step - loss: 1.3847e-06 - accuracy: 1.0000 - val_loss: 8.5470e-05 - val_accuracy: 1.0000\n",
      "Epoch 65/80\n",
      "7041/7041 [==============================] - 1s 89us/step - loss: 1.3281e-06 - accuracy: 1.0000 - val_loss: 8.5637e-05 - val_accuracy: 1.0000\n",
      "Epoch 66/80\n",
      "7041/7041 [==============================] - 1s 86us/step - loss: 1.2907e-06 - accuracy: 1.0000 - val_loss: 1.0361e-04 - val_accuracy: 1.0000\n",
      "Epoch 67/80\n",
      "7041/7041 [==============================] - 1s 89us/step - loss: 1.2245e-06 - accuracy: 1.0000 - val_loss: 8.4497e-05 - val_accuracy: 1.0000\n",
      "Epoch 68/80\n",
      "7041/7041 [==============================] - 1s 90us/step - loss: 1.1720e-06 - accuracy: 1.0000 - val_loss: 9.4473e-05 - val_accuracy: 1.0000\n",
      "Epoch 69/80\n",
      "7041/7041 [==============================] - 1s 90us/step - loss: 1.1476e-06 - accuracy: 1.0000 - val_loss: 9.5442e-05 - val_accuracy: 1.0000\n",
      "Epoch 70/80\n",
      "7041/7041 [==============================] - 1s 88us/step - loss: 1.0924e-06 - accuracy: 1.0000 - val_loss: 1.0006e-04 - val_accuracy: 1.0000\n",
      "Epoch 71/80\n",
      "7041/7041 [==============================] - 1s 88us/step - loss: 1.0539e-06 - accuracy: 1.0000 - val_loss: 7.0603e-05 - val_accuracy: 1.0000\n",
      "Epoch 72/80\n",
      "7041/7041 [==============================] - 1s 89us/step - loss: 1.0040e-06 - accuracy: 1.0000 - val_loss: 7.2986e-05 - val_accuracy: 1.0000\n",
      "Epoch 73/80\n",
      "7041/7041 [==============================] - 1s 87us/step - loss: 9.7649e-07 - accuracy: 1.0000 - val_loss: 7.5471e-05 - val_accuracy: 1.0000\n",
      "Epoch 74/80\n",
      "7041/7041 [==============================] - 1s 89us/step - loss: 9.3600e-07 - accuracy: 1.0000 - val_loss: 6.4320e-05 - val_accuracy: 1.0000\n",
      "Epoch 75/80\n",
      "7041/7041 [==============================] - 1s 87us/step - loss: 8.9704e-07 - accuracy: 1.0000 - val_loss: 7.4033e-05 - val_accuracy: 1.0000\n",
      "Epoch 76/80\n",
      "7041/7041 [==============================] - 1s 90us/step - loss: 8.5874e-07 - accuracy: 1.0000 - val_loss: 8.2632e-05 - val_accuracy: 1.0000\n",
      "Epoch 77/80\n",
      "7041/7041 [==============================] - 1s 86us/step - loss: 8.2935e-07 - accuracy: 1.0000 - val_loss: 7.1674e-05 - val_accuracy: 1.0000\n",
      "Epoch 78/80\n",
      "7041/7041 [==============================] - 1s 90us/step - loss: 8.0064e-07 - accuracy: 1.0000 - val_loss: 6.9837e-05 - val_accuracy: 1.0000\n",
      "Epoch 79/80\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7041/7041 [==============================] - 1s 87us/step - loss: 7.6963e-07 - accuracy: 1.0000 - val_loss: 7.4887e-05 - val_accuracy: 1.0000\n",
      "Epoch 80/80\n",
      "7041/7041 [==============================] - 1s 86us/step - loss: 7.4113e-07 - accuracy: 1.0000 - val_loss: 7.0469e-05 - val_accuracy: 1.0000\n",
      "[[8.8480371e-04 9.8332642e-10 3.1755793e-05 ... 1.7329681e-01\n",
      "  8.1750202e-01 4.7578419e-06]\n",
      " [3.5313119e-10 1.4808241e-15 2.8524585e-11 ... 4.2100968e-05\n",
      "  9.9995577e-01 8.6937479e-09]\n",
      " [4.9721127e-08 6.5146544e-10 3.0001566e-08 ... 5.3075546e-01\n",
      "  4.6920106e-01 2.9912931e-05]\n",
      " ...\n",
      " [1.2960288e-21 2.1287622e-19 2.0842631e-18 ... 4.9414018e-14\n",
      "  1.0000000e+00 4.1103118e-13]\n",
      " [3.9376550e-17 4.4325619e-18 1.5857896e-15 ... 1.0131697e-09\n",
      "  6.3091836e-12 3.8008537e-12]\n",
      " [3.2494684e-19 2.3815384e-18 5.5544084e-15 ... 1.0588478e-17\n",
      "  1.0000000e+00 2.4830476e-19]]\n",
      "[7 7 6 ... 7 3 7]\n",
      "<class 'numpy.ndarray'>\n",
      "One CNN, r:  1\n",
      "Computing Time:  0:01:29.390624\n",
      "Model: \"sequential_1\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv1d_1 (Conv1D)            (None, 1000, 6)           36        \n",
      "_________________________________________________________________\n",
      "average_pooling1d_1 (Average (None, 500, 6)            0         \n",
      "_________________________________________________________________\n",
      "conv1d_2 (Conv1D)            (None, 496, 16)           496       \n",
      "_________________________________________________________________\n",
      "average_pooling1d_2 (Average (None, 248, 16)           0         \n",
      "_________________________________________________________________\n",
      "conv1d_3 (Conv1D)            (None, 244, 120)          9720      \n",
      "_________________________________________________________________\n",
      "flatten_1 (Flatten)          (None, 29280)             0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 84)                2459604   \n",
      "_________________________________________________________________\n",
      "preds (Dense)                (None, 9)                 765       \n",
      "=================================================================\n",
      "Total params: 2,470,621\n",
      "Trainable params: 2,470,621\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Train on 7041 samples, validate on 783 samples\n",
      "Epoch 1/80\n",
      "7041/7041 [==============================] - 1s 118us/step - loss: 0.2214 - accuracy: 0.9421 - val_loss: 0.0040 - val_accuracy: 0.9987\n",
      "Epoch 2/80\n",
      "7041/7041 [==============================] - 1s 88us/step - loss: 0.0028 - accuracy: 0.9993 - val_loss: 0.0018 - val_accuracy: 1.0000\n",
      "Epoch 3/80\n",
      "7041/7041 [==============================] - 1s 85us/step - loss: 6.0660e-04 - accuracy: 1.0000 - val_loss: 7.8702e-04 - val_accuracy: 1.0000\n",
      "Epoch 4/80\n",
      "7041/7041 [==============================] - 1s 88us/step - loss: 3.5756e-04 - accuracy: 1.0000 - val_loss: 6.0354e-04 - val_accuracy: 1.0000\n",
      "Epoch 5/80\n",
      "7041/7041 [==============================] - 1s 85us/step - loss: 1.5523e-04 - accuracy: 1.0000 - val_loss: 4.7492e-04 - val_accuracy: 1.0000\n",
      "Epoch 6/80\n",
      "7041/7041 [==============================] - 1s 89us/step - loss: 1.0576e-04 - accuracy: 1.0000 - val_loss: 4.0823e-04 - val_accuracy: 1.0000\n",
      "Epoch 7/80\n",
      "7041/7041 [==============================] - 1s 87us/step - loss: 8.0627e-05 - accuracy: 1.0000 - val_loss: 5.5678e-04 - val_accuracy: 1.0000\n",
      "Epoch 8/80\n",
      "7041/7041 [==============================] - 1s 85us/step - loss: 6.7510e-05 - accuracy: 1.0000 - val_loss: 5.0504e-04 - val_accuracy: 1.0000\n",
      "Epoch 9/80\n",
      "7041/7041 [==============================] - 1s 91us/step - loss: 5.3711e-05 - accuracy: 1.0000 - val_loss: 4.2535e-04 - val_accuracy: 1.0000\n",
      "Epoch 10/80\n",
      "7041/7041 [==============================] - 1s 87us/step - loss: 4.6570e-05 - accuracy: 1.0000 - val_loss: 5.8198e-04 - val_accuracy: 1.0000\n",
      "Epoch 11/80\n",
      "7041/7041 [==============================] - 1s 85us/step - loss: 3.8381e-05 - accuracy: 1.0000 - val_loss: 8.5315e-04 - val_accuracy: 1.0000\n",
      "Epoch 12/80\n",
      "7041/7041 [==============================] - 1s 86us/step - loss: 4.0085e-05 - accuracy: 1.0000 - val_loss: 8.3699e-04 - val_accuracy: 1.0000\n",
      "Epoch 13/80\n",
      "7041/7041 [==============================] - 1s 87us/step - loss: 2.8549e-05 - accuracy: 1.0000 - val_loss: 6.6887e-04 - val_accuracy: 1.0000\n",
      "Epoch 14/80\n",
      "7041/7041 [==============================] - 1s 88us/step - loss: 0.0096 - accuracy: 0.9977 - val_loss: 0.0025 - val_accuracy: 1.0000\n",
      "Epoch 15/80\n",
      "7041/7041 [==============================] - 1s 87us/step - loss: 0.0011 - accuracy: 0.9999 - val_loss: 0.0078 - val_accuracy: 0.9987\n",
      "Epoch 16/80\n",
      "7041/7041 [==============================] - 1s 88us/step - loss: 0.0138 - accuracy: 0.9955 - val_loss: 0.0033 - val_accuracy: 0.9987\n",
      "Epoch 00016: early stopping\n",
      "[[1.6016929e-05 3.3795492e-05 4.6042783e-06 ... 9.1283357e-01\n",
      "  8.6670063e-02 1.7080749e-04]\n",
      " [8.6485397e-07 1.9745587e-06 1.1095591e-07 ... 7.7869691e-02\n",
      "  9.2186862e-01 1.7776649e-04]\n",
      " [4.4420807e-07 9.5865165e-05 5.1900901e-07 ... 9.3589652e-01\n",
      "  6.3731268e-02 2.3821292e-04]\n",
      " ...\n",
      " [5.2226101e-12 1.8038077e-09 5.4979434e-11 ... 3.6104430e-07\n",
      "  9.9999964e-01 3.9656342e-08]\n",
      " [9.5264755e-07 1.5187982e-08 3.7296362e-09 ... 8.6208624e-05\n",
      "  9.1643276e-05 2.5398374e-05]\n",
      " [1.0480831e-11 5.6653704e-09 1.3701623e-09 ... 2.8632897e-08\n",
      "  1.0000000e+00 6.5501793e-10]]\n",
      "[6 7 6 ... 7 3 7]\n",
      "<class 'numpy.ndarray'>\n",
      "One CNN, r:  2\n",
      "Computing Time:  0:01:42.031240\n",
      "Model: \"sequential_1\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv1d_1 (Conv1D)            (None, 1000, 6)           36        \n",
      "_________________________________________________________________\n",
      "average_pooling1d_1 (Average (None, 500, 6)            0         \n",
      "_________________________________________________________________\n",
      "conv1d_2 (Conv1D)            (None, 496, 16)           496       \n",
      "_________________________________________________________________\n",
      "average_pooling1d_2 (Average (None, 248, 16)           0         \n",
      "_________________________________________________________________\n",
      "conv1d_3 (Conv1D)            (None, 244, 120)          9720      \n",
      "_________________________________________________________________\n",
      "flatten_1 (Flatten)          (None, 29280)             0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 84)                2459604   \n",
      "_________________________________________________________________\n",
      "preds (Dense)                (None, 9)                 765       \n",
      "=================================================================\n",
      "Total params: 2,470,621\n",
      "Trainable params: 2,470,621\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Train on 7041 samples, validate on 783 samples\n",
      "Epoch 1/80\n",
      "7041/7041 [==============================] - 1s 118us/step - loss: 0.3875 - accuracy: 0.9024 - val_loss: 0.0073 - val_accuracy: 0.9987\n",
      "Epoch 2/80\n",
      "7041/7041 [==============================] - 1s 87us/step - loss: 0.0042 - accuracy: 0.9989 - val_loss: 0.0023 - val_accuracy: 1.0000\n",
      "Epoch 3/80\n",
      "7041/7041 [==============================] - 1s 86us/step - loss: 0.0025 - accuracy: 0.9994 - val_loss: 0.0011 - val_accuracy: 1.0000\n",
      "Epoch 4/80\n",
      "7041/7041 [==============================] - 1s 87us/step - loss: 6.7653e-04 - accuracy: 1.0000 - val_loss: 9.0407e-04 - val_accuracy: 1.0000\n",
      "Epoch 5/80\n",
      "7041/7041 [==============================] - 1s 90us/step - loss: 3.4423e-04 - accuracy: 1.0000 - val_loss: 0.0011 - val_accuracy: 1.0000\n",
      "Epoch 6/80\n",
      "7041/7041 [==============================] - 1s 88us/step - loss: 2.3710e-04 - accuracy: 1.0000 - val_loss: 7.0493e-04 - val_accuracy: 1.0000\n",
      "Epoch 7/80\n",
      "7041/7041 [==============================] - 1s 87us/step - loss: 1.6570e-04 - accuracy: 1.0000 - val_loss: 5.2127e-04 - val_accuracy: 1.0000\n",
      "Epoch 8/80\n",
      "7041/7041 [==============================] - 1s 89us/step - loss: 1.3479e-04 - accuracy: 1.0000 - val_loss: 4.8839e-04 - val_accuracy: 1.0000\n",
      "Epoch 9/80\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7041/7041 [==============================] - 1s 88us/step - loss: 1.1016e-04 - accuracy: 1.0000 - val_loss: 3.3776e-04 - val_accuracy: 1.0000\n",
      "Epoch 10/80\n",
      "7041/7041 [==============================] - 1s 88us/step - loss: 8.6785e-05 - accuracy: 1.0000 - val_loss: 3.0655e-04 - val_accuracy: 1.0000\n",
      "Epoch 11/80\n",
      "7041/7041 [==============================] - 1s 85us/step - loss: 7.1793e-05 - accuracy: 1.0000 - val_loss: 3.0125e-04 - val_accuracy: 1.0000\n",
      "Epoch 12/80\n",
      "7041/7041 [==============================] - 1s 90us/step - loss: 6.3907e-05 - accuracy: 1.0000 - val_loss: 2.4127e-04 - val_accuracy: 1.0000\n",
      "Epoch 13/80\n",
      "7041/7041 [==============================] - 1s 88us/step - loss: 5.4276e-05 - accuracy: 1.0000 - val_loss: 1.7259e-04 - val_accuracy: 1.0000\n",
      "Epoch 14/80\n",
      "7041/7041 [==============================] - 1s 91us/step - loss: 4.6367e-05 - accuracy: 1.0000 - val_loss: 2.6502e-04 - val_accuracy: 1.0000\n",
      "Epoch 15/80\n",
      "7041/7041 [==============================] - 1s 89us/step - loss: 3.9466e-05 - accuracy: 1.0000 - val_loss: 3.4573e-04 - val_accuracy: 1.0000\n",
      "Epoch 16/80\n",
      "7041/7041 [==============================] - 1s 86us/step - loss: 3.4736e-05 - accuracy: 1.0000 - val_loss: 2.0088e-04 - val_accuracy: 1.0000\n",
      "Epoch 17/80\n",
      "7041/7041 [==============================] - 1s 88us/step - loss: 3.1232e-05 - accuracy: 1.0000 - val_loss: 2.5477e-04 - val_accuracy: 1.0000\n",
      "Epoch 18/80\n",
      "7041/7041 [==============================] - 1s 85us/step - loss: 2.7178e-05 - accuracy: 1.0000 - val_loss: 2.1478e-04 - val_accuracy: 1.0000\n",
      "Epoch 19/80\n",
      "7041/7041 [==============================] - 1s 84us/step - loss: 2.4439e-05 - accuracy: 1.0000 - val_loss: 2.6868e-04 - val_accuracy: 1.0000\n",
      "Epoch 20/80\n",
      "7041/7041 [==============================] - 1s 88us/step - loss: 2.1694e-05 - accuracy: 1.0000 - val_loss: 2.3332e-04 - val_accuracy: 1.0000\n",
      "Epoch 21/80\n",
      "7041/7041 [==============================] - 1s 86us/step - loss: 1.9742e-05 - accuracy: 1.0000 - val_loss: 1.0790e-04 - val_accuracy: 1.0000\n",
      "Epoch 22/80\n",
      "7041/7041 [==============================] - 1s 87us/step - loss: 1.7978e-05 - accuracy: 1.0000 - val_loss: 2.6285e-04 - val_accuracy: 1.0000\n",
      "Epoch 23/80\n",
      "7041/7041 [==============================] - 1s 89us/step - loss: 1.6757e-05 - accuracy: 1.0000 - val_loss: 1.3723e-04 - val_accuracy: 1.0000\n",
      "Epoch 24/80\n",
      "7041/7041 [==============================] - 1s 88us/step - loss: 1.4749e-05 - accuracy: 1.0000 - val_loss: 2.2963e-04 - val_accuracy: 1.0000\n",
      "Epoch 25/80\n",
      "7041/7041 [==============================] - 1s 89us/step - loss: 1.3680e-05 - accuracy: 1.0000 - val_loss: 3.0091e-04 - val_accuracy: 1.0000\n",
      "Epoch 26/80\n",
      "7041/7041 [==============================] - 1s 89us/step - loss: 1.2365e-05 - accuracy: 1.0000 - val_loss: 1.7553e-04 - val_accuracy: 1.0000\n",
      "Epoch 27/80\n",
      "7041/7041 [==============================] - 1s 88us/step - loss: 1.1321e-05 - accuracy: 1.0000 - val_loss: 1.8877e-04 - val_accuracy: 1.0000\n",
      "Epoch 28/80\n",
      "7041/7041 [==============================] - 1s 87us/step - loss: 1.0597e-05 - accuracy: 1.0000 - val_loss: 1.6460e-04 - val_accuracy: 1.0000\n",
      "Epoch 29/80\n",
      "7041/7041 [==============================] - 1s 86us/step - loss: 9.6993e-06 - accuracy: 1.0000 - val_loss: 1.4412e-04 - val_accuracy: 1.0000\n",
      "Epoch 30/80\n",
      "7041/7041 [==============================] - 1s 85us/step - loss: 8.9613e-06 - accuracy: 1.0000 - val_loss: 1.4974e-04 - val_accuracy: 1.0000\n",
      "Epoch 31/80\n",
      "7041/7041 [==============================] - 1s 88us/step - loss: 8.1872e-06 - accuracy: 1.0000 - val_loss: 1.1985e-04 - val_accuracy: 1.0000\n",
      "Epoch 00031: early stopping\n",
      "[[8.71894602e-03 6.03047010e-05 3.51564049e-05 ... 8.16143692e-01\n",
      "  1.54391736e-01 1.77339723e-04]\n",
      " [2.50635203e-05 2.30626461e-06 2.85251840e-08 ... 8.98049772e-03\n",
      "  9.90584135e-01 1.29528984e-04]\n",
      " [1.22293404e-05 8.87147144e-06 3.02603303e-06 ... 7.43404627e-01\n",
      "  2.56394356e-01 1.05870189e-04]\n",
      " ...\n",
      " [1.01436918e-15 1.28651311e-12 1.58273691e-16 ... 9.52269947e-13\n",
      "  1.00000000e+00 1.02386724e-10]\n",
      " [9.68219324e-11 3.95061891e-12 2.09529018e-16 ... 1.27417167e-07\n",
      "  1.61155667e-09 7.73681397e-11]\n",
      " [3.99950221e-14 4.05090631e-12 1.81165135e-14 ... 1.06988494e-14\n",
      "  1.00000000e+00 1.95924862e-16]]\n",
      "[6 7 6 ... 7 3 7]\n",
      "<class 'numpy.ndarray'>\n",
      "One CNN, r:  3\n",
      "Computing Time:  0:02:04.156232\n",
      "Model: \"sequential_1\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv1d_1 (Conv1D)            (None, 1000, 6)           36        \n",
      "_________________________________________________________________\n",
      "average_pooling1d_1 (Average (None, 500, 6)            0         \n",
      "_________________________________________________________________\n",
      "conv1d_2 (Conv1D)            (None, 496, 16)           496       \n",
      "_________________________________________________________________\n",
      "average_pooling1d_2 (Average (None, 248, 16)           0         \n",
      "_________________________________________________________________\n",
      "conv1d_3 (Conv1D)            (None, 244, 120)          9720      \n",
      "_________________________________________________________________\n",
      "flatten_1 (Flatten)          (None, 29280)             0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 84)                2459604   \n",
      "_________________________________________________________________\n",
      "preds (Dense)                (None, 9)                 765       \n",
      "=================================================================\n",
      "Total params: 2,470,621\n",
      "Trainable params: 2,470,621\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Train on 7041 samples, validate on 783 samples\n",
      "Epoch 1/80\n",
      "7041/7041 [==============================] - 1s 118us/step - loss: 0.2182 - accuracy: 0.9348 - val_loss: 0.0035 - val_accuracy: 0.9987\n",
      "Epoch 2/80\n",
      "7041/7041 [==============================] - 1s 86us/step - loss: 0.0026 - accuracy: 0.9994 - val_loss: 0.0018 - val_accuracy: 1.0000\n",
      "Epoch 3/80\n",
      "7041/7041 [==============================] - 1s 87us/step - loss: 0.0011 - accuracy: 1.0000 - val_loss: 0.0014 - val_accuracy: 1.0000\n",
      "Epoch 4/80\n",
      "7041/7041 [==============================] - 1s 87us/step - loss: 6.1533e-04 - accuracy: 1.0000 - val_loss: 3.1083e-04 - val_accuracy: 1.0000\n",
      "Epoch 5/80\n",
      "7041/7041 [==============================] - 1s 85us/step - loss: 2.2293e-04 - accuracy: 1.0000 - val_loss: 2.4771e-04 - val_accuracy: 1.0000\n",
      "Epoch 6/80\n",
      "7041/7041 [==============================] - 1s 87us/step - loss: 1.1334e-04 - accuracy: 1.0000 - val_loss: 1.9999e-04 - val_accuracy: 1.0000\n",
      "Epoch 7/80\n",
      "7041/7041 [==============================] - 1s 87us/step - loss: 8.7178e-05 - accuracy: 1.0000 - val_loss: 1.5558e-04 - val_accuracy: 1.0000\n",
      "Epoch 8/80\n",
      "7041/7041 [==============================] - 1s 87us/step - loss: 6.8543e-05 - accuracy: 1.0000 - val_loss: 1.4959e-04 - val_accuracy: 1.0000\n",
      "Epoch 9/80\n",
      "7041/7041 [==============================] - 1s 87us/step - loss: 5.8366e-05 - accuracy: 1.0000 - val_loss: 1.2521e-04 - val_accuracy: 1.0000\n",
      "Epoch 10/80\n",
      "7041/7041 [==============================] - 1s 86us/step - loss: 4.4927e-05 - accuracy: 1.0000 - val_loss: 1.2233e-04 - val_accuracy: 1.0000\n",
      "Epoch 11/80\n",
      "7041/7041 [==============================] - 1s 84us/step - loss: 3.7763e-05 - accuracy: 1.0000 - val_loss: 1.0974e-04 - val_accuracy: 1.0000\n",
      "Epoch 12/80\n",
      "7041/7041 [==============================] - 1s 85us/step - loss: 3.2334e-05 - accuracy: 1.0000 - val_loss: 1.0671e-04 - val_accuracy: 1.0000\n",
      "Epoch 13/80\n",
      "7041/7041 [==============================] - 1s 88us/step - loss: 2.8700e-05 - accuracy: 1.0000 - val_loss: 9.9533e-05 - val_accuracy: 1.0000\n",
      "Epoch 14/80\n",
      "7041/7041 [==============================] - 1s 85us/step - loss: 2.4184e-05 - accuracy: 1.0000 - val_loss: 9.0342e-05 - val_accuracy: 1.0000\n",
      "Epoch 15/80\n",
      "7041/7041 [==============================] - 1s 86us/step - loss: 2.1375e-05 - accuracy: 1.0000 - val_loss: 8.7700e-05 - val_accuracy: 1.0000\n",
      "Epoch 16/80\n",
      "7041/7041 [==============================] - 1s 86us/step - loss: 1.9058e-05 - accuracy: 1.0000 - val_loss: 8.8157e-05 - val_accuracy: 1.0000\n",
      "Epoch 17/80\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7041/7041 [==============================] - 1s 89us/step - loss: 1.7083e-05 - accuracy: 1.0000 - val_loss: 8.4019e-05 - val_accuracy: 1.0000\n",
      "Epoch 18/80\n",
      "7041/7041 [==============================] - 1s 87us/step - loss: 1.5434e-05 - accuracy: 1.0000 - val_loss: 7.5058e-05 - val_accuracy: 1.0000\n",
      "Epoch 19/80\n",
      "7041/7041 [==============================] - 1s 86us/step - loss: 1.3718e-05 - accuracy: 1.0000 - val_loss: 6.9790e-05 - val_accuracy: 1.0000\n",
      "Epoch 20/80\n",
      "7041/7041 [==============================] - 1s 89us/step - loss: 1.2057e-05 - accuracy: 1.0000 - val_loss: 6.6340e-05 - val_accuracy: 1.0000\n",
      "Epoch 21/80\n",
      "7041/7041 [==============================] - 1s 86us/step - loss: 1.1053e-05 - accuracy: 1.0000 - val_loss: 6.7924e-05 - val_accuracy: 1.0000\n",
      "Epoch 22/80\n",
      "7041/7041 [==============================] - 1s 88us/step - loss: 1.0337e-05 - accuracy: 1.0000 - val_loss: 6.1744e-05 - val_accuracy: 1.0000\n",
      "Epoch 23/80\n",
      "7041/7041 [==============================] - 1s 87us/step - loss: 9.3540e-06 - accuracy: 1.0000 - val_loss: 5.7623e-05 - val_accuracy: 1.0000\n",
      "Epoch 24/80\n",
      "7041/7041 [==============================] - 1s 86us/step - loss: 8.4276e-06 - accuracy: 1.0000 - val_loss: 6.0617e-05 - val_accuracy: 1.0000\n",
      "Epoch 25/80\n",
      "7041/7041 [==============================] - 1s 85us/step - loss: 7.7964e-06 - accuracy: 1.0000 - val_loss: 5.8521e-05 - val_accuracy: 1.0000\n",
      "Epoch 26/80\n",
      "7041/7041 [==============================] - 1s 87us/step - loss: 7.1113e-06 - accuracy: 1.0000 - val_loss: 5.3922e-05 - val_accuracy: 1.0000\n",
      "Epoch 27/80\n",
      "7041/7041 [==============================] - 1s 86us/step - loss: 6.5777e-06 - accuracy: 1.0000 - val_loss: 5.1919e-05 - val_accuracy: 1.0000\n",
      "Epoch 28/80\n",
      "7041/7041 [==============================] - 1s 86us/step - loss: 6.1362e-06 - accuracy: 1.0000 - val_loss: 4.9588e-05 - val_accuracy: 1.0000\n",
      "Epoch 29/80\n",
      "7041/7041 [==============================] - 1s 87us/step - loss: 5.7119e-06 - accuracy: 1.0000 - val_loss: 4.7561e-05 - val_accuracy: 1.0000\n",
      "Epoch 30/80\n",
      "7041/7041 [==============================] - 1s 86us/step - loss: 5.2970e-06 - accuracy: 1.0000 - val_loss: 4.5865e-05 - val_accuracy: 1.0000\n",
      "Epoch 31/80\n",
      "7041/7041 [==============================] - 1s 87us/step - loss: 4.9179e-06 - accuracy: 1.0000 - val_loss: 4.8095e-05 - val_accuracy: 1.0000\n",
      "Epoch 32/80\n",
      "7041/7041 [==============================] - 1s 84us/step - loss: 4.6045e-06 - accuracy: 1.0000 - val_loss: 4.5132e-05 - val_accuracy: 1.0000\n",
      "Epoch 33/80\n",
      "7041/7041 [==============================] - 1s 86us/step - loss: 4.3091e-06 - accuracy: 1.0000 - val_loss: 3.6929e-05 - val_accuracy: 1.0000\n",
      "Epoch 34/80\n",
      "7041/7041 [==============================] - 1s 87us/step - loss: 0.2676 - accuracy: 0.9652 - val_loss: 0.0555 - val_accuracy: 0.9783\n",
      "Epoch 35/80\n",
      "7041/7041 [==============================] - 1s 87us/step - loss: 0.0068 - accuracy: 0.9976 - val_loss: 3.4933e-04 - val_accuracy: 1.0000\n",
      "Epoch 36/80\n",
      "7041/7041 [==============================] - 1s 89us/step - loss: 3.3917e-04 - accuracy: 1.0000 - val_loss: 2.4588e-04 - val_accuracy: 1.0000\n",
      "Epoch 37/80\n",
      "7041/7041 [==============================] - 1s 87us/step - loss: 2.0722e-04 - accuracy: 1.0000 - val_loss: 1.8354e-04 - val_accuracy: 1.0000\n",
      "Epoch 38/80\n",
      "7041/7041 [==============================] - 1s 84us/step - loss: 1.4201e-04 - accuracy: 1.0000 - val_loss: 1.4698e-04 - val_accuracy: 1.0000\n",
      "Epoch 39/80\n",
      "7041/7041 [==============================] - 1s 88us/step - loss: 1.0488e-04 - accuracy: 1.0000 - val_loss: 1.3021e-04 - val_accuracy: 1.0000\n",
      "Epoch 40/80\n",
      "7041/7041 [==============================] - 1s 85us/step - loss: 8.7312e-05 - accuracy: 1.0000 - val_loss: 1.1618e-04 - val_accuracy: 1.0000\n",
      "Epoch 41/80\n",
      "7041/7041 [==============================] - 1s 89us/step - loss: 7.4879e-05 - accuracy: 1.0000 - val_loss: 1.0899e-04 - val_accuracy: 1.0000\n",
      "Epoch 42/80\n",
      "7041/7041 [==============================] - 1s 86us/step - loss: 6.6923e-05 - accuracy: 1.0000 - val_loss: 9.8589e-05 - val_accuracy: 1.0000\n",
      "Epoch 43/80\n",
      "7041/7041 [==============================] - 1s 85us/step - loss: 5.9337e-05 - accuracy: 1.0000 - val_loss: 8.5851e-05 - val_accuracy: 1.0000\n",
      "Epoch 00043: early stopping\n",
      "[[9.2331652e-04 4.7030494e-06 2.9419832e-07 ... 8.9980417e-01\n",
      "  9.7393729e-02 1.1415494e-04]\n",
      " [1.1828543e-07 1.0496707e-08 2.5308733e-10 ... 3.7825252e-03\n",
      "  9.9620736e-01 5.3671406e-06]\n",
      " [1.2123789e-06 1.3383130e-06 1.2201165e-08 ... 9.4572210e-01\n",
      "  5.4115847e-02 1.3914317e-04]\n",
      " ...\n",
      " [1.5800101e-16 2.6174902e-14 5.9781166e-14 ... 2.0857470e-10\n",
      "  1.0000000e+00 1.4808678e-10]\n",
      " [9.5799466e-11 1.2363150e-11 1.6492824e-13 ... 5.9211216e-06\n",
      "  1.6796584e-08 4.7335416e-08]\n",
      " [8.0796403e-16 2.0845081e-12 2.4781001e-14 ... 1.5511149e-12\n",
      "  1.0000000e+00 7.8765948e-16]]\n",
      "[6 7 6 ... 7 3 7]\n",
      "<class 'numpy.ndarray'>\n",
      "One CNN, r:  4\n",
      "Computing Time:  0:02:33.281243\n",
      "num of merged_region_image 0 1734\n",
      "num of merged_region_image 1 1731\n",
      "num of merged_region_image 2 216\n",
      "num of merged_region_image 3 728\n",
      "num of merged_region_image 4 143\n",
      "num of merged_region_image 5 96\n",
      "num of merged_region_image 6 970\n",
      "num of merged_region_image 7 1997\n",
      "num of merged_region_image 8 209\n",
      "Counter({-1: 5252, 7: 1997, 0: 1734, 1: 1731, 6: 970, 3: 728, 2: 216, 8: 209, 4: 143, 5: 96})\n",
      "===========  ITE = 1   ===========\n",
      "used_img 7824 7824\n",
      "working_img(=other images=unclean images) 5252 5252\n",
      "merged regions 47 47\n",
      "other_regions 152 152\n",
      "All other regions\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>other index</th>\n",
       "      <th>pred label</th>\n",
       "      <th>truth</th>\n",
       "      <th>rate</th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>7</td>\n",
       "      <td>-1</td>\n",
       "      <td>8</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>65</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>9</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>10</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>13</td>\n",
       "      <td>6</td>\n",
       "      <td>4</td>\n",
       "      <td>0.92</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>373</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>147</th>\n",
       "      <td>193</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>148</th>\n",
       "      <td>195</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>149</th>\n",
       "      <td>196</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>150</th>\n",
       "      <td>197</td>\n",
       "      <td>6</td>\n",
       "      <td>4</td>\n",
       "      <td>0.99</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>107</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>151</th>\n",
       "      <td>198</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>152 rows × 13 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     other index  pred label  truth  rate  0  1  2  3    4  5  6  7   8\n",
       "0              2           0      0  0.00  0  0  0  0    0  0  0  0   0\n",
       "1              7          -1      8  0.00  0  0  0  0    0  0  0  0  65\n",
       "2              9           0      0  0.00  0  0  0  0    0  0  0  0   0\n",
       "3             10           0      0  0.00  0  0  0  0    0  0  0  0   0\n",
       "4             13           6      4  0.92  0  0  0  0  373  0  0  0   0\n",
       "..           ...         ...    ...   ... .. .. .. ..  ... .. .. ..  ..\n",
       "147          193           0      0  0.00  0  0  0  0    0  0  0  0   0\n",
       "148          195           0      0  0.00  0  0  0  0    0  0  0  0   0\n",
       "149          196           0      0  0.00  0  0  0  0    0  0  0  0   0\n",
       "150          197           6      4  0.99  0  0  0  0  107  0  0  0   0\n",
       "151          198           0      0  0.00  0  0  0  0    0  0  0  0   0\n",
       "\n",
       "[152 rows x 13 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "added label, regions, img amount: {1} [45] 241\n",
      "added label, regions, img amount: {3} [187] 93\n",
      "added label, regions, img amount: {6} [138, 184, 87, 95, 197] 718\n",
      "Not getting into residuals\n",
      "NUM_region 9\n",
      "number of clean images 8876\n",
      "n, p1, p2 0 0 0\n",
      "NUM_CLASSES 9\n",
      "current_train_label:  [0, 1, 2, 3, 4, 5, 6, 7, 8]\n",
      "Model: \"sequential_1\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv1d_1 (Conv1D)            (None, 1000, 6)           36        \n",
      "_________________________________________________________________\n",
      "average_pooling1d_1 (Average (None, 500, 6)            0         \n",
      "_________________________________________________________________\n",
      "conv1d_2 (Conv1D)            (None, 496, 16)           496       \n",
      "_________________________________________________________________\n",
      "average_pooling1d_2 (Average (None, 248, 16)           0         \n",
      "_________________________________________________________________\n",
      "conv1d_3 (Conv1D)            (None, 244, 120)          9720      \n",
      "_________________________________________________________________\n",
      "flatten_1 (Flatten)          (None, 29280)             0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 84)                2459604   \n",
      "_________________________________________________________________\n",
      "preds (Dense)                (None, 9)                 765       \n",
      "=================================================================\n",
      "Total params: 2,470,621\n",
      "Trainable params: 2,470,621\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Train on 7988 samples, validate on 888 samples\n",
      "Epoch 1/80\n",
      "7988/7988 [==============================] - 1s 164us/step - loss: 0.1722 - accuracy: 0.9480 - val_loss: 0.0043 - val_accuracy: 0.9977\n",
      "Epoch 2/80\n",
      "7988/7988 [==============================] - 1s 86us/step - loss: 0.0038 - accuracy: 0.9990 - val_loss: 0.0025 - val_accuracy: 0.9989\n",
      "Epoch 3/80\n",
      "7988/7988 [==============================] - 1s 87us/step - loss: 4.9201e-04 - accuracy: 1.0000 - val_loss: 0.0015 - val_accuracy: 1.0000\n",
      "Epoch 4/80\n",
      "7988/7988 [==============================] - 1s 83us/step - loss: 1.8243e-04 - accuracy: 1.0000 - val_loss: 0.0011 - val_accuracy: 1.0000\n",
      "Epoch 5/80\n",
      "7988/7988 [==============================] - 1s 89us/step - loss: 1.2596e-04 - accuracy: 1.0000 - val_loss: 5.7957e-04 - val_accuracy: 1.0000\n",
      "Epoch 6/80\n",
      "7988/7988 [==============================] - 1s 86us/step - loss: 9.3067e-05 - accuracy: 1.0000 - val_loss: 7.3724e-04 - val_accuracy: 1.0000\n",
      "Epoch 7/80\n",
      "7988/7988 [==============================] - 1s 84us/step - loss: 6.8930e-05 - accuracy: 1.0000 - val_loss: 6.6596e-04 - val_accuracy: 1.0000\n",
      "Epoch 8/80\n",
      "7988/7988 [==============================] - 1s 87us/step - loss: 5.6016e-05 - accuracy: 1.0000 - val_loss: 3.5737e-04 - val_accuracy: 1.0000\n",
      "Epoch 9/80\n",
      "7988/7988 [==============================] - 1s 86us/step - loss: 4.3213e-05 - accuracy: 1.0000 - val_loss: 4.3548e-04 - val_accuracy: 1.0000\n",
      "Epoch 10/80\n",
      "7988/7988 [==============================] - 1s 85us/step - loss: 3.5781e-05 - accuracy: 1.0000 - val_loss: 5.1090e-04 - val_accuracy: 1.0000\n",
      "Epoch 11/80\n",
      "7988/7988 [==============================] - 1s 85us/step - loss: 2.9818e-05 - accuracy: 1.0000 - val_loss: 4.3454e-04 - val_accuracy: 1.0000\n",
      "Epoch 12/80\n",
      "7988/7988 [==============================] - 1s 84us/step - loss: 2.5216e-05 - accuracy: 1.0000 - val_loss: 5.4256e-04 - val_accuracy: 1.0000\n",
      "Epoch 13/80\n",
      "7988/7988 [==============================] - 1s 88us/step - loss: 2.1955e-05 - accuracy: 1.0000 - val_loss: 4.5916e-04 - val_accuracy: 1.0000\n",
      "Epoch 14/80\n",
      "7988/7988 [==============================] - 1s 84us/step - loss: 1.8714e-05 - accuracy: 1.0000 - val_loss: 5.1864e-04 - val_accuracy: 1.0000\n",
      "Epoch 15/80\n",
      "7988/7988 [==============================] - 1s 86us/step - loss: 1.6409e-05 - accuracy: 1.0000 - val_loss: 4.2178e-04 - val_accuracy: 1.0000\n",
      "Epoch 16/80\n",
      "7988/7988 [==============================] - 1s 86us/step - loss: 1.4398e-05 - accuracy: 1.0000 - val_loss: 3.7017e-04 - val_accuracy: 1.0000\n",
      "Epoch 17/80\n",
      "7988/7988 [==============================] - 1s 86us/step - loss: 1.2675e-05 - accuracy: 1.0000 - val_loss: 3.6078e-04 - val_accuracy: 1.0000\n",
      "Epoch 18/80\n",
      "7988/7988 [==============================] - 1s 86us/step - loss: 1.1325e-05 - accuracy: 1.0000 - val_loss: 2.3365e-04 - val_accuracy: 1.0000\n",
      "Epoch 19/80\n",
      "7988/7988 [==============================] - 1s 86us/step - loss: 1.0258e-05 - accuracy: 1.0000 - val_loss: 3.9760e-04 - val_accuracy: 1.0000\n",
      "Epoch 20/80\n",
      "7988/7988 [==============================] - 1s 87us/step - loss: 9.2941e-06 - accuracy: 1.0000 - val_loss: 4.1133e-04 - val_accuracy: 1.0000\n",
      "Epoch 21/80\n",
      "7988/7988 [==============================] - 1s 87us/step - loss: 8.4821e-06 - accuracy: 1.0000 - val_loss: 2.9965e-04 - val_accuracy: 1.0000\n",
      "Epoch 22/80\n",
      "7988/7988 [==============================] - 1s 86us/step - loss: 7.6286e-06 - accuracy: 1.0000 - val_loss: 2.7714e-04 - val_accuracy: 1.0000\n",
      "Epoch 23/80\n",
      "7988/7988 [==============================] - 1s 84us/step - loss: 6.7740e-06 - accuracy: 1.0000 - val_loss: 2.5169e-04 - val_accuracy: 1.0000\n",
      "Epoch 24/80\n",
      "7988/7988 [==============================] - 1s 88us/step - loss: 6.3206e-06 - accuracy: 1.0000 - val_loss: 3.0441e-04 - val_accuracy: 1.0000\n",
      "Epoch 25/80\n",
      "7988/7988 [==============================] - 1s 84us/step - loss: 5.8555e-06 - accuracy: 1.0000 - val_loss: 2.5994e-04 - val_accuracy: 1.0000\n",
      "Epoch 26/80\n",
      "7988/7988 [==============================] - 1s 88us/step - loss: 5.1454e-06 - accuracy: 1.0000 - val_loss: 2.3034e-04 - val_accuracy: 1.0000\n",
      "Epoch 27/80\n",
      "7988/7988 [==============================] - 1s 85us/step - loss: 4.7585e-06 - accuracy: 1.0000 - val_loss: 3.2474e-04 - val_accuracy: 1.0000\n",
      "Epoch 28/80\n",
      "7988/7988 [==============================] - 1s 85us/step - loss: 4.3354e-06 - accuracy: 1.0000 - val_loss: 3.0381e-04 - val_accuracy: 1.0000\n",
      "Epoch 29/80\n",
      "7988/7988 [==============================] - 1s 85us/step - loss: 4.0027e-06 - accuracy: 1.0000 - val_loss: 2.8788e-04 - val_accuracy: 1.0000\n",
      "Epoch 30/80\n",
      "7988/7988 [==============================] - 1s 87us/step - loss: 3.7791e-06 - accuracy: 1.0000 - val_loss: 3.3975e-04 - val_accuracy: 1.0000\n",
      "Epoch 31/80\n",
      "7988/7988 [==============================] - 1s 86us/step - loss: 3.4957e-06 - accuracy: 1.0000 - val_loss: 2.6017e-04 - val_accuracy: 1.0000\n",
      "Epoch 32/80\n",
      "7988/7988 [==============================] - 1s 86us/step - loss: 3.2715e-06 - accuracy: 1.0000 - val_loss: 2.3400e-04 - val_accuracy: 1.0000\n",
      "Epoch 33/80\n",
      "7988/7988 [==============================] - 1s 85us/step - loss: 3.0912e-06 - accuracy: 1.0000 - val_loss: 2.6849e-04 - val_accuracy: 1.0000\n",
      "Epoch 34/80\n",
      "7988/7988 [==============================] - 1s 85us/step - loss: 2.7868e-06 - accuracy: 1.0000 - val_loss: 2.7967e-04 - val_accuracy: 1.0000\n",
      "Epoch 35/80\n",
      "7988/7988 [==============================] - 1s 87us/step - loss: 2.6052e-06 - accuracy: 1.0000 - val_loss: 2.9168e-04 - val_accuracy: 1.0000\n",
      "Epoch 36/80\n",
      "7988/7988 [==============================] - 1s 84us/step - loss: 2.4681e-06 - accuracy: 1.0000 - val_loss: 3.6845e-04 - val_accuracy: 1.0000\n",
      "Epoch 00036: early stopping\n",
      "[[2.9698064e-04 2.8959562e-07 1.9072768e-07 ... 9.5323771e-01\n",
      "  4.5035552e-02 1.2232240e-03]\n",
      " [3.2176212e-07 1.6478728e-09 2.6453081e-10 ... 1.6093206e-02\n",
      "  9.8364532e-01 2.5959109e-04]\n",
      " [2.6084976e-08 1.4858662e-08 7.2582242e-09 ... 6.7106497e-01\n",
      "  3.2888126e-01 5.0069262e-05]\n",
      " ...\n",
      " [3.7224001e-16 1.2918364e-16 3.8162749e-16 ... 1.0417780e-13\n",
      "  1.0000000e+00 3.2656919e-15]\n",
      " [1.2266512e-12 8.4544823e-15 3.9241154e-16 ... 2.3347485e-07\n",
      "  1.8746815e-11 1.6113230e-09]\n",
      " [1.2384163e-14 2.2315155e-15 1.4139873e-13 ... 6.1164694e-16\n",
      "  1.0000000e+00 1.4945124e-19]]\n",
      "[6 7 6 ... 7 3 7]\n",
      "<class 'numpy.ndarray'>\n",
      "One CNN, r:  0\n",
      "Computing Time:  0:00:28.271791\n",
      "Model: \"sequential_1\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv1d_1 (Conv1D)            (None, 1000, 6)           36        \n",
      "_________________________________________________________________\n",
      "average_pooling1d_1 (Average (None, 500, 6)            0         \n",
      "_________________________________________________________________\n",
      "conv1d_2 (Conv1D)            (None, 496, 16)           496       \n",
      "_________________________________________________________________\n",
      "average_pooling1d_2 (Average (None, 248, 16)           0         \n",
      "_________________________________________________________________\n",
      "conv1d_3 (Conv1D)            (None, 244, 120)          9720      \n",
      "_________________________________________________________________\n",
      "flatten_1 (Flatten)          (None, 29280)             0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 84)                2459604   \n",
      "_________________________________________________________________\n",
      "preds (Dense)                (None, 9)                 765       \n",
      "=================================================================\n",
      "Total params: 2,470,621\n",
      "Trainable params: 2,470,621\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 7988 samples, validate on 888 samples\n",
      "Epoch 1/80\n",
      "7988/7988 [==============================] - 1s 111us/step - loss: 0.1940 - accuracy: 0.9407 - val_loss: 0.0041 - val_accuracy: 0.9989\n",
      "Epoch 2/80\n",
      "7988/7988 [==============================] - 1s 88us/step - loss: 0.0028 - accuracy: 0.9996 - val_loss: 0.0016 - val_accuracy: 1.0000\n",
      "Epoch 3/80\n",
      "7988/7988 [==============================] - 1s 88us/step - loss: 6.7927e-04 - accuracy: 1.0000 - val_loss: 4.9368e-04 - val_accuracy: 1.0000\n",
      "Epoch 4/80\n",
      "7988/7988 [==============================] - 1s 87us/step - loss: 0.0011 - accuracy: 0.9997 - val_loss: 3.5387e-04 - val_accuracy: 1.0000\n",
      "Epoch 5/80\n",
      "7988/7988 [==============================] - 1s 87us/step - loss: 2.7099e-04 - accuracy: 1.0000 - val_loss: 3.0870e-04 - val_accuracy: 1.0000\n",
      "Epoch 6/80\n",
      "7988/7988 [==============================] - 1s 86us/step - loss: 7.4616e-04 - accuracy: 0.9996 - val_loss: 3.1663e-04 - val_accuracy: 1.0000\n",
      "Epoch 7/80\n",
      "7988/7988 [==============================] - 1s 86us/step - loss: 1.8643e-04 - accuracy: 1.0000 - val_loss: 1.4234e-04 - val_accuracy: 1.0000\n",
      "Epoch 8/80\n",
      "7988/7988 [==============================] - 1s 88us/step - loss: 8.3250e-05 - accuracy: 1.0000 - val_loss: 1.2453e-04 - val_accuracy: 1.0000\n",
      "Epoch 9/80\n",
      "7988/7988 [==============================] - 1s 88us/step - loss: 6.3601e-05 - accuracy: 1.0000 - val_loss: 1.1242e-04 - val_accuracy: 1.0000\n",
      "Epoch 10/80\n",
      "7988/7988 [==============================] - 1s 89us/step - loss: 5.1206e-05 - accuracy: 1.0000 - val_loss: 1.1049e-04 - val_accuracy: 1.0000\n",
      "Epoch 11/80\n",
      "7988/7988 [==============================] - 1s 87us/step - loss: 4.3662e-05 - accuracy: 1.0000 - val_loss: 1.0642e-04 - val_accuracy: 1.0000\n",
      "Epoch 12/80\n",
      "7988/7988 [==============================] - 1s 89us/step - loss: 3.6566e-05 - accuracy: 1.0000 - val_loss: 9.0761e-05 - val_accuracy: 1.0000\n",
      "Epoch 13/80\n",
      "7988/7988 [==============================] - 1s 88us/step - loss: 3.1601e-05 - accuracy: 1.0000 - val_loss: 7.8517e-05 - val_accuracy: 1.0000\n",
      "Epoch 14/80\n",
      "7988/7988 [==============================] - 1s 87us/step - loss: 2.7358e-05 - accuracy: 1.0000 - val_loss: 7.3215e-05 - val_accuracy: 1.0000\n",
      "Epoch 15/80\n",
      "7988/7988 [==============================] - 1s 87us/step - loss: 2.3587e-05 - accuracy: 1.0000 - val_loss: 6.2347e-05 - val_accuracy: 1.0000\n",
      "Epoch 16/80\n",
      "7988/7988 [==============================] - 1s 87us/step - loss: 2.0926e-05 - accuracy: 1.0000 - val_loss: 7.0909e-05 - val_accuracy: 1.0000\n",
      "Epoch 17/80\n",
      "7988/7988 [==============================] - 1s 85us/step - loss: 1.8702e-05 - accuracy: 1.0000 - val_loss: 6.4654e-05 - val_accuracy: 1.0000\n",
      "Epoch 18/80\n",
      "7988/7988 [==============================] - 1s 86us/step - loss: 1.6794e-05 - accuracy: 1.0000 - val_loss: 5.9293e-05 - val_accuracy: 1.0000\n",
      "Epoch 19/80\n",
      "7988/7988 [==============================] - 1s 90us/step - loss: 1.4748e-05 - accuracy: 1.0000 - val_loss: 5.1328e-05 - val_accuracy: 1.0000\n",
      "Epoch 20/80\n",
      "7988/7988 [==============================] - 1s 88us/step - loss: 1.3555e-05 - accuracy: 1.0000 - val_loss: 5.0955e-05 - val_accuracy: 1.0000\n",
      "Epoch 21/80\n",
      "7988/7988 [==============================] - 1s 86us/step - loss: 1.2167e-05 - accuracy: 1.0000 - val_loss: 4.9270e-05 - val_accuracy: 1.0000\n",
      "Epoch 22/80\n",
      "7988/7988 [==============================] - 1s 86us/step - loss: 1.1214e-05 - accuracy: 1.0000 - val_loss: 4.3705e-05 - val_accuracy: 1.0000\n",
      "Epoch 23/80\n",
      "7988/7988 [==============================] - 1s 86us/step - loss: 1.0067e-05 - accuracy: 1.0000 - val_loss: 4.3012e-05 - val_accuracy: 1.0000\n",
      "Epoch 24/80\n",
      "7988/7988 [==============================] - 1s 88us/step - loss: 9.3913e-06 - accuracy: 1.0000 - val_loss: 4.0848e-05 - val_accuracy: 1.0000\n",
      "Epoch 25/80\n",
      "7988/7988 [==============================] - 1s 86us/step - loss: 8.5538e-06 - accuracy: 1.0000 - val_loss: 4.1550e-05 - val_accuracy: 1.0000\n",
      "Epoch 26/80\n",
      "7988/7988 [==============================] - 1s 86us/step - loss: 7.9183e-06 - accuracy: 1.0000 - val_loss: 4.1476e-05 - val_accuracy: 1.0000\n",
      "Epoch 27/80\n",
      "7988/7988 [==============================] - 1s 88us/step - loss: 7.3619e-06 - accuracy: 1.0000 - val_loss: 3.4945e-05 - val_accuracy: 1.0000\n",
      "Epoch 28/80\n",
      "7988/7988 [==============================] - 1s 88us/step - loss: 6.8022e-06 - accuracy: 1.0000 - val_loss: 3.6169e-05 - val_accuracy: 1.0000\n",
      "Epoch 29/80\n",
      "7988/7988 [==============================] - 1s 87us/step - loss: 6.3723e-06 - accuracy: 1.0000 - val_loss: 3.5521e-05 - val_accuracy: 1.0000\n",
      "Epoch 30/80\n",
      "7988/7988 [==============================] - 1s 87us/step - loss: 5.9101e-06 - accuracy: 1.0000 - val_loss: 3.2665e-05 - val_accuracy: 1.0000\n",
      "Epoch 31/80\n",
      "7988/7988 [==============================] - 1s 86us/step - loss: 5.4985e-06 - accuracy: 1.0000 - val_loss: 3.1264e-05 - val_accuracy: 1.0000\n",
      "Epoch 32/80\n",
      "7988/7988 [==============================] - 1s 84us/step - loss: 5.1056e-06 - accuracy: 1.0000 - val_loss: 2.8326e-05 - val_accuracy: 1.0000\n",
      "Epoch 33/80\n",
      "7988/7988 [==============================] - 1s 86us/step - loss: 4.8124e-06 - accuracy: 1.0000 - val_loss: 2.8540e-05 - val_accuracy: 1.0000\n",
      "Epoch 34/80\n",
      "7988/7988 [==============================] - 1s 87us/step - loss: 4.5137e-06 - accuracy: 1.0000 - val_loss: 2.7109e-05 - val_accuracy: 1.0000\n",
      "Epoch 35/80\n",
      "7988/7988 [==============================] - 1s 89us/step - loss: 4.2586e-06 - accuracy: 1.0000 - val_loss: 2.6477e-05 - val_accuracy: 1.0000\n",
      "Epoch 36/80\n",
      "7988/7988 [==============================] - 1s 88us/step - loss: 3.9741e-06 - accuracy: 1.0000 - val_loss: 2.4761e-05 - val_accuracy: 1.0000\n",
      "Epoch 37/80\n",
      "7988/7988 [==============================] - 1s 88us/step - loss: 3.6930e-06 - accuracy: 1.0000 - val_loss: 2.5665e-05 - val_accuracy: 1.0000\n",
      "Epoch 38/80\n",
      "7988/7988 [==============================] - 1s 86us/step - loss: 3.5147e-06 - accuracy: 1.0000 - val_loss: 2.6146e-05 - val_accuracy: 1.0000\n",
      "Epoch 39/80\n",
      "7988/7988 [==============================] - 1s 88us/step - loss: 3.3182e-06 - accuracy: 1.0000 - val_loss: 2.2443e-05 - val_accuracy: 1.0000\n",
      "Epoch 40/80\n",
      "7988/7988 [==============================] - 1s 88us/step - loss: 3.1722e-06 - accuracy: 1.0000 - val_loss: 2.2874e-05 - val_accuracy: 1.0000\n",
      "Epoch 41/80\n",
      "7988/7988 [==============================] - 1s 86us/step - loss: 2.9597e-06 - accuracy: 1.0000 - val_loss: 2.0935e-05 - val_accuracy: 1.0000\n",
      "Epoch 42/80\n",
      "7988/7988 [==============================] - 1s 90us/step - loss: 2.7948e-06 - accuracy: 1.0000 - val_loss: 2.0800e-05 - val_accuracy: 1.0000\n",
      "Epoch 43/80\n",
      "7988/7988 [==============================] - 1s 86us/step - loss: 2.6235e-06 - accuracy: 1.0000 - val_loss: 2.0992e-05 - val_accuracy: 1.0000\n",
      "Epoch 44/80\n",
      "7988/7988 [==============================] - 1s 88us/step - loss: 2.4776e-06 - accuracy: 1.0000 - val_loss: 2.0323e-05 - val_accuracy: 1.0000\n",
      "Epoch 45/80\n",
      "7988/7988 [==============================] - 1s 90us/step - loss: 2.3915e-06 - accuracy: 1.0000 - val_loss: 1.9995e-05 - val_accuracy: 1.0000\n",
      "Epoch 46/80\n",
      "7988/7988 [==============================] - 1s 88us/step - loss: 2.2592e-06 - accuracy: 1.0000 - val_loss: 1.8955e-05 - val_accuracy: 1.0000\n",
      "Epoch 47/80\n",
      "7988/7988 [==============================] - 1s 86us/step - loss: 2.1305e-06 - accuracy: 1.0000 - val_loss: 1.7716e-05 - val_accuracy: 1.0000\n",
      "Epoch 48/80\n",
      "7988/7988 [==============================] - 1s 86us/step - loss: 2.0283e-06 - accuracy: 1.0000 - val_loss: 1.8623e-05 - val_accuracy: 1.0000\n",
      "Epoch 49/80\n",
      "7988/7988 [==============================] - 1s 86us/step - loss: 1.9202e-06 - accuracy: 1.0000 - val_loss: 1.6563e-05 - val_accuracy: 1.0000\n",
      "Epoch 50/80\n",
      "7988/7988 [==============================] - 1s 88us/step - loss: 1.8282e-06 - accuracy: 1.0000 - val_loss: 1.6346e-05 - val_accuracy: 1.0000\n",
      "Epoch 51/80\n",
      "7988/7988 [==============================] - ETA: 0s - loss: 1.7581e-06 - accuracy: 1.00 - 1s 85us/step - loss: 1.7403e-06 - accuracy: 1.0000 - val_loss: 1.5530e-05 - val_accuracy: 1.0000\n",
      "Epoch 52/80\n",
      "7988/7988 [==============================] - 1s 86us/step - loss: 1.6689e-06 - accuracy: 1.0000 - val_loss: 1.5377e-05 - val_accuracy: 1.0000\n",
      "Epoch 53/80\n",
      "7988/7988 [==============================] - 1s 87us/step - loss: 1.6040e-06 - accuracy: 1.0000 - val_loss: 1.5216e-05 - val_accuracy: 1.0000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 54/80\n",
      "7988/7988 [==============================] - 1s 87us/step - loss: 1.4947e-06 - accuracy: 1.0000 - val_loss: 1.3924e-05 - val_accuracy: 1.0000\n",
      "Epoch 55/80\n",
      "7988/7988 [==============================] - 1s 88us/step - loss: 1.4492e-06 - accuracy: 1.0000 - val_loss: 1.4267e-05 - val_accuracy: 1.0000\n",
      "Epoch 56/80\n",
      "7988/7988 [==============================] - 1s 86us/step - loss: 1.3552e-06 - accuracy: 1.0000 - val_loss: 1.4606e-05 - val_accuracy: 1.0000\n",
      "Epoch 57/80\n",
      "7988/7988 [==============================] - 1s 90us/step - loss: 1.3168e-06 - accuracy: 1.0000 - val_loss: 1.3750e-05 - val_accuracy: 1.0000\n",
      "Epoch 58/80\n",
      "7988/7988 [==============================] - 1s 88us/step - loss: 1.2363e-06 - accuracy: 1.0000 - val_loss: 1.2967e-05 - val_accuracy: 1.0000\n",
      "Epoch 59/80\n",
      "7988/7988 [==============================] - 1s 86us/step - loss: 1.2008e-06 - accuracy: 1.0000 - val_loss: 1.2950e-05 - val_accuracy: 1.0000\n",
      "Epoch 60/80\n",
      "7988/7988 [==============================] - 1s 88us/step - loss: 1.1316e-06 - accuracy: 1.0000 - val_loss: 1.2806e-05 - val_accuracy: 1.0000\n",
      "Epoch 61/80\n",
      "7988/7988 [==============================] - 1s 86us/step - loss: 1.0930e-06 - accuracy: 1.0000 - val_loss: 1.2883e-05 - val_accuracy: 1.0000\n",
      "Epoch 62/80\n",
      "7988/7988 [==============================] - 1s 86us/step - loss: 1.0367e-06 - accuracy: 1.0000 - val_loss: 1.1721e-05 - val_accuracy: 1.0000\n",
      "Epoch 63/80\n",
      "7988/7988 [==============================] - ETA: 0s - loss: 1.0177e-06 - accuracy: 1.00 - 1s 86us/step - loss: 1.0046e-06 - accuracy: 1.0000 - val_loss: 1.2002e-05 - val_accuracy: 1.0000\n",
      "Epoch 64/80\n",
      "7988/7988 [==============================] - 1s 87us/step - loss: 9.3882e-07 - accuracy: 1.0000 - val_loss: 1.1816e-05 - val_accuracy: 1.0000\n",
      "Epoch 65/80\n",
      "7988/7988 [==============================] - 1s 88us/step - loss: 9.1291e-07 - accuracy: 1.0000 - val_loss: 1.1659e-05 - val_accuracy: 1.0000\n",
      "Epoch 66/80\n",
      "7988/7988 [==============================] - 1s 84us/step - loss: 8.6358e-07 - accuracy: 1.0000 - val_loss: 1.0559e-05 - val_accuracy: 1.0000\n",
      "Epoch 67/80\n",
      "7988/7988 [==============================] - 1s 86us/step - loss: 8.4158e-07 - accuracy: 1.0000 - val_loss: 1.0871e-05 - val_accuracy: 1.0000\n",
      "Epoch 68/80\n",
      "7988/7988 [==============================] - 1s 88us/step - loss: 8.0250e-07 - accuracy: 1.0000 - val_loss: 1.0562e-05 - val_accuracy: 1.0000\n",
      "Epoch 69/80\n",
      "7988/7988 [==============================] - 1s 86us/step - loss: 7.5810e-07 - accuracy: 1.0000 - val_loss: 1.0998e-05 - val_accuracy: 1.0000\n",
      "Epoch 70/80\n",
      "7988/7988 [==============================] - 1s 87us/step - loss: 7.3514e-07 - accuracy: 1.0000 - val_loss: 9.9816e-06 - val_accuracy: 1.0000\n",
      "Epoch 71/80\n",
      "7988/7988 [==============================] - 1s 87us/step - loss: 7.0290e-07 - accuracy: 1.0000 - val_loss: 1.0492e-05 - val_accuracy: 1.0000\n",
      "Epoch 72/80\n",
      "7988/7988 [==============================] - 1s 86us/step - loss: 6.7079e-07 - accuracy: 1.0000 - val_loss: 9.7674e-06 - val_accuracy: 1.0000\n",
      "Epoch 73/80\n",
      "7988/7988 [==============================] - 1s 88us/step - loss: 6.4797e-07 - accuracy: 1.0000 - val_loss: 9.3155e-06 - val_accuracy: 1.0000\n",
      "Epoch 74/80\n",
      "7988/7988 [==============================] - 1s 86us/step - loss: 6.2021e-07 - accuracy: 1.0000 - val_loss: 8.6676e-06 - val_accuracy: 1.0000\n",
      "Epoch 75/80\n",
      "7988/7988 [==============================] - ETA: 0s - loss: 6.1234e-07 - accuracy: 1.00 - 1s 89us/step - loss: 5.9470e-07 - accuracy: 1.0000 - val_loss: 9.0284e-06 - val_accuracy: 1.0000\n",
      "Epoch 76/80\n",
      "7988/7988 [==============================] - 1s 87us/step - loss: 5.7555e-07 - accuracy: 1.0000 - val_loss: 8.8652e-06 - val_accuracy: 1.0000\n",
      "Epoch 77/80\n",
      "7988/7988 [==============================] - 1s 86us/step - loss: 5.4387e-07 - accuracy: 1.0000 - val_loss: 8.5621e-06 - val_accuracy: 1.0000\n",
      "Epoch 78/80\n",
      "7988/7988 [==============================] - 1s 86us/step - loss: 5.2348e-07 - accuracy: 1.0000 - val_loss: 8.7097e-06 - val_accuracy: 1.0000\n",
      "Epoch 79/80\n",
      "7988/7988 [==============================] - 1s 88us/step - loss: 5.0378e-07 - accuracy: 1.0000 - val_loss: 8.6891e-06 - val_accuracy: 1.0000\n",
      "Epoch 80/80\n",
      "7988/7988 [==============================] - 1s 88us/step - loss: 4.9047e-07 - accuracy: 1.0000 - val_loss: 8.1530e-06 - val_accuracy: 1.0000\n",
      "[[6.28403313e-07 1.10230644e-07 3.41659899e-07 ... 9.89341736e-01\n",
      "  9.99024790e-03 1.56388542e-05]\n",
      " [2.59513730e-11 1.60144698e-09 8.25521762e-10 ... 7.31817782e-02\n",
      "  9.26085532e-01 7.09328393e-04]\n",
      " [1.28846473e-11 7.63764163e-09 2.72323253e-09 ... 9.63509083e-01\n",
      "  3.64825651e-02 7.31801401e-06]\n",
      " ...\n",
      " [6.61259203e-25 2.63174078e-19 1.83015119e-19 ... 1.78216918e-15\n",
      "  1.00000000e+00 2.94646902e-13]\n",
      " [4.03689696e-13 2.37860682e-17 1.92604228e-16 ... 7.33163503e-08\n",
      "  1.17398029e-12 6.36690978e-11]\n",
      " [8.34878380e-23 7.49900238e-16 9.94803181e-15 ... 7.15136484e-17\n",
      "  1.00000000e+00 1.45207900e-17]]\n",
      "[6 7 6 ... 7 3 7]\n",
      "<class 'numpy.ndarray'>\n",
      "One CNN, r:  1\n",
      "Computing Time:  0:01:27.093177\n",
      "Model: \"sequential_1\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv1d_1 (Conv1D)            (None, 1000, 6)           36        \n",
      "_________________________________________________________________\n",
      "average_pooling1d_1 (Average (None, 500, 6)            0         \n",
      "_________________________________________________________________\n",
      "conv1d_2 (Conv1D)            (None, 496, 16)           496       \n",
      "_________________________________________________________________\n",
      "average_pooling1d_2 (Average (None, 248, 16)           0         \n",
      "_________________________________________________________________\n",
      "conv1d_3 (Conv1D)            (None, 244, 120)          9720      \n",
      "_________________________________________________________________\n",
      "flatten_1 (Flatten)          (None, 29280)             0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 84)                2459604   \n",
      "_________________________________________________________________\n",
      "preds (Dense)                (None, 9)                 765       \n",
      "=================================================================\n",
      "Total params: 2,470,621\n",
      "Trainable params: 2,470,621\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Train on 7988 samples, validate on 888 samples\n",
      "Epoch 1/80\n",
      "7988/7988 [==============================] - 1s 117us/step - loss: 0.2450 - accuracy: 0.9320 - val_loss: 0.0038 - val_accuracy: 0.9989\n",
      "Epoch 2/80\n",
      "7988/7988 [==============================] - 1s 86us/step - loss: 0.0058 - accuracy: 0.9987 - val_loss: 0.0035 - val_accuracy: 0.9989\n",
      "Epoch 3/80\n",
      "7988/7988 [==============================] - 1s 88us/step - loss: 9.7176e-04 - accuracy: 1.0000 - val_loss: 0.0032 - val_accuracy: 0.9989\n",
      "Epoch 4/80\n",
      "7988/7988 [==============================] - 1s 86us/step - loss: 6.6107e-04 - accuracy: 1.0000 - val_loss: 0.0026 - val_accuracy: 0.9989\n",
      "Epoch 5/80\n",
      "7988/7988 [==============================] - 1s 88us/step - loss: 2.2033e-04 - accuracy: 1.0000 - val_loss: 0.0014 - val_accuracy: 0.9989\n",
      "Epoch 6/80\n",
      "7988/7988 [==============================] - 1s 86us/step - loss: 1.6058e-04 - accuracy: 1.0000 - val_loss: 0.0015 - val_accuracy: 0.9989\n",
      "Epoch 7/80\n",
      "7988/7988 [==============================] - 1s 87us/step - loss: 1.1590e-04 - accuracy: 1.0000 - val_loss: 0.0016 - val_accuracy: 0.9989\n",
      "Epoch 8/80\n",
      "7988/7988 [==============================] - 1s 85us/step - loss: 9.0484e-05 - accuracy: 1.0000 - val_loss: 0.0014 - val_accuracy: 0.9989\n",
      "Epoch 9/80\n",
      "7988/7988 [==============================] - 1s 89us/step - loss: 7.5036e-05 - accuracy: 1.0000 - val_loss: 0.0015 - val_accuracy: 0.9989\n",
      "Epoch 10/80\n",
      "7988/7988 [==============================] - 1s 84us/step - loss: 6.2708e-05 - accuracy: 1.0000 - val_loss: 0.0015 - val_accuracy: 0.9989\n",
      "Epoch 11/80\n",
      "7988/7988 [==============================] - 1s 90us/step - loss: 5.1208e-05 - accuracy: 1.0000 - val_loss: 0.0011 - val_accuracy: 0.9989\n",
      "Epoch 12/80\n",
      "7988/7988 [==============================] - 1s 87us/step - loss: 4.5627e-05 - accuracy: 1.0000 - val_loss: 0.0020 - val_accuracy: 0.9989\n",
      "Epoch 13/80\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7988/7988 [==============================] - 1s 88us/step - loss: 3.7449e-05 - accuracy: 1.0000 - val_loss: 0.0020 - val_accuracy: 0.9989\n",
      "Epoch 14/80\n",
      "7988/7988 [==============================] - 1s 87us/step - loss: 3.2409e-05 - accuracy: 1.0000 - val_loss: 0.0018 - val_accuracy: 0.9989\n",
      "Epoch 15/80\n",
      "7988/7988 [==============================] - 1s 86us/step - loss: 2.9668e-05 - accuracy: 1.0000 - val_loss: 0.0016 - val_accuracy: 0.9989\n",
      "Epoch 16/80\n",
      "7988/7988 [==============================] - 1s 86us/step - loss: 2.4268e-05 - accuracy: 1.0000 - val_loss: 0.0022 - val_accuracy: 0.9989\n",
      "Epoch 17/80\n",
      "7988/7988 [==============================] - 1s 88us/step - loss: 2.2135e-05 - accuracy: 1.0000 - val_loss: 0.0023 - val_accuracy: 0.9989\n",
      "Epoch 18/80\n",
      "7988/7988 [==============================] - 1s 85us/step - loss: 2.0143e-05 - accuracy: 1.0000 - val_loss: 0.0016 - val_accuracy: 0.9989\n",
      "Epoch 19/80\n",
      "7988/7988 [==============================] - 1s 89us/step - loss: 1.7514e-05 - accuracy: 1.0000 - val_loss: 0.0018 - val_accuracy: 0.9989\n",
      "Epoch 20/80\n",
      "7988/7988 [==============================] - 1s 87us/step - loss: 1.5516e-05 - accuracy: 1.0000 - val_loss: 0.0017 - val_accuracy: 0.9989\n",
      "Epoch 21/80\n",
      "7988/7988 [==============================] - 1s 86us/step - loss: 1.4081e-05 - accuracy: 1.0000 - val_loss: 0.0015 - val_accuracy: 0.9989\n",
      "Epoch 00021: early stopping\n",
      "[[4.00761579e-04 2.61716559e-05 5.56523037e-06 ... 8.57999861e-01\n",
      "  1.41220927e-01 1.10265992e-05]\n",
      " [5.26612842e-09 3.19720556e-10 4.74864537e-10 ... 1.28876418e-03\n",
      "  9.98710871e-01 4.10429557e-08]\n",
      " [3.42838393e-06 2.53167150e-06 5.87636521e-07 ... 7.36575186e-01\n",
      "  2.63408780e-01 1.98897442e-06]\n",
      " ...\n",
      " [1.35255280e-16 6.76566720e-16 2.17551823e-16 ... 2.80743012e-13\n",
      "  1.00000000e+00 1.03439074e-13]\n",
      " [5.01753011e-14 2.42537652e-13 7.02865491e-17 ... 4.72437790e-07\n",
      "  3.63959175e-11 1.75994487e-07]\n",
      " [3.91556332e-16 1.53245760e-14 2.51968941e-14 ... 5.63885757e-14\n",
      "  1.00000000e+00 3.28906595e-18]]\n",
      "[6 7 6 ... 7 3 7]\n",
      "<class 'numpy.ndarray'>\n",
      "One CNN, r:  2\n",
      "Computing Time:  0:01:44.702588\n",
      "Model: \"sequential_1\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv1d_1 (Conv1D)            (None, 1000, 6)           36        \n",
      "_________________________________________________________________\n",
      "average_pooling1d_1 (Average (None, 500, 6)            0         \n",
      "_________________________________________________________________\n",
      "conv1d_2 (Conv1D)            (None, 496, 16)           496       \n",
      "_________________________________________________________________\n",
      "average_pooling1d_2 (Average (None, 248, 16)           0         \n",
      "_________________________________________________________________\n",
      "conv1d_3 (Conv1D)            (None, 244, 120)          9720      \n",
      "_________________________________________________________________\n",
      "flatten_1 (Flatten)          (None, 29280)             0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 84)                2459604   \n",
      "_________________________________________________________________\n",
      "preds (Dense)                (None, 9)                 765       \n",
      "=================================================================\n",
      "Total params: 2,470,621\n",
      "Trainable params: 2,470,621\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Train on 7988 samples, validate on 888 samples\n",
      "Epoch 1/80\n",
      "7988/7988 [==============================] - 1s 113us/step - loss: 0.2442 - accuracy: 0.9304 - val_loss: 0.0046 - val_accuracy: 0.9989\n",
      "Epoch 2/80\n",
      "7988/7988 [==============================] - 1s 89us/step - loss: 0.0030 - accuracy: 0.9994 - val_loss: 0.0022 - val_accuracy: 1.0000\n",
      "Epoch 3/80\n",
      "7988/7988 [==============================] - 1s 85us/step - loss: 7.7603e-04 - accuracy: 0.9999 - val_loss: 0.0017 - val_accuracy: 1.0000\n",
      "Epoch 4/80\n",
      "7988/7988 [==============================] - 1s 86us/step - loss: 2.9958e-04 - accuracy: 1.0000 - val_loss: 0.0010 - val_accuracy: 1.0000\n",
      "Epoch 5/80\n",
      "7988/7988 [==============================] - 1s 88us/step - loss: 2.1793e-04 - accuracy: 1.0000 - val_loss: 0.0010 - val_accuracy: 1.0000\n",
      "Epoch 6/80\n",
      "7988/7988 [==============================] - 1s 85us/step - loss: 1.3719e-04 - accuracy: 1.0000 - val_loss: 7.0621e-04 - val_accuracy: 1.0000\n",
      "Epoch 7/80\n",
      "7988/7988 [==============================] - 1s 86us/step - loss: 1.0661e-04 - accuracy: 1.0000 - val_loss: 6.5744e-04 - val_accuracy: 1.0000\n",
      "Epoch 8/80\n",
      "7988/7988 [==============================] - 1s 86us/step - loss: 7.6799e-05 - accuracy: 1.0000 - val_loss: 5.9312e-04 - val_accuracy: 1.0000\n",
      "Epoch 9/80\n",
      "7988/7988 [==============================] - 1s 91us/step - loss: 6.3080e-05 - accuracy: 1.0000 - val_loss: 6.4557e-04 - val_accuracy: 1.0000\n",
      "Epoch 10/80\n",
      "7988/7988 [==============================] - 1s 86us/step - loss: 5.0752e-05 - accuracy: 1.0000 - val_loss: 8.1713e-04 - val_accuracy: 1.0000\n",
      "Epoch 11/80\n",
      "7988/7988 [==============================] - 1s 88us/step - loss: 4.3111e-05 - accuracy: 1.0000 - val_loss: 6.1388e-04 - val_accuracy: 1.0000\n",
      "Epoch 12/80\n",
      "7988/7988 [==============================] - 1s 86us/step - loss: 3.6312e-05 - accuracy: 1.0000 - val_loss: 5.1769e-04 - val_accuracy: 1.0000\n",
      "Epoch 13/80\n",
      "7988/7988 [==============================] - 1s 86us/step - loss: 3.0787e-05 - accuracy: 1.0000 - val_loss: 5.2807e-04 - val_accuracy: 1.0000\n",
      "Epoch 14/80\n",
      "7988/7988 [==============================] - 1s 88us/step - loss: 2.6520e-05 - accuracy: 1.0000 - val_loss: 5.3985e-04 - val_accuracy: 1.0000\n",
      "Epoch 15/80\n",
      "7988/7988 [==============================] - 1s 87us/step - loss: 2.3619e-05 - accuracy: 1.0000 - val_loss: 5.8552e-04 - val_accuracy: 1.0000\n",
      "Epoch 16/80\n",
      "7988/7988 [==============================] - 1s 87us/step - loss: 2.0136e-05 - accuracy: 1.0000 - val_loss: 6.6096e-04 - val_accuracy: 1.0000\n",
      "Epoch 17/80\n",
      "7988/7988 [==============================] - 1s 86us/step - loss: 1.8137e-05 - accuracy: 1.0000 - val_loss: 5.5705e-04 - val_accuracy: 1.0000\n",
      "Epoch 18/80\n",
      "7988/7988 [==============================] - 1s 88us/step - loss: 1.5641e-05 - accuracy: 1.0000 - val_loss: 4.6054e-04 - val_accuracy: 1.0000\n",
      "Epoch 19/80\n",
      "7988/7988 [==============================] - 1s 86us/step - loss: 1.3997e-05 - accuracy: 1.0000 - val_loss: 5.8078e-04 - val_accuracy: 1.0000\n",
      "Epoch 20/80\n",
      "7988/7988 [==============================] - 1s 88us/step - loss: 1.3106e-05 - accuracy: 1.0000 - val_loss: 5.8862e-04 - val_accuracy: 1.0000\n",
      "Epoch 21/80\n",
      "7988/7988 [==============================] - 1s 87us/step - loss: 1.1337e-05 - accuracy: 1.0000 - val_loss: 4.4417e-04 - val_accuracy: 1.0000\n",
      "Epoch 22/80\n",
      "7988/7988 [==============================] - 1s 86us/step - loss: 1.0628e-05 - accuracy: 1.0000 - val_loss: 5.6635e-04 - val_accuracy: 1.0000\n",
      "Epoch 23/80\n",
      "7988/7988 [==============================] - 1s 86us/step - loss: 9.5400e-06 - accuracy: 1.0000 - val_loss: 4.8953e-04 - val_accuracy: 1.0000\n",
      "Epoch 24/80\n",
      "7988/7988 [==============================] - 1s 88us/step - loss: 8.7501e-06 - accuracy: 1.0000 - val_loss: 4.7551e-04 - val_accuracy: 1.0000\n",
      "Epoch 25/80\n",
      "7988/7988 [==============================] - 1s 89us/step - loss: 7.7617e-06 - accuracy: 1.0000 - val_loss: 5.3835e-04 - val_accuracy: 1.0000\n",
      "Epoch 26/80\n",
      "7988/7988 [==============================] - 1s 86us/step - loss: 7.3161e-06 - accuracy: 1.0000 - val_loss: 4.7090e-04 - val_accuracy: 1.0000\n",
      "Epoch 27/80\n",
      "7988/7988 [==============================] - 1s 87us/step - loss: 6.6687e-06 - accuracy: 1.0000 - val_loss: 4.3365e-04 - val_accuracy: 1.0000\n",
      "Epoch 28/80\n",
      "7988/7988 [==============================] - 1s 88us/step - loss: 6.1076e-06 - accuracy: 1.0000 - val_loss: 3.8514e-04 - val_accuracy: 1.0000\n",
      "Epoch 29/80\n",
      "7988/7988 [==============================] - 1s 87us/step - loss: 5.6395e-06 - accuracy: 1.0000 - val_loss: 5.3576e-04 - val_accuracy: 1.0000\n",
      "Epoch 30/80\n",
      "7988/7988 [==============================] - 1s 87us/step - loss: 5.3474e-06 - accuracy: 1.0000 - val_loss: 4.6181e-04 - val_accuracy: 1.0000\n",
      "Epoch 31/80\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7988/7988 [==============================] - 1s 86us/step - loss: 4.9832e-06 - accuracy: 1.0000 - val_loss: 4.7256e-04 - val_accuracy: 1.0000\n",
      "Epoch 32/80\n",
      "7988/7988 [==============================] - 1s 89us/step - loss: 4.4804e-06 - accuracy: 1.0000 - val_loss: 5.2075e-04 - val_accuracy: 1.0000\n",
      "Epoch 33/80\n",
      "7988/7988 [==============================] - 1s 86us/step - loss: 4.2183e-06 - accuracy: 1.0000 - val_loss: 5.8409e-04 - val_accuracy: 1.0000\n",
      "Epoch 34/80\n",
      "7988/7988 [==============================] - 1s 87us/step - loss: 3.8882e-06 - accuracy: 1.0000 - val_loss: 4.3289e-04 - val_accuracy: 1.0000\n",
      "Epoch 35/80\n",
      "7988/7988 [==============================] - 1s 86us/step - loss: 3.6104e-06 - accuracy: 1.0000 - val_loss: 4.6537e-04 - val_accuracy: 1.0000\n",
      "Epoch 36/80\n",
      "7988/7988 [==============================] - 1s 88us/step - loss: 3.4634e-06 - accuracy: 1.0000 - val_loss: 4.6841e-04 - val_accuracy: 1.0000\n",
      "Epoch 37/80\n",
      "7988/7988 [==============================] - 1s 86us/step - loss: 3.2386e-06 - accuracy: 1.0000 - val_loss: 5.0952e-04 - val_accuracy: 1.0000\n",
      "Epoch 38/80\n",
      "7988/7988 [==============================] - 1s 86us/step - loss: 2.9511e-06 - accuracy: 1.0000 - val_loss: 4.0708e-04 - val_accuracy: 1.0000\n",
      "Epoch 00038: early stopping\n",
      "[[5.2496628e-04 4.7339239e-09 3.4017844e-06 ... 9.5034611e-01\n",
      "  4.8903737e-02 5.6678268e-06]\n",
      " [1.9062269e-07 2.9552947e-11 1.6927052e-08 ... 5.5601329e-02\n",
      "  9.4438869e-01 8.0166870e-07]\n",
      " [2.0741718e-06 3.4305709e-09 6.3462387e-08 ... 9.6894526e-01\n",
      "  3.1042254e-02 7.8493611e-07]\n",
      " ...\n",
      " [7.6723452e-19 1.2564797e-14 3.1276239e-16 ... 1.0867794e-13\n",
      "  1.0000000e+00 1.6935191e-17]\n",
      " [5.7217555e-12 2.3436694e-17 2.5408119e-15 ... 3.9181266e-08\n",
      "  2.7499258e-11 7.9030593e-10]\n",
      " [2.7154379e-18 2.8677957e-14 2.8090999e-14 ... 7.5290661e-17\n",
      "  1.0000000e+00 2.5608576e-22]]\n",
      "[6 7 6 ... 7 3 7]\n",
      "<class 'numpy.ndarray'>\n",
      "One CNN, r:  3\n",
      "Computing Time:  0:02:14.140307\n",
      "Model: \"sequential_1\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv1d_1 (Conv1D)            (None, 1000, 6)           36        \n",
      "_________________________________________________________________\n",
      "average_pooling1d_1 (Average (None, 500, 6)            0         \n",
      "_________________________________________________________________\n",
      "conv1d_2 (Conv1D)            (None, 496, 16)           496       \n",
      "_________________________________________________________________\n",
      "average_pooling1d_2 (Average (None, 248, 16)           0         \n",
      "_________________________________________________________________\n",
      "conv1d_3 (Conv1D)            (None, 244, 120)          9720      \n",
      "_________________________________________________________________\n",
      "flatten_1 (Flatten)          (None, 29280)             0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 84)                2459604   \n",
      "_________________________________________________________________\n",
      "preds (Dense)                (None, 9)                 765       \n",
      "=================================================================\n",
      "Total params: 2,470,621\n",
      "Trainable params: 2,470,621\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Train on 7988 samples, validate on 888 samples\n",
      "Epoch 1/80\n",
      "7988/7988 [==============================] - 1s 113us/step - loss: 0.1750 - accuracy: 0.9492 - val_loss: 0.0117 - val_accuracy: 0.9966\n",
      "Epoch 2/80\n",
      "7988/7988 [==============================] - 1s 88us/step - loss: 0.0077 - accuracy: 0.9977 - val_loss: 0.0028 - val_accuracy: 1.0000\n",
      "Epoch 3/80\n",
      "7988/7988 [==============================] - 1s 85us/step - loss: 8.8819e-04 - accuracy: 1.0000 - val_loss: 0.0015 - val_accuracy: 1.0000\n",
      "Epoch 4/80\n",
      "7988/7988 [==============================] - 1s 87us/step - loss: 2.7129e-04 - accuracy: 1.0000 - val_loss: 0.0015 - val_accuracy: 1.0000\n",
      "Epoch 5/80\n",
      "7988/7988 [==============================] - 1s 86us/step - loss: 1.6501e-04 - accuracy: 1.0000 - val_loss: 0.0013 - val_accuracy: 1.0000\n",
      "Epoch 6/80\n",
      "7988/7988 [==============================] - 1s 88us/step - loss: 1.1949e-04 - accuracy: 1.0000 - val_loss: 9.8002e-04 - val_accuracy: 1.0000\n",
      "Epoch 7/80\n",
      "7988/7988 [==============================] - 1s 86us/step - loss: 8.6518e-05 - accuracy: 1.0000 - val_loss: 9.4003e-04 - val_accuracy: 1.0000\n",
      "Epoch 8/80\n",
      "7988/7988 [==============================] - 1s 86us/step - loss: 6.5666e-05 - accuracy: 1.0000 - val_loss: 7.8295e-04 - val_accuracy: 1.0000\n",
      "Epoch 9/80\n",
      "7988/7988 [==============================] - 1s 84us/step - loss: 5.5892e-05 - accuracy: 1.0000 - val_loss: 8.4791e-04 - val_accuracy: 1.0000\n",
      "Epoch 10/80\n",
      "7988/7988 [==============================] - 1s 88us/step - loss: 4.4716e-05 - accuracy: 1.0000 - val_loss: 7.7531e-04 - val_accuracy: 1.0000\n",
      "Epoch 11/80\n",
      "7988/7988 [==============================] - 1s 85us/step - loss: 3.7462e-05 - accuracy: 1.0000 - val_loss: 7.1295e-04 - val_accuracy: 1.0000\n",
      "Epoch 12/80\n",
      "7988/7988 [==============================] - 1s 86us/step - loss: 3.1860e-05 - accuracy: 1.0000 - val_loss: 6.8241e-04 - val_accuracy: 1.0000\n",
      "Epoch 13/80\n",
      "7988/7988 [==============================] - 1s 84us/step - loss: 2.6952e-05 - accuracy: 1.0000 - val_loss: 7.3165e-04 - val_accuracy: 1.0000\n",
      "Epoch 14/80\n",
      "7988/7988 [==============================] - 1s 86us/step - loss: 2.3908e-05 - accuracy: 1.0000 - val_loss: 9.0541e-04 - val_accuracy: 1.0000\n",
      "Epoch 15/80\n",
      "7988/7988 [==============================] - 1s 86us/step - loss: 2.0914e-05 - accuracy: 1.0000 - val_loss: 6.0151e-04 - val_accuracy: 1.0000\n",
      "Epoch 16/80\n",
      "7988/7988 [==============================] - 1s 86us/step - loss: 1.8264e-05 - accuracy: 1.0000 - val_loss: 5.5904e-04 - val_accuracy: 1.0000\n",
      "Epoch 17/80\n",
      "7988/7988 [==============================] - 1s 86us/step - loss: 1.6596e-05 - accuracy: 1.0000 - val_loss: 6.1631e-04 - val_accuracy: 1.0000\n",
      "Epoch 18/80\n",
      "7988/7988 [==============================] - 1s 87us/step - loss: 1.4586e-05 - accuracy: 1.0000 - val_loss: 4.9076e-04 - val_accuracy: 1.0000\n",
      "Epoch 19/80\n",
      "7988/7988 [==============================] - 1s 85us/step - loss: 1.3146e-05 - accuracy: 1.0000 - val_loss: 6.6050e-04 - val_accuracy: 1.0000\n",
      "Epoch 20/80\n",
      "7988/7988 [==============================] - 1s 84us/step - loss: 1.1430e-05 - accuracy: 1.0000 - val_loss: 4.0127e-04 - val_accuracy: 1.0000\n",
      "Epoch 21/80\n",
      "7988/7988 [==============================] - 1s 86us/step - loss: 1.0918e-05 - accuracy: 1.0000 - val_loss: 4.0249e-04 - val_accuracy: 1.0000\n",
      "Epoch 22/80\n",
      "7988/7988 [==============================] - 1s 85us/step - loss: 9.8136e-06 - accuracy: 1.0000 - val_loss: 3.8211e-04 - val_accuracy: 1.0000\n",
      "Epoch 23/80\n",
      "7988/7988 [==============================] - 1s 86us/step - loss: 9.0955e-06 - accuracy: 1.0000 - val_loss: 3.3824e-04 - val_accuracy: 1.0000\n",
      "Epoch 24/80\n",
      "7988/7988 [==============================] - 1s 86us/step - loss: 8.1968e-06 - accuracy: 1.0000 - val_loss: 3.9148e-04 - val_accuracy: 1.0000\n",
      "Epoch 25/80\n",
      "7988/7988 [==============================] - 1s 87us/step - loss: 7.4982e-06 - accuracy: 1.0000 - val_loss: 3.3829e-04 - val_accuracy: 1.0000\n",
      "Epoch 26/80\n",
      "7988/7988 [==============================] - 1s 85us/step - loss: 7.0178e-06 - accuracy: 1.0000 - val_loss: 3.6763e-04 - val_accuracy: 1.0000\n",
      "Epoch 27/80\n",
      "7988/7988 [==============================] - 1s 88us/step - loss: 6.3862e-06 - accuracy: 1.0000 - val_loss: 3.6627e-04 - val_accuracy: 1.0000\n",
      "Epoch 28/80\n",
      "7988/7988 [==============================] - 1s 84us/step - loss: 5.9073e-06 - accuracy: 1.0000 - val_loss: 3.9305e-04 - val_accuracy: 1.0000\n",
      "Epoch 29/80\n",
      "7988/7988 [==============================] - 1s 86us/step - loss: 5.5619e-06 - accuracy: 1.0000 - val_loss: 3.1128e-04 - val_accuracy: 1.0000\n",
      "Epoch 30/80\n",
      "7988/7988 [==============================] - 1s 86us/step - loss: 5.0730e-06 - accuracy: 1.0000 - val_loss: 4.1417e-04 - val_accuracy: 1.0000\n",
      "Epoch 31/80\n",
      "7988/7988 [==============================] - 1s 87us/step - loss: 4.8714e-06 - accuracy: 1.0000 - val_loss: 3.6248e-04 - val_accuracy: 1.0000\n",
      "Epoch 32/80\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7988/7988 [==============================] - 1s 86us/step - loss: 4.3958e-06 - accuracy: 1.0000 - val_loss: 2.7931e-04 - val_accuracy: 1.0000\n",
      "Epoch 33/80\n",
      "7988/7988 [==============================] - 1s 85us/step - loss: 4.1534e-06 - accuracy: 1.0000 - val_loss: 2.6930e-04 - val_accuracy: 1.0000\n",
      "Epoch 34/80\n",
      "7988/7988 [==============================] - 1s 88us/step - loss: 3.9761e-06 - accuracy: 1.0000 - val_loss: 2.5952e-04 - val_accuracy: 1.0000\n",
      "Epoch 35/80\n",
      "7988/7988 [==============================] - 1s 86us/step - loss: 3.6763e-06 - accuracy: 1.0000 - val_loss: 2.9235e-04 - val_accuracy: 1.0000\n",
      "Epoch 36/80\n",
      "7988/7988 [==============================] - 1s 87us/step - loss: 3.4353e-06 - accuracy: 1.0000 - val_loss: 2.7696e-04 - val_accuracy: 1.0000\n",
      "Epoch 37/80\n",
      "7988/7988 [==============================] - 1s 85us/step - loss: 3.2875e-06 - accuracy: 1.0000 - val_loss: 2.3102e-04 - val_accuracy: 1.0000\n",
      "Epoch 38/80\n",
      "7988/7988 [==============================] - 1s 86us/step - loss: 3.0758e-06 - accuracy: 1.0000 - val_loss: 2.4442e-04 - val_accuracy: 1.0000\n",
      "Epoch 39/80\n",
      "7988/7988 [==============================] - 1s 87us/step - loss: 2.8496e-06 - accuracy: 1.0000 - val_loss: 2.6241e-04 - val_accuracy: 1.0000\n",
      "Epoch 40/80\n",
      "7988/7988 [==============================] - 1s 87us/step - loss: 2.6867e-06 - accuracy: 1.0000 - val_loss: 2.2102e-04 - val_accuracy: 1.0000\n",
      "Epoch 41/80\n",
      "7988/7988 [==============================] - 1s 86us/step - loss: 2.5398e-06 - accuracy: 1.0000 - val_loss: 2.4728e-04 - val_accuracy: 1.0000\n",
      "Epoch 42/80\n",
      "7988/7988 [==============================] - 1s 87us/step - loss: 2.3951e-06 - accuracy: 1.0000 - val_loss: 2.0058e-04 - val_accuracy: 1.0000\n",
      "Epoch 43/80\n",
      "7988/7988 [==============================] - 1s 86us/step - loss: 2.2741e-06 - accuracy: 1.0000 - val_loss: 2.1035e-04 - val_accuracy: 1.0000\n",
      "Epoch 44/80\n",
      "7988/7988 [==============================] - 1s 86us/step - loss: 2.1306e-06 - accuracy: 1.0000 - val_loss: 1.7958e-04 - val_accuracy: 1.0000\n",
      "Epoch 45/80\n",
      "7988/7988 [==============================] - 1s 86us/step - loss: 2.0515e-06 - accuracy: 1.0000 - val_loss: 2.1167e-04 - val_accuracy: 1.0000\n",
      "Epoch 46/80\n",
      "7988/7988 [==============================] - 1s 87us/step - loss: 1.9015e-06 - accuracy: 1.0000 - val_loss: 2.2493e-04 - val_accuracy: 1.0000\n",
      "Epoch 47/80\n",
      "7988/7988 [==============================] - 1s 85us/step - loss: 1.8386e-06 - accuracy: 1.0000 - val_loss: 2.1339e-04 - val_accuracy: 1.0000\n",
      "Epoch 48/80\n",
      "7988/7988 [==============================] - 1s 86us/step - loss: 1.7208e-06 - accuracy: 1.0000 - val_loss: 1.8989e-04 - val_accuracy: 1.0000\n",
      "Epoch 49/80\n",
      "7988/7988 [==============================] - 1s 86us/step - loss: 1.6332e-06 - accuracy: 1.0000 - val_loss: 1.9483e-04 - val_accuracy: 1.0000\n",
      "Epoch 50/80\n",
      "7988/7988 [==============================] - 1s 86us/step - loss: 1.5504e-06 - accuracy: 1.0000 - val_loss: 1.8314e-04 - val_accuracy: 1.0000\n",
      "Epoch 51/80\n",
      "7988/7988 [==============================] - 1s 86us/step - loss: 1.4611e-06 - accuracy: 1.0000 - val_loss: 1.8777e-04 - val_accuracy: 1.0000\n",
      "Epoch 52/80\n",
      "7988/7988 [==============================] - 1s 88us/step - loss: 1.4065e-06 - accuracy: 1.0000 - val_loss: 1.8833e-04 - val_accuracy: 1.0000\n",
      "Epoch 53/80\n",
      "7988/7988 [==============================] - 1s 88us/step - loss: 1.3468e-06 - accuracy: 1.0000 - val_loss: 2.0719e-04 - val_accuracy: 1.0000\n",
      "Epoch 54/80\n",
      "7988/7988 [==============================] - 1s 87us/step - loss: 1.2747e-06 - accuracy: 1.0000 - val_loss: 1.8357e-04 - val_accuracy: 1.0000\n",
      "Epoch 00054: early stopping\n",
      "[[1.8363058e-05 5.8469112e-08 3.3826566e-07 ... 9.7408968e-01\n",
      "  2.5769839e-02 1.8185574e-07]\n",
      " [8.7789931e-10 1.5239940e-12 1.7480806e-09 ... 6.4466476e-02\n",
      "  9.3553269e-01 8.6288296e-08]\n",
      " [6.0953078e-09 2.3949833e-09 1.0743300e-08 ... 9.8847616e-01\n",
      "  1.1522517e-02 4.9888737e-08]\n",
      " ...\n",
      " [2.4395825e-22 4.9270843e-19 9.3839443e-19 ... 5.3586465e-14\n",
      "  1.0000000e+00 1.6915924e-20]\n",
      " [3.3555382e-17 4.0488005e-18 1.5845784e-17 ... 1.0132971e-09\n",
      "  1.8862626e-12 2.1626654e-11]\n",
      " [6.2875130e-23 8.9615341e-19 8.1209135e-18 ... 1.5303222e-18\n",
      "  1.0000000e+00 6.7588932e-28]]\n",
      "[6 7 6 ... 7 3 7]\n",
      "<class 'numpy.ndarray'>\n",
      "One CNN, r:  4\n",
      "Computing Time:  0:02:54.358814\n",
      "num of merged_region_image 0 1734\n",
      "num of merged_region_image 1 1972\n",
      "num of merged_region_image 2 216\n",
      "num of merged_region_image 3 821\n",
      "num of merged_region_image 4 143\n",
      "num of merged_region_image 5 96\n",
      "num of merged_region_image 6 1688\n",
      "num of merged_region_image 7 1997\n",
      "num of merged_region_image 8 209\n",
      "Counter({-1: 4200, 7: 1997, 1: 1972, 0: 1734, 6: 1688, 3: 821, 2: 216, 8: 209, 4: 143, 5: 96})\n",
      "===========  ITE = 2   ===========\n",
      "used_img 8876 8876\n",
      "working_img(=other images=unclean images) 4200 4200\n",
      "merged regions 54 54\n",
      "other_regions 145 145\n",
      "All other regions\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>other index</th>\n",
       "      <th>pred label</th>\n",
       "      <th>truth</th>\n",
       "      <th>rate</th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>7</td>\n",
       "      <td>-1</td>\n",
       "      <td>8</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>65</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>9</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>10</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>13</td>\n",
       "      <td>6</td>\n",
       "      <td>4</td>\n",
       "      <td>0.9</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>373</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>140</th>\n",
       "      <td>192</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>141</th>\n",
       "      <td>193</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>142</th>\n",
       "      <td>195</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>143</th>\n",
       "      <td>196</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>144</th>\n",
       "      <td>198</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>145 rows × 13 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     other index  pred label  truth  rate  0  1  2  3    4  5  6  7   8\n",
       "0              2           0      0   0.0  0  0  0  0    0  0  0  0   0\n",
       "1              7          -1      8   0.0  0  0  0  0    0  0  0  0  65\n",
       "2              9           0      0   0.0  0  0  0  0    0  0  0  0   0\n",
       "3             10           0      0   0.0  0  0  0  0    0  0  0  0   0\n",
       "4             13           6      4   0.9  0  0  0  0  373  0  0  0   0\n",
       "..           ...         ...    ...   ... .. .. .. ..  ... .. .. ..  ..\n",
       "140          192           0      0   0.0  0  0  0  0    0  0  0  0   0\n",
       "141          193           0      0   0.0  0  0  0  0    0  0  0  0   0\n",
       "142          195           0      0   0.0  0  0  0  0    0  0  0  0   0\n",
       "143          196           0      0   0.0  0  0  0  0    0  0  0  0   0\n",
       "144          198           0      0   0.0  0  0  0  0    0  0  0  0   0\n",
       "\n",
       "[145 rows x 13 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "added label, regions, img amount: {3} [41, 137] 164\n",
      "added label, regions, img amount: {6} [89, 94, 186, 13, 111] 922\n",
      "Not getting into residuals\n",
      "NUM_region 9\n",
      "number of clean images 9962\n",
      "n, p1, p2 0 0 0\n",
      "NUM_CLASSES 9\n",
      "current_train_label:  [0, 1, 2, 3, 4, 5, 6, 7, 8]\n",
      "Model: \"sequential_1\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv1d_1 (Conv1D)            (None, 1000, 6)           36        \n",
      "_________________________________________________________________\n",
      "average_pooling1d_1 (Average (None, 500, 6)            0         \n",
      "_________________________________________________________________\n",
      "conv1d_2 (Conv1D)            (None, 496, 16)           496       \n",
      "_________________________________________________________________\n",
      "average_pooling1d_2 (Average (None, 248, 16)           0         \n",
      "_________________________________________________________________\n",
      "conv1d_3 (Conv1D)            (None, 244, 120)          9720      \n",
      "_________________________________________________________________\n",
      "flatten_1 (Flatten)          (None, 29280)             0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 84)                2459604   \n",
      "_________________________________________________________________\n",
      "preds (Dense)                (None, 9)                 765       \n",
      "=================================================================\n",
      "Total params: 2,470,621\n",
      "Trainable params: 2,470,621\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Train on 8965 samples, validate on 997 samples\n",
      "Epoch 1/80\n",
      "8965/8965 [==============================] - 1s 150us/step - loss: 0.1710 - accuracy: 0.9458 - val_loss: 0.0025 - val_accuracy: 1.0000\n",
      "Epoch 2/80\n",
      "8965/8965 [==============================] - 1s 89us/step - loss: 0.0039 - accuracy: 0.9990 - val_loss: 0.0053 - val_accuracy: 0.9990\n",
      "Epoch 3/80\n",
      "8965/8965 [==============================] - 1s 85us/step - loss: 0.0015 - accuracy: 0.9999 - val_loss: 0.0016 - val_accuracy: 1.0000\n",
      "Epoch 4/80\n",
      "8965/8965 [==============================] - 1s 87us/step - loss: 0.0096 - accuracy: 0.9967 - val_loss: 0.0052 - val_accuracy: 0.9990\n",
      "Epoch 5/80\n",
      "8965/8965 [==============================] - 1s 87us/step - loss: 0.0019 - accuracy: 0.9998 - val_loss: 7.4318e-04 - val_accuracy: 1.0000\n",
      "Epoch 6/80\n",
      "8965/8965 [==============================] - 1s 88us/step - loss: 2.0197e-04 - accuracy: 1.0000 - val_loss: 5.2810e-04 - val_accuracy: 1.0000\n",
      "Epoch 7/80\n",
      "8965/8965 [==============================] - 1s 84us/step - loss: 1.1063e-04 - accuracy: 1.0000 - val_loss: 4.4538e-04 - val_accuracy: 1.0000\n",
      "Epoch 8/80\n",
      "8965/8965 [==============================] - 1s 87us/step - loss: 7.7503e-05 - accuracy: 1.0000 - val_loss: 3.4381e-04 - val_accuracy: 1.0000\n",
      "Epoch 9/80\n",
      "8965/8965 [==============================] - 1s 88us/step - loss: 5.7715e-05 - accuracy: 1.0000 - val_loss: 3.2319e-04 - val_accuracy: 1.0000\n",
      "Epoch 10/80\n",
      "8965/8965 [==============================] - 1s 86us/step - loss: 4.5883e-05 - accuracy: 1.0000 - val_loss: 3.0238e-04 - val_accuracy: 1.0000\n",
      "Epoch 11/80\n",
      "8965/8965 [==============================] - 1s 86us/step - loss: 3.6537e-05 - accuracy: 1.0000 - val_loss: 2.6294e-04 - val_accuracy: 1.0000\n",
      "Epoch 12/80\n",
      "8965/8965 [==============================] - 1s 87us/step - loss: 3.0563e-05 - accuracy: 1.0000 - val_loss: 2.3314e-04 - val_accuracy: 1.0000\n",
      "Epoch 13/80\n",
      "8965/8965 [==============================] - 1s 87us/step - loss: 2.6293e-05 - accuracy: 1.0000 - val_loss: 2.3587e-04 - val_accuracy: 1.0000\n",
      "Epoch 14/80\n",
      "8965/8965 [==============================] - 1s 86us/step - loss: 2.2825e-05 - accuracy: 1.0000 - val_loss: 2.0062e-04 - val_accuracy: 1.0000\n",
      "Epoch 15/80\n",
      "8965/8965 [==============================] - 1s 84us/step - loss: 1.9815e-05 - accuracy: 1.0000 - val_loss: 1.9185e-04 - val_accuracy: 1.0000\n",
      "Epoch 16/80\n",
      "8965/8965 [==============================] - 1s 87us/step - loss: 1.7038e-05 - accuracy: 1.0000 - val_loss: 1.7575e-04 - val_accuracy: 1.0000\n",
      "Epoch 17/80\n",
      "8965/8965 [==============================] - 1s 88us/step - loss: 1.5110e-05 - accuracy: 1.0000 - val_loss: 1.7445e-04 - val_accuracy: 1.0000\n",
      "Epoch 18/80\n",
      "8965/8965 [==============================] - 1s 87us/step - loss: 1.3533e-05 - accuracy: 1.0000 - val_loss: 1.5671e-04 - val_accuracy: 1.0000\n",
      "Epoch 19/80\n",
      "8965/8965 [==============================] - 1s 86us/step - loss: 1.2052e-05 - accuracy: 1.0000 - val_loss: 1.5299e-04 - val_accuracy: 1.0000\n",
      "Epoch 20/80\n",
      "8965/8965 [==============================] - 1s 87us/step - loss: 1.0998e-05 - accuracy: 1.0000 - val_loss: 1.3910e-04 - val_accuracy: 1.0000\n",
      "Epoch 21/80\n",
      "8965/8965 [==============================] - 1s 86us/step - loss: 9.9282e-06 - accuracy: 1.0000 - val_loss: 1.3646e-04 - val_accuracy: 1.0000\n",
      "Epoch 22/80\n",
      "8965/8965 [==============================] - 1s 85us/step - loss: 9.0162e-06 - accuracy: 1.0000 - val_loss: 1.2863e-04 - val_accuracy: 1.0000\n",
      "Epoch 23/80\n",
      "8965/8965 [==============================] - 1s 86us/step - loss: 8.1580e-06 - accuracy: 1.0000 - val_loss: 1.2141e-04 - val_accuracy: 1.0000\n",
      "Epoch 24/80\n",
      "8965/8965 [==============================] - 1s 86us/step - loss: 7.6101e-06 - accuracy: 1.0000 - val_loss: 1.1545e-04 - val_accuracy: 1.0000\n",
      "Epoch 25/80\n",
      "8965/8965 [==============================] - 1s 84us/step - loss: 6.9547e-06 - accuracy: 1.0000 - val_loss: 1.1286e-04 - val_accuracy: 1.0000\n",
      "Epoch 26/80\n",
      "8965/8965 [==============================] - 1s 89us/step - loss: 6.4131e-06 - accuracy: 1.0000 - val_loss: 1.0508e-04 - val_accuracy: 1.0000\n",
      "Epoch 27/80\n",
      "8965/8965 [==============================] - 1s 85us/step - loss: 5.8693e-06 - accuracy: 1.0000 - val_loss: 1.0445e-04 - val_accuracy: 1.0000\n",
      "Epoch 28/80\n",
      "8965/8965 [==============================] - 1s 86us/step - loss: 5.4908e-06 - accuracy: 1.0000 - val_loss: 1.0066e-04 - val_accuracy: 1.0000\n",
      "Epoch 29/80\n",
      "8965/8965 [==============================] - 1s 87us/step - loss: 5.0399e-06 - accuracy: 1.0000 - val_loss: 9.5969e-05 - val_accuracy: 1.0000\n",
      "Epoch 30/80\n",
      "8965/8965 [==============================] - 1s 87us/step - loss: 4.6828e-06 - accuracy: 1.0000 - val_loss: 9.1819e-05 - val_accuracy: 1.0000\n",
      "Epoch 31/80\n",
      "8965/8965 [==============================] - 1s 84us/step - loss: 4.5172e-06 - accuracy: 1.0000 - val_loss: 8.8226e-05 - val_accuracy: 1.0000\n",
      "Epoch 32/80\n",
      "8965/8965 [==============================] - 1s 87us/step - loss: 4.0730e-06 - accuracy: 1.0000 - val_loss: 8.3855e-05 - val_accuracy: 1.0000\n",
      "Epoch 33/80\n",
      "8965/8965 [==============================] - 1s 89us/step - loss: 3.7903e-06 - accuracy: 1.0000 - val_loss: 8.1846e-05 - val_accuracy: 1.0000\n",
      "Epoch 34/80\n",
      "8965/8965 [==============================] - 1s 87us/step - loss: 3.5801e-06 - accuracy: 1.0000 - val_loss: 8.2738e-05 - val_accuracy: 1.0000\n",
      "Epoch 35/80\n",
      "8965/8965 [==============================] - 1s 86us/step - loss: 3.3417e-06 - accuracy: 1.0000 - val_loss: 7.8025e-05 - val_accuracy: 1.0000\n",
      "Epoch 36/80\n",
      "8965/8965 [==============================] - 1s 87us/step - loss: 3.1139e-06 - accuracy: 1.0000 - val_loss: 7.6434e-05 - val_accuracy: 1.0000\n",
      "Epoch 37/80\n",
      "8965/8965 [==============================] - 1s 89us/step - loss: 2.9495e-06 - accuracy: 1.0000 - val_loss: 7.4619e-05 - val_accuracy: 1.0000\n",
      "Epoch 38/80\n",
      "8965/8965 [==============================] - 1s 87us/step - loss: 2.7681e-06 - accuracy: 1.0000 - val_loss: 7.1035e-05 - val_accuracy: 1.0000\n",
      "Epoch 39/80\n",
      "8965/8965 [==============================] - 1s 85us/step - loss: 2.6049e-06 - accuracy: 1.0000 - val_loss: 6.8324e-05 - val_accuracy: 1.0000\n",
      "Epoch 40/80\n",
      "8965/8965 [==============================] - 1s 91us/step - loss: 2.4590e-06 - accuracy: 1.0000 - val_loss: 6.7250e-05 - val_accuracy: 1.0000\n",
      "Epoch 41/80\n",
      "8965/8965 [==============================] - 1s 85us/step - loss: 2.3269e-06 - accuracy: 1.0000 - val_loss: 6.5952e-05 - val_accuracy: 1.0000\n",
      "Epoch 42/80\n",
      "8965/8965 [==============================] - 1s 87us/step - loss: 2.1949e-06 - accuracy: 1.0000 - val_loss: 6.3101e-05 - val_accuracy: 1.0000\n",
      "Epoch 43/80\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8965/8965 [==============================] - 1s 84us/step - loss: 2.1094e-06 - accuracy: 1.0000 - val_loss: 5.9067e-05 - val_accuracy: 1.0000\n",
      "Epoch 44/80\n",
      "8965/8965 [==============================] - 1s 85us/step - loss: 1.9734e-06 - accuracy: 1.0000 - val_loss: 6.0141e-05 - val_accuracy: 1.0000\n",
      "Epoch 45/80\n",
      "8965/8965 [==============================] - 1s 85us/step - loss: 1.8653e-06 - accuracy: 1.0000 - val_loss: 5.9669e-05 - val_accuracy: 1.0000\n",
      "Epoch 46/80\n",
      "8965/8965 [==============================] - 1s 87us/step - loss: 1.7606e-06 - accuracy: 1.0000 - val_loss: 5.7172e-05 - val_accuracy: 1.0000\n",
      "Epoch 47/80\n",
      "8965/8965 [==============================] - 1s 87us/step - loss: 1.6751e-06 - accuracy: 1.0000 - val_loss: 5.5790e-05 - val_accuracy: 1.0000\n",
      "Epoch 48/80\n",
      "8965/8965 [==============================] - 1s 87us/step - loss: 1.5884e-06 - accuracy: 1.0000 - val_loss: 5.5164e-05 - val_accuracy: 1.0000\n",
      "Epoch 49/80\n",
      "8965/8965 [==============================] - 1s 87us/step - loss: 1.7452e-06 - accuracy: 1.0000 - val_loss: 5.3447e-05 - val_accuracy: 1.0000\n",
      "Epoch 50/80\n",
      "8965/8965 [==============================] - 1s 86us/step - loss: 1.4309e-06 - accuracy: 1.0000 - val_loss: 5.0507e-05 - val_accuracy: 1.0000\n",
      "Epoch 51/80\n",
      "8965/8965 [==============================] - 1s 86us/step - loss: 1.3462e-06 - accuracy: 1.0000 - val_loss: 5.0941e-05 - val_accuracy: 1.0000\n",
      "Epoch 52/80\n",
      "8965/8965 [==============================] - 1s 85us/step - loss: 1.2851e-06 - accuracy: 1.0000 - val_loss: 4.9323e-05 - val_accuracy: 1.0000\n",
      "Epoch 53/80\n",
      "8965/8965 [==============================] - 1s 87us/step - loss: 1.2225e-06 - accuracy: 1.0000 - val_loss: 4.7951e-05 - val_accuracy: 1.0000\n",
      "Epoch 54/80\n",
      "8965/8965 [==============================] - 1s 89us/step - loss: 1.1607e-06 - accuracy: 1.0000 - val_loss: 4.6857e-05 - val_accuracy: 1.0000\n",
      "Epoch 55/80\n",
      "8965/8965 [==============================] - 1s 85us/step - loss: 1.1086e-06 - accuracy: 1.0000 - val_loss: 4.5825e-05 - val_accuracy: 1.0000\n",
      "Epoch 56/80\n",
      "8965/8965 [==============================] - 1s 85us/step - loss: 1.0523e-06 - accuracy: 1.0000 - val_loss: 4.5786e-05 - val_accuracy: 1.0000\n",
      "Epoch 57/80\n",
      "8965/8965 [==============================] - 1s 90us/step - loss: 1.0049e-06 - accuracy: 1.0000 - val_loss: 4.4574e-05 - val_accuracy: 1.0000\n",
      "Epoch 58/80\n",
      "8965/8965 [==============================] - 1s 86us/step - loss: 9.5468e-07 - accuracy: 1.0000 - val_loss: 4.4020e-05 - val_accuracy: 1.0000\n",
      "Epoch 59/80\n",
      "8965/8965 [==============================] - 1s 88us/step - loss: 9.1859e-07 - accuracy: 1.0000 - val_loss: 4.1855e-05 - val_accuracy: 1.0000\n",
      "Epoch 60/80\n",
      "8965/8965 [==============================] - 1s 88us/step - loss: 8.7601e-07 - accuracy: 1.0000 - val_loss: 4.1394e-05 - val_accuracy: 1.0000\n",
      "Epoch 61/80\n",
      "8965/8965 [==============================] - 1s 88us/step - loss: 8.3653e-07 - accuracy: 1.0000 - val_loss: 4.0841e-05 - val_accuracy: 1.0000\n",
      "Epoch 62/80\n",
      "8965/8965 [==============================] - 1s 86us/step - loss: 8.0270e-07 - accuracy: 1.0000 - val_loss: 4.0257e-05 - val_accuracy: 1.0000\n",
      "Epoch 63/80\n",
      "8965/8965 [==============================] - 1s 87us/step - loss: 7.6150e-07 - accuracy: 1.0000 - val_loss: 3.9975e-05 - val_accuracy: 1.0000\n",
      "Epoch 64/80\n",
      "8965/8965 [==============================] - 1s 87us/step - loss: 7.3486e-07 - accuracy: 1.0000 - val_loss: 3.8364e-05 - val_accuracy: 1.0000\n",
      "Epoch 65/80\n",
      "8965/8965 [==============================] - 1s 85us/step - loss: 6.9523e-07 - accuracy: 1.0000 - val_loss: 3.7795e-05 - val_accuracy: 1.0000\n",
      "Epoch 66/80\n",
      "8965/8965 [==============================] - 1s 86us/step - loss: 6.6716e-07 - accuracy: 1.0000 - val_loss: 3.7249e-05 - val_accuracy: 1.0000\n",
      "Epoch 67/80\n",
      "8965/8965 [==============================] - 1s 88us/step - loss: 6.4449e-07 - accuracy: 1.0000 - val_loss: 3.7235e-05 - val_accuracy: 1.0000\n",
      "Epoch 68/80\n",
      "8965/8965 [==============================] - 1s 87us/step - loss: 6.0696e-07 - accuracy: 1.0000 - val_loss: 3.6099e-05 - val_accuracy: 1.0000\n",
      "Epoch 69/80\n",
      "8965/8965 [==============================] - 1s 86us/step - loss: 5.8299e-07 - accuracy: 1.0000 - val_loss: 3.3980e-05 - val_accuracy: 1.0000\n",
      "Epoch 70/80\n",
      "8965/8965 [==============================] - 1s 87us/step - loss: 5.5424e-07 - accuracy: 1.0000 - val_loss: 3.4221e-05 - val_accuracy: 1.0000\n",
      "Epoch 71/80\n",
      "8965/8965 [==============================] - 1s 88us/step - loss: 5.3515e-07 - accuracy: 1.0000 - val_loss: 3.3241e-05 - val_accuracy: 1.0000\n",
      "Epoch 72/80\n",
      "8965/8965 [==============================] - 1s 88us/step - loss: 5.1074e-07 - accuracy: 1.0000 - val_loss: 3.1924e-05 - val_accuracy: 1.0000\n",
      "Epoch 73/80\n",
      "8965/8965 [==============================] - 1s 85us/step - loss: 4.8979e-07 - accuracy: 1.0000 - val_loss: 3.1505e-05 - val_accuracy: 1.0000\n",
      "Epoch 74/80\n",
      "8965/8965 [==============================] - 1s 83us/step - loss: 4.6819e-07 - accuracy: 1.0000 - val_loss: 3.1773e-05 - val_accuracy: 1.0000\n",
      "Epoch 75/80\n",
      "8965/8965 [==============================] - 1s 85us/step - loss: 4.5153e-07 - accuracy: 1.0000 - val_loss: 3.0515e-05 - val_accuracy: 1.0000\n",
      "Epoch 76/80\n",
      "8965/8965 [==============================] - 1s 85us/step - loss: 4.2951e-07 - accuracy: 1.0000 - val_loss: 2.9113e-05 - val_accuracy: 1.0000\n",
      "Epoch 77/80\n",
      "8965/8965 [==============================] - 1s 88us/step - loss: 4.1484e-07 - accuracy: 1.0000 - val_loss: 2.7646e-05 - val_accuracy: 1.0000\n",
      "Epoch 78/80\n",
      "8965/8965 [==============================] - 1s 92us/step - loss: 4.0473e-07 - accuracy: 1.0000 - val_loss: 2.7969e-05 - val_accuracy: 1.0000\n",
      "Epoch 79/80\n",
      "8965/8965 [==============================] - 1s 89us/step - loss: 3.8128e-07 - accuracy: 1.0000 - val_loss: 2.7888e-05 - val_accuracy: 1.0000\n",
      "Epoch 80/80\n",
      "8965/8965 [==============================] - 1s 89us/step - loss: 3.6301e-07 - accuracy: 1.0000 - val_loss: 2.7610e-05 - val_accuracy: 1.0000\n",
      "[[3.23830449e-07 1.96928318e-09 1.54480109e-08 ... 9.92218733e-01\n",
      "  7.77966203e-03 4.52763231e-08]\n",
      " [1.23904789e-10 2.46296490e-11 1.03196104e-10 ... 4.78236489e-02\n",
      "  9.52176332e-01 3.71368749e-08]\n",
      " [8.47258930e-11 7.47595374e-10 1.19318067e-09 ... 9.97771800e-01\n",
      "  2.22804374e-03 1.10429397e-07]\n",
      " ...\n",
      " [3.37286757e-22 2.37779195e-16 1.81715016e-18 ... 1.45009398e-14\n",
      "  1.00000000e+00 1.83968641e-17]\n",
      " [1.15480739e-20 1.86361348e-21 2.34308489e-20 ... 7.56174845e-10\n",
      "  1.04996555e-19 2.90014237e-12]\n",
      " [1.58553671e-21 7.39600963e-18 1.33146657e-16 ... 3.14358014e-16\n",
      "  1.00000000e+00 4.99194415e-24]]\n",
      "[6 7 6 ... 7 3 7]\n",
      "<class 'numpy.ndarray'>\n",
      "One CNN, r:  0\n",
      "Computing Time:  0:01:05.890784\n",
      "Model: \"sequential_1\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv1d_1 (Conv1D)            (None, 1000, 6)           36        \n",
      "_________________________________________________________________\n",
      "average_pooling1d_1 (Average (None, 500, 6)            0         \n",
      "_________________________________________________________________\n",
      "conv1d_2 (Conv1D)            (None, 496, 16)           496       \n",
      "_________________________________________________________________\n",
      "average_pooling1d_2 (Average (None, 248, 16)           0         \n",
      "_________________________________________________________________\n",
      "conv1d_3 (Conv1D)            (None, 244, 120)          9720      \n",
      "_________________________________________________________________\n",
      "flatten_1 (Flatten)          (None, 29280)             0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 84)                2459604   \n",
      "_________________________________________________________________\n",
      "preds (Dense)                (None, 9)                 765       \n",
      "=================================================================\n",
      "Total params: 2,470,621\n",
      "Trainable params: 2,470,621\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Train on 8965 samples, validate on 997 samples\n",
      "Epoch 1/80\n",
      "8965/8965 [==============================] - 1s 122us/step - loss: 0.3019 - accuracy: 0.9177 - val_loss: 0.0053 - val_accuracy: 1.0000\n",
      "Epoch 2/80\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8965/8965 [==============================] - 1s 86us/step - loss: 0.0044 - accuracy: 0.9987 - val_loss: 0.0074 - val_accuracy: 0.9980\n",
      "Epoch 3/80\n",
      "8965/8965 [==============================] - 1s 87us/step - loss: 0.0030 - accuracy: 0.9991 - val_loss: 0.0043 - val_accuracy: 0.9980\n",
      "Epoch 4/80\n",
      "8965/8965 [==============================] - 1s 90us/step - loss: 7.6502e-04 - accuracy: 1.0000 - val_loss: 0.0010 - val_accuracy: 1.0000\n",
      "Epoch 5/80\n",
      "8965/8965 [==============================] - 1s 87us/step - loss: 2.3858e-04 - accuracy: 1.0000 - val_loss: 0.0010 - val_accuracy: 1.0000\n",
      "Epoch 6/80\n",
      "8965/8965 [==============================] - 1s 87us/step - loss: 1.5497e-04 - accuracy: 1.0000 - val_loss: 7.5363e-04 - val_accuracy: 1.0000\n",
      "Epoch 7/80\n",
      "8965/8965 [==============================] - 1s 89us/step - loss: 1.0828e-04 - accuracy: 1.0000 - val_loss: 5.1964e-04 - val_accuracy: 1.0000\n",
      "Epoch 8/80\n",
      "8965/8965 [==============================] - 1s 85us/step - loss: 8.5647e-05 - accuracy: 1.0000 - val_loss: 5.9453e-04 - val_accuracy: 1.0000\n",
      "Epoch 9/80\n",
      "8965/8965 [==============================] - 1s 90us/step - loss: 6.6908e-05 - accuracy: 1.0000 - val_loss: 4.9333e-04 - val_accuracy: 1.0000\n",
      "Epoch 10/80\n",
      "8965/8965 [==============================] - 1s 87us/step - loss: 5.4799e-05 - accuracy: 1.0000 - val_loss: 4.1259e-04 - val_accuracy: 1.0000\n",
      "Epoch 11/80\n",
      "8965/8965 [==============================] - 1s 89us/step - loss: 4.5391e-05 - accuracy: 1.0000 - val_loss: 5.1734e-04 - val_accuracy: 1.0000\n",
      "Epoch 12/80\n",
      "8965/8965 [==============================] - 1s 88us/step - loss: 3.9708e-05 - accuracy: 1.0000 - val_loss: 3.7832e-04 - val_accuracy: 1.0000\n",
      "Epoch 13/80\n",
      "8965/8965 [==============================] - 1s 88us/step - loss: 3.3064e-05 - accuracy: 1.0000 - val_loss: 3.4218e-04 - val_accuracy: 1.0000\n",
      "Epoch 14/80\n",
      "8965/8965 [==============================] - 1s 88us/step - loss: 2.8759e-05 - accuracy: 1.0000 - val_loss: 3.8079e-04 - val_accuracy: 1.0000\n",
      "Epoch 15/80\n",
      "8965/8965 [==============================] - 1s 89us/step - loss: 2.5970e-05 - accuracy: 1.0000 - val_loss: 3.4612e-04 - val_accuracy: 1.0000\n",
      "Epoch 16/80\n",
      "8965/8965 [==============================] - 1s 91us/step - loss: 2.2363e-05 - accuracy: 1.0000 - val_loss: 2.8524e-04 - val_accuracy: 1.0000\n",
      "Epoch 17/80\n",
      "8965/8965 [==============================] - 1s 91us/step - loss: 1.9336e-05 - accuracy: 1.0000 - val_loss: 2.9396e-04 - val_accuracy: 1.0000\n",
      "Epoch 18/80\n",
      "8965/8965 [==============================] - 1s 92us/step - loss: 1.7412e-05 - accuracy: 1.0000 - val_loss: 3.1505e-04 - val_accuracy: 1.0000\n",
      "Epoch 19/80\n",
      "8965/8965 [==============================] - 1s 91us/step - loss: 1.5515e-05 - accuracy: 1.0000 - val_loss: 2.5323e-04 - val_accuracy: 1.0000\n",
      "Epoch 20/80\n",
      "8965/8965 [==============================] - 1s 90us/step - loss: 1.3779e-05 - accuracy: 1.0000 - val_loss: 2.3679e-04 - val_accuracy: 1.0000\n",
      "Epoch 21/80\n",
      "8965/8965 [==============================] - 1s 89us/step - loss: 1.2598e-05 - accuracy: 1.0000 - val_loss: 2.4135e-04 - val_accuracy: 1.0000\n",
      "Epoch 22/80\n",
      "8965/8965 [==============================] - 1s 92us/step - loss: 1.1277e-05 - accuracy: 1.0000 - val_loss: 2.3369e-04 - val_accuracy: 1.0000\n",
      "Epoch 23/80\n",
      "8965/8965 [==============================] - 1s 91us/step - loss: 1.0297e-05 - accuracy: 1.0000 - val_loss: 2.3875e-04 - val_accuracy: 1.0000\n",
      "Epoch 24/80\n",
      "8965/8965 [==============================] - 1s 92us/step - loss: 9.3622e-06 - accuracy: 1.0000 - val_loss: 2.1594e-04 - val_accuracy: 1.0000\n",
      "Epoch 25/80\n",
      "8965/8965 [==============================] - 1s 92us/step - loss: 8.6572e-06 - accuracy: 1.0000 - val_loss: 2.1891e-04 - val_accuracy: 1.0000\n",
      "Epoch 26/80\n",
      "8965/8965 [==============================] - 1s 94us/step - loss: 7.7739e-06 - accuracy: 1.0000 - val_loss: 2.2434e-04 - val_accuracy: 1.0000\n",
      "Epoch 27/80\n",
      "8965/8965 [==============================] - 1s 91us/step - loss: 7.0784e-06 - accuracy: 1.0000 - val_loss: 2.0605e-04 - val_accuracy: 1.0000\n",
      "Epoch 28/80\n",
      "8965/8965 [==============================] - 1s 90us/step - loss: 6.3785e-06 - accuracy: 1.0000 - val_loss: 1.8460e-04 - val_accuracy: 1.0000\n",
      "Epoch 29/80\n",
      "8965/8965 [==============================] - 1s 93us/step - loss: 5.9260e-06 - accuracy: 1.0000 - val_loss: 1.5719e-04 - val_accuracy: 1.0000\n",
      "Epoch 30/80\n",
      "8965/8965 [==============================] - 1s 91us/step - loss: 6.2448e-06 - accuracy: 1.0000 - val_loss: 1.8203e-04 - val_accuracy: 1.0000\n",
      "Epoch 31/80\n",
      "8965/8965 [==============================] - 1s 90us/step - loss: 5.0591e-06 - accuracy: 1.0000 - val_loss: 1.8833e-04 - val_accuracy: 1.0000\n",
      "Epoch 32/80\n",
      "8965/8965 [==============================] - 1s 92us/step - loss: 4.6467e-06 - accuracy: 1.0000 - val_loss: 1.6953e-04 - val_accuracy: 1.0000\n",
      "Epoch 33/80\n",
      "8965/8965 [==============================] - 1s 90us/step - loss: 4.2896e-06 - accuracy: 1.0000 - val_loss: 1.6477e-04 - val_accuracy: 1.0000\n",
      "Epoch 34/80\n",
      "8965/8965 [==============================] - 1s 91us/step - loss: 4.0268e-06 - accuracy: 1.0000 - val_loss: 1.3307e-04 - val_accuracy: 1.0000\n",
      "Epoch 35/80\n",
      "8965/8965 [==============================] - 1s 92us/step - loss: 3.7225e-06 - accuracy: 1.0000 - val_loss: 1.2835e-04 - val_accuracy: 1.0000\n",
      "Epoch 36/80\n",
      "8965/8965 [==============================] - 1s 91us/step - loss: 3.3847e-06 - accuracy: 1.0000 - val_loss: 1.2371e-04 - val_accuracy: 1.0000\n",
      "Epoch 37/80\n",
      "8965/8965 [==============================] - 1s 95us/step - loss: 3.1935e-06 - accuracy: 1.0000 - val_loss: 1.2751e-04 - val_accuracy: 1.0000\n",
      "Epoch 38/80\n",
      "8965/8965 [==============================] - 1s 90us/step - loss: 2.9522e-06 - accuracy: 1.0000 - val_loss: 1.3358e-04 - val_accuracy: 1.0000\n",
      "Epoch 39/80\n",
      "8965/8965 [==============================] - 1s 92us/step - loss: 2.8117e-06 - accuracy: 1.0000 - val_loss: 1.1892e-04 - val_accuracy: 1.0000\n",
      "Epoch 40/80\n",
      "8965/8965 [==============================] - 1s 91us/step - loss: 2.6208e-06 - accuracy: 1.0000 - val_loss: 1.3003e-04 - val_accuracy: 1.0000\n",
      "Epoch 41/80\n",
      "8965/8965 [==============================] - 1s 90us/step - loss: 2.4179e-06 - accuracy: 1.0000 - val_loss: 1.3589e-04 - val_accuracy: 1.0000\n",
      "Epoch 42/80\n",
      "8965/8965 [==============================] - 1s 91us/step - loss: 2.2803e-06 - accuracy: 1.0000 - val_loss: 1.2700e-04 - val_accuracy: 1.0000\n",
      "Epoch 43/80\n",
      "8965/8965 [==============================] - 1s 90us/step - loss: 2.1682e-06 - accuracy: 1.0000 - val_loss: 1.1412e-04 - val_accuracy: 1.0000\n",
      "Epoch 44/80\n",
      "8965/8965 [==============================] - 1s 94us/step - loss: 2.1578e-06 - accuracy: 1.0000 - val_loss: 1.0017e-04 - val_accuracy: 1.0000\n",
      "Epoch 45/80\n",
      "8965/8965 [==============================] - 1s 93us/step - loss: 1.9146e-06 - accuracy: 1.0000 - val_loss: 1.1286e-04 - val_accuracy: 1.0000\n",
      "Epoch 46/80\n",
      "8965/8965 [==============================] - 1s 91us/step - loss: 1.8173e-06 - accuracy: 1.0000 - val_loss: 9.8218e-05 - val_accuracy: 1.0000\n",
      "Epoch 47/80\n",
      "8965/8965 [==============================] - 1s 95us/step - loss: 1.6704e-06 - accuracy: 1.0000 - val_loss: 9.3099e-05 - val_accuracy: 1.0000\n",
      "Epoch 48/80\n",
      "8965/8965 [==============================] - 1s 90us/step - loss: 1.7988e-06 - accuracy: 1.0000 - val_loss: 1.0450e-04 - val_accuracy: 1.0000\n",
      "Epoch 49/80\n",
      "8965/8965 [==============================] - 1s 89us/step - loss: 1.4810e-06 - accuracy: 1.0000 - val_loss: 8.9501e-05 - val_accuracy: 1.0000\n",
      "Epoch 50/80\n",
      "8965/8965 [==============================] - 1s 88us/step - loss: 1.3970e-06 - accuracy: 1.0000 - val_loss: 8.5342e-05 - val_accuracy: 1.0000\n",
      "Epoch 51/80\n",
      "8965/8965 [==============================] - 1s 88us/step - loss: 1.3141e-06 - accuracy: 1.0000 - val_loss: 9.4244e-05 - val_accuracy: 1.0000\n",
      "Epoch 52/80\n",
      "8965/8965 [==============================] - 1s 87us/step - loss: 1.2255e-06 - accuracy: 1.0000 - val_loss: 1.0831e-04 - val_accuracy: 1.0000\n",
      "Epoch 53/80\n",
      "8965/8965 [==============================] - 1s 95us/step - loss: 1.1610e-06 - accuracy: 1.0000 - val_loss: 8.2865e-05 - val_accuracy: 1.0000\n",
      "Epoch 54/80\n",
      "8965/8965 [==============================] - 1s 87us/step - loss: 1.1130e-06 - accuracy: 1.0000 - val_loss: 9.3459e-05 - val_accuracy: 1.0000\n",
      "Epoch 55/80\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8965/8965 [==============================] - 1s 87us/step - loss: 1.0700e-06 - accuracy: 1.0000 - val_loss: 9.0279e-05 - val_accuracy: 1.0000\n",
      "Epoch 56/80\n",
      "8965/8965 [==============================] - 1s 87us/step - loss: 1.0079e-06 - accuracy: 1.0000 - val_loss: 1.0003e-04 - val_accuracy: 1.0000\n",
      "Epoch 57/80\n",
      "8965/8965 [==============================] - 1s 89us/step - loss: 9.7821e-07 - accuracy: 1.0000 - val_loss: 7.2630e-05 - val_accuracy: 1.0000\n",
      "Epoch 58/80\n",
      "8965/8965 [==============================] - 1s 87us/step - loss: 8.9460e-07 - accuracy: 1.0000 - val_loss: 8.3062e-05 - val_accuracy: 1.0000\n",
      "Epoch 59/80\n",
      "8965/8965 [==============================] - 1s 87us/step - loss: 9.8636e-07 - accuracy: 1.0000 - val_loss: 9.3667e-05 - val_accuracy: 1.0000\n",
      "Epoch 60/80\n",
      "8965/8965 [==============================] - 1s 89us/step - loss: 8.2719e-07 - accuracy: 1.0000 - val_loss: 8.5078e-05 - val_accuracy: 1.0000\n",
      "Epoch 61/80\n",
      "8965/8965 [==============================] - 1s 87us/step - loss: 7.5108e-07 - accuracy: 1.0000 - val_loss: 9.7136e-05 - val_accuracy: 1.0000\n",
      "Epoch 62/80\n",
      "8965/8965 [==============================] - 1s 87us/step - loss: 7.2870e-07 - accuracy: 1.0000 - val_loss: 7.5910e-05 - val_accuracy: 1.0000\n",
      "Epoch 63/80\n",
      "8965/8965 [==============================] - 1s 90us/step - loss: 6.9273e-07 - accuracy: 1.0000 - val_loss: 1.0488e-04 - val_accuracy: 1.0000\n",
      "Epoch 64/80\n",
      "8965/8965 [==============================] - 1s 88us/step - loss: 6.6849e-07 - accuracy: 1.0000 - val_loss: 7.6783e-05 - val_accuracy: 1.0000\n",
      "Epoch 65/80\n",
      "8965/8965 [==============================] - 1s 87us/step - loss: 6.3062e-07 - accuracy: 1.0000 - val_loss: 8.7756e-05 - val_accuracy: 1.0000\n",
      "Epoch 66/80\n",
      "8965/8965 [==============================] - 1s 87us/step - loss: 5.8830e-07 - accuracy: 1.0000 - val_loss: 6.7582e-05 - val_accuracy: 1.0000\n",
      "Epoch 67/80\n",
      "8965/8965 [==============================] - 1s 87us/step - loss: 5.7026e-07 - accuracy: 1.0000 - val_loss: 6.7922e-05 - val_accuracy: 1.0000\n",
      "Epoch 68/80\n",
      "8965/8965 [==============================] - 1s 89us/step - loss: 5.4455e-07 - accuracy: 1.0000 - val_loss: 7.6712e-05 - val_accuracy: 1.0000\n",
      "Epoch 69/80\n",
      "8965/8965 [==============================] - 1s 87us/step - loss: 5.2546e-07 - accuracy: 1.0000 - val_loss: 7.8447e-05 - val_accuracy: 1.0000\n",
      "Epoch 70/80\n",
      "8965/8965 [==============================] - 1s 86us/step - loss: 4.9292e-07 - accuracy: 1.0000 - val_loss: 8.8815e-05 - val_accuracy: 1.0000\n",
      "Epoch 71/80\n",
      "8965/8965 [==============================] - 1s 87us/step - loss: 4.8034e-07 - accuracy: 1.0000 - val_loss: 8.8219e-05 - val_accuracy: 1.0000\n",
      "Epoch 72/80\n",
      "8965/8965 [==============================] - 1s 87us/step - loss: 4.4253e-07 - accuracy: 1.0000 - val_loss: 8.6751e-05 - val_accuracy: 1.0000\n",
      "Epoch 73/80\n",
      "8965/8965 [==============================] - 1s 86us/step - loss: 4.2866e-07 - accuracy: 1.0000 - val_loss: 9.8162e-05 - val_accuracy: 1.0000\n",
      "Epoch 74/80\n",
      "8965/8965 [==============================] - 1s 87us/step - loss: 4.0975e-07 - accuracy: 1.0000 - val_loss: 9.1999e-05 - val_accuracy: 1.0000\n",
      "Epoch 75/80\n",
      "8965/8965 [==============================] - 1s 87us/step - loss: 3.9060e-07 - accuracy: 1.0000 - val_loss: 9.3031e-05 - val_accuracy: 1.0000\n",
      "Epoch 76/80\n",
      "8965/8965 [==============================] - 1s 86us/step - loss: 3.8311e-07 - accuracy: 1.0000 - val_loss: 6.8660e-05 - val_accuracy: 1.0000\n",
      "Epoch 00076: early stopping\n",
      "[[3.1719461e-05 2.9334121e-08 1.0723261e-06 ... 8.9204532e-01\n",
      "  1.0791459e-01 2.8908286e-07]\n",
      " [3.0082319e-09 2.2824097e-12 1.2692999e-10 ... 6.3895676e-03\n",
      "  9.9361044e-01 1.1160790e-08]\n",
      " [3.1240057e-07 2.7067736e-08 1.4437115e-08 ... 7.9712927e-01\n",
      "  2.0286988e-01 4.9765225e-07]\n",
      " ...\n",
      " [1.1814030e-14 1.6752454e-17 6.5433097e-18 ... 4.4033749e-17\n",
      "  1.0000000e+00 1.0162456e-19]\n",
      " [2.6439621e-15 2.1988503e-20 5.1250601e-18 ... 2.4737654e-10\n",
      "  4.8970575e-15 2.9962231e-12]\n",
      " [9.0818618e-16 2.0107785e-20 2.5507926e-17 ... 1.9223686e-20\n",
      "  1.0000000e+00 1.4445294e-28]]\n",
      "[6 7 6 ... 7 3 7]\n",
      "<class 'numpy.ndarray'>\n",
      "One CNN, r:  1\n",
      "Computing Time:  0:02:10.124764\n",
      "Model: \"sequential_1\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv1d_1 (Conv1D)            (None, 1000, 6)           36        \n",
      "_________________________________________________________________\n",
      "average_pooling1d_1 (Average (None, 500, 6)            0         \n",
      "_________________________________________________________________\n",
      "conv1d_2 (Conv1D)            (None, 496, 16)           496       \n",
      "_________________________________________________________________\n",
      "average_pooling1d_2 (Average (None, 248, 16)           0         \n",
      "_________________________________________________________________\n",
      "conv1d_3 (Conv1D)            (None, 244, 120)          9720      \n",
      "_________________________________________________________________\n",
      "flatten_1 (Flatten)          (None, 29280)             0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 84)                2459604   \n",
      "_________________________________________________________________\n",
      "preds (Dense)                (None, 9)                 765       \n",
      "=================================================================\n",
      "Total params: 2,470,621\n",
      "Trainable params: 2,470,621\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Train on 8965 samples, validate on 997 samples\n",
      "Epoch 1/80\n",
      "8965/8965 [==============================] - 1s 113us/step - loss: 0.2047 - accuracy: 0.9420 - val_loss: 0.0058 - val_accuracy: 0.9990\n",
      "Epoch 2/80\n",
      "8965/8965 [==============================] - 1s 87us/step - loss: 0.0079 - accuracy: 0.9975 - val_loss: 0.0026 - val_accuracy: 0.9990\n",
      "Epoch 3/80\n",
      "8965/8965 [==============================] - 1s 86us/step - loss: 0.0018 - accuracy: 0.9996 - val_loss: 0.0014 - val_accuracy: 0.9990\n",
      "Epoch 4/80\n",
      "8965/8965 [==============================] - 1s 96us/step - loss: 4.4739e-04 - accuracy: 1.0000 - val_loss: 0.0017 - val_accuracy: 1.0000\n",
      "Epoch 5/80\n",
      "8965/8965 [==============================] - 1s 86us/step - loss: 2.5483e-04 - accuracy: 1.0000 - val_loss: 5.1510e-04 - val_accuracy: 1.0000\n",
      "Epoch 6/80\n",
      "8965/8965 [==============================] - 1s 85us/step - loss: 1.5047e-04 - accuracy: 1.0000 - val_loss: 4.0277e-04 - val_accuracy: 1.0000\n",
      "Epoch 7/80\n",
      "8965/8965 [==============================] - 1s 91us/step - loss: 1.1182e-04 - accuracy: 1.0000 - val_loss: 3.0032e-04 - val_accuracy: 1.0000\n",
      "Epoch 8/80\n",
      "8965/8965 [==============================] - 1s 86us/step - loss: 9.0052e-05 - accuracy: 1.0000 - val_loss: 2.7245e-04 - val_accuracy: 1.0000\n",
      "Epoch 9/80\n",
      "8965/8965 [==============================] - 1s 91us/step - loss: 6.8870e-05 - accuracy: 1.0000 - val_loss: 2.4508e-04 - val_accuracy: 1.0000\n",
      "Epoch 10/80\n",
      "8965/8965 [==============================] - 1s 89us/step - loss: 5.5758e-05 - accuracy: 1.0000 - val_loss: 2.2049e-04 - val_accuracy: 1.0000\n",
      "Epoch 11/80\n",
      "8965/8965 [==============================] - 1s 86us/step - loss: 4.9720e-05 - accuracy: 1.0000 - val_loss: 1.9972e-04 - val_accuracy: 1.0000\n",
      "Epoch 12/80\n",
      "8965/8965 [==============================] - 1s 85us/step - loss: 4.0975e-05 - accuracy: 1.0000 - val_loss: 1.6566e-04 - val_accuracy: 1.0000\n",
      "Epoch 13/80\n",
      "8965/8965 [==============================] - 1s 88us/step - loss: 3.4975e-05 - accuracy: 1.0000 - val_loss: 1.4818e-04 - val_accuracy: 1.0000\n",
      "Epoch 14/80\n",
      "8965/8965 [==============================] - 1s 87us/step - loss: 3.0851e-05 - accuracy: 1.0000 - val_loss: 1.4000e-04 - val_accuracy: 1.0000\n",
      "Epoch 15/80\n",
      "8965/8965 [==============================] - 1s 86us/step - loss: 2.7050e-05 - accuracy: 1.0000 - val_loss: 1.1902e-04 - val_accuracy: 1.0000\n",
      "Epoch 16/80\n",
      "8965/8965 [==============================] - 1s 85us/step - loss: 2.3841e-05 - accuracy: 1.0000 - val_loss: 1.2870e-04 - val_accuracy: 1.0000\n",
      "Epoch 17/80\n",
      "8965/8965 [==============================] - 1s 86us/step - loss: 2.0389e-05 - accuracy: 1.0000 - val_loss: 1.0136e-04 - val_accuracy: 1.0000\n",
      "Epoch 18/80\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8965/8965 [==============================] - 1s 90us/step - loss: 1.8110e-05 - accuracy: 1.0000 - val_loss: 9.9710e-05 - val_accuracy: 1.0000\n",
      "Epoch 19/80\n",
      "8965/8965 [==============================] - 1s 95us/step - loss: 1.6168e-05 - accuracy: 1.0000 - val_loss: 1.0414e-04 - val_accuracy: 1.0000\n",
      "Epoch 20/80\n",
      "8965/8965 [==============================] - 1s 87us/step - loss: 1.4686e-05 - accuracy: 1.0000 - val_loss: 8.2313e-05 - val_accuracy: 1.0000\n",
      "Epoch 21/80\n",
      "8965/8965 [==============================] - 1s 85us/step - loss: 1.4886e-05 - accuracy: 1.0000 - val_loss: 1.0736e-04 - val_accuracy: 1.0000\n",
      "Epoch 22/80\n",
      "8965/8965 [==============================] - 1s 85us/step - loss: 1.1869e-05 - accuracy: 1.0000 - val_loss: 7.3454e-05 - val_accuracy: 1.0000\n",
      "Epoch 23/80\n",
      "8965/8965 [==============================] - 1s 87us/step - loss: 1.0522e-05 - accuracy: 1.0000 - val_loss: 7.3578e-05 - val_accuracy: 1.0000\n",
      "Epoch 24/80\n",
      "8965/8965 [==============================] - 1s 88us/step - loss: 9.8865e-06 - accuracy: 1.0000 - val_loss: 6.6940e-05 - val_accuracy: 1.0000\n",
      "Epoch 25/80\n",
      "8965/8965 [==============================] - 1s 85us/step - loss: 8.8053e-06 - accuracy: 1.0000 - val_loss: 5.9874e-05 - val_accuracy: 1.0000\n",
      "Epoch 26/80\n",
      "8965/8965 [==============================] - 1s 88us/step - loss: 8.1170e-06 - accuracy: 1.0000 - val_loss: 5.9751e-05 - val_accuracy: 1.0000\n",
      "Epoch 27/80\n",
      "8965/8965 [==============================] - 1s 85us/step - loss: 7.6322e-06 - accuracy: 1.0000 - val_loss: 5.6975e-05 - val_accuracy: 1.0000\n",
      "Epoch 28/80\n",
      "8965/8965 [==============================] - 1s 85us/step - loss: 7.3663e-06 - accuracy: 1.0000 - val_loss: 5.2627e-05 - val_accuracy: 1.0000\n",
      "Epoch 29/80\n",
      "8965/8965 [==============================] - 1s 85us/step - loss: 6.3596e-06 - accuracy: 1.0000 - val_loss: 4.7621e-05 - val_accuracy: 1.0000\n",
      "Epoch 30/80\n",
      "8965/8965 [==============================] - 1s 86us/step - loss: 5.9991e-06 - accuracy: 1.0000 - val_loss: 4.4696e-05 - val_accuracy: 1.0000\n",
      "Epoch 31/80\n",
      "8965/8965 [==============================] - 1s 88us/step - loss: 5.3005e-06 - accuracy: 1.0000 - val_loss: 4.4558e-05 - val_accuracy: 1.0000\n",
      "Epoch 32/80\n",
      "8965/8965 [==============================] - 1s 84us/step - loss: 4.9836e-06 - accuracy: 1.0000 - val_loss: 4.4154e-05 - val_accuracy: 1.0000\n",
      "Epoch 33/80\n",
      "8965/8965 [==============================] - 1s 87us/step - loss: 4.6500e-06 - accuracy: 1.0000 - val_loss: 3.9072e-05 - val_accuracy: 1.0000\n",
      "Epoch 34/80\n",
      "8965/8965 [==============================] - 1s 87us/step - loss: 4.3839e-06 - accuracy: 1.0000 - val_loss: 4.1346e-05 - val_accuracy: 1.0000\n",
      "Epoch 35/80\n",
      "8965/8965 [==============================] - 1s 88us/step - loss: 4.1967e-06 - accuracy: 1.0000 - val_loss: 3.9143e-05 - val_accuracy: 1.0000\n",
      "Epoch 36/80\n",
      "8965/8965 [==============================] - 1s 86us/step - loss: 3.7154e-06 - accuracy: 1.0000 - val_loss: 3.4898e-05 - val_accuracy: 1.0000\n",
      "Epoch 37/80\n",
      "8965/8965 [==============================] - 1s 86us/step - loss: 3.4825e-06 - accuracy: 1.0000 - val_loss: 3.5456e-05 - val_accuracy: 1.0000\n",
      "Epoch 38/80\n",
      "8965/8965 [==============================] - 1s 86us/step - loss: 3.2894e-06 - accuracy: 1.0000 - val_loss: 3.3107e-05 - val_accuracy: 1.0000\n",
      "Epoch 39/80\n",
      "8965/8965 [==============================] - 1s 85us/step - loss: 3.1056e-06 - accuracy: 1.0000 - val_loss: 3.4942e-05 - val_accuracy: 1.0000\n",
      "Epoch 40/80\n",
      "8965/8965 [==============================] - 1s 84us/step - loss: 2.9826e-06 - accuracy: 1.0000 - val_loss: 3.1024e-05 - val_accuracy: 1.0000\n",
      "Epoch 41/80\n",
      "8965/8965 [==============================] - 1s 87us/step - loss: 2.7105e-06 - accuracy: 1.0000 - val_loss: 2.9350e-05 - val_accuracy: 1.0000\n",
      "Epoch 42/80\n",
      "8965/8965 [==============================] - 1s 87us/step - loss: 2.5389e-06 - accuracy: 1.0000 - val_loss: 2.7763e-05 - val_accuracy: 1.0000\n",
      "Epoch 43/80\n",
      "8965/8965 [==============================] - 1s 87us/step - loss: 2.3556e-06 - accuracy: 1.0000 - val_loss: 2.5999e-05 - val_accuracy: 1.0000\n",
      "Epoch 44/80\n",
      "8965/8965 [==============================] - 1s 86us/step - loss: 2.2408e-06 - accuracy: 1.0000 - val_loss: 2.6693e-05 - val_accuracy: 1.0000\n",
      "Epoch 45/80\n",
      "8965/8965 [==============================] - 1s 86us/step - loss: 2.1217e-06 - accuracy: 1.0000 - val_loss: 2.4064e-05 - val_accuracy: 1.0000\n",
      "Epoch 46/80\n",
      "8965/8965 [==============================] - 1s 85us/step - loss: 1.9769e-06 - accuracy: 1.0000 - val_loss: 2.3900e-05 - val_accuracy: 1.0000\n",
      "Epoch 47/80\n",
      "8965/8965 [==============================] - 1s 87us/step - loss: 1.8839e-06 - accuracy: 1.0000 - val_loss: 2.2865e-05 - val_accuracy: 1.0000\n",
      "Epoch 48/80\n",
      "8965/8965 [==============================] - 1s 84us/step - loss: 1.7593e-06 - accuracy: 1.0000 - val_loss: 2.2027e-05 - val_accuracy: 1.0000\n",
      "Epoch 49/80\n",
      "8965/8965 [==============================] - 1s 87us/step - loss: 1.6758e-06 - accuracy: 1.0000 - val_loss: 2.1324e-05 - val_accuracy: 1.0000\n",
      "Epoch 50/80\n",
      "8965/8965 [==============================] - 1s 85us/step - loss: 1.5506e-06 - accuracy: 1.0000 - val_loss: 2.1012e-05 - val_accuracy: 1.0000\n",
      "Epoch 51/80\n",
      "8965/8965 [==============================] - 1s 87us/step - loss: 1.4541e-06 - accuracy: 1.0000 - val_loss: 2.1306e-05 - val_accuracy: 1.0000\n",
      "Epoch 52/80\n",
      "8965/8965 [==============================] - 1s 86us/step - loss: 1.4206e-06 - accuracy: 1.0000 - val_loss: 1.9793e-05 - val_accuracy: 1.0000\n",
      "Epoch 53/80\n",
      "8965/8965 [==============================] - 1s 86us/step - loss: 1.3235e-06 - accuracy: 1.0000 - val_loss: 1.8563e-05 - val_accuracy: 1.0000\n",
      "Epoch 54/80\n",
      "8965/8965 [==============================] - 1s 85us/step - loss: 1.2566e-06 - accuracy: 1.0000 - val_loss: 1.8138e-05 - val_accuracy: 1.0000\n",
      "Epoch 55/80\n",
      "8965/8965 [==============================] - 1s 87us/step - loss: 1.1788e-06 - accuracy: 1.0000 - val_loss: 1.7360e-05 - val_accuracy: 1.0000\n",
      "Epoch 56/80\n",
      "8965/8965 [==============================] - 1s 87us/step - loss: 1.1265e-06 - accuracy: 1.0000 - val_loss: 1.7601e-05 - val_accuracy: 1.0000\n",
      "Epoch 57/80\n",
      "8965/8965 [==============================] - 1s 86us/step - loss: 1.0810e-06 - accuracy: 1.0000 - val_loss: 1.7045e-05 - val_accuracy: 1.0000\n",
      "Epoch 58/80\n",
      "8965/8965 [==============================] - 1s 87us/step - loss: 1.0111e-06 - accuracy: 1.0000 - val_loss: 1.6318e-05 - val_accuracy: 1.0000\n",
      "Epoch 59/80\n",
      "8965/8965 [==============================] - 1s 87us/step - loss: 9.5396e-07 - accuracy: 1.0000 - val_loss: 1.6084e-05 - val_accuracy: 1.0000\n",
      "Epoch 60/80\n",
      "8965/8965 [==============================] - 1s 87us/step - loss: 9.0029e-07 - accuracy: 1.0000 - val_loss: 1.5442e-05 - val_accuracy: 1.0000\n",
      "Epoch 61/80\n",
      "8965/8965 [==============================] - 1s 89us/step - loss: 8.5237e-07 - accuracy: 1.0000 - val_loss: 1.4440e-05 - val_accuracy: 1.0000\n",
      "Epoch 62/80\n",
      "8965/8965 [==============================] - 1s 88us/step - loss: 8.1320e-07 - accuracy: 1.0000 - val_loss: 1.4112e-05 - val_accuracy: 1.0000\n",
      "Epoch 63/80\n",
      "8965/8965 [==============================] - 1s 85us/step - loss: 7.7360e-07 - accuracy: 1.0000 - val_loss: 1.3671e-05 - val_accuracy: 1.0000\n",
      "Epoch 64/80\n",
      "8965/8965 [==============================] - 1s 85us/step - loss: 7.3658e-07 - accuracy: 1.0000 - val_loss: 1.3956e-05 - val_accuracy: 1.0000\n",
      "Epoch 65/80\n",
      "8965/8965 [==============================] - 1s 86us/step - loss: 7.4138e-07 - accuracy: 1.0000 - val_loss: 1.3737e-05 - val_accuracy: 1.0000\n",
      "Epoch 66/80\n",
      "8965/8965 [==============================] - 1s 86us/step - loss: 6.7315e-07 - accuracy: 1.0000 - val_loss: 1.2727e-05 - val_accuracy: 1.0000\n",
      "Epoch 67/80\n",
      "8965/8965 [==============================] - 1s 85us/step - loss: 6.2629e-07 - accuracy: 1.0000 - val_loss: 1.2668e-05 - val_accuracy: 1.0000\n",
      "Epoch 68/80\n",
      "8965/8965 [==============================] - 1s 85us/step - loss: 6.0217e-07 - accuracy: 1.0000 - val_loss: 1.1800e-05 - val_accuracy: 1.0000\n",
      "Epoch 69/80\n",
      "8965/8965 [==============================] - 1s 86us/step - loss: 5.9408e-07 - accuracy: 1.0000 - val_loss: 1.2065e-05 - val_accuracy: 1.0000\n",
      "Epoch 70/80\n",
      "8965/8965 [==============================] - 1s 87us/step - loss: 5.4361e-07 - accuracy: 1.0000 - val_loss: 1.1340e-05 - val_accuracy: 1.0000\n",
      "Epoch 71/80\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8965/8965 [==============================] - 1s 86us/step - loss: 5.3357e-07 - accuracy: 1.0000 - val_loss: 1.1072e-05 - val_accuracy: 1.0000\n",
      "Epoch 72/80\n",
      "8965/8965 [==============================] - 1s 88us/step - loss: 4.9457e-07 - accuracy: 1.0000 - val_loss: 1.0459e-05 - val_accuracy: 1.0000\n",
      "Epoch 73/80\n",
      "8965/8965 [==============================] - 1s 84us/step - loss: 4.6998e-07 - accuracy: 1.0000 - val_loss: 1.0251e-05 - val_accuracy: 1.0000\n",
      "Epoch 74/80\n",
      "8965/8965 [==============================] - 1s 85us/step - loss: 4.5468e-07 - accuracy: 1.0000 - val_loss: 9.9878e-06 - val_accuracy: 1.0000\n",
      "Epoch 75/80\n",
      "8965/8965 [==============================] - 1s 87us/step - loss: 4.3199e-07 - accuracy: 1.0000 - val_loss: 9.8412e-06 - val_accuracy: 1.0000\n",
      "Epoch 76/80\n",
      "8965/8965 [==============================] - 1s 87us/step - loss: 4.2235e-07 - accuracy: 1.0000 - val_loss: 9.7222e-06 - val_accuracy: 1.0000\n",
      "Epoch 77/80\n",
      "8965/8965 [==============================] - 1s 87us/step - loss: 3.9003e-07 - accuracy: 1.0000 - val_loss: 9.1716e-06 - val_accuracy: 1.0000\n",
      "Epoch 78/80\n",
      "8965/8965 [==============================] - 1s 85us/step - loss: 3.7006e-07 - accuracy: 1.0000 - val_loss: 9.2431e-06 - val_accuracy: 1.0000\n",
      "Epoch 79/80\n",
      "8965/8965 [==============================] - ETA: 0s - loss: 3.5404e-07 - accuracy: 1.00 - 1s 84us/step - loss: 3.5669e-07 - accuracy: 1.0000 - val_loss: 9.5429e-06 - val_accuracy: 1.0000\n",
      "Epoch 80/80\n",
      "8965/8965 [==============================] - 1s 85us/step - loss: 3.5711e-07 - accuracy: 1.0000 - val_loss: 8.7824e-06 - val_accuracy: 1.0000\n",
      "[[1.16121853e-04 4.75839883e-08 3.37309491e-09 ... 9.92280126e-01\n",
      "  7.36735621e-03 5.88452203e-05]\n",
      " [1.55241298e-06 4.46600569e-11 2.60236450e-12 ... 1.75956368e-01\n",
      "  8.20883274e-01 3.15031153e-03]\n",
      " [1.42737155e-10 1.14803694e-10 1.26419269e-14 ... 9.99040067e-01\n",
      "  9.59625002e-04 2.23243759e-07]\n",
      " ...\n",
      " [9.11053948e-20 6.94790511e-19 2.94236106e-22 ... 1.51511519e-18\n",
      "  1.00000000e+00 8.23616391e-17]\n",
      " [4.99888193e-16 1.42857284e-19 9.75785548e-22 ... 1.67150915e-08\n",
      "  1.40486547e-14 2.07613801e-10]\n",
      " [3.54593998e-17 2.61686569e-18 2.07774800e-16 ... 2.73945720e-21\n",
      "  1.00000000e+00 2.72316796e-24]]\n",
      "[6 7 6 ... 7 3 7]\n",
      "<class 'numpy.ndarray'>\n",
      "One CNN, r:  2\n",
      "Computing Time:  0:03:15.312660\n",
      "Model: \"sequential_1\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv1d_1 (Conv1D)            (None, 1000, 6)           36        \n",
      "_________________________________________________________________\n",
      "average_pooling1d_1 (Average (None, 500, 6)            0         \n",
      "_________________________________________________________________\n",
      "conv1d_2 (Conv1D)            (None, 496, 16)           496       \n",
      "_________________________________________________________________\n",
      "average_pooling1d_2 (Average (None, 248, 16)           0         \n",
      "_________________________________________________________________\n",
      "conv1d_3 (Conv1D)            (None, 244, 120)          9720      \n",
      "_________________________________________________________________\n",
      "flatten_1 (Flatten)          (None, 29280)             0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 84)                2459604   \n",
      "_________________________________________________________________\n",
      "preds (Dense)                (None, 9)                 765       \n",
      "=================================================================\n",
      "Total params: 2,470,621\n",
      "Trainable params: 2,470,621\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Train on 8965 samples, validate on 997 samples\n",
      "Epoch 1/80\n",
      "8965/8965 [==============================] - 1s 110us/step - loss: 0.2765 - accuracy: 0.9123 - val_loss: 0.0056 - val_accuracy: 1.0000\n",
      "Epoch 2/80\n",
      "8965/8965 [==============================] - 1s 91us/step - loss: 0.0032 - accuracy: 0.9993 - val_loss: 0.0028 - val_accuracy: 0.9990\n",
      "Epoch 3/80\n",
      "8965/8965 [==============================] - 1s 87us/step - loss: 0.0014 - accuracy: 0.9999 - val_loss: 0.0017 - val_accuracy: 0.9990\n",
      "Epoch 4/80\n",
      "8965/8965 [==============================] - 1s 88us/step - loss: 4.3273e-04 - accuracy: 1.0000 - val_loss: 0.0010 - val_accuracy: 1.0000\n",
      "Epoch 5/80\n",
      "8965/8965 [==============================] - 1s 87us/step - loss: 2.2663e-04 - accuracy: 1.0000 - val_loss: 0.0011 - val_accuracy: 1.0000\n",
      "Epoch 6/80\n",
      "8965/8965 [==============================] - 1s 85us/step - loss: 1.4131e-04 - accuracy: 1.0000 - val_loss: 5.8409e-04 - val_accuracy: 1.0000\n",
      "Epoch 7/80\n",
      "8965/8965 [==============================] - 1s 89us/step - loss: 8.9636e-05 - accuracy: 1.0000 - val_loss: 5.4954e-04 - val_accuracy: 1.0000\n",
      "Epoch 8/80\n",
      "8965/8965 [==============================] - 1s 85us/step - loss: 5.8063e-05 - accuracy: 1.0000 - val_loss: 3.2657e-04 - val_accuracy: 1.0000\n",
      "Epoch 9/80\n",
      "8965/8965 [==============================] - 1s 87us/step - loss: 4.3055e-05 - accuracy: 1.0000 - val_loss: 8.4863e-04 - val_accuracy: 1.0000\n",
      "Epoch 10/80\n",
      "8965/8965 [==============================] - 1s 86us/step - loss: 3.1534e-05 - accuracy: 1.0000 - val_loss: 3.6712e-04 - val_accuracy: 1.0000\n",
      "Epoch 11/80\n",
      "8965/8965 [==============================] - 1s 87us/step - loss: 2.5468e-05 - accuracy: 1.0000 - val_loss: 6.2235e-04 - val_accuracy: 1.0000\n",
      "Epoch 12/80\n",
      "8965/8965 [==============================] - 1s 86us/step - loss: 1.9375e-05 - accuracy: 1.0000 - val_loss: 2.0946e-04 - val_accuracy: 1.0000\n",
      "Epoch 13/80\n",
      "8965/8965 [==============================] - 1s 86us/step - loss: 1.6861e-05 - accuracy: 1.0000 - val_loss: 3.7317e-04 - val_accuracy: 1.0000\n",
      "Epoch 14/80\n",
      "8965/8965 [==============================] - 1s 87us/step - loss: 1.4016e-05 - accuracy: 1.0000 - val_loss: 6.8040e-04 - val_accuracy: 1.0000\n",
      "Epoch 15/80\n",
      "8965/8965 [==============================] - 1s 87us/step - loss: 1.2159e-05 - accuracy: 1.0000 - val_loss: 3.7050e-04 - val_accuracy: 1.0000\n",
      "Epoch 16/80\n",
      "8965/8965 [==============================] - 1s 85us/step - loss: 1.0139e-05 - accuracy: 1.0000 - val_loss: 2.9889e-04 - val_accuracy: 1.0000\n",
      "Epoch 17/80\n",
      "8965/8965 [==============================] - 1s 90us/step - loss: 8.9948e-06 - accuracy: 1.0000 - val_loss: 2.5806e-04 - val_accuracy: 1.0000\n",
      "Epoch 18/80\n",
      "8965/8965 [==============================] - 1s 87us/step - loss: 7.6282e-06 - accuracy: 1.0000 - val_loss: 4.3584e-04 - val_accuracy: 1.0000\n",
      "Epoch 19/80\n",
      "8965/8965 [==============================] - 1s 87us/step - loss: 6.9845e-06 - accuracy: 1.0000 - val_loss: 3.1279e-04 - val_accuracy: 1.0000\n",
      "Epoch 20/80\n",
      "8965/8965 [==============================] - 1s 87us/step - loss: 5.7607e-06 - accuracy: 1.0000 - val_loss: 3.0748e-04 - val_accuracy: 1.0000\n",
      "Epoch 21/80\n",
      "8965/8965 [==============================] - 1s 89us/step - loss: 5.2440e-06 - accuracy: 1.0000 - val_loss: 3.9764e-04 - val_accuracy: 1.0000\n",
      "Epoch 22/80\n",
      "8965/8965 [==============================] - 1s 86us/step - loss: 4.9167e-06 - accuracy: 1.0000 - val_loss: 2.3008e-04 - val_accuracy: 1.0000\n",
      "Epoch 00022: early stopping\n",
      "[[1.4357163e-04 2.0885562e-08 3.9881384e-06 ... 8.9808857e-01\n",
      "  1.0081590e-01 1.0334376e-07]\n",
      " [1.0437381e-08 9.1272909e-13 4.5187737e-10 ... 1.1753070e-03\n",
      "  9.9882227e-01 2.9982083e-08]\n",
      " [6.1353069e-07 8.6268246e-09 2.5538826e-08 ... 9.5490092e-01\n",
      "  4.5084242e-02 7.0781601e-07]\n",
      " ...\n",
      " [4.6528357e-20 8.9363754e-19 3.7376785e-18 ... 3.7744068e-15\n",
      "  1.0000000e+00 6.8960232e-14]\n",
      " [3.3140304e-16 2.4981067e-18 4.9213025e-17 ... 1.8243209e-07\n",
      "  5.5709614e-14 7.9161809e-14]\n",
      " [1.1595047e-19 1.3673893e-17 1.8743350e-15 ... 9.3348929e-18\n",
      "  1.0000000e+00 1.7297324e-21]]\n",
      "[6 7 6 ... 7 3 7]\n",
      "<class 'numpy.ndarray'>\n",
      "One CNN, r:  3\n",
      "Computing Time:  0:03:35.671641\n",
      "Model: \"sequential_1\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv1d_1 (Conv1D)            (None, 1000, 6)           36        \n",
      "_________________________________________________________________\n",
      "average_pooling1d_1 (Average (None, 500, 6)            0         \n",
      "_________________________________________________________________\n",
      "conv1d_2 (Conv1D)            (None, 496, 16)           496       \n",
      "_________________________________________________________________\n",
      "average_pooling1d_2 (Average (None, 248, 16)           0         \n",
      "_________________________________________________________________\n",
      "conv1d_3 (Conv1D)            (None, 244, 120)          9720      \n",
      "_________________________________________________________________\n",
      "flatten_1 (Flatten)          (None, 29280)             0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 84)                2459604   \n",
      "_________________________________________________________________\n",
      "preds (Dense)                (None, 9)                 765       \n",
      "=================================================================\n",
      "Total params: 2,470,621\n",
      "Trainable params: 2,470,621\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 8965 samples, validate on 997 samples\n",
      "Epoch 1/80\n",
      "8965/8965 [==============================] - 1s 112us/step - loss: 0.3632 - accuracy: 0.9015 - val_loss: 0.0090 - val_accuracy: 0.9990\n",
      "Epoch 2/80\n",
      "8965/8965 [==============================] - 1s 85us/step - loss: 0.0043 - accuracy: 0.9994 - val_loss: 0.0078 - val_accuracy: 0.9990\n",
      "Epoch 3/80\n",
      "8965/8965 [==============================] - 1s 88us/step - loss: 0.0019 - accuracy: 1.0000 - val_loss: 0.0023 - val_accuracy: 0.9990\n",
      "Epoch 4/80\n",
      "8965/8965 [==============================] - 1s 88us/step - loss: 7.9234e-04 - accuracy: 1.0000 - val_loss: 0.0025 - val_accuracy: 1.0000\n",
      "Epoch 5/80\n",
      "8965/8965 [==============================] - 1s 87us/step - loss: 3.5262e-04 - accuracy: 1.0000 - val_loss: 7.6943e-04 - val_accuracy: 1.0000\n",
      "Epoch 6/80\n",
      "8965/8965 [==============================] - 1s 84us/step - loss: 2.1121e-04 - accuracy: 1.0000 - val_loss: 6.1738e-04 - val_accuracy: 1.0000\n",
      "Epoch 7/80\n",
      "8965/8965 [==============================] - 1s 86us/step - loss: 1.5647e-04 - accuracy: 1.0000 - val_loss: 4.2996e-04 - val_accuracy: 1.0000\n",
      "Epoch 8/80\n",
      "8965/8965 [==============================] - 1s 86us/step - loss: 1.0244e-04 - accuracy: 1.0000 - val_loss: 5.1520e-04 - val_accuracy: 1.0000\n",
      "Epoch 9/80\n",
      "8965/8965 [==============================] - 1s 84us/step - loss: 7.6152e-05 - accuracy: 1.0000 - val_loss: 2.9888e-04 - val_accuracy: 1.0000\n",
      "Epoch 10/80\n",
      "8965/8965 [==============================] - 1s 87us/step - loss: 6.1721e-05 - accuracy: 1.0000 - val_loss: 3.2383e-04 - val_accuracy: 1.0000\n",
      "Epoch 11/80\n",
      "8965/8965 [==============================] - 1s 87us/step - loss: 5.2182e-05 - accuracy: 1.0000 - val_loss: 2.7430e-04 - val_accuracy: 1.0000\n",
      "Epoch 12/80\n",
      "8965/8965 [==============================] - 1s 87us/step - loss: 3.9860e-05 - accuracy: 1.0000 - val_loss: 2.0380e-04 - val_accuracy: 1.0000\n",
      "Epoch 13/80\n",
      "8965/8965 [==============================] - 1s 86us/step - loss: 3.5289e-05 - accuracy: 1.0000 - val_loss: 3.0530e-04 - val_accuracy: 1.0000\n",
      "Epoch 14/80\n",
      "8965/8965 [==============================] - 1s 87us/step - loss: 2.9029e-05 - accuracy: 1.0000 - val_loss: 2.0768e-04 - val_accuracy: 1.0000\n",
      "Epoch 15/80\n",
      "8965/8965 [==============================] - 1s 87us/step - loss: 2.3601e-05 - accuracy: 1.0000 - val_loss: 2.0487e-04 - val_accuracy: 1.0000\n",
      "Epoch 16/80\n",
      "8965/8965 [==============================] - 1s 86us/step - loss: 1.9818e-05 - accuracy: 1.0000 - val_loss: 2.2659e-04 - val_accuracy: 1.0000\n",
      "Epoch 17/80\n",
      "8965/8965 [==============================] - 1s 86us/step - loss: 1.7982e-05 - accuracy: 1.0000 - val_loss: 1.4727e-04 - val_accuracy: 1.0000\n",
      "Epoch 18/80\n",
      "8965/8965 [==============================] - 1s 86us/step - loss: 1.5864e-05 - accuracy: 1.0000 - val_loss: 1.3880e-04 - val_accuracy: 1.0000\n",
      "Epoch 19/80\n",
      "8965/8965 [==============================] - 1s 86us/step - loss: 1.4466e-05 - accuracy: 1.0000 - val_loss: 1.4559e-04 - val_accuracy: 1.0000\n",
      "Epoch 20/80\n",
      "8965/8965 [==============================] - 1s 85us/step - loss: 1.1349e-05 - accuracy: 1.0000 - val_loss: 1.0329e-04 - val_accuracy: 1.0000\n",
      "Epoch 21/80\n",
      "8965/8965 [==============================] - 1s 87us/step - loss: 9.5351e-06 - accuracy: 1.0000 - val_loss: 1.5805e-04 - val_accuracy: 1.0000\n",
      "Epoch 22/80\n",
      "8965/8965 [==============================] - 1s 86us/step - loss: 8.6735e-06 - accuracy: 1.0000 - val_loss: 1.0826e-04 - val_accuracy: 1.0000\n",
      "Epoch 23/80\n",
      "8965/8965 [==============================] - 1s 87us/step - loss: 7.8680e-06 - accuracy: 1.0000 - val_loss: 2.1522e-04 - val_accuracy: 1.0000\n",
      "Epoch 24/80\n",
      "8965/8965 [==============================] - 1s 87us/step - loss: 7.3223e-06 - accuracy: 1.0000 - val_loss: 1.0932e-04 - val_accuracy: 1.0000\n",
      "Epoch 25/80\n",
      "8965/8965 [==============================] - 1s 88us/step - loss: 6.2074e-06 - accuracy: 1.0000 - val_loss: 1.0680e-04 - val_accuracy: 1.0000\n",
      "Epoch 26/80\n",
      "8965/8965 [==============================] - 1s 87us/step - loss: 5.5310e-06 - accuracy: 1.0000 - val_loss: 9.4749e-05 - val_accuracy: 1.0000\n",
      "Epoch 27/80\n",
      "8965/8965 [==============================] - 1s 85us/step - loss: 4.9233e-06 - accuracy: 1.0000 - val_loss: 1.0031e-04 - val_accuracy: 1.0000\n",
      "Epoch 28/80\n",
      "8965/8965 [==============================] - 1s 85us/step - loss: 4.5947e-06 - accuracy: 1.0000 - val_loss: 1.1319e-04 - val_accuracy: 1.0000\n",
      "Epoch 29/80\n",
      "8965/8965 [==============================] - 1s 85us/step - loss: 4.0421e-06 - accuracy: 1.0000 - val_loss: 1.1530e-04 - val_accuracy: 1.0000\n",
      "Epoch 30/80\n",
      "8965/8965 [==============================] - 1s 87us/step - loss: 3.7452e-06 - accuracy: 1.0000 - val_loss: 1.1547e-04 - val_accuracy: 1.0000\n",
      "Epoch 31/80\n",
      "8965/8965 [==============================] - 1s 86us/step - loss: 3.3705e-06 - accuracy: 1.0000 - val_loss: 6.2486e-05 - val_accuracy: 1.0000\n",
      "Epoch 32/80\n",
      "8965/8965 [==============================] - 1s 84us/step - loss: 3.2948e-06 - accuracy: 1.0000 - val_loss: 8.0450e-05 - val_accuracy: 1.0000\n",
      "Epoch 33/80\n",
      "8965/8965 [==============================] - 1s 85us/step - loss: 3.3791e-06 - accuracy: 1.0000 - val_loss: 9.2820e-05 - val_accuracy: 1.0000\n",
      "Epoch 34/80\n",
      "8965/8965 [==============================] - 1s 87us/step - loss: 2.5846e-06 - accuracy: 1.0000 - val_loss: 6.6663e-05 - val_accuracy: 1.0000\n",
      "Epoch 35/80\n",
      "8965/8965 [==============================] - 1s 86us/step - loss: 2.3906e-06 - accuracy: 1.0000 - val_loss: 7.4243e-05 - val_accuracy: 1.0000\n",
      "Epoch 36/80\n",
      "8965/8965 [==============================] - 1s 87us/step - loss: 2.4495e-06 - accuracy: 1.0000 - val_loss: 6.3693e-05 - val_accuracy: 1.0000\n",
      "Epoch 37/80\n",
      "8965/8965 [==============================] - 1s 87us/step - loss: 2.8128e-06 - accuracy: 1.0000 - val_loss: 7.7663e-05 - val_accuracy: 1.0000\n",
      "Epoch 38/80\n",
      "8965/8965 [==============================] - 1s 87us/step - loss: 1.9376e-06 - accuracy: 1.0000 - val_loss: 8.8002e-05 - val_accuracy: 1.0000\n",
      "Epoch 39/80\n",
      "8965/8965 [==============================] - 1s 85us/step - loss: 1.7719e-06 - accuracy: 1.0000 - val_loss: 9.3806e-05 - val_accuracy: 1.0000\n",
      "Epoch 40/80\n",
      "8965/8965 [==============================] - 1s 87us/step - loss: 1.7358e-06 - accuracy: 1.0000 - val_loss: 6.2712e-05 - val_accuracy: 1.0000\n",
      "Epoch 41/80\n",
      "8965/8965 [==============================] - 1s 87us/step - loss: 1.5296e-06 - accuracy: 1.0000 - val_loss: 6.2269e-05 - val_accuracy: 1.0000\n",
      "Epoch 42/80\n",
      "8965/8965 [==============================] - 1s 85us/step - loss: 1.4275e-06 - accuracy: 1.0000 - val_loss: 5.3883e-05 - val_accuracy: 1.0000\n",
      "Epoch 43/80\n",
      "8965/8965 [==============================] - 1s 86us/step - loss: 1.3363e-06 - accuracy: 1.0000 - val_loss: 4.8488e-05 - val_accuracy: 1.0000\n",
      "Epoch 44/80\n",
      "8965/8965 [==============================] - 1s 88us/step - loss: 1.2595e-06 - accuracy: 1.0000 - val_loss: 4.2581e-05 - val_accuracy: 1.0000\n",
      "Epoch 45/80\n",
      "8965/8965 [==============================] - 1s 88us/step - loss: 1.1630e-06 - accuracy: 1.0000 - val_loss: 5.6214e-05 - val_accuracy: 1.0000\n",
      "Epoch 46/80\n",
      "8965/8965 [==============================] - 1s 87us/step - loss: 1.1150e-06 - accuracy: 1.0000 - val_loss: 6.1288e-05 - val_accuracy: 1.0000\n",
      "Epoch 47/80\n",
      "8965/8965 [==============================] - 1s 85us/step - loss: 1.0458e-06 - accuracy: 1.0000 - val_loss: 5.3860e-05 - val_accuracy: 1.0000\n",
      "Epoch 48/80\n",
      "8965/8965 [==============================] - 1s 87us/step - loss: 9.6835e-07 - accuracy: 1.0000 - val_loss: 5.2967e-05 - val_accuracy: 1.0000\n",
      "Epoch 49/80\n",
      "8965/8965 [==============================] - 1s 87us/step - loss: 9.0794e-07 - accuracy: 1.0000 - val_loss: 6.9515e-05 - val_accuracy: 1.0000\n",
      "Epoch 50/80\n",
      "8965/8965 [==============================] - 1s 87us/step - loss: 8.7903e-07 - accuracy: 1.0000 - val_loss: 4.0773e-05 - val_accuracy: 1.0000\n",
      "Epoch 51/80\n",
      "8965/8965 [==============================] - 1s 87us/step - loss: 8.4228e-07 - accuracy: 1.0000 - val_loss: 6.2892e-05 - val_accuracy: 1.0000\n",
      "Epoch 52/80\n",
      "8965/8965 [==============================] - 1s 87us/step - loss: 7.7474e-07 - accuracy: 1.0000 - val_loss: 3.9376e-05 - val_accuracy: 1.0000\n",
      "Epoch 53/80\n",
      "8965/8965 [==============================] - 1s 87us/step - loss: 7.2482e-07 - accuracy: 1.0000 - val_loss: 5.5607e-05 - val_accuracy: 1.0000\n",
      "Epoch 54/80\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8965/8965 [==============================] - 1s 88us/step - loss: 6.9475e-07 - accuracy: 1.0000 - val_loss: 4.7925e-05 - val_accuracy: 1.0000\n",
      "Epoch 55/80\n",
      "8965/8965 [==============================] - 1s 86us/step - loss: 6.8493e-07 - accuracy: 1.0000 - val_loss: 4.9817e-05 - val_accuracy: 1.0000\n",
      "Epoch 56/80\n",
      "8965/8965 [==============================] - 1s 86us/step - loss: 6.1644e-07 - accuracy: 1.0000 - val_loss: 4.1636e-05 - val_accuracy: 1.0000\n",
      "Epoch 57/80\n",
      "8965/8965 [==============================] - 1s 86us/step - loss: 5.8031e-07 - accuracy: 1.0000 - val_loss: 4.8180e-05 - val_accuracy: 1.0000\n",
      "Epoch 58/80\n",
      "8965/8965 [==============================] - 1s 87us/step - loss: 5.5988e-07 - accuracy: 1.0000 - val_loss: 2.8626e-05 - val_accuracy: 1.0000\n",
      "Epoch 59/80\n",
      "8965/8965 [==============================] - 1s 86us/step - loss: 5.3779e-07 - accuracy: 1.0000 - val_loss: 3.8125e-05 - val_accuracy: 1.0000\n",
      "Epoch 60/80\n",
      "8965/8965 [==============================] - 1s 87us/step - loss: 5.0986e-07 - accuracy: 1.0000 - val_loss: 3.5665e-05 - val_accuracy: 1.0000\n",
      "Epoch 61/80\n",
      "8965/8965 [==============================] - 1s 85us/step - loss: 4.8674e-07 - accuracy: 1.0000 - val_loss: 3.2571e-05 - val_accuracy: 1.0000\n",
      "Epoch 62/80\n",
      "8965/8965 [==============================] - 1s 87us/step - loss: 4.6137e-07 - accuracy: 1.0000 - val_loss: 2.5606e-05 - val_accuracy: 1.0000\n",
      "Epoch 63/80\n",
      "8965/8965 [==============================] - 1s 87us/step - loss: 4.3831e-07 - accuracy: 1.0000 - val_loss: 2.7991e-05 - val_accuracy: 1.0000\n",
      "Epoch 64/80\n",
      "8965/8965 [==============================] - 1s 86us/step - loss: 4.0963e-07 - accuracy: 1.0000 - val_loss: 2.4711e-05 - val_accuracy: 1.0000\n",
      "Epoch 65/80\n",
      "8965/8965 [==============================] - 1s 87us/step - loss: 3.8734e-07 - accuracy: 1.0000 - val_loss: 2.4929e-05 - val_accuracy: 1.0000\n",
      "Epoch 66/80\n",
      "8965/8965 [==============================] - 1s 87us/step - loss: 3.6840e-07 - accuracy: 1.0000 - val_loss: 3.3651e-05 - val_accuracy: 1.0000\n",
      "Epoch 67/80\n",
      "8965/8965 [==============================] - 1s 85us/step - loss: 3.4902e-07 - accuracy: 1.0000 - val_loss: 2.3932e-05 - val_accuracy: 1.0000\n",
      "Epoch 68/80\n",
      "8965/8965 [==============================] - 1s 86us/step - loss: 3.3666e-07 - accuracy: 1.0000 - val_loss: 2.8685e-05 - val_accuracy: 1.0000\n",
      "Epoch 69/80\n",
      "8965/8965 [==============================] - 1s 87us/step - loss: 3.1981e-07 - accuracy: 1.0000 - val_loss: 2.9721e-05 - val_accuracy: 1.0000\n",
      "Epoch 70/80\n",
      "8965/8965 [==============================] - 1s 86us/step - loss: 3.1287e-07 - accuracy: 1.0000 - val_loss: 3.2311e-05 - val_accuracy: 1.0000\n",
      "Epoch 71/80\n",
      "8965/8965 [==============================] - 1s 88us/step - loss: 2.9018e-07 - accuracy: 1.0000 - val_loss: 2.9359e-05 - val_accuracy: 1.0000\n",
      "Epoch 72/80\n",
      "8965/8965 [==============================] - 1s 85us/step - loss: 2.7100e-07 - accuracy: 1.0000 - val_loss: 2.9854e-05 - val_accuracy: 1.0000\n",
      "Epoch 73/80\n",
      "8965/8965 [==============================] - 1s 87us/step - loss: 2.6524e-07 - accuracy: 1.0000 - val_loss: 2.8352e-05 - val_accuracy: 1.0000\n",
      "Epoch 74/80\n",
      "8965/8965 [==============================] - 1s 85us/step - loss: 2.7021e-07 - accuracy: 1.0000 - val_loss: 4.0385e-05 - val_accuracy: 1.0000\n",
      "Epoch 75/80\n",
      "8965/8965 [==============================] - 1s 85us/step - loss: 2.3975e-07 - accuracy: 1.0000 - val_loss: 2.4438e-05 - val_accuracy: 1.0000\n",
      "Epoch 76/80\n",
      "8965/8965 [==============================] - 1s 87us/step - loss: 2.2541e-07 - accuracy: 1.0000 - val_loss: 3.1878e-05 - val_accuracy: 1.0000\n",
      "Epoch 77/80\n",
      "8965/8965 [==============================] - 1s 85us/step - loss: 2.1601e-07 - accuracy: 1.0000 - val_loss: 2.6020e-05 - val_accuracy: 1.0000\n",
      "Epoch 00077: early stopping\n",
      "[[6.02413384e-05 1.06265921e-08 2.09470618e-11 ... 9.94023979e-01\n",
      "  5.73109230e-03 1.17154457e-06]\n",
      " [4.50927962e-09 9.78791375e-13 2.51480745e-14 ... 2.18704678e-02\n",
      "  9.78129268e-01 8.42030374e-08]\n",
      " [2.73732725e-09 3.24286459e-10 4.75178267e-14 ... 9.93551135e-01\n",
      "  6.44718762e-03 1.64832943e-06]\n",
      " ...\n",
      " [2.03285621e-23 6.11359058e-19 7.61803375e-21 ... 1.26491725e-18\n",
      "  1.00000000e+00 7.30200536e-20]\n",
      " [7.11534040e-16 6.50085039e-15 3.19727652e-24 ... 1.53855340e-09\n",
      "  3.11740813e-13 1.99963501e-11]\n",
      " [1.02945504e-23 1.42777594e-21 3.31969973e-16 ... 6.53656732e-20\n",
      "  1.00000000e+00 1.01718339e-28]]\n",
      "[6 7 6 ... 7 3 7]\n",
      "<class 'numpy.ndarray'>\n",
      "One CNN, r:  4\n",
      "Computing Time:  0:04:38.609137\n",
      "num of merged_region_image 0 1734\n",
      "num of merged_region_image 1 1972\n",
      "num of merged_region_image 2 216\n",
      "num of merged_region_image 3 985\n",
      "num of merged_region_image 4 143\n",
      "num of merged_region_image 5 96\n",
      "num of merged_region_image 6 2610\n",
      "num of merged_region_image 7 1997\n",
      "num of merged_region_image 8 209\n",
      "Counter({-1: 3114, 6: 2610, 7: 1997, 1: 1972, 0: 1734, 3: 985, 2: 216, 8: 209, 4: 143, 5: 96})\n",
      "===========  ITE = 3   ===========\n",
      "used_img 9962 9962\n",
      "working_img(=other images=unclean images) 3114 3114\n",
      "merged regions 61 61\n",
      "other_regions 138 138\n",
      "All other regions\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>other index</th>\n",
       "      <th>pred label</th>\n",
       "      <th>truth</th>\n",
       "      <th>rate</th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>7</td>\n",
       "      <td>-1</td>\n",
       "      <td>8</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>65</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>9</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>10</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>18</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>133</th>\n",
       "      <td>192</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>134</th>\n",
       "      <td>193</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>135</th>\n",
       "      <td>195</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>136</th>\n",
       "      <td>196</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>137</th>\n",
       "      <td>198</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>138 rows × 13 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     other index  pred label  truth  rate  0  1  2  3  4  5  6  7   8\n",
       "0              2           0      0   0.0  0  0  0  0  0  0  0  0   0\n",
       "1              7          -1      8   0.0  0  0  0  0  0  0  0  0  65\n",
       "2              9           0      0   0.0  0  0  0  0  0  0  0  0   0\n",
       "3             10           0      0   0.0  0  0  0  0  0  0  0  0   0\n",
       "4             18           0      0   0.0  0  0  0  0  0  0  0  0   0\n",
       "..           ...         ...    ...   ... .. .. .. .. .. .. .. ..  ..\n",
       "133          192           0      0   0.0  0  0  0  0  0  0  0  0   0\n",
       "134          193           0      0   0.0  0  0  0  0  0  0  0  0   0\n",
       "135          195           0      0   0.0  0  0  0  0  0  0  0  0   0\n",
       "136          196           0      0   0.0  0  0  0  0  0  0  0  0   0\n",
       "137          198           0      0   0.0  0  0  0  0  0  0  0  0   0\n",
       "\n",
       "[138 rows x 13 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "added label, regions, img amount: {6} [103] 305\n",
      "Not getting into residuals\n",
      "NUM_region 9\n",
      "number of clean images 10267\n",
      "n, p1, p2 0 0 0\n",
      "NUM_CLASSES 9\n",
      "current_train_label:  [0, 1, 2, 3, 4, 5, 6, 7, 8]\n",
      "Model: \"sequential_1\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv1d_1 (Conv1D)            (None, 1000, 6)           36        \n",
      "_________________________________________________________________\n",
      "average_pooling1d_1 (Average (None, 500, 6)            0         \n",
      "_________________________________________________________________\n",
      "conv1d_2 (Conv1D)            (None, 496, 16)           496       \n",
      "_________________________________________________________________\n",
      "average_pooling1d_2 (Average (None, 248, 16)           0         \n",
      "_________________________________________________________________\n",
      "conv1d_3 (Conv1D)            (None, 244, 120)          9720      \n",
      "_________________________________________________________________\n",
      "flatten_1 (Flatten)          (None, 29280)             0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 84)                2459604   \n",
      "_________________________________________________________________\n",
      "preds (Dense)                (None, 9)                 765       \n",
      "=================================================================\n",
      "Total params: 2,470,621\n",
      "Trainable params: 2,470,621\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Train on 9240 samples, validate on 1027 samples\n",
      "Epoch 1/80\n",
      "9240/9240 [==============================] - 1s 154us/step - loss: 0.3179 - accuracy: 0.9102 - val_loss: 0.0082 - val_accuracy: 0.9981\n",
      "Epoch 2/80\n",
      "9240/9240 [==============================] - 1s 90us/step - loss: 0.0056 - accuracy: 0.9985 - val_loss: 0.0015 - val_accuracy: 1.0000\n",
      "Epoch 3/80\n",
      "9240/9240 [==============================] - 1s 86us/step - loss: 0.0015 - accuracy: 0.9999 - val_loss: 0.0011 - val_accuracy: 1.0000\n",
      "Epoch 4/80\n",
      "9240/9240 [==============================] - 1s 86us/step - loss: 5.9906e-04 - accuracy: 1.0000 - val_loss: 7.0412e-04 - val_accuracy: 1.0000\n",
      "Epoch 5/80\n",
      "9240/9240 [==============================] - 1s 85us/step - loss: 3.1728e-04 - accuracy: 1.0000 - val_loss: 4.8477e-04 - val_accuracy: 1.0000\n",
      "Epoch 6/80\n",
      "9240/9240 [==============================] - 1s 88us/step - loss: 2.4346e-04 - accuracy: 1.0000 - val_loss: 5.8056e-04 - val_accuracy: 1.0000\n",
      "Epoch 7/80\n",
      "9240/9240 [==============================] - 1s 85us/step - loss: 1.5882e-04 - accuracy: 1.0000 - val_loss: 3.6192e-04 - val_accuracy: 1.0000\n",
      "Epoch 8/80\n",
      "9240/9240 [==============================] - 1s 86us/step - loss: 1.2408e-04 - accuracy: 1.0000 - val_loss: 2.9086e-04 - val_accuracy: 1.0000\n",
      "Epoch 9/80\n",
      "9240/9240 [==============================] - 1s 85us/step - loss: 9.6065e-05 - accuracy: 1.0000 - val_loss: 3.1617e-04 - val_accuracy: 1.0000\n",
      "Epoch 10/80\n",
      "9240/9240 [==============================] - 1s 86us/step - loss: 7.6707e-05 - accuracy: 1.0000 - val_loss: 3.1488e-04 - val_accuracy: 1.0000\n",
      "Epoch 11/80\n",
      "9240/9240 [==============================] - 1s 88us/step - loss: 6.4083e-05 - accuracy: 1.0000 - val_loss: 2.1692e-04 - val_accuracy: 1.0000\n",
      "Epoch 12/80\n",
      "9240/9240 [==============================] - 1s 85us/step - loss: 5.9874e-05 - accuracy: 1.0000 - val_loss: 2.1144e-04 - val_accuracy: 1.0000\n",
      "Epoch 13/80\n",
      "9240/9240 [==============================] - 1s 85us/step - loss: 4.4559e-05 - accuracy: 1.0000 - val_loss: 2.1586e-04 - val_accuracy: 1.0000\n",
      "Epoch 14/80\n",
      "9240/9240 [==============================] - 1s 87us/step - loss: 4.0235e-05 - accuracy: 1.0000 - val_loss: 1.8371e-04 - val_accuracy: 1.0000\n",
      "Epoch 15/80\n",
      "9240/9240 [==============================] - 1s 85us/step - loss: 3.2963e-05 - accuracy: 1.0000 - val_loss: 1.5124e-04 - val_accuracy: 1.0000\n",
      "Epoch 16/80\n",
      "9240/9240 [==============================] - 1s 87us/step - loss: 2.9467e-05 - accuracy: 1.0000 - val_loss: 1.5622e-04 - val_accuracy: 1.0000\n",
      "Epoch 17/80\n",
      "9240/9240 [==============================] - 1s 86us/step - loss: 2.5776e-05 - accuracy: 1.0000 - val_loss: 1.2773e-04 - val_accuracy: 1.0000\n",
      "Epoch 18/80\n",
      "9240/9240 [==============================] - 1s 86us/step - loss: 2.2639e-05 - accuracy: 1.0000 - val_loss: 1.1913e-04 - val_accuracy: 1.0000\n",
      "Epoch 19/80\n",
      "9240/9240 [==============================] - 1s 85us/step - loss: 1.9799e-05 - accuracy: 1.0000 - val_loss: 1.1487e-04 - val_accuracy: 1.0000\n",
      "Epoch 20/80\n",
      "9240/9240 [==============================] - 1s 87us/step - loss: 1.8032e-05 - accuracy: 1.0000 - val_loss: 8.9499e-05 - val_accuracy: 1.0000\n",
      "Epoch 21/80\n",
      "9240/9240 [==============================] - 1s 85us/step - loss: 1.6394e-05 - accuracy: 1.0000 - val_loss: 1.0626e-04 - val_accuracy: 1.0000\n",
      "Epoch 22/80\n",
      "9240/9240 [==============================] - 1s 86us/step - loss: 1.4006e-05 - accuracy: 1.0000 - val_loss: 8.3160e-05 - val_accuracy: 1.0000\n",
      "Epoch 23/80\n",
      "9240/9240 [==============================] - 1s 88us/step - loss: 1.4056e-05 - accuracy: 1.0000 - val_loss: 1.0480e-04 - val_accuracy: 1.0000\n",
      "Epoch 24/80\n",
      "9240/9240 [==============================] - 1s 86us/step - loss: 1.2287e-05 - accuracy: 1.0000 - val_loss: 7.5670e-05 - val_accuracy: 1.0000\n",
      "Epoch 25/80\n",
      "9240/9240 [==============================] - 1s 86us/step - loss: 1.0605e-05 - accuracy: 1.0000 - val_loss: 7.8472e-05 - val_accuracy: 1.0000\n",
      "Epoch 26/80\n",
      "9240/9240 [==============================] - 1s 87us/step - loss: 1.0289e-05 - accuracy: 1.0000 - val_loss: 6.6732e-05 - val_accuracy: 1.0000\n",
      "Epoch 27/80\n",
      "9240/9240 [==============================] - 1s 85us/step - loss: 8.9671e-06 - accuracy: 1.0000 - val_loss: 7.3680e-05 - val_accuracy: 1.0000\n",
      "Epoch 28/80\n",
      "9240/9240 [==============================] - 1s 86us/step - loss: 7.9210e-06 - accuracy: 1.0000 - val_loss: 8.0216e-05 - val_accuracy: 1.0000\n",
      "Epoch 29/80\n",
      "9240/9240 [==============================] - 1s 86us/step - loss: 7.4151e-06 - accuracy: 1.0000 - val_loss: 6.9403e-05 - val_accuracy: 1.0000\n",
      "Epoch 30/80\n",
      "9240/9240 [==============================] - 1s 88us/step - loss: 6.7469e-06 - accuracy: 1.0000 - val_loss: 6.3095e-05 - val_accuracy: 1.0000\n",
      "Epoch 31/80\n",
      "9240/9240 [==============================] - 1s 86us/step - loss: 6.2267e-06 - accuracy: 1.0000 - val_loss: 5.5250e-05 - val_accuracy: 1.0000\n",
      "Epoch 32/80\n",
      "9240/9240 [==============================] - 1s 87us/step - loss: 5.7286e-06 - accuracy: 1.0000 - val_loss: 6.8112e-05 - val_accuracy: 1.0000\n",
      "Epoch 33/80\n",
      "9240/9240 [==============================] - 1s 87us/step - loss: 5.3562e-06 - accuracy: 1.0000 - val_loss: 6.4793e-05 - val_accuracy: 1.0000\n",
      "Epoch 34/80\n",
      "9240/9240 [==============================] - 1s 87us/step - loss: 5.0294e-06 - accuracy: 1.0000 - val_loss: 5.1947e-05 - val_accuracy: 1.0000\n",
      "Epoch 35/80\n",
      "9240/9240 [==============================] - 1s 87us/step - loss: 4.5942e-06 - accuracy: 1.0000 - val_loss: 5.8064e-05 - val_accuracy: 1.0000\n",
      "Epoch 36/80\n",
      "9240/9240 [==============================] - 1s 86us/step - loss: 4.2767e-06 - accuracy: 1.0000 - val_loss: 5.5910e-05 - val_accuracy: 1.0000\n",
      "Epoch 37/80\n",
      "9240/9240 [==============================] - 1s 84us/step - loss: 3.8815e-06 - accuracy: 1.0000 - val_loss: 5.2390e-05 - val_accuracy: 1.0000\n",
      "Epoch 38/80\n",
      "9240/9240 [==============================] - 1s 86us/step - loss: 3.7126e-06 - accuracy: 1.0000 - val_loss: 5.0192e-05 - val_accuracy: 1.0000\n",
      "Epoch 39/80\n",
      "9240/9240 [==============================] - 1s 86us/step - loss: 3.3654e-06 - accuracy: 1.0000 - val_loss: 4.7348e-05 - val_accuracy: 1.0000\n",
      "Epoch 40/80\n",
      "9240/9240 [==============================] - 1s 87us/step - loss: 3.1388e-06 - accuracy: 1.0000 - val_loss: 4.1444e-05 - val_accuracy: 1.0000\n",
      "Epoch 41/80\n",
      "9240/9240 [==============================] - 1s 88us/step - loss: 2.9778e-06 - accuracy: 1.0000 - val_loss: 4.3337e-05 - val_accuracy: 1.0000\n",
      "Epoch 42/80\n",
      "9240/9240 [==============================] - 1s 86us/step - loss: 2.8022e-06 - accuracy: 1.0000 - val_loss: 3.7879e-05 - val_accuracy: 1.0000\n",
      "Epoch 43/80\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9240/9240 [==============================] - 1s 87us/step - loss: 2.6147e-06 - accuracy: 1.0000 - val_loss: 3.8380e-05 - val_accuracy: 1.0000\n",
      "Epoch 44/80\n",
      "9240/9240 [==============================] - 1s 84us/step - loss: 2.4051e-06 - accuracy: 1.0000 - val_loss: 3.9921e-05 - val_accuracy: 1.0000\n",
      "Epoch 45/80\n",
      "9240/9240 [==============================] - 1s 86us/step - loss: 2.2515e-06 - accuracy: 1.0000 - val_loss: 3.9543e-05 - val_accuracy: 1.0000\n",
      "Epoch 46/80\n",
      "9240/9240 [==============================] - 1s 88us/step - loss: 2.1256e-06 - accuracy: 1.0000 - val_loss: 3.7323e-05 - val_accuracy: 1.0000\n",
      "Epoch 47/80\n",
      "9240/9240 [==============================] - 1s 87us/step - loss: 2.0328e-06 - accuracy: 1.0000 - val_loss: 3.2940e-05 - val_accuracy: 1.0000\n",
      "Epoch 48/80\n",
      "9240/9240 [==============================] - 1s 86us/step - loss: 1.8824e-06 - accuracy: 1.0000 - val_loss: 3.0560e-05 - val_accuracy: 1.0000\n",
      "Epoch 49/80\n",
      "9240/9240 [==============================] - 1s 85us/step - loss: 1.8123e-06 - accuracy: 1.0000 - val_loss: 3.5527e-05 - val_accuracy: 1.0000\n",
      "Epoch 50/80\n",
      "9240/9240 [==============================] - 1s 86us/step - loss: 1.7206e-06 - accuracy: 1.0000 - val_loss: 3.4002e-05 - val_accuracy: 1.0000\n",
      "Epoch 51/80\n",
      "9240/9240 [==============================] - 1s 86us/step - loss: 1.5382e-06 - accuracy: 1.0000 - val_loss: 3.8980e-05 - val_accuracy: 1.0000\n",
      "Epoch 52/80\n",
      "9240/9240 [==============================] - 1s 86us/step - loss: 1.5022e-06 - accuracy: 1.0000 - val_loss: 3.4158e-05 - val_accuracy: 1.0000\n",
      "Epoch 53/80\n",
      "9240/9240 [==============================] - 1s 86us/step - loss: 1.3890e-06 - accuracy: 1.0000 - val_loss: 2.8082e-05 - val_accuracy: 1.0000\n",
      "Epoch 54/80\n",
      "9240/9240 [==============================] - 1s 86us/step - loss: 1.3241e-06 - accuracy: 1.0000 - val_loss: 2.8130e-05 - val_accuracy: 1.0000\n",
      "Epoch 55/80\n",
      "9240/9240 [==============================] - 1s 88us/step - loss: 1.2235e-06 - accuracy: 1.0000 - val_loss: 3.1251e-05 - val_accuracy: 1.0000\n",
      "Epoch 56/80\n",
      "9240/9240 [==============================] - 1s 85us/step - loss: 1.1446e-06 - accuracy: 1.0000 - val_loss: 2.9652e-05 - val_accuracy: 1.0000\n",
      "Epoch 57/80\n",
      "9240/9240 [==============================] - 1s 88us/step - loss: 1.0958e-06 - accuracy: 1.0000 - val_loss: 2.5266e-05 - val_accuracy: 1.0000\n",
      "Epoch 58/80\n",
      "9240/9240 [==============================] - 1s 86us/step - loss: 1.0429e-06 - accuracy: 1.0000 - val_loss: 2.9256e-05 - val_accuracy: 1.0000\n",
      "Epoch 59/80\n",
      "9240/9240 [==============================] - 1s 85us/step - loss: 9.8934e-07 - accuracy: 1.0000 - val_loss: 2.3371e-05 - val_accuracy: 1.0000\n",
      "Epoch 60/80\n",
      "9240/9240 [==============================] - 1s 87us/step - loss: 9.2034e-07 - accuracy: 1.0000 - val_loss: 2.7409e-05 - val_accuracy: 1.0000\n",
      "Epoch 61/80\n",
      "9240/9240 [==============================] - 1s 85us/step - loss: 8.8912e-07 - accuracy: 1.0000 - val_loss: 2.7728e-05 - val_accuracy: 1.0000\n",
      "Epoch 62/80\n",
      "9240/9240 [==============================] - 1s 88us/step - loss: 8.3192e-07 - accuracy: 1.0000 - val_loss: 2.4937e-05 - val_accuracy: 1.0000\n",
      "Epoch 63/80\n",
      "9240/9240 [==============================] - 1s 85us/step - loss: 7.8176e-07 - accuracy: 1.0000 - val_loss: 2.1926e-05 - val_accuracy: 1.0000\n",
      "Epoch 64/80\n",
      "9240/9240 [==============================] - 1s 87us/step - loss: 7.4498e-07 - accuracy: 1.0000 - val_loss: 2.1896e-05 - val_accuracy: 1.0000\n",
      "Epoch 65/80\n",
      "9240/9240 [==============================] - 1s 85us/step - loss: 7.0379e-07 - accuracy: 1.0000 - val_loss: 1.9611e-05 - val_accuracy: 1.0000\n",
      "Epoch 66/80\n",
      "9240/9240 [==============================] - 1s 86us/step - loss: 6.6751e-07 - accuracy: 1.0000 - val_loss: 2.1380e-05 - val_accuracy: 1.0000\n",
      "Epoch 67/80\n",
      "9240/9240 [==============================] - 1s 85us/step - loss: 6.3185e-07 - accuracy: 1.0000 - val_loss: 1.9890e-05 - val_accuracy: 1.0000\n",
      "Epoch 68/80\n",
      "9240/9240 [==============================] - 1s 85us/step - loss: 5.9779e-07 - accuracy: 1.0000 - val_loss: 1.9829e-05 - val_accuracy: 1.0000\n",
      "Epoch 69/80\n",
      "9240/9240 [==============================] - 1s 88us/step - loss: 5.6679e-07 - accuracy: 1.0000 - val_loss: 1.8998e-05 - val_accuracy: 1.0000\n",
      "Epoch 70/80\n",
      "9240/9240 [==============================] - 1s 89us/step - loss: 5.4120e-07 - accuracy: 1.0000 - val_loss: 1.8286e-05 - val_accuracy: 1.0000\n",
      "Epoch 71/80\n",
      "9240/9240 [==============================] - 1s 85us/step - loss: 5.1872e-07 - accuracy: 1.0000 - val_loss: 1.9139e-05 - val_accuracy: 1.0000\n",
      "Epoch 72/80\n",
      "9240/9240 [==============================] - 1s 87us/step - loss: 4.8533e-07 - accuracy: 1.0000 - val_loss: 1.9320e-05 - val_accuracy: 1.0000\n",
      "Epoch 73/80\n",
      "9240/9240 [==============================] - 1s 87us/step - loss: 4.6783e-07 - accuracy: 1.0000 - val_loss: 2.1226e-05 - val_accuracy: 1.0000\n",
      "Epoch 74/80\n",
      "9240/9240 [==============================] - 1s 86us/step - loss: 4.3875e-07 - accuracy: 1.0000 - val_loss: 1.9860e-05 - val_accuracy: 1.0000\n",
      "Epoch 75/80\n",
      "9240/9240 [==============================] - 1s 85us/step - loss: 4.1941e-07 - accuracy: 1.0000 - val_loss: 1.7252e-05 - val_accuracy: 1.0000\n",
      "Epoch 76/80\n",
      "9240/9240 [==============================] - 1s 86us/step - loss: 3.9487e-07 - accuracy: 1.0000 - val_loss: 2.0830e-05 - val_accuracy: 1.0000\n",
      "Epoch 77/80\n",
      "9240/9240 [==============================] - 1s 87us/step - loss: 3.7536e-07 - accuracy: 1.0000 - val_loss: 2.1100e-05 - val_accuracy: 1.0000\n",
      "Epoch 78/80\n",
      "9240/9240 [==============================] - 1s 85us/step - loss: 3.6023e-07 - accuracy: 1.0000 - val_loss: 1.4818e-05 - val_accuracy: 1.0000\n",
      "Epoch 79/80\n",
      "9240/9240 [==============================] - 1s 88us/step - loss: 3.4456e-07 - accuracy: 1.0000 - val_loss: 1.4948e-05 - val_accuracy: 1.0000\n",
      "Epoch 80/80\n",
      "9240/9240 [==============================] - 1s 85us/step - loss: 3.2812e-07 - accuracy: 1.0000 - val_loss: 1.5715e-05 - val_accuracy: 1.0000\n",
      "[[8.7687777e-06 9.6953379e-08 2.3396836e-07 ... 9.7307760e-01\n",
      "  2.6669890e-02 1.9507743e-05]\n",
      " [2.8769892e-10 4.1287578e-11 6.0933747e-10 ... 3.9698862e-02\n",
      "  9.6028113e-01 1.9950336e-05]\n",
      " [2.7365687e-10 3.3994279e-09 3.8381529e-08 ... 9.9765468e-01\n",
      "  2.2649202e-03 7.9724952e-05]\n",
      " ...\n",
      " [5.5655659e-22 6.4522225e-17 8.3766823e-19 ... 1.5125931e-16\n",
      "  1.0000000e+00 3.7492080e-15]\n",
      " [1.8728699e-15 3.0946499e-19 2.3825358e-20 ... 2.7163088e-10\n",
      "  3.2184946e-17 2.9996296e-13]\n",
      " [5.0553971e-23 4.9226151e-18 2.3434984e-18 ... 2.0691323e-18\n",
      "  1.0000000e+00 2.9314254e-23]]\n",
      "[6 7 6 ... 7 3 7]\n",
      "<class 'numpy.ndarray'>\n",
      "One CNN, r:  0\n",
      "Computing Time:  0:01:07.504009\n",
      "Model: \"sequential_1\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv1d_1 (Conv1D)            (None, 1000, 6)           36        \n",
      "_________________________________________________________________\n",
      "average_pooling1d_1 (Average (None, 500, 6)            0         \n",
      "_________________________________________________________________\n",
      "conv1d_2 (Conv1D)            (None, 496, 16)           496       \n",
      "_________________________________________________________________\n",
      "average_pooling1d_2 (Average (None, 248, 16)           0         \n",
      "_________________________________________________________________\n",
      "conv1d_3 (Conv1D)            (None, 244, 120)          9720      \n",
      "_________________________________________________________________\n",
      "flatten_1 (Flatten)          (None, 29280)             0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 84)                2459604   \n",
      "_________________________________________________________________\n",
      "preds (Dense)                (None, 9)                 765       \n",
      "=================================================================\n",
      "Total params: 2,470,621\n",
      "Trainable params: 2,470,621\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Train on 9240 samples, validate on 1027 samples\n",
      "Epoch 1/80\n",
      "9240/9240 [==============================] - 1s 117us/step - loss: 0.2217 - accuracy: 0.9315 - val_loss: 0.0047 - val_accuracy: 1.0000\n",
      "Epoch 2/80\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9240/9240 [==============================] - 1s 87us/step - loss: 0.0031 - accuracy: 0.9997 - val_loss: 0.0127 - val_accuracy: 0.9951\n",
      "Epoch 3/80\n",
      "9240/9240 [==============================] - 1s 85us/step - loss: 0.0032 - accuracy: 0.9992 - val_loss: 0.0033 - val_accuracy: 0.9990\n",
      "Epoch 4/80\n",
      "9240/9240 [==============================] - 1s 86us/step - loss: 0.0030 - accuracy: 0.9991 - val_loss: 0.0017 - val_accuracy: 1.0000\n",
      "Epoch 5/80\n",
      "9240/9240 [==============================] - 1s 85us/step - loss: 6.3232e-04 - accuracy: 1.0000 - val_loss: 0.0016 - val_accuracy: 1.0000\n",
      "Epoch 6/80\n",
      "9240/9240 [==============================] - 1s 86us/step - loss: 1.7487e-04 - accuracy: 1.0000 - val_loss: 0.0010 - val_accuracy: 1.0000\n",
      "Epoch 7/80\n",
      "9240/9240 [==============================] - 1s 88us/step - loss: 9.8286e-05 - accuracy: 1.0000 - val_loss: 8.7430e-04 - val_accuracy: 1.0000\n",
      "Epoch 8/80\n",
      "9240/9240 [==============================] - 1s 86us/step - loss: 7.3047e-05 - accuracy: 1.0000 - val_loss: 8.4227e-04 - val_accuracy: 1.0000\n",
      "Epoch 9/80\n",
      "9240/9240 [==============================] - 1s 87us/step - loss: 6.0508e-05 - accuracy: 1.0000 - val_loss: 6.8960e-04 - val_accuracy: 1.0000\n",
      "Epoch 10/80\n",
      "9240/9240 [==============================] - 1s 87us/step - loss: 4.9214e-05 - accuracy: 1.0000 - val_loss: 6.1959e-04 - val_accuracy: 1.0000\n",
      "Epoch 11/80\n",
      "9240/9240 [==============================] - 1s 86us/step - loss: 4.2169e-05 - accuracy: 1.0000 - val_loss: 6.0401e-04 - val_accuracy: 1.0000\n",
      "Epoch 12/80\n",
      "9240/9240 [==============================] - 1s 85us/step - loss: 3.5118e-05 - accuracy: 1.0000 - val_loss: 5.6478e-04 - val_accuracy: 1.0000\n",
      "Epoch 13/80\n",
      "9240/9240 [==============================] - 1s 90us/step - loss: 3.0810e-05 - accuracy: 1.0000 - val_loss: 4.7170e-04 - val_accuracy: 1.0000\n",
      "Epoch 14/80\n",
      "9240/9240 [==============================] - 1s 87us/step - loss: 2.7155e-05 - accuracy: 1.0000 - val_loss: 5.3824e-04 - val_accuracy: 1.0000\n",
      "Epoch 15/80\n",
      "9240/9240 [==============================] - 1s 86us/step - loss: 2.3658e-05 - accuracy: 1.0000 - val_loss: 4.3926e-04 - val_accuracy: 1.0000\n",
      "Epoch 16/80\n",
      "9240/9240 [==============================] - 1s 88us/step - loss: 2.0962e-05 - accuracy: 1.0000 - val_loss: 4.6042e-04 - val_accuracy: 1.0000\n",
      "Epoch 17/80\n",
      "9240/9240 [==============================] - 1s 86us/step - loss: 1.9073e-05 - accuracy: 1.0000 - val_loss: 4.0897e-04 - val_accuracy: 1.0000\n",
      "Epoch 18/80\n",
      "9240/9240 [==============================] - 1s 86us/step - loss: 1.7387e-05 - accuracy: 1.0000 - val_loss: 3.7473e-04 - val_accuracy: 1.0000\n",
      "Epoch 19/80\n",
      "9240/9240 [==============================] - 1s 85us/step - loss: 1.5267e-05 - accuracy: 1.0000 - val_loss: 3.7142e-04 - val_accuracy: 1.0000\n",
      "Epoch 20/80\n",
      "9240/9240 [==============================] - 1s 86us/step - loss: 1.4053e-05 - accuracy: 1.0000 - val_loss: 3.7696e-04 - val_accuracy: 1.0000\n",
      "Epoch 21/80\n",
      "9240/9240 [==============================] - 1s 85us/step - loss: 1.2622e-05 - accuracy: 1.0000 - val_loss: 3.8442e-04 - val_accuracy: 1.0000\n",
      "Epoch 22/80\n",
      "9240/9240 [==============================] - 1s 87us/step - loss: 1.1832e-05 - accuracy: 1.0000 - val_loss: 3.4421e-04 - val_accuracy: 1.0000\n",
      "Epoch 23/80\n",
      "9240/9240 [==============================] - 1s 85us/step - loss: 1.0691e-05 - accuracy: 1.0000 - val_loss: 3.2982e-04 - val_accuracy: 1.0000\n",
      "Epoch 24/80\n",
      "9240/9240 [==============================] - 1s 87us/step - loss: 9.7132e-06 - accuracy: 1.0000 - val_loss: 3.5750e-04 - val_accuracy: 1.0000\n",
      "Epoch 25/80\n",
      "9240/9240 [==============================] - 1s 87us/step - loss: 8.8782e-06 - accuracy: 1.0000 - val_loss: 3.2600e-04 - val_accuracy: 1.0000\n",
      "Epoch 26/80\n",
      "9240/9240 [==============================] - 1s 88us/step - loss: 8.2433e-06 - accuracy: 1.0000 - val_loss: 2.9892e-04 - val_accuracy: 1.0000\n",
      "Epoch 27/80\n",
      "9240/9240 [==============================] - 1s 89us/step - loss: 7.6387e-06 - accuracy: 1.0000 - val_loss: 3.1465e-04 - val_accuracy: 1.0000\n",
      "Epoch 28/80\n",
      "9240/9240 [==============================] - 1s 85us/step - loss: 7.0524e-06 - accuracy: 1.0000 - val_loss: 2.9657e-04 - val_accuracy: 1.0000\n",
      "Epoch 29/80\n",
      "9240/9240 [==============================] - 1s 86us/step - loss: 6.6087e-06 - accuracy: 1.0000 - val_loss: 2.9996e-04 - val_accuracy: 1.0000\n",
      "Epoch 30/80\n",
      "9240/9240 [==============================] - 1s 86us/step - loss: 6.1821e-06 - accuracy: 1.0000 - val_loss: 2.5851e-04 - val_accuracy: 1.0000\n",
      "Epoch 31/80\n",
      "9240/9240 [==============================] - 1s 85us/step - loss: 5.7376e-06 - accuracy: 1.0000 - val_loss: 2.3582e-04 - val_accuracy: 1.0000\n",
      "Epoch 32/80\n",
      "9240/9240 [==============================] - 1s 88us/step - loss: 5.3454e-06 - accuracy: 1.0000 - val_loss: 2.6899e-04 - val_accuracy: 1.0000\n",
      "Epoch 33/80\n",
      "9240/9240 [==============================] - 1s 86us/step - loss: 5.0049e-06 - accuracy: 1.0000 - val_loss: 2.6291e-04 - val_accuracy: 1.0000\n",
      "Epoch 34/80\n",
      "9240/9240 [==============================] - 1s 86us/step - loss: 4.6816e-06 - accuracy: 1.0000 - val_loss: 2.3892e-04 - val_accuracy: 1.0000\n",
      "Epoch 35/80\n",
      "9240/9240 [==============================] - 1s 86us/step - loss: 4.4487e-06 - accuracy: 1.0000 - val_loss: 2.2770e-04 - val_accuracy: 1.0000\n",
      "Epoch 36/80\n",
      "9240/9240 [==============================] - 1s 84us/step - loss: 4.1662e-06 - accuracy: 1.0000 - val_loss: 2.4107e-04 - val_accuracy: 1.0000\n",
      "Epoch 37/80\n",
      "9240/9240 [==============================] - 1s 83us/step - loss: 3.8074e-06 - accuracy: 1.0000 - val_loss: 2.0738e-04 - val_accuracy: 1.0000\n",
      "Epoch 38/80\n",
      "9240/9240 [==============================] - 1s 85us/step - loss: 3.6245e-06 - accuracy: 1.0000 - val_loss: 2.1180e-04 - val_accuracy: 1.0000\n",
      "Epoch 39/80\n",
      "9240/9240 [==============================] - 1s 88us/step - loss: 3.4173e-06 - accuracy: 1.0000 - val_loss: 2.2461e-04 - val_accuracy: 1.0000\n",
      "Epoch 40/80\n",
      "9240/9240 [==============================] - 1s 86us/step - loss: 3.2018e-06 - accuracy: 1.0000 - val_loss: 1.9673e-04 - val_accuracy: 1.0000\n",
      "Epoch 41/80\n",
      "9240/9240 [==============================] - 1s 85us/step - loss: 3.0711e-06 - accuracy: 1.0000 - val_loss: 1.9631e-04 - val_accuracy: 1.0000\n",
      "Epoch 42/80\n",
      "9240/9240 [==============================] - 1s 88us/step - loss: 2.9094e-06 - accuracy: 1.0000 - val_loss: 2.2932e-04 - val_accuracy: 1.0000\n",
      "Epoch 43/80\n",
      "9240/9240 [==============================] - 1s 86us/step - loss: 2.7042e-06 - accuracy: 1.0000 - val_loss: 2.2804e-04 - val_accuracy: 1.0000\n",
      "Epoch 44/80\n",
      "9240/9240 [==============================] - 1s 86us/step - loss: 2.5593e-06 - accuracy: 1.0000 - val_loss: 2.1050e-04 - val_accuracy: 1.0000\n",
      "Epoch 45/80\n",
      "9240/9240 [==============================] - 1s 86us/step - loss: 2.4353e-06 - accuracy: 1.0000 - val_loss: 2.0386e-04 - val_accuracy: 1.0000\n",
      "Epoch 46/80\n",
      "9240/9240 [==============================] - 1s 86us/step - loss: 2.2894e-06 - accuracy: 1.0000 - val_loss: 1.7661e-04 - val_accuracy: 1.0000\n",
      "Epoch 47/80\n",
      "9240/9240 [==============================] - 1s 87us/step - loss: 2.1590e-06 - accuracy: 1.0000 - val_loss: 1.8863e-04 - val_accuracy: 1.0000\n",
      "Epoch 48/80\n",
      "9240/9240 [==============================] - 1s 86us/step - loss: 2.0347e-06 - accuracy: 1.0000 - val_loss: 1.9291e-04 - val_accuracy: 1.0000\n",
      "Epoch 49/80\n",
      "9240/9240 [==============================] - 1s 85us/step - loss: 1.9867e-06 - accuracy: 1.0000 - val_loss: 1.9100e-04 - val_accuracy: 1.0000\n",
      "Epoch 50/80\n",
      "9240/9240 [==============================] - 1s 86us/step - loss: 1.8356e-06 - accuracy: 1.0000 - val_loss: 1.7210e-04 - val_accuracy: 1.0000\n",
      "Epoch 51/80\n",
      "9240/9240 [==============================] - 1s 86us/step - loss: 1.7374e-06 - accuracy: 1.0000 - val_loss: 1.5822e-04 - val_accuracy: 1.0000\n",
      "Epoch 52/80\n",
      "9240/9240 [==============================] - 1s 85us/step - loss: 1.6398e-06 - accuracy: 1.0000 - val_loss: 1.6627e-04 - val_accuracy: 1.0000\n",
      "Epoch 53/80\n",
      "9240/9240 [==============================] - 1s 89us/step - loss: 1.5632e-06 - accuracy: 1.0000 - val_loss: 1.6374e-04 - val_accuracy: 1.0000\n",
      "Epoch 54/80\n",
      "9240/9240 [==============================] - 1s 86us/step - loss: 1.5137e-06 - accuracy: 1.0000 - val_loss: 1.6329e-04 - val_accuracy: 1.0000\n",
      "Epoch 55/80\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9240/9240 [==============================] - 1s 86us/step - loss: 1.4381e-06 - accuracy: 1.0000 - val_loss: 1.6405e-04 - val_accuracy: 1.0000\n",
      "Epoch 56/80\n",
      "9240/9240 [==============================] - 1s 87us/step - loss: 1.3589e-06 - accuracy: 1.0000 - val_loss: 1.5851e-04 - val_accuracy: 1.0000\n",
      "Epoch 57/80\n",
      "9240/9240 [==============================] - 1s 84us/step - loss: 1.2796e-06 - accuracy: 1.0000 - val_loss: 1.5967e-04 - val_accuracy: 1.0000\n",
      "Epoch 58/80\n",
      "9240/9240 [==============================] - 1s 86us/step - loss: 1.2206e-06 - accuracy: 1.0000 - val_loss: 1.4975e-04 - val_accuracy: 1.0000\n",
      "Epoch 59/80\n",
      "9240/9240 [==============================] - 1s 88us/step - loss: 1.1524e-06 - accuracy: 1.0000 - val_loss: 1.4949e-04 - val_accuracy: 1.0000\n",
      "Epoch 60/80\n",
      "9240/9240 [==============================] - 1s 88us/step - loss: 1.0926e-06 - accuracy: 1.0000 - val_loss: 1.5157e-04 - val_accuracy: 1.0000\n",
      "Epoch 61/80\n",
      "9240/9240 [==============================] - 1s 85us/step - loss: 1.0430e-06 - accuracy: 1.0000 - val_loss: 1.5119e-04 - val_accuracy: 1.0000\n",
      "Epoch 62/80\n",
      "9240/9240 [==============================] - 1s 87us/step - loss: 9.8646e-07 - accuracy: 1.0000 - val_loss: 1.4214e-04 - val_accuracy: 1.0000\n",
      "Epoch 63/80\n",
      "9240/9240 [==============================] - 1s 85us/step - loss: 9.5251e-07 - accuracy: 1.0000 - val_loss: 1.3615e-04 - val_accuracy: 1.0000\n",
      "Epoch 64/80\n",
      "9240/9240 [==============================] - 1s 85us/step - loss: 9.1700e-07 - accuracy: 1.0000 - val_loss: 1.2961e-04 - val_accuracy: 1.0000\n",
      "Epoch 65/80\n",
      "9240/9240 [==============================] - 1s 85us/step - loss: 8.5821e-07 - accuracy: 1.0000 - val_loss: 1.4366e-04 - val_accuracy: 1.0000\n",
      "Epoch 66/80\n",
      "9240/9240 [==============================] - 1s 85us/step - loss: 8.1924e-07 - accuracy: 1.0000 - val_loss: 1.3125e-04 - val_accuracy: 1.0000\n",
      "Epoch 67/80\n",
      "9240/9240 [==============================] - 1s 88us/step - loss: 7.9323e-07 - accuracy: 1.0000 - val_loss: 1.3127e-04 - val_accuracy: 1.0000\n",
      "Epoch 68/80\n",
      "9240/9240 [==============================] - 1s 88us/step - loss: 7.4364e-07 - accuracy: 1.0000 - val_loss: 1.2934e-04 - val_accuracy: 1.0000\n",
      "Epoch 69/80\n",
      "9240/9240 [==============================] - 1s 86us/step - loss: 7.1392e-07 - accuracy: 1.0000 - val_loss: 1.3195e-04 - val_accuracy: 1.0000\n",
      "Epoch 70/80\n",
      "9240/9240 [==============================] - 1s 86us/step - loss: 6.7775e-07 - accuracy: 1.0000 - val_loss: 1.2880e-04 - val_accuracy: 1.0000\n",
      "Epoch 71/80\n",
      "9240/9240 [==============================] - 1s 85us/step - loss: 6.5076e-07 - accuracy: 1.0000 - val_loss: 1.2437e-04 - val_accuracy: 1.0000\n",
      "Epoch 72/80\n",
      "9240/9240 [==============================] - 1s 86us/step - loss: 6.1447e-07 - accuracy: 1.0000 - val_loss: 1.1877e-04 - val_accuracy: 1.0000\n",
      "Epoch 73/80\n",
      "9240/9240 [==============================] - 1s 87us/step - loss: 5.9081e-07 - accuracy: 1.0000 - val_loss: 1.2218e-04 - val_accuracy: 1.0000\n",
      "Epoch 74/80\n",
      "9240/9240 [==============================] - 1s 87us/step - loss: 5.6510e-07 - accuracy: 1.0000 - val_loss: 1.2689e-04 - val_accuracy: 1.0000\n",
      "Epoch 75/80\n",
      "9240/9240 [==============================] - 1s 86us/step - loss: 5.4185e-07 - accuracy: 1.0000 - val_loss: 1.1350e-04 - val_accuracy: 1.0000\n",
      "Epoch 76/80\n",
      "9240/9240 [==============================] - 1s 84us/step - loss: 5.1525e-07 - accuracy: 1.0000 - val_loss: 1.1918e-04 - val_accuracy: 1.0000\n",
      "Epoch 77/80\n",
      "9240/9240 [==============================] - 1s 86us/step - loss: 4.9421e-07 - accuracy: 1.0000 - val_loss: 1.0660e-04 - val_accuracy: 1.0000\n",
      "Epoch 78/80\n",
      "9240/9240 [==============================] - 1s 87us/step - loss: 4.7007e-07 - accuracy: 1.0000 - val_loss: 1.0647e-04 - val_accuracy: 1.0000\n",
      "Epoch 79/80\n",
      "9240/9240 [==============================] - 1s 85us/step - loss: 4.5340e-07 - accuracy: 1.0000 - val_loss: 1.3277e-04 - val_accuracy: 1.0000\n",
      "Epoch 80/80\n",
      "9240/9240 [==============================] - 1s 87us/step - loss: 4.3176e-07 - accuracy: 1.0000 - val_loss: 1.1198e-04 - val_accuracy: 1.0000\n",
      "[[4.4152620e-03 1.2179805e-07 4.4923509e-06 ... 9.6992749e-01\n",
      "  2.5374454e-02 3.5731449e-05]\n",
      " [1.4673765e-05 2.4935096e-09 9.4423740e-09 ... 9.6222311e-02\n",
      "  9.0375346e-01 6.6531879e-06]\n",
      " [2.4706364e-06 8.2155411e-09 1.0199222e-08 ... 9.6309924e-01\n",
      "  3.6896564e-02 1.2106320e-06]\n",
      " ...\n",
      " [3.2968020e-19 4.7371920e-19 1.1156810e-18 ... 3.6234423e-18\n",
      "  1.0000000e+00 3.4662683e-18]\n",
      " [1.4895935e-13 9.5709343e-17 3.9400309e-16 ... 1.8954882e-08\n",
      "  8.3284913e-15 1.4234658e-14]\n",
      " [3.5183148e-19 1.1896184e-17 4.7681213e-19 ... 8.9921491e-19\n",
      "  1.0000000e+00 4.5658445e-24]]\n",
      "[6 7 6 ... 7 3 7]\n",
      "<class 'numpy.ndarray'>\n",
      "One CNN, r:  1\n",
      "Computing Time:  0:02:14.358701\n",
      "Model: \"sequential_1\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv1d_1 (Conv1D)            (None, 1000, 6)           36        \n",
      "_________________________________________________________________\n",
      "average_pooling1d_1 (Average (None, 500, 6)            0         \n",
      "_________________________________________________________________\n",
      "conv1d_2 (Conv1D)            (None, 496, 16)           496       \n",
      "_________________________________________________________________\n",
      "average_pooling1d_2 (Average (None, 248, 16)           0         \n",
      "_________________________________________________________________\n",
      "conv1d_3 (Conv1D)            (None, 244, 120)          9720      \n",
      "_________________________________________________________________\n",
      "flatten_1 (Flatten)          (None, 29280)             0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 84)                2459604   \n",
      "_________________________________________________________________\n",
      "preds (Dense)                (None, 9)                 765       \n",
      "=================================================================\n",
      "Total params: 2,470,621\n",
      "Trainable params: 2,470,621\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Train on 9240 samples, validate on 1027 samples\n",
      "Epoch 1/80\n",
      "9240/9240 [==============================] - 1s 112us/step - loss: 0.1809 - accuracy: 0.9449 - val_loss: 0.0086 - val_accuracy: 0.9971\n",
      "Epoch 2/80\n",
      "9240/9240 [==============================] - 1s 86us/step - loss: 0.0033 - accuracy: 0.9991 - val_loss: 0.0042 - val_accuracy: 0.9990\n",
      "Epoch 3/80\n",
      "9240/9240 [==============================] - 1s 90us/step - loss: 7.1389e-04 - accuracy: 1.0000 - val_loss: 0.0029 - val_accuracy: 0.9990\n",
      "Epoch 4/80\n",
      "9240/9240 [==============================] - 1s 87us/step - loss: 2.4435e-04 - accuracy: 1.0000 - val_loss: 0.0011 - val_accuracy: 1.0000\n",
      "Epoch 5/80\n",
      "9240/9240 [==============================] - 1s 87us/step - loss: 1.3990e-04 - accuracy: 1.0000 - val_loss: 0.0011 - val_accuracy: 1.0000\n",
      "Epoch 6/80\n",
      "9240/9240 [==============================] - 1s 88us/step - loss: 1.0062e-04 - accuracy: 1.0000 - val_loss: 7.8998e-04 - val_accuracy: 1.0000\n",
      "Epoch 7/80\n",
      "9240/9240 [==============================] - 1s 87us/step - loss: 7.3761e-05 - accuracy: 1.0000 - val_loss: 6.9486e-04 - val_accuracy: 1.0000\n",
      "Epoch 8/80\n",
      "9240/9240 [==============================] - 1s 85us/step - loss: 5.7808e-05 - accuracy: 1.0000 - val_loss: 7.7583e-04 - val_accuracy: 1.0000\n",
      "Epoch 9/80\n",
      "9240/9240 [==============================] - 1s 87us/step - loss: 4.6871e-05 - accuracy: 1.0000 - val_loss: 5.4918e-04 - val_accuracy: 1.0000\n",
      "Epoch 10/80\n",
      "9240/9240 [==============================] - 1s 88us/step - loss: 4.0473e-05 - accuracy: 1.0000 - val_loss: 4.5288e-04 - val_accuracy: 1.0000\n",
      "Epoch 11/80\n",
      "9240/9240 [==============================] - 1s 86us/step - loss: 3.2367e-05 - accuracy: 1.0000 - val_loss: 5.2445e-04 - val_accuracy: 1.0000\n",
      "Epoch 12/80\n",
      "9240/9240 [==============================] - 1s 87us/step - loss: 2.7640e-05 - accuracy: 1.0000 - val_loss: 4.2522e-04 - val_accuracy: 1.0000\n",
      "Epoch 13/80\n",
      "9240/9240 [==============================] - 1s 88us/step - loss: 2.3878e-05 - accuracy: 1.0000 - val_loss: 4.1481e-04 - val_accuracy: 1.0000\n",
      "Epoch 14/80\n",
      "9240/9240 [==============================] - 1s 87us/step - loss: 2.0309e-05 - accuracy: 1.0000 - val_loss: 3.5165e-04 - val_accuracy: 1.0000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 15/80\n",
      "9240/9240 [==============================] - 1s 86us/step - loss: 1.7802e-05 - accuracy: 1.0000 - val_loss: 3.5589e-04 - val_accuracy: 1.0000\n",
      "Epoch 16/80\n",
      "9240/9240 [==============================] - 1s 90us/step - loss: 1.5571e-05 - accuracy: 1.0000 - val_loss: 3.2137e-04 - val_accuracy: 1.0000\n",
      "Epoch 17/80\n",
      "9240/9240 [==============================] - 1s 86us/step - loss: 1.3695e-05 - accuracy: 1.0000 - val_loss: 3.2029e-04 - val_accuracy: 1.0000\n",
      "Epoch 18/80\n",
      "9240/9240 [==============================] - 1s 88us/step - loss: 1.2354e-05 - accuracy: 1.0000 - val_loss: 2.9486e-04 - val_accuracy: 1.0000\n",
      "Epoch 19/80\n",
      "9240/9240 [==============================] - 1s 86us/step - loss: 1.1063e-05 - accuracy: 1.0000 - val_loss: 2.6401e-04 - val_accuracy: 1.0000\n",
      "Epoch 20/80\n",
      "9240/9240 [==============================] - 1s 86us/step - loss: 1.0023e-05 - accuracy: 1.0000 - val_loss: 2.7427e-04 - val_accuracy: 1.0000\n",
      "Epoch 21/80\n",
      "9240/9240 [==============================] - 1s 88us/step - loss: 9.1838e-06 - accuracy: 1.0000 - val_loss: 2.6666e-04 - val_accuracy: 1.0000\n",
      "Epoch 22/80\n",
      "9240/9240 [==============================] - 1s 86us/step - loss: 8.1333e-06 - accuracy: 1.0000 - val_loss: 2.8114e-04 - val_accuracy: 1.0000\n",
      "Epoch 23/80\n",
      "9240/9240 [==============================] - 1s 90us/step - loss: 7.5584e-06 - accuracy: 1.0000 - val_loss: 2.3483e-04 - val_accuracy: 1.0000\n",
      "Epoch 24/80\n",
      "9240/9240 [==============================] - 1s 88us/step - loss: 6.7205e-06 - accuracy: 1.0000 - val_loss: 2.3493e-04 - val_accuracy: 1.0000\n",
      "Epoch 25/80\n",
      "9240/9240 [==============================] - 1s 88us/step - loss: 6.1611e-06 - accuracy: 1.0000 - val_loss: 2.2116e-04 - val_accuracy: 1.0000\n",
      "Epoch 26/80\n",
      "9240/9240 [==============================] - 1s 87us/step - loss: 5.6970e-06 - accuracy: 1.0000 - val_loss: 2.0616e-04 - val_accuracy: 1.0000\n",
      "Epoch 27/80\n",
      "9240/9240 [==============================] - 1s 85us/step - loss: 5.2349e-06 - accuracy: 1.0000 - val_loss: 1.9348e-04 - val_accuracy: 1.0000\n",
      "Epoch 28/80\n",
      "9240/9240 [==============================] - 1s 86us/step - loss: 4.8737e-06 - accuracy: 1.0000 - val_loss: 2.0965e-04 - val_accuracy: 1.0000\n",
      "Epoch 29/80\n",
      "9240/9240 [==============================] - 1s 88us/step - loss: 4.4401e-06 - accuracy: 1.0000 - val_loss: 1.8404e-04 - val_accuracy: 1.0000\n",
      "Epoch 30/80\n",
      "9240/9240 [==============================] - 1s 88us/step - loss: 4.1780e-06 - accuracy: 1.0000 - val_loss: 1.7833e-04 - val_accuracy: 1.0000\n",
      "Epoch 31/80\n",
      "9240/9240 [==============================] - 1s 85us/step - loss: 3.7307e-06 - accuracy: 1.0000 - val_loss: 1.6675e-04 - val_accuracy: 1.0000\n",
      "Epoch 32/80\n",
      "9240/9240 [==============================] - 1s 88us/step - loss: 3.7292e-06 - accuracy: 1.0000 - val_loss: 1.7499e-04 - val_accuracy: 1.0000\n",
      "Epoch 33/80\n",
      "9240/9240 [==============================] - 1s 86us/step - loss: 3.3016e-06 - accuracy: 1.0000 - val_loss: 1.6162e-04 - val_accuracy: 1.0000\n",
      "Epoch 34/80\n",
      "9240/9240 [==============================] - 1s 87us/step - loss: 3.1349e-06 - accuracy: 1.0000 - val_loss: 1.6930e-04 - val_accuracy: 1.0000\n",
      "Epoch 35/80\n",
      "9240/9240 [==============================] - 1s 86us/step - loss: 2.9387e-06 - accuracy: 1.0000 - val_loss: 1.5437e-04 - val_accuracy: 1.0000\n",
      "Epoch 36/80\n",
      "9240/9240 [==============================] - 1s 88us/step - loss: 2.7203e-06 - accuracy: 1.0000 - val_loss: 1.4696e-04 - val_accuracy: 1.0000\n",
      "Epoch 37/80\n",
      "9240/9240 [==============================] - 1s 86us/step - loss: 2.5861e-06 - accuracy: 1.0000 - val_loss: 1.4496e-04 - val_accuracy: 1.0000\n",
      "Epoch 38/80\n",
      "9240/9240 [==============================] - 1s 86us/step - loss: 2.4318e-06 - accuracy: 1.0000 - val_loss: 1.4374e-04 - val_accuracy: 1.0000\n",
      "Epoch 39/80\n",
      "9240/9240 [==============================] - 1s 85us/step - loss: 2.2358e-06 - accuracy: 1.0000 - val_loss: 1.3928e-04 - val_accuracy: 1.0000\n",
      "Epoch 40/80\n",
      "9240/9240 [==============================] - 1s 88us/step - loss: 2.1466e-06 - accuracy: 1.0000 - val_loss: 1.3352e-04 - val_accuracy: 1.0000\n",
      "Epoch 41/80\n",
      "9240/9240 [==============================] - 1s 86us/step - loss: 1.9777e-06 - accuracy: 1.0000 - val_loss: 1.2901e-04 - val_accuracy: 1.0000\n",
      "Epoch 42/80\n",
      "9240/9240 [==============================] - 1s 87us/step - loss: 1.8814e-06 - accuracy: 1.0000 - val_loss: 1.3261e-04 - val_accuracy: 1.0000\n",
      "Epoch 43/80\n",
      "9240/9240 [==============================] - 1s 86us/step - loss: 1.7668e-06 - accuracy: 1.0000 - val_loss: 1.2573e-04 - val_accuracy: 1.0000\n",
      "Epoch 44/80\n",
      "9240/9240 [==============================] - 1s 86us/step - loss: 1.6462e-06 - accuracy: 1.0000 - val_loss: 1.2788e-04 - val_accuracy: 1.0000\n",
      "Epoch 45/80\n",
      "9240/9240 [==============================] - 1s 87us/step - loss: 1.5877e-06 - accuracy: 1.0000 - val_loss: 1.1966e-04 - val_accuracy: 1.0000\n",
      "Epoch 46/80\n",
      "9240/9240 [==============================] - 1s 88us/step - loss: 1.4964e-06 - accuracy: 1.0000 - val_loss: 1.1304e-04 - val_accuracy: 1.0000\n",
      "Epoch 47/80\n",
      "9240/9240 [==============================] - 1s 86us/step - loss: 1.3670e-06 - accuracy: 1.0000 - val_loss: 1.1638e-04 - val_accuracy: 1.0000\n",
      "Epoch 48/80\n",
      "9240/9240 [==============================] - 1s 86us/step - loss: 1.3128e-06 - accuracy: 1.0000 - val_loss: 1.0456e-04 - val_accuracy: 1.0000\n",
      "Epoch 49/80\n",
      "9240/9240 [==============================] - 1s 87us/step - loss: 1.2508e-06 - accuracy: 1.0000 - val_loss: 1.1148e-04 - val_accuracy: 1.0000\n",
      "Epoch 50/80\n",
      "9240/9240 [==============================] - 1s 87us/step - loss: 1.1930e-06 - accuracy: 1.0000 - val_loss: 1.1000e-04 - val_accuracy: 1.0000\n",
      "Epoch 51/80\n",
      "9240/9240 [==============================] - 1s 86us/step - loss: 1.1139e-06 - accuracy: 1.0000 - val_loss: 1.0672e-04 - val_accuracy: 1.0000\n",
      "Epoch 52/80\n",
      "9240/9240 [==============================] - 1s 88us/step - loss: 1.0423e-06 - accuracy: 1.0000 - val_loss: 9.8828e-05 - val_accuracy: 1.0000\n",
      "Epoch 53/80\n",
      "9240/9240 [==============================] - 1s 86us/step - loss: 1.0112e-06 - accuracy: 1.0000 - val_loss: 1.0461e-04 - val_accuracy: 1.0000\n",
      "Epoch 54/80\n",
      "9240/9240 [==============================] - 1s 87us/step - loss: 9.5706e-07 - accuracy: 1.0000 - val_loss: 9.5523e-05 - val_accuracy: 1.0000\n",
      "Epoch 55/80\n",
      "9240/9240 [==============================] - 1s 86us/step - loss: 8.9929e-07 - accuracy: 1.0000 - val_loss: 9.8420e-05 - val_accuracy: 1.0000\n",
      "Epoch 56/80\n",
      "9240/9240 [==============================] - 1s 86us/step - loss: 8.7700e-07 - accuracy: 1.0000 - val_loss: 8.8884e-05 - val_accuracy: 1.0000\n",
      "Epoch 57/80\n",
      "9240/9240 [==============================] - 1s 86us/step - loss: 8.0756e-07 - accuracy: 1.0000 - val_loss: 9.5144e-05 - val_accuracy: 1.0000\n",
      "Epoch 58/80\n",
      "9240/9240 [==============================] - 1s 85us/step - loss: 7.7607e-07 - accuracy: 1.0000 - val_loss: 8.8431e-05 - val_accuracy: 1.0000\n",
      "Epoch 59/80\n",
      "9240/9240 [==============================] - 1s 86us/step - loss: 7.3567e-07 - accuracy: 1.0000 - val_loss: 8.7541e-05 - val_accuracy: 1.0000\n",
      "Epoch 60/80\n",
      "9240/9240 [==============================] - 1s 85us/step - loss: 6.9585e-07 - accuracy: 1.0000 - val_loss: 9.5399e-05 - val_accuracy: 1.0000\n",
      "Epoch 61/80\n",
      "9240/9240 [==============================] - 1s 86us/step - loss: 6.6013e-07 - accuracy: 1.0000 - val_loss: 8.2045e-05 - val_accuracy: 1.0000\n",
      "Epoch 62/80\n",
      "9240/9240 [==============================] - 1s 86us/step - loss: 6.3673e-07 - accuracy: 1.0000 - val_loss: 8.5172e-05 - val_accuracy: 1.0000\n",
      "Epoch 63/80\n",
      "9240/9240 [==============================] - 1s 88us/step - loss: 6.0996e-07 - accuracy: 1.0000 - val_loss: 8.2932e-05 - val_accuracy: 1.0000\n",
      "Epoch 64/80\n",
      "9240/9240 [==============================] - 1s 86us/step - loss: 5.7102e-07 - accuracy: 1.0000 - val_loss: 8.1810e-05 - val_accuracy: 1.0000\n",
      "Epoch 65/80\n",
      "9240/9240 [==============================] - 1s 86us/step - loss: 5.4113e-07 - accuracy: 1.0000 - val_loss: 8.6598e-05 - val_accuracy: 1.0000\n",
      "Epoch 66/80\n",
      "9240/9240 [==============================] - 1s 88us/step - loss: 5.2760e-07 - accuracy: 1.0000 - val_loss: 8.2374e-05 - val_accuracy: 1.0000\n",
      "Epoch 67/80\n",
      "9240/9240 [==============================] - 1s 88us/step - loss: 4.9476e-07 - accuracy: 1.0000 - val_loss: 7.4345e-05 - val_accuracy: 1.0000\n",
      "Epoch 68/80\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9240/9240 [==============================] - 1s 86us/step - loss: 4.7708e-07 - accuracy: 1.0000 - val_loss: 7.9802e-05 - val_accuracy: 1.0000\n",
      "Epoch 69/80\n",
      "9240/9240 [==============================] - 1s 88us/step - loss: 4.4979e-07 - accuracy: 1.0000 - val_loss: 7.6026e-05 - val_accuracy: 1.0000\n",
      "Epoch 70/80\n",
      "9240/9240 [==============================] - 1s 87us/step - loss: 4.4125e-07 - accuracy: 1.0000 - val_loss: 7.7766e-05 - val_accuracy: 1.0000\n",
      "Epoch 71/80\n",
      "9240/9240 [==============================] - 1s 87us/step - loss: 4.1442e-07 - accuracy: 1.0000 - val_loss: 6.7428e-05 - val_accuracy: 1.0000\n",
      "Epoch 72/80\n",
      "9240/9240 [==============================] - 1s 85us/step - loss: 3.9059e-07 - accuracy: 1.0000 - val_loss: 7.2901e-05 - val_accuracy: 1.0000\n",
      "Epoch 73/80\n",
      "9240/9240 [==============================] - 1s 88us/step - loss: 3.7022e-07 - accuracy: 1.0000 - val_loss: 6.6831e-05 - val_accuracy: 1.0000\n",
      "Epoch 74/80\n",
      "9240/9240 [==============================] - 1s 88us/step - loss: 3.5412e-07 - accuracy: 1.0000 - val_loss: 7.2955e-05 - val_accuracy: 1.0000\n",
      "Epoch 75/80\n",
      "9240/9240 [==============================] - 1s 86us/step - loss: 3.4069e-07 - accuracy: 1.0000 - val_loss: 6.4716e-05 - val_accuracy: 1.0000\n",
      "Epoch 76/80\n",
      "9240/9240 [==============================] - 1s 88us/step - loss: 3.2780e-07 - accuracy: 1.0000 - val_loss: 6.3925e-05 - val_accuracy: 1.0000\n",
      "Epoch 77/80\n",
      "9240/9240 [==============================] - 1s 86us/step - loss: 3.0781e-07 - accuracy: 1.0000 - val_loss: 6.6613e-05 - val_accuracy: 1.0000\n",
      "Epoch 78/80\n",
      "9240/9240 [==============================] - 1s 88us/step - loss: 2.9748e-07 - accuracy: 1.0000 - val_loss: 6.5684e-05 - val_accuracy: 1.0000\n",
      "Epoch 79/80\n",
      "9240/9240 [==============================] - 1s 87us/step - loss: 2.8397e-07 - accuracy: 1.0000 - val_loss: 6.1630e-05 - val_accuracy: 1.0000\n",
      "Epoch 80/80\n",
      "9240/9240 [==============================] - 1s 85us/step - loss: 2.7448e-07 - accuracy: 1.0000 - val_loss: 5.8039e-05 - val_accuracy: 1.0000\n",
      "[[3.0431745e-05 2.9251018e-07 3.9069560e-06 ... 9.9299049e-01\n",
      "  6.2873554e-03 2.1914134e-06]\n",
      " [6.2501687e-10 1.3701030e-09 2.1042224e-09 ... 1.3401301e-01\n",
      "  8.6598325e-01 3.4859568e-06]\n",
      " [2.0434120e-11 1.2323498e-09 2.9047975e-09 ... 9.9867541e-01\n",
      "  1.3245252e-03 4.1621782e-08]\n",
      " ...\n",
      " [1.6770480e-25 4.2192183e-18 4.9531963e-22 ... 1.5215095e-18\n",
      "  1.0000000e+00 7.5156942e-17]\n",
      " [2.6420438e-17 1.1511981e-17 5.6249326e-19 ... 1.7308254e-09\n",
      "  3.8909692e-14 4.4854987e-17]\n",
      " [4.1561110e-22 1.5494720e-18 2.3034449e-19 ... 2.6850181e-20\n",
      "  1.0000000e+00 4.8441250e-22]]\n",
      "[6 7 6 ... 7 3 7]\n",
      "<class 'numpy.ndarray'>\n",
      "One CNN, r:  2\n",
      "Computing Time:  0:03:21.968098\n",
      "Model: \"sequential_1\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv1d_1 (Conv1D)            (None, 1000, 6)           36        \n",
      "_________________________________________________________________\n",
      "average_pooling1d_1 (Average (None, 500, 6)            0         \n",
      "_________________________________________________________________\n",
      "conv1d_2 (Conv1D)            (None, 496, 16)           496       \n",
      "_________________________________________________________________\n",
      "average_pooling1d_2 (Average (None, 248, 16)           0         \n",
      "_________________________________________________________________\n",
      "conv1d_3 (Conv1D)            (None, 244, 120)          9720      \n",
      "_________________________________________________________________\n",
      "flatten_1 (Flatten)          (None, 29280)             0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 84)                2459604   \n",
      "_________________________________________________________________\n",
      "preds (Dense)                (None, 9)                 765       \n",
      "=================================================================\n",
      "Total params: 2,470,621\n",
      "Trainable params: 2,470,621\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Train on 9240 samples, validate on 1027 samples\n",
      "Epoch 1/80\n",
      "9240/9240 [==============================] - 1s 113us/step - loss: 0.2256 - accuracy: 0.9346 - val_loss: 0.0130 - val_accuracy: 0.9951\n",
      "Epoch 2/80\n",
      "9240/9240 [==============================] - 1s 86us/step - loss: 0.0059 - accuracy: 0.9987 - val_loss: 0.0050 - val_accuracy: 0.9981\n",
      "Epoch 3/80\n",
      "9240/9240 [==============================] - 1s 88us/step - loss: 0.0023 - accuracy: 0.9997 - val_loss: 0.0039 - val_accuracy: 0.9981\n",
      "Epoch 4/80\n",
      "9240/9240 [==============================] - 1s 86us/step - loss: 6.9538e-04 - accuracy: 1.0000 - val_loss: 0.0026 - val_accuracy: 0.9990\n",
      "Epoch 5/80\n",
      "9240/9240 [==============================] - 1s 88us/step - loss: 2.5580e-04 - accuracy: 1.0000 - val_loss: 0.0015 - val_accuracy: 0.9990\n",
      "Epoch 6/80\n",
      "9240/9240 [==============================] - 1s 87us/step - loss: 2.7286e-04 - accuracy: 1.0000 - val_loss: 0.0032 - val_accuracy: 0.9981\n",
      "Epoch 7/80\n",
      "9240/9240 [==============================] - 1s 87us/step - loss: 0.0016 - accuracy: 0.9995 - val_loss: 0.0024 - val_accuracy: 1.0000\n",
      "Epoch 8/80\n",
      "9240/9240 [==============================] - 1s 86us/step - loss: 0.0043 - accuracy: 0.9991 - val_loss: 0.0044 - val_accuracy: 0.9990\n",
      "Epoch 9/80\n",
      "9240/9240 [==============================] - 1s 86us/step - loss: 3.1861e-04 - accuracy: 0.9999 - val_loss: 0.0012 - val_accuracy: 1.0000\n",
      "Epoch 10/80\n",
      "9240/9240 [==============================] - 1s 87us/step - loss: 8.3737e-05 - accuracy: 1.0000 - val_loss: 8.0981e-04 - val_accuracy: 1.0000\n",
      "Epoch 11/80\n",
      "9240/9240 [==============================] - 1s 86us/step - loss: 5.9082e-05 - accuracy: 1.0000 - val_loss: 6.7117e-04 - val_accuracy: 1.0000\n",
      "Epoch 12/80\n",
      "9240/9240 [==============================] - 1s 88us/step - loss: 4.2557e-05 - accuracy: 1.0000 - val_loss: 7.0971e-04 - val_accuracy: 1.0000\n",
      "Epoch 13/80\n",
      "9240/9240 [==============================] - 1s 88us/step - loss: 3.3848e-05 - accuracy: 1.0000 - val_loss: 6.6926e-04 - val_accuracy: 1.0000\n",
      "Epoch 14/80\n",
      "9240/9240 [==============================] - 1s 86us/step - loss: 2.7867e-05 - accuracy: 1.0000 - val_loss: 5.9327e-04 - val_accuracy: 1.0000\n",
      "Epoch 15/80\n",
      "9240/9240 [==============================] - 1s 86us/step - loss: 2.3396e-05 - accuracy: 1.0000 - val_loss: 5.7778e-04 - val_accuracy: 1.0000\n",
      "Epoch 16/80\n",
      "9240/9240 [==============================] - 1s 86us/step - loss: 2.0208e-05 - accuracy: 1.0000 - val_loss: 5.1663e-04 - val_accuracy: 1.0000\n",
      "Epoch 17/80\n",
      "9240/9240 [==============================] - 1s 86us/step - loss: 1.7477e-05 - accuracy: 1.0000 - val_loss: 5.0311e-04 - val_accuracy: 1.0000\n",
      "Epoch 18/80\n",
      "9240/9240 [==============================] - 1s 88us/step - loss: 1.5144e-05 - accuracy: 1.0000 - val_loss: 4.9839e-04 - val_accuracy: 1.0000\n",
      "Epoch 19/80\n",
      "9240/9240 [==============================] - 1s 88us/step - loss: 1.3352e-05 - accuracy: 1.0000 - val_loss: 4.8365e-04 - val_accuracy: 1.0000\n",
      "Epoch 20/80\n",
      "9240/9240 [==============================] - 1s 86us/step - loss: 1.1743e-05 - accuracy: 1.0000 - val_loss: 4.2353e-04 - val_accuracy: 1.0000\n",
      "Epoch 21/80\n",
      "9240/9240 [==============================] - 1s 86us/step - loss: 1.0699e-05 - accuracy: 1.0000 - val_loss: 4.1481e-04 - val_accuracy: 1.0000\n",
      "Epoch 22/80\n",
      "9240/9240 [==============================] - 1s 86us/step - loss: 9.5117e-06 - accuracy: 1.0000 - val_loss: 4.0378e-04 - val_accuracy: 1.0000\n",
      "Epoch 23/80\n",
      "9240/9240 [==============================] - 1s 87us/step - loss: 8.6185e-06 - accuracy: 1.0000 - val_loss: 3.7991e-04 - val_accuracy: 1.0000\n",
      "Epoch 24/80\n",
      "9240/9240 [==============================] - 1s 86us/step - loss: 7.8284e-06 - accuracy: 1.0000 - val_loss: 3.7224e-04 - val_accuracy: 1.0000\n",
      "Epoch 25/80\n",
      "9240/9240 [==============================] - 1s 85us/step - loss: 7.1399e-06 - accuracy: 1.0000 - val_loss: 3.5555e-04 - val_accuracy: 1.0000\n",
      "Epoch 26/80\n",
      "9240/9240 [==============================] - 1s 85us/step - loss: 6.5505e-06 - accuracy: 1.0000 - val_loss: 3.4800e-04 - val_accuracy: 1.0000\n",
      "Epoch 27/80\n",
      "9240/9240 [==============================] - 1s 86us/step - loss: 6.0141e-06 - accuracy: 1.0000 - val_loss: 3.4755e-04 - val_accuracy: 1.0000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 28/80\n",
      "9240/9240 [==============================] - 1s 87us/step - loss: 5.5370e-06 - accuracy: 1.0000 - val_loss: 3.3633e-04 - val_accuracy: 1.0000\n",
      "Epoch 29/80\n",
      "9240/9240 [==============================] - 1s 85us/step - loss: 5.1317e-06 - accuracy: 1.0000 - val_loss: 3.0687e-04 - val_accuracy: 1.0000\n",
      "Epoch 30/80\n",
      "9240/9240 [==============================] - 1s 86us/step - loss: 4.7245e-06 - accuracy: 1.0000 - val_loss: 3.1182e-04 - val_accuracy: 1.0000\n",
      "Epoch 31/80\n",
      "9240/9240 [==============================] - 1s 88us/step - loss: 4.4150e-06 - accuracy: 1.0000 - val_loss: 2.9487e-04 - val_accuracy: 1.0000\n",
      "Epoch 32/80\n",
      "9240/9240 [==============================] - 1s 87us/step - loss: 4.0672e-06 - accuracy: 1.0000 - val_loss: 2.9813e-04 - val_accuracy: 1.0000\n",
      "Epoch 33/80\n",
      "9240/9240 [==============================] - 1s 86us/step - loss: 3.8114e-06 - accuracy: 1.0000 - val_loss: 2.8861e-04 - val_accuracy: 1.0000\n",
      "Epoch 34/80\n",
      "9240/9240 [==============================] - 1s 88us/step - loss: 3.5744e-06 - accuracy: 1.0000 - val_loss: 2.6547e-04 - val_accuracy: 1.0000\n",
      "Epoch 35/80\n",
      "9240/9240 [==============================] - 1s 86us/step - loss: 3.3014e-06 - accuracy: 1.0000 - val_loss: 2.4917e-04 - val_accuracy: 1.0000\n",
      "Epoch 36/80\n",
      "9240/9240 [==============================] - 1s 87us/step - loss: 3.0868e-06 - accuracy: 1.0000 - val_loss: 2.6689e-04 - val_accuracy: 1.0000\n",
      "Epoch 37/80\n",
      "9240/9240 [==============================] - 1s 87us/step - loss: 2.9406e-06 - accuracy: 1.0000 - val_loss: 2.6313e-04 - val_accuracy: 1.0000\n",
      "Epoch 38/80\n",
      "9240/9240 [==============================] - 1s 85us/step - loss: 2.7060e-06 - accuracy: 1.0000 - val_loss: 2.4182e-04 - val_accuracy: 1.0000\n",
      "Epoch 39/80\n",
      "9240/9240 [==============================] - 1s 86us/step - loss: 2.5193e-06 - accuracy: 1.0000 - val_loss: 2.2783e-04 - val_accuracy: 1.0000\n",
      "Epoch 40/80\n",
      "9240/9240 [==============================] - 1s 87us/step - loss: 2.3875e-06 - accuracy: 1.0000 - val_loss: 2.1807e-04 - val_accuracy: 1.0000\n",
      "Epoch 41/80\n",
      "9240/9240 [==============================] - 1s 85us/step - loss: 2.2198e-06 - accuracy: 1.0000 - val_loss: 2.1563e-04 - val_accuracy: 1.0000\n",
      "Epoch 42/80\n",
      "9240/9240 [==============================] - 1s 86us/step - loss: 2.0822e-06 - accuracy: 1.0000 - val_loss: 2.0584e-04 - val_accuracy: 1.0000\n",
      "Epoch 43/80\n",
      "9240/9240 [==============================] - 1s 88us/step - loss: 1.9850e-06 - accuracy: 1.0000 - val_loss: 2.0206e-04 - val_accuracy: 1.0000\n",
      "Epoch 44/80\n",
      "9240/9240 [==============================] - 1s 86us/step - loss: 1.8486e-06 - accuracy: 1.0000 - val_loss: 1.9328e-04 - val_accuracy: 1.0000\n",
      "Epoch 45/80\n",
      "9240/9240 [==============================] - 1s 88us/step - loss: 1.7354e-06 - accuracy: 1.0000 - val_loss: 1.9595e-04 - val_accuracy: 1.0000\n",
      "Epoch 46/80\n",
      "9240/9240 [==============================] - 1s 88us/step - loss: 1.6335e-06 - accuracy: 1.0000 - val_loss: 1.9228e-04 - val_accuracy: 1.0000\n",
      "Epoch 47/80\n",
      "9240/9240 [==============================] - 1s 87us/step - loss: 1.5444e-06 - accuracy: 1.0000 - val_loss: 1.7726e-04 - val_accuracy: 1.0000\n",
      "Epoch 48/80\n",
      "9240/9240 [==============================] - 1s 88us/step - loss: 1.4521e-06 - accuracy: 1.0000 - val_loss: 1.7502e-04 - val_accuracy: 1.0000\n",
      "Epoch 49/80\n",
      "9240/9240 [==============================] - 1s 86us/step - loss: 1.3643e-06 - accuracy: 1.0000 - val_loss: 1.6301e-04 - val_accuracy: 1.0000\n",
      "Epoch 50/80\n",
      "9240/9240 [==============================] - 1s 87us/step - loss: 1.3026e-06 - accuracy: 1.0000 - val_loss: 1.6453e-04 - val_accuracy: 1.0000\n",
      "Epoch 51/80\n",
      "9240/9240 [==============================] - 1s 86us/step - loss: 1.2152e-06 - accuracy: 1.0000 - val_loss: 1.5908e-04 - val_accuracy: 1.0000\n",
      "Epoch 52/80\n",
      "9240/9240 [==============================] - 1s 86us/step - loss: 1.1538e-06 - accuracy: 1.0000 - val_loss: 1.5973e-04 - val_accuracy: 1.0000\n",
      "Epoch 53/80\n",
      "9240/9240 [==============================] - 1s 87us/step - loss: 1.0797e-06 - accuracy: 1.0000 - val_loss: 1.5319e-04 - val_accuracy: 1.0000\n",
      "Epoch 54/80\n",
      "9240/9240 [==============================] - 1s 85us/step - loss: 1.0298e-06 - accuracy: 1.0000 - val_loss: 1.4995e-04 - val_accuracy: 1.0000\n",
      "Epoch 55/80\n",
      "9240/9240 [==============================] - 1s 87us/step - loss: 9.7713e-07 - accuracy: 1.0000 - val_loss: 1.4380e-04 - val_accuracy: 1.0000\n",
      "Epoch 56/80\n",
      "9240/9240 [==============================] - 1s 87us/step - loss: 9.3197e-07 - accuracy: 1.0000 - val_loss: 1.4312e-04 - val_accuracy: 1.0000\n",
      "Epoch 57/80\n",
      "9240/9240 [==============================] - 1s 86us/step - loss: 8.6743e-07 - accuracy: 1.0000 - val_loss: 1.3636e-04 - val_accuracy: 1.0000\n",
      "Epoch 58/80\n",
      "9240/9240 [==============================] - 1s 87us/step - loss: 8.1629e-07 - accuracy: 1.0000 - val_loss: 1.3610e-04 - val_accuracy: 1.0000\n",
      "Epoch 59/80\n",
      "9240/9240 [==============================] - 1s 88us/step - loss: 7.7928e-07 - accuracy: 1.0000 - val_loss: 1.3121e-04 - val_accuracy: 1.0000\n",
      "Epoch 60/80\n",
      "9240/9240 [==============================] - 1s 88us/step - loss: 7.3241e-07 - accuracy: 1.0000 - val_loss: 1.2112e-04 - val_accuracy: 1.0000\n",
      "Epoch 61/80\n",
      "9240/9240 [==============================] - 1s 85us/step - loss: 6.9656e-07 - accuracy: 1.0000 - val_loss: 1.2232e-04 - val_accuracy: 1.0000\n",
      "Epoch 62/80\n",
      "9240/9240 [==============================] - 1s 86us/step - loss: 6.5960e-07 - accuracy: 1.0000 - val_loss: 1.2831e-04 - val_accuracy: 1.0000\n",
      "Epoch 63/80\n",
      "9240/9240 [==============================] - 1s 85us/step - loss: 6.2350e-07 - accuracy: 1.0000 - val_loss: 1.1459e-04 - val_accuracy: 1.0000\n",
      "Epoch 64/80\n",
      "9240/9240 [==============================] - 1s 86us/step - loss: 5.9223e-07 - accuracy: 1.0000 - val_loss: 1.1612e-04 - val_accuracy: 1.0000\n",
      "Epoch 65/80\n",
      "9240/9240 [==============================] - 1s 86us/step - loss: 5.6787e-07 - accuracy: 1.0000 - val_loss: 1.1491e-04 - val_accuracy: 1.0000\n",
      "Epoch 66/80\n",
      "9240/9240 [==============================] - 1s 87us/step - loss: 5.3509e-07 - accuracy: 1.0000 - val_loss: 1.1089e-04 - val_accuracy: 1.0000\n",
      "Epoch 67/80\n",
      "9240/9240 [==============================] - 1s 87us/step - loss: 5.1098e-07 - accuracy: 1.0000 - val_loss: 1.0634e-04 - val_accuracy: 1.0000\n",
      "Epoch 68/80\n",
      "9240/9240 [==============================] - 1s 86us/step - loss: 4.8226e-07 - accuracy: 1.0000 - val_loss: 1.0494e-04 - val_accuracy: 1.0000\n",
      "Epoch 69/80\n",
      "9240/9240 [==============================] - 1s 88us/step - loss: 4.5707e-07 - accuracy: 1.0000 - val_loss: 1.0159e-04 - val_accuracy: 1.0000\n",
      "Epoch 70/80\n",
      "9240/9240 [==============================] - 1s 86us/step - loss: 4.3201e-07 - accuracy: 1.0000 - val_loss: 1.0128e-04 - val_accuracy: 1.0000\n",
      "Epoch 71/80\n",
      "9240/9240 [==============================] - 1s 88us/step - loss: 4.1238e-07 - accuracy: 1.0000 - val_loss: 1.0163e-04 - val_accuracy: 1.0000\n",
      "Epoch 72/80\n",
      "9240/9240 [==============================] - 1s 89us/step - loss: 3.8439e-07 - accuracy: 1.0000 - val_loss: 9.6242e-05 - val_accuracy: 1.0000\n",
      "Epoch 73/80\n",
      "9240/9240 [==============================] - 1s 87us/step - loss: 3.6953e-07 - accuracy: 1.0000 - val_loss: 8.7371e-05 - val_accuracy: 1.0000\n",
      "Epoch 74/80\n",
      "9240/9240 [==============================] - 1s 87us/step - loss: 3.4845e-07 - accuracy: 1.0000 - val_loss: 8.8636e-05 - val_accuracy: 1.0000\n",
      "Epoch 75/80\n",
      "9240/9240 [==============================] - 1s 87us/step - loss: 3.3293e-07 - accuracy: 1.0000 - val_loss: 8.7502e-05 - val_accuracy: 1.0000\n",
      "Epoch 76/80\n",
      "9240/9240 [==============================] - 1s 86us/step - loss: 3.1077e-07 - accuracy: 1.0000 - val_loss: 9.2576e-05 - val_accuracy: 1.0000\n",
      "Epoch 77/80\n",
      "9240/9240 [==============================] - 1s 85us/step - loss: 2.9919e-07 - accuracy: 1.0000 - val_loss: 8.6247e-05 - val_accuracy: 1.0000\n",
      "Epoch 78/80\n",
      "9240/9240 [==============================] - 1s 85us/step - loss: 2.8538e-07 - accuracy: 1.0000 - val_loss: 8.6013e-05 - val_accuracy: 1.0000\n",
      "Epoch 79/80\n",
      "9240/9240 [==============================] - 1s 86us/step - loss: 2.7488e-07 - accuracy: 1.0000 - val_loss: 8.2222e-05 - val_accuracy: 1.0000\n",
      "Epoch 80/80\n",
      "9240/9240 [==============================] - 1s 86us/step - loss: 2.5579e-07 - accuracy: 1.0000 - val_loss: 8.1894e-05 - val_accuracy: 1.0000\n",
      "[[1.4914552e-03 3.1970745e-10 2.9827150e-09 ... 9.9263847e-01\n",
      "  5.5815680e-03 2.6344258e-06]\n",
      " [7.2397188e-07 3.5618611e-13 2.8714199e-12 ... 7.4741794e-03\n",
      "  9.9252397e-01 1.0746938e-06]\n",
      " [1.4815510e-07 1.0483689e-09 1.3169441e-10 ... 9.8685676e-01\n",
      "  1.3133002e-02 5.8499404e-06]\n",
      " ...\n",
      " [6.9628090e-21 4.1850848e-21 1.6465101e-21 ... 2.7621904e-18\n",
      "  1.0000000e+00 3.6526832e-18]\n",
      " [9.3744059e-16 9.8445165e-23 5.0820417e-23 ... 2.3328003e-10\n",
      "  1.2456355e-16 2.5358309e-18]\n",
      " [2.8586994e-20 5.3559504e-21 2.0490780e-19 ... 3.7049414e-19\n",
      "  1.0000000e+00 5.5588163e-23]]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[6 7 6 ... 7 3 7]\n",
      "<class 'numpy.ndarray'>\n",
      "One CNN, r:  3\n",
      "Computing Time:  0:04:29.374261\n",
      "Model: \"sequential_1\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv1d_1 (Conv1D)            (None, 1000, 6)           36        \n",
      "_________________________________________________________________\n",
      "average_pooling1d_1 (Average (None, 500, 6)            0         \n",
      "_________________________________________________________________\n",
      "conv1d_2 (Conv1D)            (None, 496, 16)           496       \n",
      "_________________________________________________________________\n",
      "average_pooling1d_2 (Average (None, 248, 16)           0         \n",
      "_________________________________________________________________\n",
      "conv1d_3 (Conv1D)            (None, 244, 120)          9720      \n",
      "_________________________________________________________________\n",
      "flatten_1 (Flatten)          (None, 29280)             0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 84)                2459604   \n",
      "_________________________________________________________________\n",
      "preds (Dense)                (None, 9)                 765       \n",
      "=================================================================\n",
      "Total params: 2,470,621\n",
      "Trainable params: 2,470,621\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Train on 9240 samples, validate on 1027 samples\n",
      "Epoch 1/80\n",
      "9240/9240 [==============================] - 1s 120us/step - loss: 0.2143 - accuracy: 0.9384 - val_loss: 0.0067 - val_accuracy: 0.9990\n",
      "Epoch 2/80\n",
      "9240/9240 [==============================] - 1s 86us/step - loss: 0.0024 - accuracy: 0.9996 - val_loss: 0.0030 - val_accuracy: 0.9990\n",
      "Epoch 3/80\n",
      "9240/9240 [==============================] - 1s 87us/step - loss: 0.0018 - accuracy: 0.9998 - val_loss: 0.0061 - val_accuracy: 0.9971\n",
      "Epoch 4/80\n",
      "9240/9240 [==============================] - 1s 85us/step - loss: 8.6804e-04 - accuracy: 0.9998 - val_loss: 0.0014 - val_accuracy: 1.0000\n",
      "Epoch 5/80\n",
      "9240/9240 [==============================] - 1s 86us/step - loss: 1.5989e-04 - accuracy: 1.0000 - val_loss: 0.0010 - val_accuracy: 1.0000\n",
      "Epoch 6/80\n",
      "9240/9240 [==============================] - 1s 86us/step - loss: 9.2984e-05 - accuracy: 1.0000 - val_loss: 9.9521e-04 - val_accuracy: 1.0000\n",
      "Epoch 7/80\n",
      "9240/9240 [==============================] - 1s 86us/step - loss: 6.5220e-05 - accuracy: 1.0000 - val_loss: 8.3120e-04 - val_accuracy: 1.0000\n",
      "Epoch 8/80\n",
      "9240/9240 [==============================] - 1s 86us/step - loss: 5.3025e-05 - accuracy: 1.0000 - val_loss: 8.2207e-04 - val_accuracy: 1.0000\n",
      "Epoch 9/80\n",
      "9240/9240 [==============================] - 1s 86us/step - loss: 4.2244e-05 - accuracy: 1.0000 - val_loss: 7.9207e-04 - val_accuracy: 1.0000\n",
      "Epoch 10/80\n",
      "9240/9240 [==============================] - 1s 87us/step - loss: 3.4912e-05 - accuracy: 1.0000 - val_loss: 7.5829e-04 - val_accuracy: 1.0000\n",
      "Epoch 11/80\n",
      "9240/9240 [==============================] - 1s 86us/step - loss: 2.9894e-05 - accuracy: 1.0000 - val_loss: 8.2208e-04 - val_accuracy: 1.0000\n",
      "Epoch 12/80\n",
      "9240/9240 [==============================] - 1s 84us/step - loss: 2.6026e-05 - accuracy: 1.0000 - val_loss: 7.0559e-04 - val_accuracy: 1.0000\n",
      "Epoch 13/80\n",
      "9240/9240 [==============================] - 1s 85us/step - loss: 2.2513e-05 - accuracy: 1.0000 - val_loss: 6.7229e-04 - val_accuracy: 1.0000\n",
      "Epoch 14/80\n",
      "9240/9240 [==============================] - 1s 86us/step - loss: 1.9840e-05 - accuracy: 1.0000 - val_loss: 6.4553e-04 - val_accuracy: 1.0000\n",
      "Epoch 15/80\n",
      "9240/9240 [==============================] - 1s 87us/step - loss: 1.7525e-05 - accuracy: 1.0000 - val_loss: 5.6226e-04 - val_accuracy: 1.0000\n",
      "Epoch 16/80\n",
      "9240/9240 [==============================] - 1s 86us/step - loss: 1.5445e-05 - accuracy: 1.0000 - val_loss: 5.4901e-04 - val_accuracy: 1.0000\n",
      "Epoch 17/80\n",
      "9240/9240 [==============================] - 1s 87us/step - loss: 1.3601e-05 - accuracy: 1.0000 - val_loss: 5.4092e-04 - val_accuracy: 1.0000\n",
      "Epoch 18/80\n",
      "9240/9240 [==============================] - 1s 85us/step - loss: 1.2337e-05 - accuracy: 1.0000 - val_loss: 5.1061e-04 - val_accuracy: 1.0000\n",
      "Epoch 19/80\n",
      "9240/9240 [==============================] - 1s 86us/step - loss: 1.1058e-05 - accuracy: 1.0000 - val_loss: 5.4099e-04 - val_accuracy: 1.0000\n",
      "Epoch 20/80\n",
      "9240/9240 [==============================] - 1s 88us/step - loss: 1.0107e-05 - accuracy: 1.0000 - val_loss: 4.7817e-04 - val_accuracy: 1.0000\n",
      "Epoch 21/80\n",
      "9240/9240 [==============================] - 1s 88us/step - loss: 9.3610e-06 - accuracy: 1.0000 - val_loss: 4.8588e-04 - val_accuracy: 1.0000\n",
      "Epoch 22/80\n",
      "9240/9240 [==============================] - 1s 86us/step - loss: 8.3973e-06 - accuracy: 1.0000 - val_loss: 4.8241e-04 - val_accuracy: 1.0000\n",
      "Epoch 23/80\n",
      "9240/9240 [==============================] - 1s 86us/step - loss: 7.6301e-06 - accuracy: 1.0000 - val_loss: 5.6237e-04 - val_accuracy: 1.0000\n",
      "Epoch 24/80\n",
      "9240/9240 [==============================] - 1s 84us/step - loss: 7.0429e-06 - accuracy: 1.0000 - val_loss: 4.5981e-04 - val_accuracy: 1.0000\n",
      "Epoch 25/80\n",
      "9240/9240 [==============================] - 1s 86us/step - loss: 6.5511e-06 - accuracy: 1.0000 - val_loss: 4.5761e-04 - val_accuracy: 1.0000\n",
      "Epoch 26/80\n",
      "9240/9240 [==============================] - 1s 83us/step - loss: 5.9661e-06 - accuracy: 1.0000 - val_loss: 4.2355e-04 - val_accuracy: 1.0000\n",
      "Epoch 27/80\n",
      "9240/9240 [==============================] - 1s 87us/step - loss: 5.5864e-06 - accuracy: 1.0000 - val_loss: 4.2891e-04 - val_accuracy: 1.0000\n",
      "Epoch 28/80\n",
      "9240/9240 [==============================] - 1s 87us/step - loss: 5.1803e-06 - accuracy: 1.0000 - val_loss: 4.1310e-04 - val_accuracy: 1.0000\n",
      "Epoch 29/80\n",
      "9240/9240 [==============================] - 1s 86us/step - loss: 4.7865e-06 - accuracy: 1.0000 - val_loss: 3.8748e-04 - val_accuracy: 1.0000\n",
      "Epoch 30/80\n",
      "9240/9240 [==============================] - 1s 86us/step - loss: 4.4502e-06 - accuracy: 1.0000 - val_loss: 3.9548e-04 - val_accuracy: 1.0000\n",
      "Epoch 31/80\n",
      "9240/9240 [==============================] - 1s 85us/step - loss: 4.1164e-06 - accuracy: 1.0000 - val_loss: 3.8619e-04 - val_accuracy: 1.0000\n",
      "Epoch 32/80\n",
      "9240/9240 [==============================] - 1s 85us/step - loss: 3.9419e-06 - accuracy: 1.0000 - val_loss: 3.9919e-04 - val_accuracy: 1.0000\n",
      "Epoch 33/80\n",
      "9240/9240 [==============================] - 1s 87us/step - loss: 3.5679e-06 - accuracy: 1.0000 - val_loss: 3.9037e-04 - val_accuracy: 1.0000\n",
      "Epoch 34/80\n",
      "9240/9240 [==============================] - 1s 87us/step - loss: 3.3801e-06 - accuracy: 1.0000 - val_loss: 3.7748e-04 - val_accuracy: 1.0000\n",
      "Epoch 35/80\n",
      "9240/9240 [==============================] - 1s 86us/step - loss: 3.1864e-06 - accuracy: 1.0000 - val_loss: 3.5754e-04 - val_accuracy: 1.0000\n",
      "Epoch 36/80\n",
      "9240/9240 [==============================] - 1s 88us/step - loss: 2.9745e-06 - accuracy: 1.0000 - val_loss: 3.3675e-04 - val_accuracy: 1.0000\n",
      "Epoch 37/80\n",
      "9240/9240 [==============================] - 1s 87us/step - loss: 2.8665e-06 - accuracy: 1.0000 - val_loss: 3.4767e-04 - val_accuracy: 1.0000\n",
      "Epoch 38/80\n",
      "9240/9240 [==============================] - 1s 85us/step - loss: 2.6398e-06 - accuracy: 1.0000 - val_loss: 3.5027e-04 - val_accuracy: 1.0000\n",
      "Epoch 39/80\n",
      "9240/9240 [==============================] - 1s 86us/step - loss: 2.4898e-06 - accuracy: 1.0000 - val_loss: 3.4272e-04 - val_accuracy: 1.0000\n",
      "Epoch 40/80\n",
      "9240/9240 [==============================] - 1s 86us/step - loss: 2.3096e-06 - accuracy: 1.0000 - val_loss: 3.3003e-04 - val_accuracy: 1.0000\n",
      "Epoch 41/80\n",
      "9240/9240 [==============================] - 1s 87us/step - loss: 2.2237e-06 - accuracy: 1.0000 - val_loss: 3.2608e-04 - val_accuracy: 1.0000\n",
      "Epoch 42/80\n",
      "9240/9240 [==============================] - 1s 88us/step - loss: 2.0763e-06 - accuracy: 1.0000 - val_loss: 3.1343e-04 - val_accuracy: 1.0000\n",
      "Epoch 43/80\n",
      "9240/9240 [==============================] - 1s 87us/step - loss: 1.9621e-06 - accuracy: 1.0000 - val_loss: 3.0460e-04 - val_accuracy: 1.0000\n",
      "Epoch 44/80\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9240/9240 [==============================] - 1s 85us/step - loss: 1.8485e-06 - accuracy: 1.0000 - val_loss: 2.9878e-04 - val_accuracy: 1.0000\n",
      "Epoch 45/80\n",
      "9240/9240 [==============================] - 1s 86us/step - loss: 1.7591e-06 - accuracy: 1.0000 - val_loss: 2.9997e-04 - val_accuracy: 1.0000\n",
      "Epoch 46/80\n",
      "9240/9240 [==============================] - 1s 87us/step - loss: 1.6489e-06 - accuracy: 1.0000 - val_loss: 3.0032e-04 - val_accuracy: 1.0000\n",
      "Epoch 47/80\n",
      "9240/9240 [==============================] - 1s 85us/step - loss: 1.5557e-06 - accuracy: 1.0000 - val_loss: 2.8740e-04 - val_accuracy: 1.0000\n",
      "Epoch 48/80\n",
      "9240/9240 [==============================] - 1s 88us/step - loss: 1.4722e-06 - accuracy: 1.0000 - val_loss: 3.0150e-04 - val_accuracy: 1.0000\n",
      "Epoch 49/80\n",
      "9240/9240 [==============================] - 1s 86us/step - loss: 1.3870e-06 - accuracy: 1.0000 - val_loss: 2.7732e-04 - val_accuracy: 1.0000\n",
      "Epoch 50/80\n",
      "9240/9240 [==============================] - 1s 86us/step - loss: 1.3285e-06 - accuracy: 1.0000 - val_loss: 2.8930e-04 - val_accuracy: 1.0000\n",
      "Epoch 51/80\n",
      "9240/9240 [==============================] - 1s 86us/step - loss: 1.2541e-06 - accuracy: 1.0000 - val_loss: 2.6163e-04 - val_accuracy: 1.0000\n",
      "Epoch 52/80\n",
      "9240/9240 [==============================] - 1s 85us/step - loss: 1.1923e-06 - accuracy: 1.0000 - val_loss: 2.7757e-04 - val_accuracy: 1.0000\n",
      "Epoch 53/80\n",
      "9240/9240 [==============================] - 1s 86us/step - loss: 1.1292e-06 - accuracy: 1.0000 - val_loss: 2.6254e-04 - val_accuracy: 1.0000\n",
      "Epoch 54/80\n",
      "9240/9240 [==============================] - 1s 86us/step - loss: 1.0837e-06 - accuracy: 1.0000 - val_loss: 2.5705e-04 - val_accuracy: 1.0000\n",
      "Epoch 55/80\n",
      "9240/9240 [==============================] - 1s 88us/step - loss: 1.0376e-06 - accuracy: 1.0000 - val_loss: 2.5608e-04 - val_accuracy: 1.0000\n",
      "Epoch 56/80\n",
      "9240/9240 [==============================] - 1s 86us/step - loss: 9.7079e-07 - accuracy: 1.0000 - val_loss: 2.6624e-04 - val_accuracy: 1.0000\n",
      "Epoch 57/80\n",
      "9240/9240 [==============================] - 1s 86us/step - loss: 9.2981e-07 - accuracy: 1.0000 - val_loss: 2.4207e-04 - val_accuracy: 1.0000\n",
      "Epoch 58/80\n",
      "9240/9240 [==============================] - 1s 86us/step - loss: 8.8687e-07 - accuracy: 1.0000 - val_loss: 2.5445e-04 - val_accuracy: 1.0000\n",
      "Epoch 59/80\n",
      "9240/9240 [==============================] - 1s 86us/step - loss: 8.3341e-07 - accuracy: 1.0000 - val_loss: 2.4574e-04 - val_accuracy: 1.0000\n",
      "Epoch 60/80\n",
      "9240/9240 [==============================] - 1s 84us/step - loss: 7.9194e-07 - accuracy: 1.0000 - val_loss: 2.4768e-04 - val_accuracy: 1.0000\n",
      "Epoch 61/80\n",
      "9240/9240 [==============================] - 1s 88us/step - loss: 7.7892e-07 - accuracy: 1.0000 - val_loss: 2.4643e-04 - val_accuracy: 1.0000\n",
      "Epoch 62/80\n",
      "9240/9240 [==============================] - 1s 87us/step - loss: 7.2568e-07 - accuracy: 1.0000 - val_loss: 2.3719e-04 - val_accuracy: 1.0000\n",
      "Epoch 63/80\n",
      "9240/9240 [==============================] - 1s 88us/step - loss: 6.9049e-07 - accuracy: 1.0000 - val_loss: 2.2878e-04 - val_accuracy: 1.0000\n",
      "Epoch 64/80\n",
      "9240/9240 [==============================] - 1s 87us/step - loss: 6.5600e-07 - accuracy: 1.0000 - val_loss: 2.3101e-04 - val_accuracy: 1.0000\n",
      "Epoch 65/80\n",
      "9240/9240 [==============================] - 1s 85us/step - loss: 6.3023e-07 - accuracy: 1.0000 - val_loss: 2.1981e-04 - val_accuracy: 1.0000\n",
      "Epoch 66/80\n",
      "9240/9240 [==============================] - 1s 86us/step - loss: 5.9636e-07 - accuracy: 1.0000 - val_loss: 2.2381e-04 - val_accuracy: 1.0000\n",
      "Epoch 67/80\n",
      "9240/9240 [==============================] - 1s 85us/step - loss: 5.6910e-07 - accuracy: 1.0000 - val_loss: 2.1875e-04 - val_accuracy: 1.0000\n",
      "Epoch 68/80\n",
      "9240/9240 [==============================] - 1s 86us/step - loss: 5.4855e-07 - accuracy: 1.0000 - val_loss: 2.1408e-04 - val_accuracy: 1.0000\n",
      "Epoch 69/80\n",
      "9240/9240 [==============================] - 1s 86us/step - loss: 5.1885e-07 - accuracy: 1.0000 - val_loss: 2.0817e-04 - val_accuracy: 1.0000\n",
      "Epoch 70/80\n",
      "9240/9240 [==============================] - 1s 88us/step - loss: 4.9711e-07 - accuracy: 1.0000 - val_loss: 2.1493e-04 - val_accuracy: 1.0000\n",
      "Epoch 71/80\n",
      "9240/9240 [==============================] - 1s 86us/step - loss: 4.8897e-07 - accuracy: 1.0000 - val_loss: 2.1576e-04 - val_accuracy: 1.0000\n",
      "Epoch 72/80\n",
      "9240/9240 [==============================] - 1s 86us/step - loss: 4.5258e-07 - accuracy: 1.0000 - val_loss: 2.0270e-04 - val_accuracy: 1.0000\n",
      "Epoch 73/80\n",
      "9240/9240 [==============================] - 1s 85us/step - loss: 4.3334e-07 - accuracy: 1.0000 - val_loss: 2.0315e-04 - val_accuracy: 1.0000\n",
      "Epoch 74/80\n",
      "9240/9240 [==============================] - 1s 86us/step - loss: 4.1502e-07 - accuracy: 1.0000 - val_loss: 2.0043e-04 - val_accuracy: 1.0000\n",
      "Epoch 75/80\n",
      "9240/9240 [==============================] - 1s 87us/step - loss: 3.9694e-07 - accuracy: 1.0000 - val_loss: 1.9571e-04 - val_accuracy: 1.0000\n",
      "Epoch 76/80\n",
      "9240/9240 [==============================] - 1s 86us/step - loss: 3.7424e-07 - accuracy: 1.0000 - val_loss: 2.0904e-04 - val_accuracy: 1.0000\n",
      "Epoch 77/80\n",
      "9240/9240 [==============================] - 1s 86us/step - loss: 3.6147e-07 - accuracy: 1.0000 - val_loss: 1.9929e-04 - val_accuracy: 1.0000\n",
      "Epoch 78/80\n",
      "9240/9240 [==============================] - 1s 87us/step - loss: 3.4787e-07 - accuracy: 1.0000 - val_loss: 1.9396e-04 - val_accuracy: 1.0000\n",
      "Epoch 79/80\n",
      "9240/9240 [==============================] - 1s 87us/step - loss: 3.2855e-07 - accuracy: 1.0000 - val_loss: 1.8733e-04 - val_accuracy: 1.0000\n",
      "Epoch 80/80\n",
      "9240/9240 [==============================] - 1s 86us/step - loss: 3.1528e-07 - accuracy: 1.0000 - val_loss: 1.8882e-04 - val_accuracy: 1.0000\n",
      "[[3.0656119e-03 2.4238926e-08 2.7549303e-08 ... 9.4954705e-01\n",
      "  4.7118481e-02 3.7248108e-05]\n",
      " [1.1190188e-05 3.0804109e-10 6.0447154e-11 ... 4.4830713e-02\n",
      "  9.5513839e-01 1.8825911e-05]\n",
      " [5.9435079e-09 7.6913170e-11 5.1783744e-10 ... 9.8322725e-01\n",
      "  1.6772330e-02 3.1168929e-07]\n",
      " ...\n",
      " [6.4508896e-18 4.1741653e-20 5.6215215e-19 ... 2.4423622e-18\n",
      "  1.0000000e+00 1.5632415e-16]\n",
      " [1.9073551e-15 5.7350239e-18 1.7535033e-21 ... 1.7798986e-09\n",
      "  4.2882843e-15 8.1141445e-15]\n",
      " [1.1212073e-16 5.2464118e-20 5.7575423e-16 ... 2.4690871e-19\n",
      "  1.0000000e+00 4.6932273e-21]]\n",
      "[6 7 6 ... 7 3 7]\n",
      "<class 'numpy.ndarray'>\n",
      "One CNN, r:  4\n",
      "Computing Time:  0:05:36.671182\n",
      "num of merged_region_image 0 1734\n",
      "num of merged_region_image 1 1972\n",
      "num of merged_region_image 2 216\n",
      "num of merged_region_image 3 985\n",
      "num of merged_region_image 4 143\n",
      "num of merged_region_image 5 96\n",
      "num of merged_region_image 6 2915\n",
      "num of merged_region_image 7 1997\n",
      "num of merged_region_image 8 209\n",
      "Counter({6: 2915, -1: 2809, 7: 1997, 1: 1972, 0: 1734, 3: 985, 2: 216, 8: 209, 4: 143, 5: 96})\n",
      "===========  ITE = 4   ===========\n",
      "used_img 10267 10267\n",
      "working_img(=other images=unclean images) 2809 2809\n",
      "merged regions 62 62\n",
      "other_regions 137 137\n",
      "All other regions\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>other index</th>\n",
       "      <th>pred label</th>\n",
       "      <th>truth</th>\n",
       "      <th>rate</th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>7</td>\n",
       "      <td>-1</td>\n",
       "      <td>8</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>65</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>9</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>10</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>18</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>132</th>\n",
       "      <td>192</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>133</th>\n",
       "      <td>193</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>134</th>\n",
       "      <td>195</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>135</th>\n",
       "      <td>196</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>136</th>\n",
       "      <td>198</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>137 rows × 13 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     other index  pred label  truth  rate  0  1  2  3  4  5  6  7   8\n",
       "0              2           0      0   0.0  0  0  0  0  0  0  0  0   0\n",
       "1              7          -1      8   0.0  0  0  0  0  0  0  0  0  65\n",
       "2              9           0      0   0.0  0  0  0  0  0  0  0  0   0\n",
       "3             10           0      0   0.0  0  0  0  0  0  0  0  0   0\n",
       "4             18           0      0   0.0  0  0  0  0  0  0  0  0   0\n",
       "..           ...         ...    ...   ... .. .. .. .. .. .. .. ..  ..\n",
       "132          192           0      0   0.0  0  0  0  0  0  0  0  0   0\n",
       "133          193           0      0   0.0  0  0  0  0  0  0  0  0   0\n",
       "134          195           0      0   0.0  0  0  0  0  0  0  0  0   0\n",
       "135          196           0      0   0.0  0  0  0  0  0  0  0  0   0\n",
       "136          198           0      0   0.0  0  0  0  0  0  0  0  0   0\n",
       "\n",
       "[137 rows x 13 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tSNE_table (13076, 3)\n",
      "pairwise_dist (2809, 2809)\n",
      "nei_table_images (2809, 10)\n",
      "working_img_label [-1 -1 -1 ... -1  0 -1]\n",
      "add residuals  306\n",
      "number of next merged_region_image 10573\n"
     ]
    }
   ],
   "source": [
    "for case_i in range(NUM_CASE):\n",
    "\n",
    "    #===== create folder case1, case2, case3...\n",
    "    print(\"case=\",case_i+1)\n",
    "    newpath = './case' + str(case_i+1)\n",
    "    if (not INTE_bool):\n",
    "        if not os.path.exists(newpath):   #No necessary in Integration\n",
    "            os.makedirs(newpath)\n",
    "    \n",
    "    #==== open csv 1\n",
    "    csv_path1 = newpath+'/' + 'accu_history.csv'\n",
    "    with open(csv_path1, 'a', newline='') as f:\n",
    "        csv_file = csv.writer(f)\n",
    "        csv_file.writerow(['ITE', 'correct', 'denominator', 'accu', 'description'])\n",
    "\n",
    "# 1.\n",
    "    if (not INTE_bool):\n",
    "        create_image_0(PATH6, case_i)   #No necessary in Integration\n",
    "\n",
    "\n",
    "    for ITE in range(ITE_START, ITE_END):\n",
    "# 2. CNN\n",
    "        CNN_part(PATH5,ITE)\n",
    "\n",
    "# 3. statistic\n",
    "        statistic(PATH5,ITE)\n",
    "\n",
    "# 4. merged_and_expand \n",
    "        merged_and_expand(PATH5,ITE)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Interpret the accuracy results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(overall 5-consensus)\n",
      "criterion 1\n",
      "correct in 5-consensus\n",
      "------------------------------------\n",
      "5-consensus\n",
      "\n",
      "ITE 0     8149 / 11565 = 0.705\n",
      "ITE 1     9985 / 11595 = 0.861\n",
      "ITE 2     10220 / 12000 = 0.852\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "criterion 2\n",
      "correct in 5-consensus\n",
      "------------------------------------\n",
      "all\n",
      "\n",
      "ITE 0     8149 / 13076 = 0.623\n",
      "ITE 1     9985 / 13076 = 0.764\n",
      "ITE 2     10220 / 13076 = 0.782\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "(clean)\n",
      "criterion 3\n",
      "correct in train in 5-consensus\n",
      "------------------------------------\n",
      "train in 5-consensus\n",
      "\n",
      "ITE 0     3264 / 3601 = 0.9059999999999999\n",
      "ITE 1     7217 / 7824 = 0.922\n",
      "ITE 2     7934 / 8876 = 0.894\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "criterion 4\n",
      "correct in train in 5-consensus \n",
      "------------------------------------\n",
      "all\n",
      "\n",
      "ITE 0     3264 / 13076 = 0.25\n",
      "ITE 1     7217 / 13076 = 0.552\n",
      "ITE 2     7934 / 13076 = 0.607\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "(unclean)\n",
      "criterion 5\n",
      "correct in test in 5-consensus\n",
      "------------------------------------\n",
      "test in 5-consensus\n",
      "\n",
      "ITE 0     4886 / 9475 = 0.516\n",
      "ITE 1     2772 / 5252 = 0.528\n",
      "ITE 2     2287 / 4200 = 0.545\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "criterion 6\n",
      "correct in test in 5-consensus\n",
      "------------------------------------\n",
      "all\n",
      "\n",
      "ITE 0     4886 / 13076 = 0.374\n",
      "ITE 1     2772 / 13076 = 0.212\n",
      "ITE 2     2287 / 13076 = 0.175\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "(majority)\n",
      "criterion 7\n",
      "correct\n",
      "------------------\n",
      "all\n",
      "\n",
      "ITE 0     8763 / 13076 = 0.67\n",
      "ITE 1     10654 / 13076 = 0.815\n",
      "ITE 2     10789 / 13076 = 0.825\n",
      "\n",
      "\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "interpret_accu_results(interpret_path, AMOUNT_ITE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "done\n"
     ]
    }
   ],
   "source": [
    "print(\"done\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
