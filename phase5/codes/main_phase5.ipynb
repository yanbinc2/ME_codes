{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***\n",
    "### <span style='color:green'> ME Algorithm  &emsp;&emsp; May, 2024 </span>\n",
    "### <span style='color:Blue'> Phase 5 </span>\n",
    "### <p> Yan-Bin Chen (陳彥賓) &emsp; yanbin@ntu.edu.tw </p>\n",
    "### <p> Master Program in Statistics, National Taiwan University, Taipei, Taiwan.</p>\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas\n",
    "import numpy as np\n",
    "import pickle\n",
    "import os\n",
    "import csv\n",
    "import time\n",
    "import datetime\n",
    "import collections\n",
    "from itertools import chain\n",
    "from scipy.spatial.distance import squareform, pdist"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Input"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# input\n",
    "PATH4='../../phase3/data/ResNet18_PlantDisease_45K_Spec200.csv'\n",
    "PATH5='../../phase3/data/embedded_data.pickle'\n",
    "PATH6='../data/mergedseedclasslabels.txt'\n",
    "PATH7='../../phase3/data/region_for_phase5.pickle'\n",
    "\n",
    "\n",
    "# === parameters ===================================================\n",
    "MNIST     = False\n",
    "NUM_CASE  = 1\n",
    "INTE_bool = False  #True: Integrate two networks VGG+ResNet    False: single network\n",
    "SAVE_bool = True\n",
    "ITE_FROM  = 5 # This setting is ONLY for Integration\n",
    "REG_COLUMN = \"Spec200\"\n",
    "RAW_2D_DATA = False\n",
    "interpret_path='./case1/accu_history.csv'  #interprete the accuracy results\n",
    "AMOUNT_ITE=3\n",
    "\n",
    "\n",
    "if RAW_2D_DATA: # 2D\n",
    "    from CNN_Modules import ME_CNN\n",
    "else: # 1D\n",
    "    from CNN_Modules_1D import ME_CNN\n",
    "    \n",
    "\n",
    "if (INTE_bool):\n",
    "    ITE_START=ITE_FROM\n",
    "    ITE_END=ITE_FROM+4\n",
    "else:\n",
    "    ITE_START=0\n",
    "    ITE_END=5"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Define functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def append_csv(x, path):\n",
    "    with open(path,'a+', newline='') as f:\n",
    "        csv_file = csv.writer(f)#   = f.write()\n",
    "        csv_file.writerow(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Only for single network. No necessary in Integrated networks\n",
    "if (not INTE_bool):\n",
    "    def create_image_0(PATH6, case_i):\n",
    "        # ===================\n",
    "        #\n",
    "        #  prepare  merged_region_image_0\n",
    "        #\n",
    "        #====================\n",
    "        # (A)\n",
    "        #get \"(1)merged_region\"      only seed regions, no neighboring regions\n",
    "        df = pandas.read_csv(PATH6, delim_whitespace=' ', header=0,  index_col=None)\n",
    "        table = df.to_numpy()\n",
    "        print(\"mergedseedclasslabels table\")\n",
    "        display(table)\n",
    "\n",
    "        merged_region=[]\n",
    "        for i in range(min(table.T[case_i+1]), max(table.T[case_i+1])+1):  #18 ---merge to --> 10\n",
    "            addr=np.where(table.T[case_i+1]==i)[0] # 2nd column equal to 0(min),1,2,3...10(max); DO NOT consider 3rd column, which is hidden\n",
    "            if(len(addr) and i>0): #if not empty and i=0 is the invalid seed region.\n",
    "                merged_region.append(table[addr][:,0].tolist())\n",
    "        print(\"merged_region\")\n",
    "        display(merged_region)\n",
    "\n",
    "\n",
    "        # (B)\n",
    "        #get \"merged_reg_and_nei\"\n",
    "        #get \"merged_reg_and_nei_image\"\n",
    "        #generate \"merged_region_image_0.pickle\"\n",
    "\n",
    "        # (B_a)=== without neighbors ====\n",
    "        #if ((DATASET == 2) or (DATASET == 4)): \n",
    "        ##20240105\n",
    "        if (not True): \n",
    "            # ==== collect regions. No neighbors, just use merged regions ====\n",
    "            merged_reg_and_nei=merged_region.copy()\n",
    "\n",
    "            # ==== collect images ====\n",
    "            img_temp=[]\n",
    "            for i in range(len(merged_region)):\n",
    "                addr=[]\n",
    "                for j in range(len(merged_region[i])):\n",
    "                    temp=np.where(all_region_index==merged_region[i][j])[0].tolist()   #tolist(): convert temp into list\n",
    "                    addr=addr+temp\n",
    "                    print(len(temp),end=' ')\n",
    "                img_temp.append(addr)\n",
    "                print(\"=\",len(img_temp[i]))\n",
    "            merged_reg_and_nei_image = img_temp.copy()\n",
    "\n",
    "\n",
    "        # (B_b)=== with neighbors ==== \n",
    "        else: \n",
    "            with open(PATH7, 'rb') as f:\n",
    "                pre_region, pre_reg_nei, pre_region_image_pure, pre_region_image= pickle.load(f)\n",
    "            #    1reg         2reg+nei        1's img            2's img\n",
    "\n",
    "            # ==== collect regions with neighbors====\n",
    "            # remove duplicate  -->  https://stackoverflow.com/questions/9835762/how-do-i-find-the-duplicates-in-a-list-and-create-another-list-with-them\n",
    "            merged_reg_and_nei=[]\n",
    "            NUM_region=len(merged_region)\n",
    "            for i in range(NUM_region):\n",
    "                temp=[]\n",
    "                for j in range(len(merged_region[i])):\n",
    "                    idx=np.where(pre_region==merged_region[i][j])[0][0] \n",
    "                    temp=temp+pre_reg_nei[idx]\n",
    "                    print(idx,pre_region[idx])\n",
    "                merged_reg_and_nei.append(temp)\n",
    "\n",
    "\n",
    "                #check whether it has duplicates\n",
    "                if (len(merged_reg_and_nei[i]) != len(set(merged_reg_and_nei[i]))):\n",
    "                    a=merged_reg_and_nei[i].copy()\n",
    "\n",
    "                    # find the duplicate.\n",
    "                    seen = set()\n",
    "                    dupli                 = [x for x in a if (x in seen or seen.add(x))]\n",
    "                    print(\"***duplicates:\",dupli)\n",
    "\n",
    "                    # keep fisrt one, remove succeeding duplicates.\n",
    "                    seen = set()\n",
    "                    merged_reg_and_nei[i] = [x for x in a if not (x in seen or seen.add(x))]  # a is the data to process; x is a working varialbe\n",
    "                    print(\"unique:\",merged_reg_and_nei[i])\n",
    "\n",
    "                print(\"total\",len(merged_reg_and_nei[i]),end=\"\\n\\n\")\n",
    "\n",
    "\n",
    "            print(\"\\nmerged_reg_and_nei\")\n",
    "            for i in range(len(merged_reg_and_nei)):\n",
    "                print(merged_reg_and_nei[i])\n",
    "\n",
    "\n",
    "            # Collect images\n",
    "            merged_reg_and_nei_image=[]\n",
    "            for i in range(NUM_region):\n",
    "                #search and add\n",
    "                img=[]\n",
    "                for j in range(len(merged_region[i])):\n",
    "                    idx=np.where(pre_region==merged_region[i][j])[0][0]\n",
    "                    print(len(pre_region_image[idx]),\"(\",idx,\")\",end=' ')\n",
    "                    img=img+pre_region_image[idx] \n",
    "                print(\"=\",len(img),end=\" \")\n",
    "\n",
    "                #check whether it has duplicates\n",
    "                if (len(img) != len(set(img))):\n",
    "                    img=list(set(img)) #remove duplicates\n",
    "                    print(\"     **duplicate, shrink to\",len(img),end=\"\\n\")  \n",
    "                else:\n",
    "                    print(end=\"\\n\")\n",
    "\n",
    "                #append\n",
    "                merged_reg_and_nei_image.append(img)\n",
    "\n",
    "            print(\"\\nmerged_reg_and_nei_image\")\n",
    "            for i in range(len(merged_reg_and_nei_image)):\n",
    "                print(len(merged_reg_and_nei_image[i]),merged_reg_and_nei_image[i][:5],\"...\")\n",
    "\n",
    "        # save\n",
    "        if (SAVE_bool):\n",
    "            with open(newpath+'/merged_region_image_0.pickle', 'wb') as f:\n",
    "                pickle.dump([merged_reg_and_nei, merged_reg_and_nei_image], f)     "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def CNN_part(PATH5,ITE):\n",
    "    TRIALS          = 5\n",
    "\n",
    "    savelog_path = newpath+'/' + 'log.txt'\n",
    "\n",
    "    # ==== test_array ====\n",
    "    with open(PATH5, 'rb') as f:\n",
    "        test_array, test_label_answer = pickle.load(f)\n",
    "        \n",
    "    if RAW_2D_DATA: # 2D\n",
    "        print(\"\")\n",
    "    else: # 1D\n",
    "        test_array = np.expand_dims(test_array, axis = -1)\n",
    "\n",
    "    \n",
    "    #if((DATASET==2) or (DATASET==4)):\n",
    "    #    test_array = np.expand_dims(test_array, axis = -1)\n",
    "    #elif(DATASET==1):\n",
    "    #    test_array = np.expand_dims(test_array, axis = -1)\n",
    "    #    test_array /= 255\n",
    "    #elif(DATASET==0):\n",
    "    #    test_array /= 255\n",
    "    #display(np.shape(test_array))\n",
    "\n",
    "\n",
    "    with open(newpath+'/merged_region_image_'+str(ITE)+'.pickle', 'rb') as f:\n",
    "        merged_reg_and_nei, merged_region_image = pickle.load(f)\n",
    "    region_image=merged_region_image.copy()\n",
    "    del merged_reg_and_nei\n",
    "\n",
    "\n",
    "    NUM_region=len(region_image)\n",
    "    print(\"NUM_region\",NUM_region)\n",
    "\n",
    "\n",
    "    from itertools import chain\n",
    "    region_image_flatten=list(chain.from_iterable(region_image))\n",
    "    print(\"number of clean images\",len(region_image_flatten))\n",
    "\n",
    "\n",
    "    ROUND_start = time.time()\n",
    "    #========  merge ==========\n",
    "    #prepare selected_region, region\n",
    "    for n in range(1): #extra_original\n",
    "    #   #reset\n",
    "        region=region_image.copy()\n",
    "        region=list(region)\n",
    "        selected_region = list(range(NUM_region))  #[0,1,2, ... ,29]\n",
    "\n",
    "        #merge\n",
    "        if (n > 4):\n",
    "            p1=comb[n-1][0]\n",
    "            p2=comb[n-1][1]\n",
    "            region[p1]=region[p1]+region[p2]\n",
    "            region.pop(p2)\n",
    "            selected_region.pop(-1)  # remove last region index\n",
    "        #original\n",
    "        else:  #n=0\n",
    "            p1=0\n",
    "            p2=0\n",
    "\n",
    "        print(\"n, p1, p2\", n, p1, p2)\n",
    "\n",
    "\n",
    "        # ===== one CNN =============\n",
    "        NUM_CLASSES = len(selected_region)  #NUM_CLASSES should be here to update for each loop\n",
    "        \n",
    "        # Clip the numeber of class. The \"test_label_answer\" is just for the verification. The changed \"test_label_answer\"\n",
    "        # doesn't affact the CNN predictions.\n",
    "        if NUM_CLASSES < len(np.unique(test_label_answer)):\n",
    "            test_label_answer=np.clip(test_label_answer, 0, NUM_CLASSES-1)\n",
    "\n",
    "        # input image and label\n",
    "        Input_img     = []\n",
    "        Input_img_len = []\n",
    "        for c,sel in enumerate(selected_region, start=0):\n",
    "            Input_img = Input_img + list(region[sel])\n",
    "            Input_img_len.append(len(region[sel])) #can only concatenate list (not \"int\") to list    \n",
    "            \n",
    "        # 20240319\n",
    "        if RAW_2D_DATA: # 2D\n",
    "            W           = np.shape(test_array[0])[0]\n",
    "            H           = np.shape(test_array[0])[1]\n",
    "            train_array = np.zeros((len(Input_img), W, H), dtype=float)\n",
    "            for i in range (len(Input_img)):\n",
    "                train_array[i] = test_array[Input_img[i]].reshape(W,H)\n",
    "        else: # 1D\n",
    "            W           = np.shape(test_array[0])[0]\n",
    "            train_array = np.zeros((len(Input_img), W), dtype=float)\n",
    "            for i in range (len(Input_img)):\n",
    "                train_array[i] = test_array[Input_img[i]].reshape(W)\n",
    "                  \n",
    "        train_array = np.expand_dims(train_array, axis = -1)\n",
    "\n",
    "\n",
    "        # fill up the training label to each training image\n",
    "        current_train_label = np.zeros(len(train_array), dtype=int)  # Assign 0 to the label\n",
    "        accum_base=0  #accumulate\n",
    "        for label in range(1,NUM_CLASSES):\n",
    "            sector = Input_img_len[label-1]\n",
    "            accum_base = accum_base + sector  # sector is the sector length\n",
    "            current_train_label[accum_base:] = label  # fill the label\n",
    "\n",
    "\n",
    "        # CNN\n",
    "        #===============================================\n",
    "        one_predicted_results  = np.zeros((TRIALS, len(test_label_answer)), dtype=int)\n",
    "        one_predict_percentage = np.zeros((TRIALS, len(test_label_answer), NUM_CLASSES), dtype=float)    \n",
    "        model_history = np.zeros(TRIALS, dtype=list)\n",
    "        print(\"NUM_CLASSES\",NUM_CLASSES)\n",
    "        print(\"current_train_label: \",list(set(current_train_label)))\n",
    "        for r in range(TRIALS):  #10\n",
    "            one_predicted_results[r], one_predict_percentage[r], model_history[r] = ME_CNN(\n",
    "                    x_train     = train_array,\n",
    "                    train_label = current_train_label,\n",
    "                    test_array  = test_array,\n",
    "                    true_answer = test_label_answer,\n",
    "                    Num_Classes = NUM_CLASSES\n",
    "                    )\n",
    "            print(type(model_history))\n",
    "\n",
    "\n",
    "            # ===== delete CNN tensors =====\n",
    "            from keras import backend as K\n",
    "            K.clear_session()\n",
    "            import gc\n",
    "            gc.collect()\n",
    "\n",
    "            print(\"One CNN, r: \",r)\n",
    "            ROUND_duration = time.time() - ROUND_start\n",
    "            print(\"Computing Time: \", str(datetime.timedelta(seconds=ROUND_duration)))\n",
    "\n",
    "\n",
    "        # === save to file ===\n",
    "        #This is useless in phase IV. Prepare for further checking in the future.\n",
    "        savefile_path = str(newpath) +  '/(classes=' + str(NUM_CLASSES)+')_n0_R' + str(p1) + '+R'+ str(p2) +'_trial' + str(n)+'_'+str(ITE)+'.pickle'  #extra_original\n",
    "        with open(savefile_path, 'wb') as f:\n",
    "            pickle.dump([Input_img, Input_img_len, one_predicted_results, one_predict_percentage, model_history], f)\n",
    "\n",
    "        savefile_path2 = str(newpath) +  '/(classes=' + str(NUM_CLASSES)+')_5_tests_simple_ITE'+str(ITE)+'.pickle'  #extra_original\n",
    "        with open(savefile_path2, 'wb') as f:\n",
    "            pickle.dump([one_predicted_results, one_predict_percentage], f)\n",
    "\n",
    "        # === save to log ===    \n",
    "        savelog = open(savelog_path, 'a+')\n",
    "        print(\"\\n\", savefile_path, file = savelog)\n",
    "        print(\"Saved parameters: Input_img, Input_img_len, one_predicted_results, one_predict_percentage\", file = savelog) #0722\n",
    "\n",
    "        # total time\n",
    "        ROUND_duration = time.time() - ROUND_start\n",
    "        print(\"Completion time: \", datetime.datetime.now(), file = savelog)\n",
    "        print(\"Total Computing Time: \", str(datetime.timedelta(seconds=ROUND_duration)), file = savelog)\n",
    "\n",
    "        savelog.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def statistic_method(PATH5,NUM_region,region_label,table_1D):\n",
    "    with open(PATH5, 'rb') as f:\n",
    "        test_array, test_label_answer = pickle.load(f)\n",
    "    del test_array\n",
    "    \n",
    "    dist_table_truth=np.zeros((NUM_region, len(np.unique(test_label_answer))),dtype=int)   # [6 x 9] matrix. The size of \"NUM_region\" may be less than answer.\n",
    "    region_correct=[]\n",
    "    region_amount=[]\n",
    "    overall_correct=0\n",
    "    overall_amount=0\n",
    "    for i in range(NUM_region):\n",
    "        #(1) input\n",
    "        region_image=np.where(table_1D==i)[0]\n",
    "        #region_image=merged_region_image[i].copy()\n",
    "        \n",
    "        #(2) establish confusion matrix\n",
    "        for j in range(len(np.unique(test_label_answer))):\n",
    "            dist_table_truth[i][j]=len(np.where(test_label_answer[region_image]==j)[0]) #the number of images which equals to true answer \n",
    "        \n",
    "        #(3) statisitc\n",
    "        region_correct.append(dist_table_truth[i][region_label[i]])\n",
    "        region_amount.append(len(region_image))\n",
    "      \n",
    "    #(4) statistic for overall\n",
    "    overall_correct=sum(region_correct)\n",
    "    overall_amount=sum(region_amount)\n",
    "\n",
    "    return region_correct, region_amount, overall_correct, overall_amount, dist_table_truth"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def statistic(PATH5,ITE):\n",
    "    # input 1:\n",
    "    # (1)merged_region_image_(ITE)\n",
    "    with open(newpath+'/merged_region_image_'+str(ITE)+'.pickle', 'rb') as f:\n",
    "        merged_reg_and_nei, merged_region_image = pickle.load(f)\n",
    "    del merged_reg_and_nei\n",
    "    NUM_region=len(merged_region_image)\n",
    "    \n",
    "    # (2)test_label_answer\n",
    "    with open(PATH5, 'rb') as f:\n",
    "        test_array, test_label_answer = pickle.load(f)\n",
    "    del test_array\n",
    "\n",
    "    # (3)get consistent result table\n",
    "    with open(newpath+'/(classes=' + str(NUM_region) + ')_5_tests_simple_ITE'+str(ITE)+'.pickle', 'rb') as f:\n",
    "        one_predicted_results, one_predict_percentage = pickle.load(f)\n",
    "    del one_predict_percentage\n",
    "    LENGTH=np.shape(one_predicted_results)[1]\n",
    "    Original_result=np.zeros(LENGTH,dtype=int)\n",
    "    for i in range(LENGTH):\n",
    "        if (len(set(one_predicted_results.T[i])) == 1):  # (***)\n",
    "            Original_result[i]=one_predicted_results[0][i]\n",
    "        else:\n",
    "            Original_result[i]=-1\n",
    " \n",
    "    # (4) Obtain the true label (answer) in our estimated region_image\n",
    "    region_label=[] #true label by selecting dominate ones\n",
    "    for i in range(NUM_region):\n",
    "        region_image=merged_region_image[i].copy()\n",
    "        region_label.append(collections.Counter(test_label_answer[region_image]).most_common()[0][0])  #images --> true label --> most_common label\n",
    "    print(\"true region_label=\", region_label)\n",
    "\n",
    "\n",
    "   #========================================     \n",
    "   # (1)train + test\n",
    "    a2,b2,c2,d2,e2=statistic_method(PATH5,NUM_region,region_label,Original_result)\n",
    "    print(\"dist_table_truth\\n\",e2)\n",
    "    na2=np.asarray(a2)\n",
    "    nb2=np.asarray(b2)\n",
    "    nc2=np.asarray(c2)\n",
    "    nd2=np.asarray(d2)\n",
    "    all_num=len(Original_result)\n",
    "    append_csv([ITE, c2, d2,      round(nc2/nd2    ,3), \"5con over all, but 5-consensus\"], csv_path1)\n",
    "    append_csv([ITE, c2, all_num, round(nc2/all_num,3), \"5con over all\"], csv_path1)\n",
    " \n",
    "\n",
    "        \n",
    "    # (2)train\n",
    "    train_results=-1*np.ones(LENGTH,dtype=int)\n",
    "    for i in range(NUM_region):\n",
    "        images=merged_region_image[i]\n",
    "        train_results[images]=i\n",
    "        print(\"num of merged_region_image\",i,len(merged_region_image[i]))\n",
    "    print(collections.Counter(train_results))\n",
    "        \n",
    "    a1,b1,c1,d1,e1=statistic_method(PATH5,NUM_region,region_label,train_results)\n",
    "    na1=np.asarray(a1)  #region_correct\n",
    "    nb1=np.asarray(b1)  #region_amount\n",
    "    nc1=np.asarray(c1)  #overall_correct\n",
    "    nd1=np.asarray(d1)  #overall_amount\n",
    "    all_num=len(Original_result)\n",
    "    append_csv([ITE, c1, d1, round(nc1/nd1,3), \"5con over trained\"], csv_path1)\n",
    "    append_csv([ITE, c1, all_num, round(nc1/all_num,3), \"5con over all\"], csv_path1)\n",
    "    \n",
    "        \n",
    "    # (3)test\n",
    "    # remove training data(good images), only check test data(bad images)\n",
    "    from itertools import chain\n",
    "    used_image=merged_region_image.copy()\n",
    "    used_image=list(chain.from_iterable(used_image))\n",
    "    Original_result2=Original_result.copy()\n",
    "    Original_result2[used_image]=-2\n",
    "\n",
    "        \n",
    "    a4,b4,c4,d4,e4=statistic_method(PATH5,NUM_region,region_label, Original_result2)\n",
    "    na4=np.asarray(a4)\n",
    "    nb4=np.asarray(b4)\n",
    "    nc4=np.asarray(c4)\n",
    "    nd4=np.asarray(d4) #this is len(Original_result)-len(used_image)-len(unconsistent)\n",
    "    untrain=len(Original_result)-len(used_image)\n",
    "    all_num=len(Original_result)\n",
    "    append_csv([ITE, c4, untrain, round(nc4/untrain, 3), \"5con over untrained, but 5-consensus\"], csv_path1)\n",
    "    append_csv([ITE, c4, all_num, round(nc4/all_num, 3), \"5con over untrained (unclean)\"], csv_path1)\n",
    "\n",
    "        \n",
    "    # (4)set majority as label for each image        \n",
    "    # set majority from 5 trias as label for each image\n",
    "    predicted_results_major=np.zeros(LENGTH,dtype=int)\n",
    "    for i in range(LENGTH):\n",
    "        predicted_results_major[i]=collections.Counter(one_predicted_results.T[i]).most_common()[0][0]\n",
    "    \n",
    "\n",
    "    a3,b3,c3,d3,e3=statistic_method(PATH5,NUM_region,region_label,predicted_results_major)\n",
    "    na3=np.asarray(a3)\n",
    "    nb3=np.asarray(b3)\n",
    "    nc3=np.asarray(c3)\n",
    "    nd3=np.asarray(d3) #this is all in majority criterion\n",
    "    append_csv([ITE, c3, d3, round(nc3/nd3    ,3), \"majo over all\"], csv_path1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def merged_and_expand(PATH5,ITE):\n",
    "# all4.\n",
    "    print(\"\\n\\n==== merged_and_expand(PATH5,ITE) ====\")\n",
    "    # load\n",
    "    with open('./region_initials.pickle', 'rb') as f:\n",
    "        all_region_index, all_region_image = pickle.load(f)\n",
    "    MAX_region = max(all_region_index)\n",
    "\n",
    "    with open(newpath+'/merged_region_image_'+str(ITE)+'.pickle', 'rb') as f:\n",
    "        merged_reg_and_nei, merged_region_image = pickle.load(f)\n",
    "    NUM_region = len(merged_reg_and_nei) # NUM_region is the number of clusters\n",
    "\n",
    "    with open(newpath+'/(classes='+str(NUM_region)+')_5_tests_simple_ITE'+str(ITE)+'.pickle', 'rb') as f:\n",
    "        one_predicted_results, one_predict_percentage = pickle.load(f)\n",
    "    del one_predict_percentage\n",
    "\n",
    "    with open(PATH5, 'rb') as f:\n",
    "        test_array, test_label_answer = pickle.load(f)\n",
    "    del test_array\n",
    "\n",
    "\n",
    "    # choose absolutely consistent images\n",
    "    NUM_test=np.shape(one_predicted_results)[1]\n",
    "    Original_result=np.zeros(NUM_test,dtype=int)\n",
    "\n",
    "    # (***)\n",
    "    # As set contains only unique elements, so convert the list to set.\n",
    "    # If set size is 1 then it means all elements in given list are same\n",
    "    for i in range(NUM_test):\n",
    "        if (len(set(one_predicted_results.T[i])) == 1):  # (***)\n",
    "            Original_result[i]=one_predicted_results[0][i]\n",
    "        else:\n",
    "            Original_result[i]=-1\n",
    "    \n",
    "    used_img=list(chain.from_iterable(merged_region_image))\n",
    "    used_img=np.sort(used_img)\n",
    "    working_img = np.asarray(list(  set(range(NUM_test))-set(used_img)  ))  #working_img means the unclean ones for working on the further adding process\n",
    "    print(\"===========  ITE =\",ITE, \"  ===========\")    \n",
    "    print(\"used_img\",len(used_img), len(set(used_img)))    \n",
    "    print(\"working_img(=other images=unclean images)\",len(working_img), len(set(working_img)))\n",
    "\n",
    "    # save clean and unclean images\n",
    "    if (SAVE_bool):\n",
    "        with open(newpath + '/clean_and_unclean_image_ITE='+str(ITE)+'.pickle', 'wb') as f:\n",
    "            pickle.dump([used_img, working_img], f) #used_img is clean, working_img is others\n",
    "\n",
    "    # other_regions\n",
    "    # ==== Process of other regions. Generate \"other_regions\" ====\n",
    "    merged_reg_and_nei_flatten=list(chain.from_iterable(merged_reg_and_nei))\n",
    "    print(\"merged regions\", len(merged_reg_and_nei_flatten), len(set(merged_reg_and_nei_flatten)))\n",
    "    other_regions       = list(  set(range(1,MAX_region+1))-set(merged_reg_and_nei_flatten)  ) #region index exclude used regions. 1 to 200.\n",
    "    print(\"other_regions\",len(other_regions), len(set(other_regions)))\n",
    "    \n",
    "    dmn_img             = [] # Index of dmn_img is consistent with other_regions\n",
    "    NUM_other_regions   = len(other_regions) # number of clusters in other regions\n",
    "    dist_table_truth    = np.zeros((NUM_other_regions,NUM_region),dtype=int)\n",
    "    p_reg_label_dmn     = np.zeros(NUM_other_regions,dtype=int)   #one value. dominate label in predicted lagels.\n",
    "    grd_reg_answer_dmn  = np.zeros(NUM_other_regions,dtype=int)   #one value. dominate label in true answers.\n",
    "    p_reg_dmn_rate      = np.zeros(NUM_other_regions,dtype=float) #one value. dominate ratio in a region\n",
    "\n",
    "    #(1) other_regions      --> establish all other region table \n",
    "    for i,region_name in enumerate(other_regions): #check all other regions\n",
    "\n",
    "        #(a)===== predicted images (multiple values) =====\n",
    "        p_img        = all_region_image[region_name-1] # In this region, get their images. \"region_name-1\" is due to region index starts from 1 to 200\n",
    "        p_img_label  = Original_result[p_img]   # Predicted labels in the region.\n",
    "        p_img_total  = len(p_img)\n",
    "        # the value of predicted labels is the index of trainning region. These indices are the labels\n",
    "        # but these p_img_answer are predicted, may not always be the truth.\n",
    "        if not p_img: # if p_img is empty, skip this loop\n",
    "            dmn_img.append([])\n",
    "            continue\n",
    "\n",
    "        #(b)===== region dominate; one value =====\n",
    "        #region label\n",
    "        p_reg_label_dmn[i] = collections.Counter(p_img_label).most_common()[0][0] # one value\n",
    "        # region dominate rate\n",
    "        if(p_reg_label_dmn[i]>=0):\n",
    "            p_reg_dmn_rate[i] = collections.Counter(p_img_label).most_common()[0][1]/p_img_total\n",
    "        else:              # means invalid label\n",
    "            p_reg_dmn_rate[i] = 0\n",
    "\n",
    "\n",
    "        #(c)==== ground truth =====\n",
    "        grd_label                 = test_label_answer[p_img]  #multiple values\n",
    "        grd_reg_answer_dmn[i]     = collections.Counter(grd_label).most_common()[0][0] #one value\n",
    "\n",
    "\n",
    "        #(d)==== establish confusion table=====\n",
    "        for j in range(NUM_region):\n",
    "            dist_table_truth[i][j]=len(np.where(grd_label==j)[0])\n",
    "\n",
    "\n",
    "        #(e)=== collect dominated images =============\n",
    "        addr2=np.where( (p_img_label==p_reg_label_dmn[i]) & (p_img_label>=0) )[0] # ignore -1 which are non-consistency\n",
    "        #         the labels which  == 7               the labels which >= 0\n",
    "        temp=[]\n",
    "        for k in range(len(addr2)):\n",
    "            temp.append(p_img[addr2[k]])\n",
    "        dmn_img.append(temp)\n",
    "        #=============================================\n",
    "\n",
    "\n",
    "    df1 = pandas.DataFrame({\"other index\":other_regions}) # 1 to 200   other region index\n",
    "    df2 = pandas.DataFrame({\"pred label\":p_reg_label_dmn})      \n",
    "    df4 = pandas.DataFrame({\"truth\":grd_reg_answer_dmn})\n",
    "    df6 = pandas.DataFrame({\"rate\":np.round(p_reg_dmn_rate,2)})\n",
    "    df7 = pandas.DataFrame(dist_table_truth)\n",
    "    entire_table=pandas.concat([df1, df2, df4, df6, df7], axis=1)\n",
    "    print(\"All other regions\")\n",
    "    display(entire_table)\n",
    "\n",
    "\n",
    "\n",
    "    #(2)get regions according to conditions\n",
    "    NN=5 #choose top 5 regions\n",
    "    RATE=0.7\n",
    "    candidate_reg_by_top_NN=[]\n",
    "\n",
    "    # === get candidate regions by the order of dmn label 0 to 9 ====\n",
    "    for i in range(NUM_region):\n",
    "        # (2-1) ==== select region by rate > 0.7 and top 5 ====\n",
    "        index     = np.where(p_reg_label_dmn==i)[0] # index is the index of other_regions(0~183), rather than original entire region index 1 to 200        \n",
    "        working_table = entire_table.iloc[index]\n",
    "        working_table = working_table.sort_values(by=['rate'], ascending=False)\n",
    "        working_table = working_table.loc[working_table['rate'] > RATE]  #rate > 0.7\n",
    "        NUM_region_in_one_class = len(working_table.iloc[:NN])  #top 5\n",
    "               \n",
    "        # (2-2) ==== get candidate regions ====\n",
    "        # get top N records; save only the column 'other_reg', and transfer it to list from DataFrame by \"tolist()\"\n",
    "        candidate_reg_by_top_NN.append(working_table[:NN]['other index'].tolist())\n",
    "         \n",
    "    #(3) add regions and images\n",
    "    for i in range(NUM_region):\n",
    "        added_img=[]\n",
    "        if (len(candidate_reg_by_top_NN[i])>0):\n",
    "            for j in range(len(candidate_reg_by_top_NN[i])):\n",
    "                reg_addr  = np.where( np.array(other_regions)==candidate_reg_by_top_NN[i][j] )[0][0].tolist()\n",
    "                added_img = added_img + dmn_img[reg_addr]\n",
    "            # (3-1) add image\n",
    "            temp=len(merged_region_image[i])\n",
    "            merged_region_image[i] = merged_region_image[i] + added_img\n",
    "            merged_region_image[i] = list(set(merged_region_image[i]))\n",
    "            img_amount=len(merged_region_image[i])-temp\n",
    "            \n",
    "            # (3-2) add region\n",
    "            merged_reg_and_nei[i]  = merged_reg_and_nei[i] + candidate_reg_by_top_NN[i]\n",
    "            \n",
    "            # (3-3) print out\n",
    "            print(\"added label, regions, img amount:\", set(Original_result[added_img]), candidate_reg_by_top_NN[i], img_amount)\n",
    "\n",
    "            \n",
    "    # (4) collect residual images\n",
    "    # This works only for CIFAR10. All images in the MNIST and MNIST-TRAN are clean. No this issue.        \n",
    "    #20240105\n",
    "    if (not MNIST):\n",
    "    #if ((DATASET==2) or (DATASET==4)):\n",
    "        if (len(list(chain.from_iterable(candidate_reg_by_top_NN))) == 0):  #if no extra regions\n",
    "            #20240105\n",
    "            if (True):\n",
    "            #if(DATASET==4):\n",
    "                df = pandas.read_csv(PATH4)\n",
    "                tSNE_table = df.to_numpy()[:,:3]\n",
    "            else:\n",
    "                df = pandas.read_csv(PATH8)\n",
    "                tSNE_table = df.to_numpy()\n",
    "            print(\"tSNE_table\",np.shape(tSNE_table))\n",
    "\n",
    "            working_table=tSNE_table[working_img]\n",
    "            pairwise_dist=squareform(pdist(working_table, 'euclidean'))\n",
    "            print(\"pairwise_dist\",np.shape(pairwise_dist)) #value of data point, rather than image index\n",
    "\n",
    "            TopN=10\n",
    "            M=len(working_img)\n",
    "            nei_table_images  = np.zeros((M,TopN),dtype=int)  #contain top 10 images\n",
    "            nei_table_label   = np.zeros((M,TopN),dtype=int)\n",
    "            working_img_label = np.zeros(M,dtype=int)\n",
    "            for i in range(M):   \n",
    "                # fill up top 10 \n",
    "                addr=np.argsort(pairwise_dist[i])\n",
    "                for j in range(TopN):\n",
    "                    nei_table_images[i][j]=working_img[ addr[j+1] ] #Ignore first one. First one is itself\n",
    "                    nei_table_label[i][j] =Original_result[nei_table_images[i][j]]\n",
    "                # consistent\n",
    "                if (len(set(nei_table_label[i])) == 1): #only get the one which is entire consistent\n",
    "                    working_img_label[i]=nei_table_label[i][0]\n",
    "                else:\n",
    "                    working_img_label[i]=-1\n",
    "\n",
    "            print(\"nei_table_images\",np.shape(nei_table_images))\n",
    "            print(\"working_img_label\",working_img_label)\n",
    "\n",
    "            new_img=[] # just  for monitoring\n",
    "            for i in range(NUM_region):\n",
    "                addr=np.where(working_img_label==i)[0].tolist()\n",
    "                new_img.append(working_img[addr])\n",
    "                merged_region_image[i].extend(working_img[addr])\n",
    "            print(\"add residuals \",len(list(chain.from_iterable(new_img))))\n",
    "            print(\"number of next merged_region_image\", len(list(chain.from_iterable(merged_region_image))))\n",
    "        else:\n",
    "            print(\"Not getting into residuals\")\n",
    "\n",
    "    #save\n",
    "    if (SAVE_bool):\n",
    "        with open(newpath + '/merged_region_image_'+str(ITE+1)+'.pickle', 'wb') as f:\n",
    "            pickle.dump([merged_reg_and_nei, merged_region_image], f)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Makeup region_initials.pickle\n",
    "#### For both single network and integrate network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>X1</th>\n",
       "      <th>X2</th>\n",
       "      <th>X3</th>\n",
       "      <th>Class</th>\n",
       "      <th>Label</th>\n",
       "      <th>Spec200</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-6.131136</td>\n",
       "      <td>-11.714952</td>\n",
       "      <td>14.559869</td>\n",
       "      <td>Cherry</td>\n",
       "      <td>2</td>\n",
       "      <td>100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>4.653914</td>\n",
       "      <td>-15.913769</td>\n",
       "      <td>8.271565</td>\n",
       "      <td>Cherry</td>\n",
       "      <td>2</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>4.666949</td>\n",
       "      <td>-15.911179</td>\n",
       "      <td>8.316633</td>\n",
       "      <td>Cherry</td>\n",
       "      <td>2</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-1.160013</td>\n",
       "      <td>-8.344077</td>\n",
       "      <td>19.694381</td>\n",
       "      <td>Cherry</td>\n",
       "      <td>2</td>\n",
       "      <td>166</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>-0.430728</td>\n",
       "      <td>-5.483346</td>\n",
       "      <td>17.380125</td>\n",
       "      <td>Cherry</td>\n",
       "      <td>2</td>\n",
       "      <td>170</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         X1         X2         X3   Class  Label  Spec200\n",
       "0 -6.131136 -11.714952  14.559869  Cherry      2      100\n",
       "1  4.653914 -15.913769   8.271565  Cherry      2        6\n",
       "2  4.666949 -15.911179   8.316633  Cherry      2        6\n",
       "3 -1.160013  -8.344077  19.694381  Cherry      2      166\n",
       "4 -0.430728  -5.483346  17.380125  Cherry      2      170"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "43217\n",
      "all_region_index\n",
      " [100   6   6 166 170]\n"
     ]
    }
   ],
   "source": [
    "df = pandas.read_csv(PATH4)\n",
    "display(df.head())\n",
    "#all_region_index = df.to_numpy().T[REGION_INDEX_LOC].astype(int)\n",
    "#print(len(all_region_index))\n",
    "all_region_index  = df[REG_COLUMN].to_numpy().astype(int)\n",
    "print(len(all_region_index))\n",
    "print(\"all_region_index\\n\",all_region_index[:5])\n",
    "\n",
    "all_region_image=[]\n",
    "MAX_region=max(all_region_index)\n",
    "for i in range(MAX_region):\n",
    "    addr=list(np.where(all_region_index==i+1)[0])\n",
    "    all_region_image.append(addr)    \n",
    "\n",
    "#save\n",
    "if (SAVE_bool):\n",
    "    with open('./region_initials.pickle', 'wb') as f:\n",
    "        pickle.dump([all_region_index, all_region_image], f)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Main function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def interpret_accu_results(path, AMOUNT_ITE):\n",
    "    df = pandas.read_csv(path)\n",
    "    label_table = df.to_numpy()\n",
    "    NUM_CRI=7  #number of our accuracy criteriors, now is 7\n",
    "    \n",
    "    criterion_string=\\\n",
    "    [ \"correct in 5-consensus\\n------------------------------------\\n5-consensus\\n\",\n",
    "     \"correct in 5-consensus\\n------------------------------------\\nall\\n\",\n",
    "     \"correct in train in 5-consensus\\n------------------------------------\\ntrain in 5-consensus\\n\",\n",
    "     \"correct in train in 5-consensus \\n------------------------------------\\nall\\n\",\n",
    "     \"correct in test in 5-consensus\\n------------------------------------\\ntest in 5-consensus\\n\",\n",
    "     \"correct in test in 5-consensus\\n------------------------------------\\nall\\n\",\n",
    "      \"correct\\n------------------\\nall\\n\",\n",
    "    ]\n",
    "    for SHIFT in range (NUM_CRI):\n",
    "        if (SHIFT+1==1):\n",
    "            print(\"(overall 5-consensus)\")\n",
    "        elif (SHIFT+1==3):\n",
    "            print(\"(clean)\")\n",
    "        elif (SHIFT+1==5):\n",
    "            print(\"(unclean)\")\n",
    "        elif (SHIFT+1==7):\n",
    "            print(\"(majority)\")\n",
    "        print(\"criterion\", SHIFT+1)\n",
    "        print(criterion_string[SHIFT])\n",
    "        for i in range(AMOUNT_ITE):\n",
    "            print(\"ITE\",label_table[NUM_CRI*i+SHIFT].T[0], \"   \",label_table[NUM_CRI*i+SHIFT].T[1],\"/\", label_table[NUM_CRI*i+SHIFT].T[2], \"=\",label_table[NUM_CRI*i+SHIFT].T[3])\n",
    "        print(\"\\n\\n\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "case= 1\n",
      "mergedseedclasslabels table\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[ 33,   3],\n",
       "       [ 95,   0],\n",
       "       [131,   0],\n",
       "       [ 24,   1],\n",
       "       [125,   2],\n",
       "       [ 10,   4],\n",
       "       [ 94,   0],\n",
       "       [192,   2],\n",
       "       [135,   0],\n",
       "       [ 25,   3],\n",
       "       [139,   0],\n",
       "       [168,   0],\n",
       "       [110,   0],\n",
       "       [ 60,   1],\n",
       "       [134,   4],\n",
       "       [ 27,   5],\n",
       "       [ 58,   6],\n",
       "       [ 28,   0]], dtype=int64)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "merged_region\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[[24, 60], [125, 192], [33, 25], [10, 134], [27], [58]]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3 24\n",
      "13 60\n",
      "total 11\n",
      "\n",
      "4 125\n",
      "7 192\n",
      "total 12\n",
      "\n",
      "0 33\n",
      "9 25\n",
      "total 12\n",
      "\n",
      "5 10\n",
      "14 134\n",
      "total 12\n",
      "\n",
      "15 27\n",
      "total 6\n",
      "\n",
      "16 58\n",
      "total 5\n",
      "\n",
      "\n",
      "merged_reg_and_nei\n",
      "[24, 15, 63, 146, 115, 109, 60, 61, 160, 121, 26]\n",
      "[125, 68, 127, 36, 67, 174, 192, 116, 147, 91, 64, 198]\n",
      "[33, 138, 55, 48, 87, 1, 25, 17, 156, 175, 88, 66]\n",
      "[10, 197, 120, 96, 130, 50, 134, 155, 161, 41, 86, 157]\n",
      "[27, 178, 56, 5, 42, 75]\n",
      "[58, 126, 180, 89, 179]\n",
      "1148 ( 3 ) 1068 ( 13 ) = 2216 \n",
      "842 ( 4 ) 1730 ( 7 ) = 2572 \n",
      "2038 ( 0 ) 1195 ( 9 ) = 3233 \n",
      "1324 ( 5 ) 1285 ( 14 ) = 2609 \n",
      "1344 ( 15 ) = 1344 \n",
      "1904 ( 16 ) = 1904 \n",
      "\n",
      "merged_reg_and_nei_image\n",
      "2216 [18223, 18299, 18329, 18370, 18382] ...\n",
      "2572 [8854, 8856, 8885, 8915, 8925] ...\n",
      "3233 [28228, 28235, 28239, 28279, 28281] ...\n",
      "2609 [4427, 4444, 4450, 4459, 4477] ...\n",
      "1344 [23220, 23228, 23232, 23236, 23239] ...\n",
      "1904 [13347, 13348, 13349, 13352, 13353] ...\n",
      "NUM_region 6\n",
      "number of clean images 13878\n",
      "n, p1, p2 0 0 0\n",
      "NUM_CLASSES 6\n",
      "current_train_label:  [0, 1, 2, 3, 4, 5]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_1\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv1d_1 (Conv1D)            (None, 3, 6)              12        \n",
      "_________________________________________________________________\n",
      "average_pooling1d_1 (Average (None, 1, 6)              0         \n",
      "_________________________________________________________________\n",
      "conv1d_2 (Conv1D)            (None, 1, 16)             112       \n",
      "_________________________________________________________________\n",
      "average_pooling1d_2 (Average (None, 1, 16)             0         \n",
      "_________________________________________________________________\n",
      "conv1d_3 (Conv1D)            (None, 1, 120)            2040      \n",
      "_________________________________________________________________\n",
      "flatten_1 (Flatten)          (None, 120)               0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 84)                10164     \n",
      "_________________________________________________________________\n",
      "preds (Dense)                (None, 6)                 510       \n",
      "=================================================================\n",
      "Total params: 12,838\n",
      "Trainable params: 12,838\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Train on 12490 samples, validate on 1388 samples\n",
      "Epoch 1/80\n",
      "12490/12490 [==============================] - 2s 166us/step - loss: 0.9302 - accuracy: 0.6169 - val_loss: 0.5860 - val_accuracy: 0.7558\n",
      "Epoch 2/80\n",
      "12490/12490 [==============================] - 1s 44us/step - loss: 0.4971 - accuracy: 0.7955 - val_loss: 0.4381 - val_accuracy: 0.8019\n",
      "Epoch 3/80\n",
      "12490/12490 [==============================] - 0s 40us/step - loss: 0.3965 - accuracy: 0.8343 - val_loss: 0.3681 - val_accuracy: 0.8429\n",
      "Epoch 4/80\n",
      "12490/12490 [==============================] - 0s 38us/step - loss: 0.3311 - accuracy: 0.8677 - val_loss: 0.3194 - val_accuracy: 0.8739\n",
      "Epoch 5/80\n",
      "12490/12490 [==============================] - 0s 38us/step - loss: 0.2736 - accuracy: 0.8929 - val_loss: 0.2607 - val_accuracy: 0.8948\n",
      "Epoch 6/80\n",
      "12490/12490 [==============================] - 0s 40us/step - loss: 0.2485 - accuracy: 0.8990 - val_loss: 0.2445 - val_accuracy: 0.8919\n",
      "Epoch 7/80\n",
      "12490/12490 [==============================] - 1s 41us/step - loss: 0.2261 - accuracy: 0.9034 - val_loss: 0.2313 - val_accuracy: 0.9071\n",
      "Epoch 8/80\n",
      "12490/12490 [==============================] - 0s 38us/step - loss: 0.2136 - accuracy: 0.9066 - val_loss: 0.2247 - val_accuracy: 0.9027\n",
      "Epoch 9/80\n",
      "12490/12490 [==============================] - 1s 40us/step - loss: 0.2068 - accuracy: 0.9082 - val_loss: 0.2216 - val_accuracy: 0.9071\n",
      "Epoch 10/80\n",
      "12490/12490 [==============================] - 0s 39us/step - loss: 0.2056 - accuracy: 0.9077 - val_loss: 0.2617 - val_accuracy: 0.9006\n",
      "Epoch 11/80\n",
      "12490/12490 [==============================] - 1s 41us/step - loss: 0.2093 - accuracy: 0.9050 - val_loss: 0.1988 - val_accuracy: 0.9099\n",
      "Epoch 12/80\n",
      "12490/12490 [==============================] - 0s 40us/step - loss: 0.1971 - accuracy: 0.9096 - val_loss: 0.1948 - val_accuracy: 0.9085\n",
      "Epoch 13/80\n",
      "12490/12490 [==============================] - 0s 37us/step - loss: 0.1975 - accuracy: 0.9102 - val_loss: 0.1942 - val_accuracy: 0.9035\n",
      "Epoch 14/80\n",
      "12490/12490 [==============================] - 1s 41us/step - loss: 0.1892 - accuracy: 0.9139 - val_loss: 0.1879 - val_accuracy: 0.9114\n",
      "Epoch 15/80\n",
      "12490/12490 [==============================] - 1s 40us/step - loss: 0.1870 - accuracy: 0.9128 - val_loss: 0.2037 - val_accuracy: 0.8955\n",
      "Epoch 16/80\n",
      "12490/12490 [==============================] - 0s 36us/step - loss: 0.1892 - accuracy: 0.9130 - val_loss: 0.1894 - val_accuracy: 0.9143\n",
      "Epoch 17/80\n",
      "12490/12490 [==============================] - 0s 38us/step - loss: 0.1839 - accuracy: 0.9143 - val_loss: 0.1855 - val_accuracy: 0.9114\n",
      "Epoch 18/80\n",
      "12490/12490 [==============================] - 0s 37us/step - loss: 0.1842 - accuracy: 0.9133 - val_loss: 0.1896 - val_accuracy: 0.9150\n",
      "Epoch 19/80\n",
      "12490/12490 [==============================] - 0s 39us/step - loss: 0.1817 - accuracy: 0.9144 - val_loss: 0.1942 - val_accuracy: 0.9020\n",
      "Epoch 20/80\n",
      "12490/12490 [==============================] - 1s 43us/step - loss: 0.1886 - accuracy: 0.9135 - val_loss: 0.1828 - val_accuracy: 0.9135\n",
      "Epoch 21/80\n",
      "12490/12490 [==============================] - 1s 40us/step - loss: 0.1829 - accuracy: 0.9178 - val_loss: 0.1802 - val_accuracy: 0.9114\n",
      "Epoch 22/80\n",
      "12490/12490 [==============================] - 0s 36us/step - loss: 0.1782 - accuracy: 0.9168 - val_loss: 0.1759 - val_accuracy: 0.9200\n",
      "Epoch 23/80\n",
      "12490/12490 [==============================] - 0s 39us/step - loss: 0.1789 - accuracy: 0.9160 - val_loss: 0.1781 - val_accuracy: 0.9171\n",
      "Epoch 24/80\n",
      "12490/12490 [==============================] - 0s 39us/step - loss: 0.1806 - accuracy: 0.9156 - val_loss: 0.1809 - val_accuracy: 0.9143\n",
      "Epoch 25/80\n",
      "12490/12490 [==============================] - 0s 38us/step - loss: 0.1763 - accuracy: 0.9178 - val_loss: 0.1833 - val_accuracy: 0.9215\n",
      "Epoch 26/80\n",
      "12490/12490 [==============================] - 1s 41us/step - loss: 0.1816 - accuracy: 0.9168 - val_loss: 0.1701 - val_accuracy: 0.9229\n",
      "Epoch 27/80\n",
      "12490/12490 [==============================] - 0s 39us/step - loss: 0.1756 - accuracy: 0.9161 - val_loss: 0.1791 - val_accuracy: 0.9157\n",
      "Epoch 28/80\n",
      "12490/12490 [==============================] - 0s 38us/step - loss: 0.1793 - accuracy: 0.9180 - val_loss: 0.1814 - val_accuracy: 0.9099\n",
      "Epoch 29/80\n",
      "12490/12490 [==============================] - 1s 41us/step - loss: 0.1715 - accuracy: 0.9209 - val_loss: 0.1686 - val_accuracy: 0.9164\n",
      "Epoch 30/80\n",
      "12490/12490 [==============================] - 0s 38us/step - loss: 0.1709 - accuracy: 0.9198 - val_loss: 0.1702 - val_accuracy: 0.9186\n",
      "Epoch 31/80\n",
      "12490/12490 [==============================] - 0s 40us/step - loss: 0.1707 - accuracy: 0.9207 - val_loss: 0.1739 - val_accuracy: 0.9236\n",
      "Epoch 32/80\n",
      "12490/12490 [==============================] - 0s 35us/step - loss: 0.1715 - accuracy: 0.9207 - val_loss: 0.1698 - val_accuracy: 0.9301\n",
      "Epoch 33/80\n",
      "12490/12490 [==============================] - 0s 39us/step - loss: 0.1688 - accuracy: 0.9230 - val_loss: 0.1857 - val_accuracy: 0.9099\n",
      "Epoch 34/80\n",
      "12490/12490 [==============================] - 0s 38us/step - loss: 0.1727 - accuracy: 0.9211 - val_loss: 0.1706 - val_accuracy: 0.9179\n",
      "Epoch 35/80\n",
      "12490/12490 [==============================] - 0s 39us/step - loss: 0.1708 - accuracy: 0.9203 - val_loss: 0.1643 - val_accuracy: 0.9229\n",
      "Epoch 36/80\n",
      "12490/12490 [==============================] - 1s 41us/step - loss: 0.1669 - accuracy: 0.9219 - val_loss: 0.1776 - val_accuracy: 0.9128\n",
      "Epoch 37/80\n",
      "12490/12490 [==============================] - 0s 39us/step - loss: 0.1673 - accuracy: 0.9229 - val_loss: 0.1673 - val_accuracy: 0.9308\n",
      "Epoch 38/80\n",
      "12490/12490 [==============================] - 0s 39us/step - loss: 0.1665 - accuracy: 0.9235 - val_loss: 0.1604 - val_accuracy: 0.9280\n",
      "Epoch 39/80\n",
      "12490/12490 [==============================] - 0s 39us/step - loss: 0.1647 - accuracy: 0.9254 - val_loss: 0.1629 - val_accuracy: 0.9222\n",
      "Epoch 40/80\n",
      "12490/12490 [==============================] - 0s 39us/step - loss: 0.1649 - accuracy: 0.9235 - val_loss: 0.1634 - val_accuracy: 0.9222\n",
      "Epoch 41/80\n",
      "12490/12490 [==============================] - 0s 40us/step - loss: 0.1622 - accuracy: 0.9246 - val_loss: 0.1675 - val_accuracy: 0.9150\n",
      "Epoch 42/80\n",
      "12490/12490 [==============================] - 0s 39us/step - loss: 0.1630 - accuracy: 0.9259 - val_loss: 0.1642 - val_accuracy: 0.9193\n",
      "Epoch 43/80\n",
      "12490/12490 [==============================] - 1s 40us/step - loss: 0.1634 - accuracy: 0.9242 - val_loss: 0.1588 - val_accuracy: 0.9229\n",
      "Epoch 44/80\n",
      "12490/12490 [==============================] - 0s 37us/step - loss: 0.1636 - accuracy: 0.9231 - val_loss: 0.1578 - val_accuracy: 0.9308\n",
      "Epoch 45/80\n",
      "12490/12490 [==============================] - 0s 36us/step - loss: 0.1623 - accuracy: 0.9237 - val_loss: 0.1588 - val_accuracy: 0.9244\n",
      "Epoch 46/80\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "12490/12490 [==============================] - 0s 38us/step - loss: 0.1626 - accuracy: 0.9243 - val_loss: 0.1559 - val_accuracy: 0.9251\n",
      "Epoch 47/80\n",
      "12490/12490 [==============================] - 0s 37us/step - loss: 0.1654 - accuracy: 0.9251 - val_loss: 0.1868 - val_accuracy: 0.9215\n",
      "Epoch 48/80\n",
      "12490/12490 [==============================] - 0s 36us/step - loss: 0.1622 - accuracy: 0.9247 - val_loss: 0.1559 - val_accuracy: 0.9280\n",
      "Epoch 49/80\n",
      "12490/12490 [==============================] - 0s 37us/step - loss: 0.1613 - accuracy: 0.9245 - val_loss: 0.1641 - val_accuracy: 0.9164\n",
      "Epoch 50/80\n",
      "12490/12490 [==============================] - 0s 37us/step - loss: 0.1613 - accuracy: 0.9250 - val_loss: 0.1561 - val_accuracy: 0.9294\n",
      "Epoch 51/80\n",
      "12490/12490 [==============================] - 0s 35us/step - loss: 0.1592 - accuracy: 0.9261 - val_loss: 0.1692 - val_accuracy: 0.9157\n",
      "Epoch 52/80\n",
      "12490/12490 [==============================] - 1s 40us/step - loss: 0.1596 - accuracy: 0.9263 - val_loss: 0.1703 - val_accuracy: 0.9236\n",
      "Epoch 53/80\n",
      "12490/12490 [==============================] - 1s 43us/step - loss: 0.1662 - accuracy: 0.9212 - val_loss: 0.1584 - val_accuracy: 0.9236\n",
      "Epoch 54/80\n",
      "12490/12490 [==============================] - 0s 38us/step - loss: 0.1706 - accuracy: 0.9217 - val_loss: 0.1546 - val_accuracy: 0.9344\n",
      "Epoch 55/80\n",
      "12490/12490 [==============================] - 1s 42us/step - loss: 0.1577 - accuracy: 0.9259 - val_loss: 0.1573 - val_accuracy: 0.9287\n",
      "Epoch 56/80\n",
      "12490/12490 [==============================] - 0s 40us/step - loss: 0.1595 - accuracy: 0.9260 - val_loss: 0.1542 - val_accuracy: 0.9280\n",
      "Epoch 57/80\n",
      "12490/12490 [==============================] - 0s 39us/step - loss: 0.1560 - accuracy: 0.9277 - val_loss: 0.1527 - val_accuracy: 0.9265\n",
      "Epoch 58/80\n",
      "12490/12490 [==============================] - 0s 39us/step - loss: 0.1569 - accuracy: 0.9273 - val_loss: 0.1683 - val_accuracy: 0.9207\n",
      "Epoch 59/80\n",
      "12490/12490 [==============================] - 0s 37us/step - loss: 0.1583 - accuracy: 0.9266 - val_loss: 0.1670 - val_accuracy: 0.9236\n",
      "Epoch 60/80\n",
      "12490/12490 [==============================] - 0s 39us/step - loss: 0.1549 - accuracy: 0.9280 - val_loss: 0.1684 - val_accuracy: 0.9251\n",
      "Epoch 61/80\n",
      "12490/12490 [==============================] - 0s 32us/step - loss: 0.1584 - accuracy: 0.9267 - val_loss: 0.1527 - val_accuracy: 0.9265\n",
      "Epoch 62/80\n",
      "12490/12490 [==============================] - 0s 36us/step - loss: 0.1552 - accuracy: 0.9289 - val_loss: 0.1618 - val_accuracy: 0.9251\n",
      "Epoch 63/80\n",
      "12490/12490 [==============================] - 0s 36us/step - loss: 0.1545 - accuracy: 0.9275 - val_loss: 0.1592 - val_accuracy: 0.9301\n",
      "Epoch 64/80\n",
      "12490/12490 [==============================] - 1s 40us/step - loss: 0.1587 - accuracy: 0.9263 - val_loss: 0.1530 - val_accuracy: 0.9265\n",
      "Epoch 65/80\n",
      "12490/12490 [==============================] - 0s 33us/step - loss: 0.1559 - accuracy: 0.9255 - val_loss: 0.1592 - val_accuracy: 0.9301\n",
      "Epoch 66/80\n",
      "12490/12490 [==============================] - 0s 33us/step - loss: 0.1550 - accuracy: 0.9267 - val_loss: 0.1621 - val_accuracy: 0.9280\n",
      "Epoch 67/80\n",
      "12490/12490 [==============================] - 0s 34us/step - loss: 0.1533 - accuracy: 0.9268 - val_loss: 0.1683 - val_accuracy: 0.9215\n",
      "Epoch 68/80\n",
      "12490/12490 [==============================] - 0s 33us/step - loss: 0.1546 - accuracy: 0.9275 - val_loss: 0.1657 - val_accuracy: 0.9200\n",
      "Epoch 69/80\n",
      "12490/12490 [==============================] - 0s 36us/step - loss: 0.1558 - accuracy: 0.9277 - val_loss: 0.1705 - val_accuracy: 0.9229\n",
      "Epoch 70/80\n",
      "12490/12490 [==============================] - 0s 36us/step - loss: 0.1608 - accuracy: 0.9255 - val_loss: 0.1574 - val_accuracy: 0.9287\n",
      "Epoch 71/80\n",
      "12490/12490 [==============================] - 0s 38us/step - loss: 0.1528 - accuracy: 0.9287 - val_loss: 0.1564 - val_accuracy: 0.9280\n",
      "Epoch 00071: early stopping\n",
      "[[1.0000000e+00 1.7342192e-09 4.8209553e-36 1.9136146e-16 5.2840438e-08\n",
      "  5.3286948e-09]\n",
      " [3.3422693e-04 6.3036541e-03 8.4639767e-17 4.5176556e-08 2.9500569e-03\n",
      "  9.9041206e-01]\n",
      " [3.2317490e-04 6.1842282e-03 8.7494301e-17 4.5151427e-08 2.9288561e-03\n",
      "  9.9056375e-01]\n",
      " ...\n",
      " [5.0712035e-14 9.5240907e-12 9.9929130e-01 7.0855051e-04 1.0515237e-11\n",
      "  9.0120018e-08]\n",
      " [7.6169442e-08 6.5912931e-10 9.1020048e-01 2.5923042e-02 6.0835246e-02\n",
      "  3.0411682e-03]\n",
      " [2.2336917e-03 1.5981353e-11 3.0096546e-15 4.1320394e-08 9.9533373e-01\n",
      "  2.4325168e-03]]\n",
      "[0 5 5 ... 2 2 4]\n",
      "<class 'numpy.ndarray'>\n",
      "One CNN, r:  0\n",
      "Computing Time:  0:00:50.619820\n",
      "Model: \"sequential_1\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv1d_1 (Conv1D)            (None, 3, 6)              12        \n",
      "_________________________________________________________________\n",
      "average_pooling1d_1 (Average (None, 1, 6)              0         \n",
      "_________________________________________________________________\n",
      "conv1d_2 (Conv1D)            (None, 1, 16)             112       \n",
      "_________________________________________________________________\n",
      "average_pooling1d_2 (Average (None, 1, 16)             0         \n",
      "_________________________________________________________________\n",
      "conv1d_3 (Conv1D)            (None, 1, 120)            2040      \n",
      "_________________________________________________________________\n",
      "flatten_1 (Flatten)          (None, 120)               0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 84)                10164     \n",
      "_________________________________________________________________\n",
      "preds (Dense)                (None, 6)                 510       \n",
      "=================================================================\n",
      "Total params: 12,838\n",
      "Trainable params: 12,838\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Train on 12490 samples, validate on 1388 samples\n",
      "Epoch 1/80\n",
      "12490/12490 [==============================] - 1s 56us/step - loss: 0.8236 - accuracy: 0.7094 - val_loss: 0.5146 - val_accuracy: 0.7759\n",
      "Epoch 2/80\n",
      "12490/12490 [==============================] - 1s 43us/step - loss: 0.4552 - accuracy: 0.8024 - val_loss: 0.4417 - val_accuracy: 0.8026\n",
      "Epoch 3/80\n",
      "12490/12490 [==============================] - 1s 40us/step - loss: 0.3945 - accuracy: 0.8233 - val_loss: 0.3872 - val_accuracy: 0.8242\n",
      "Epoch 4/80\n",
      "12490/12490 [==============================] - 1s 40us/step - loss: 0.3546 - accuracy: 0.8473 - val_loss: 0.3620 - val_accuracy: 0.8595\n",
      "Epoch 5/80\n",
      "12490/12490 [==============================] - ETA: 0s - loss: 0.3137 - accuracy: 0.86 - 0s 36us/step - loss: 0.3139 - accuracy: 0.8685 - val_loss: 0.3021 - val_accuracy: 0.8768\n",
      "Epoch 6/80\n",
      "12490/12490 [==============================] - 1s 40us/step - loss: 0.2730 - accuracy: 0.8879 - val_loss: 0.2631 - val_accuracy: 0.8927\n",
      "Epoch 7/80\n",
      "12490/12490 [==============================] - 0s 37us/step - loss: 0.2484 - accuracy: 0.8967 - val_loss: 0.2333 - val_accuracy: 0.9071\n",
      "Epoch 8/80\n",
      "12490/12490 [==============================] - 1s 40us/step - loss: 0.2268 - accuracy: 0.9022 - val_loss: 0.2153 - val_accuracy: 0.9121\n",
      "Epoch 9/80\n",
      "12490/12490 [==============================] - 0s 39us/step - loss: 0.2176 - accuracy: 0.9052 - val_loss: 0.2006 - val_accuracy: 0.9179\n",
      "Epoch 10/80\n",
      "12490/12490 [==============================] - 1s 41us/step - loss: 0.2066 - accuracy: 0.9087 - val_loss: 0.1971 - val_accuracy: 0.9164\n",
      "Epoch 11/80\n",
      "12490/12490 [==============================] - 1s 40us/step - loss: 0.2003 - accuracy: 0.9092 - val_loss: 0.1924 - val_accuracy: 0.9179\n",
      "Epoch 12/80\n",
      "12490/12490 [==============================] - 0s 40us/step - loss: 0.1957 - accuracy: 0.9111 - val_loss: 0.1805 - val_accuracy: 0.9229\n",
      "Epoch 13/80\n",
      "12490/12490 [==============================] - 0s 38us/step - loss: 0.1882 - accuracy: 0.9128 - val_loss: 0.2166 - val_accuracy: 0.8970\n",
      "Epoch 14/80\n",
      "12490/12490 [==============================] - 0s 38us/step - loss: 0.1968 - accuracy: 0.9122 - val_loss: 0.2325 - val_accuracy: 0.8963\n",
      "Epoch 15/80\n",
      "12490/12490 [==============================] - 0s 37us/step - loss: 0.1856 - accuracy: 0.9151 - val_loss: 0.1727 - val_accuracy: 0.9244\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 16/80\n",
      "12490/12490 [==============================] - 0s 36us/step - loss: 0.1829 - accuracy: 0.9144 - val_loss: 0.1717 - val_accuracy: 0.9215\n",
      "Epoch 17/80\n",
      "12490/12490 [==============================] - ETA: 0s - loss: 0.1814 - accuracy: 0.91 - 1s 40us/step - loss: 0.1814 - accuracy: 0.9161 - val_loss: 0.1807 - val_accuracy: 0.9207\n",
      "Epoch 18/80\n",
      "12490/12490 [==============================] - 0s 39us/step - loss: 0.1831 - accuracy: 0.9146 - val_loss: 0.1699 - val_accuracy: 0.9280\n",
      "Epoch 19/80\n",
      "12490/12490 [==============================] - 1s 41us/step - loss: 0.1745 - accuracy: 0.9200 - val_loss: 0.1693 - val_accuracy: 0.9258\n",
      "Epoch 20/80\n",
      "12490/12490 [==============================] - 0s 40us/step - loss: 0.1736 - accuracy: 0.9207 - val_loss: 0.1596 - val_accuracy: 0.9294\n",
      "Epoch 21/80\n",
      "12490/12490 [==============================] - 0s 36us/step - loss: 0.1775 - accuracy: 0.9190 - val_loss: 0.1663 - val_accuracy: 0.9229\n",
      "Epoch 22/80\n",
      "12490/12490 [==============================] - 0s 39us/step - loss: 0.1761 - accuracy: 0.9163 - val_loss: 0.1647 - val_accuracy: 0.9294\n",
      "Epoch 23/80\n",
      "12490/12490 [==============================] - 0s 39us/step - loss: 0.1715 - accuracy: 0.9216 - val_loss: 0.1641 - val_accuracy: 0.9251\n",
      "Epoch 24/80\n",
      "12490/12490 [==============================] - 0s 39us/step - loss: 0.1704 - accuracy: 0.9208 - val_loss: 0.1544 - val_accuracy: 0.9280\n",
      "Epoch 25/80\n",
      "12490/12490 [==============================] - 0s 37us/step - loss: 0.1666 - accuracy: 0.9222 - val_loss: 0.1589 - val_accuracy: 0.9280\n",
      "Epoch 26/80\n",
      "12490/12490 [==============================] - 0s 40us/step - loss: 0.1667 - accuracy: 0.9217 - val_loss: 0.1578 - val_accuracy: 0.9265\n",
      "Epoch 27/80\n",
      "12490/12490 [==============================] - 0s 38us/step - loss: 0.1723 - accuracy: 0.9187 - val_loss: 0.1501 - val_accuracy: 0.9344\n",
      "Epoch 28/80\n",
      "12490/12490 [==============================] - 1s 40us/step - loss: 0.1699 - accuracy: 0.9211 - val_loss: 0.1710 - val_accuracy: 0.9222\n",
      "Epoch 29/80\n",
      "12490/12490 [==============================] - 0s 39us/step - loss: 0.1717 - accuracy: 0.9202 - val_loss: 0.1566 - val_accuracy: 0.9251\n",
      "Epoch 30/80\n",
      "12490/12490 [==============================] - 0s 40us/step - loss: 0.1674 - accuracy: 0.9218 - val_loss: 0.1619 - val_accuracy: 0.9236\n",
      "Epoch 31/80\n",
      "12490/12490 [==============================] - 1s 41us/step - loss: 0.1629 - accuracy: 0.9212 - val_loss: 0.1496 - val_accuracy: 0.9323\n",
      "Epoch 32/80\n",
      "12490/12490 [==============================] - 0s 36us/step - loss: 0.1613 - accuracy: 0.9242 - val_loss: 0.1518 - val_accuracy: 0.9258\n",
      "Epoch 33/80\n",
      "12490/12490 [==============================] - 0s 39us/step - loss: 0.1631 - accuracy: 0.9218 - val_loss: 0.1511 - val_accuracy: 0.9280\n",
      "Epoch 34/80\n",
      "12490/12490 [==============================] - 0s 39us/step - loss: 0.1594 - accuracy: 0.9226 - val_loss: 0.1442 - val_accuracy: 0.9352\n",
      "Epoch 35/80\n",
      "12490/12490 [==============================] - 0s 38us/step - loss: 0.1603 - accuracy: 0.9246 - val_loss: 0.1484 - val_accuracy: 0.9287\n",
      "Epoch 36/80\n",
      "12490/12490 [==============================] - 0s 37us/step - loss: 0.1601 - accuracy: 0.9223 - val_loss: 0.1499 - val_accuracy: 0.9316\n",
      "Epoch 37/80\n",
      "12490/12490 [==============================] - 0s 36us/step - loss: 0.1618 - accuracy: 0.9242 - val_loss: 0.1518 - val_accuracy: 0.9272\n",
      "Epoch 38/80\n",
      "12490/12490 [==============================] - 0s 36us/step - loss: 0.1577 - accuracy: 0.9260 - val_loss: 0.1594 - val_accuracy: 0.9251\n",
      "Epoch 39/80\n",
      "12490/12490 [==============================] - 0s 38us/step - loss: 0.1600 - accuracy: 0.9235 - val_loss: 0.1466 - val_accuracy: 0.9316\n",
      "Epoch 40/80\n",
      "12490/12490 [==============================] - 0s 39us/step - loss: 0.1605 - accuracy: 0.9243 - val_loss: 0.1451 - val_accuracy: 0.9337\n",
      "Epoch 41/80\n",
      "12490/12490 [==============================] - 0s 36us/step - loss: 0.1542 - accuracy: 0.9254 - val_loss: 0.1454 - val_accuracy: 0.9272\n",
      "Epoch 42/80\n",
      "12490/12490 [==============================] - 1s 41us/step - loss: 0.1588 - accuracy: 0.9241 - val_loss: 0.1522 - val_accuracy: 0.9366\n",
      "Epoch 43/80\n",
      "12490/12490 [==============================] - 0s 39us/step - loss: 0.1558 - accuracy: 0.9258 - val_loss: 0.1499 - val_accuracy: 0.9287\n",
      "Epoch 44/80\n",
      "12490/12490 [==============================] - 1s 41us/step - loss: 0.1604 - accuracy: 0.9235 - val_loss: 0.1557 - val_accuracy: 0.9215\n",
      "Epoch 00044: early stopping\n",
      "[[9.9999905e-01 3.0801618e-07 1.4163365e-10 6.1521132e-07 5.6746443e-09\n",
      "  1.8812774e-08]\n",
      " [1.0327827e-05 5.8764480e-03 6.1982627e-07 3.2471692e-07 3.4841316e-04\n",
      "  9.9376386e-01]\n",
      " [1.0009261e-05 5.7916315e-03 6.1651059e-07 3.1842720e-07 3.4563415e-04\n",
      "  9.9385178e-01]\n",
      " ...\n",
      " [2.7533648e-07 4.5475673e-08 9.8022205e-01 1.9648742e-02 1.6301038e-10\n",
      "  1.2883633e-04]\n",
      " [3.7247181e-04 8.8928368e-07 9.6987802e-01 1.4298213e-02 8.2967589e-03\n",
      "  7.1536689e-03]\n",
      " [2.0769086e-04 2.6521599e-07 3.9845409e-06 8.7462831e-07 9.9796116e-01\n",
      "  1.8260323e-03]]\n",
      "[0 5 5 ... 2 2 4]\n",
      "<class 'numpy.ndarray'>\n",
      "One CNN, r:  1\n",
      "Computing Time:  0:01:16.666731\n",
      "Model: \"sequential_1\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv1d_1 (Conv1D)            (None, 3, 6)              12        \n",
      "_________________________________________________________________\n",
      "average_pooling1d_1 (Average (None, 1, 6)              0         \n",
      "_________________________________________________________________\n",
      "conv1d_2 (Conv1D)            (None, 1, 16)             112       \n",
      "_________________________________________________________________\n",
      "average_pooling1d_2 (Average (None, 1, 16)             0         \n",
      "_________________________________________________________________\n",
      "conv1d_3 (Conv1D)            (None, 1, 120)            2040      \n",
      "_________________________________________________________________\n",
      "flatten_1 (Flatten)          (None, 120)               0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 84)                10164     \n",
      "_________________________________________________________________\n",
      "preds (Dense)                (None, 6)                 510       \n",
      "=================================================================\n",
      "Total params: 12,838\n",
      "Trainable params: 12,838\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Train on 12490 samples, validate on 1388 samples\n",
      "Epoch 1/80\n",
      "12490/12490 [==============================] - 1s 58us/step - loss: 0.8948 - accuracy: 0.6859 - val_loss: 0.5051 - val_accuracy: 0.7767\n",
      "Epoch 2/80\n",
      "12490/12490 [==============================] - 1s 44us/step - loss: 0.4336 - accuracy: 0.8141 - val_loss: 0.3955 - val_accuracy: 0.8357\n",
      "Epoch 3/80\n",
      "12490/12490 [==============================] - 0s 38us/step - loss: 0.3408 - accuracy: 0.8611 - val_loss: 0.3119 - val_accuracy: 0.8782\n",
      "Epoch 4/80\n",
      "12490/12490 [==============================] - 1s 42us/step - loss: 0.2693 - accuracy: 0.8934 - val_loss: 0.2465 - val_accuracy: 0.8977\n",
      "Epoch 5/80\n",
      "12490/12490 [==============================] - 0s 40us/step - loss: 0.2291 - accuracy: 0.9016 - val_loss: 0.2103 - val_accuracy: 0.9071\n",
      "Epoch 6/80\n",
      "12490/12490 [==============================] - 1s 42us/step - loss: 0.2080 - accuracy: 0.9116 - val_loss: 0.1970 - val_accuracy: 0.9063\n",
      "Epoch 7/80\n",
      "12490/12490 [==============================] - 0s 39us/step - loss: 0.1937 - accuracy: 0.9154 - val_loss: 0.1920 - val_accuracy: 0.9229\n",
      "Epoch 8/80\n",
      "12490/12490 [==============================] - 1s 41us/step - loss: 0.1890 - accuracy: 0.9159 - val_loss: 0.1951 - val_accuracy: 0.9150\n",
      "Epoch 9/80\n",
      "12490/12490 [==============================] - 1s 40us/step - loss: 0.1844 - accuracy: 0.9161 - val_loss: 0.1910 - val_accuracy: 0.9222\n",
      "Epoch 10/80\n",
      "12490/12490 [==============================] - 1s 40us/step - loss: 0.1788 - accuracy: 0.9148 - val_loss: 0.1761 - val_accuracy: 0.9229\n",
      "Epoch 11/80\n",
      "12490/12490 [==============================] - 0s 39us/step - loss: 0.1788 - accuracy: 0.9159 - val_loss: 0.1822 - val_accuracy: 0.9143\n",
      "Epoch 12/80\n",
      "12490/12490 [==============================] - 1s 41us/step - loss: 0.1758 - accuracy: 0.9166 - val_loss: 0.1770 - val_accuracy: 0.9186\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 13/80\n",
      "12490/12490 [==============================] - 1s 40us/step - loss: 0.1710 - accuracy: 0.9179 - val_loss: 0.1736 - val_accuracy: 0.9236\n",
      "Epoch 14/80\n",
      "12490/12490 [==============================] - 0s 39us/step - loss: 0.1692 - accuracy: 0.9218 - val_loss: 0.1701 - val_accuracy: 0.9157\n",
      "Epoch 15/80\n",
      "12490/12490 [==============================] - 1s 40us/step - loss: 0.1667 - accuracy: 0.9203 - val_loss: 0.1739 - val_accuracy: 0.9171\n",
      "Epoch 16/80\n",
      "12490/12490 [==============================] - 0s 39us/step - loss: 0.1676 - accuracy: 0.9207 - val_loss: 0.1756 - val_accuracy: 0.9179\n",
      "Epoch 17/80\n",
      "12490/12490 [==============================] - 1s 40us/step - loss: 0.1649 - accuracy: 0.9226 - val_loss: 0.1640 - val_accuracy: 0.9294\n",
      "Epoch 18/80\n",
      "12490/12490 [==============================] - 0s 35us/step - loss: 0.1632 - accuracy: 0.9218 - val_loss: 0.1742 - val_accuracy: 0.9179\n",
      "Epoch 19/80\n",
      "12490/12490 [==============================] - 0s 39us/step - loss: 0.1643 - accuracy: 0.9247 - val_loss: 0.1673 - val_accuracy: 0.9236\n",
      "Epoch 20/80\n",
      "12490/12490 [==============================] - 1s 40us/step - loss: 0.1651 - accuracy: 0.9222 - val_loss: 0.1709 - val_accuracy: 0.9229\n",
      "Epoch 21/80\n",
      "12490/12490 [==============================] - 1s 40us/step - loss: 0.1602 - accuracy: 0.9229 - val_loss: 0.1638 - val_accuracy: 0.9207\n",
      "Epoch 22/80\n",
      "12490/12490 [==============================] - 0s 39us/step - loss: 0.1624 - accuracy: 0.9244 - val_loss: 0.1580 - val_accuracy: 0.9179\n",
      "Epoch 23/80\n",
      "12490/12490 [==============================] - 1s 41us/step - loss: 0.1605 - accuracy: 0.9231 - val_loss: 0.1660 - val_accuracy: 0.9179\n",
      "Epoch 24/80\n",
      "12490/12490 [==============================] - 0s 39us/step - loss: 0.1558 - accuracy: 0.9266 - val_loss: 0.1586 - val_accuracy: 0.9207\n",
      "Epoch 25/80\n",
      "12490/12490 [==============================] - 0s 38us/step - loss: 0.1562 - accuracy: 0.9241 - val_loss: 0.1585 - val_accuracy: 0.9244\n",
      "Epoch 26/80\n",
      "12490/12490 [==============================] - 1s 40us/step - loss: 0.1557 - accuracy: 0.9261 - val_loss: 0.1571 - val_accuracy: 0.9265\n",
      "Epoch 27/80\n",
      "12490/12490 [==============================] - 1s 40us/step - loss: 0.1574 - accuracy: 0.9256 - val_loss: 0.1730 - val_accuracy: 0.9193\n",
      "Epoch 28/80\n",
      "12490/12490 [==============================] - 0s 40us/step - loss: 0.1553 - accuracy: 0.9246 - val_loss: 0.1519 - val_accuracy: 0.9207\n",
      "Epoch 29/80\n",
      "12490/12490 [==============================] - 0s 38us/step - loss: 0.1533 - accuracy: 0.9277 - val_loss: 0.1594 - val_accuracy: 0.9143\n",
      "Epoch 30/80\n",
      "12490/12490 [==============================] - 0s 39us/step - loss: 0.1522 - accuracy: 0.9269 - val_loss: 0.1691 - val_accuracy: 0.9150\n",
      "Epoch 31/80\n",
      "12490/12490 [==============================] - 0s 39us/step - loss: 0.1575 - accuracy: 0.9255 - val_loss: 0.1688 - val_accuracy: 0.9229\n",
      "Epoch 32/80\n",
      "12490/12490 [==============================] - 1s 42us/step - loss: 0.1509 - accuracy: 0.9267 - val_loss: 0.1647 - val_accuracy: 0.9179\n",
      "Epoch 33/80\n",
      "12490/12490 [==============================] - 0s 39us/step - loss: 0.1516 - accuracy: 0.9266 - val_loss: 0.1604 - val_accuracy: 0.9215\n",
      "Epoch 34/80\n",
      "12490/12490 [==============================] - 1s 40us/step - loss: 0.1513 - accuracy: 0.9275 - val_loss: 0.1534 - val_accuracy: 0.9287\n",
      "Epoch 35/80\n",
      "12490/12490 [==============================] - 0s 40us/step - loss: 0.1496 - accuracy: 0.9289 - val_loss: 0.1562 - val_accuracy: 0.9207\n",
      "Epoch 36/80\n",
      "12490/12490 [==============================] - 1s 40us/step - loss: 0.1497 - accuracy: 0.9280 - val_loss: 0.1525 - val_accuracy: 0.9215\n",
      "Epoch 37/80\n",
      "12490/12490 [==============================] - 0s 39us/step - loss: 0.1452 - accuracy: 0.9298 - val_loss: 0.1513 - val_accuracy: 0.9265\n",
      "Epoch 38/80\n",
      "12490/12490 [==============================] - 0s 40us/step - loss: 0.1456 - accuracy: 0.9306 - val_loss: 0.1567 - val_accuracy: 0.9157\n",
      "Epoch 39/80\n",
      "12490/12490 [==============================] - 0s 39us/step - loss: 0.1456 - accuracy: 0.9303 - val_loss: 0.1544 - val_accuracy: 0.9200\n",
      "Epoch 40/80\n",
      "12490/12490 [==============================] - 0s 38us/step - loss: 0.1457 - accuracy: 0.9303 - val_loss: 0.1493 - val_accuracy: 0.9272\n",
      "Epoch 41/80\n",
      "12490/12490 [==============================] - 1s 40us/step - loss: 0.1431 - accuracy: 0.9316 - val_loss: 0.1530 - val_accuracy: 0.9229\n",
      "Epoch 42/80\n",
      "12490/12490 [==============================] - 0s 39us/step - loss: 0.1455 - accuracy: 0.9279 - val_loss: 0.1487 - val_accuracy: 0.9265\n",
      "Epoch 43/80\n",
      "12490/12490 [==============================] - 0s 39us/step - loss: 0.1458 - accuracy: 0.9288 - val_loss: 0.1540 - val_accuracy: 0.9294\n",
      "Epoch 44/80\n",
      "12490/12490 [==============================] - 1s 41us/step - loss: 0.1442 - accuracy: 0.9301 - val_loss: 0.1518 - val_accuracy: 0.9301\n",
      "Epoch 45/80\n",
      "12490/12490 [==============================] - 1s 42us/step - loss: 0.1459 - accuracy: 0.9293 - val_loss: 0.1489 - val_accuracy: 0.9280\n",
      "Epoch 46/80\n",
      "12490/12490 [==============================] - 1s 41us/step - loss: 0.1525 - accuracy: 0.9254 - val_loss: 0.1482 - val_accuracy: 0.9265\n",
      "Epoch 47/80\n",
      "12490/12490 [==============================] - 0s 40us/step - loss: 0.1476 - accuracy: 0.9287 - val_loss: 0.1599 - val_accuracy: 0.9179\n",
      "Epoch 48/80\n",
      "12490/12490 [==============================] - 1s 41us/step - loss: 0.1417 - accuracy: 0.9301 - val_loss: 0.1514 - val_accuracy: 0.9236\n",
      "Epoch 49/80\n",
      "12490/12490 [==============================] - 0s 40us/step - loss: 0.1413 - accuracy: 0.9314 - val_loss: 0.1662 - val_accuracy: 0.9272\n",
      "Epoch 50/80\n",
      "12490/12490 [==============================] - 0s 35us/step - loss: 0.1408 - accuracy: 0.9319 - val_loss: 0.1589 - val_accuracy: 0.9236\n",
      "Epoch 51/80\n",
      "12490/12490 [==============================] - 1s 40us/step - loss: 0.1449 - accuracy: 0.9292 - val_loss: 0.1513 - val_accuracy: 0.9251\n",
      "Epoch 52/80\n",
      "12490/12490 [==============================] - 0s 37us/step - loss: 0.1439 - accuracy: 0.9306 - val_loss: 0.1495 - val_accuracy: 0.9207\n",
      "Epoch 53/80\n",
      "12490/12490 [==============================] - 0s 38us/step - loss: 0.1439 - accuracy: 0.9315 - val_loss: 0.1519 - val_accuracy: 0.9265\n",
      "Epoch 54/80\n",
      "12490/12490 [==============================] - 0s 38us/step - loss: 0.1397 - accuracy: 0.9313 - val_loss: 0.1422 - val_accuracy: 0.9258\n",
      "Epoch 55/80\n",
      "12490/12490 [==============================] - 1s 42us/step - loss: 0.1389 - accuracy: 0.9337 - val_loss: 0.1496 - val_accuracy: 0.9280\n",
      "Epoch 56/80\n",
      "12490/12490 [==============================] - 0s 40us/step - loss: 0.1405 - accuracy: 0.9303 - val_loss: 0.1444 - val_accuracy: 0.9200\n",
      "Epoch 57/80\n",
      "12490/12490 [==============================] - 0s 38us/step - loss: 0.1456 - accuracy: 0.9294 - val_loss: 0.1533 - val_accuracy: 0.9280\n",
      "Epoch 58/80\n",
      "12490/12490 [==============================] - 0s 37us/step - loss: 0.1427 - accuracy: 0.9305 - val_loss: 0.1477 - val_accuracy: 0.9287\n",
      "Epoch 59/80\n",
      "12490/12490 [==============================] - 0s 36us/step - loss: 0.1388 - accuracy: 0.9327 - val_loss: 0.1502 - val_accuracy: 0.9215\n",
      "Epoch 60/80\n",
      "12490/12490 [==============================] - 0s 38us/step - loss: 0.1401 - accuracy: 0.9340 - val_loss: 0.1495 - val_accuracy: 0.9244\n",
      "Epoch 61/80\n",
      "12490/12490 [==============================] - 1s 41us/step - loss: 0.1419 - accuracy: 0.9298 - val_loss: 0.1555 - val_accuracy: 0.9251\n",
      "Epoch 62/80\n",
      "12490/12490 [==============================] - 0s 38us/step - loss: 0.1405 - accuracy: 0.9315 - val_loss: 0.1423 - val_accuracy: 0.9301\n",
      "Epoch 63/80\n",
      "12490/12490 [==============================] - 1s 41us/step - loss: 0.1388 - accuracy: 0.9328 - val_loss: 0.1436 - val_accuracy: 0.9294\n",
      "Epoch 64/80\n",
      "12490/12490 [==============================] - 0s 39us/step - loss: 0.1383 - accuracy: 0.9316 - val_loss: 0.1448 - val_accuracy: 0.9265\n",
      "Epoch 00064: early stopping\n",
      "[[1.00000000e+00 4.34196595e-10 2.84580814e-11 1.13404967e-12\n",
      "  1.27598314e-08 1.88575738e-10]\n",
      " [8.45073519e-05 3.73424427e-03 2.69162274e-06 1.68598451e-08\n",
      "  4.04241990e-04 9.95774329e-01]\n",
      " [8.26310788e-05 3.66808055e-03 2.67406244e-06 1.66089666e-08\n",
      "  4.02266305e-04 9.95844305e-01]\n",
      " ...\n",
      " [4.05245767e-11 4.01951450e-09 9.99953270e-01 4.62074495e-05\n",
      "  1.36485875e-12 4.50979883e-07]\n",
      " [8.50421711e-05 2.37633890e-06 9.87870753e-01 1.16975326e-03\n",
      "  1.02719255e-02 6.00237574e-04]\n",
      " [4.21211356e-04 1.76619523e-07 4.54235851e-06 2.02658029e-10\n",
      "  9.97657418e-01 1.91668794e-03]]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0 5 5 ... 2 2 4]\n",
      "<class 'numpy.ndarray'>\n",
      "One CNN, r:  2\n",
      "Computing Time:  0:01:53.432386\n",
      "Model: \"sequential_1\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv1d_1 (Conv1D)            (None, 3, 6)              12        \n",
      "_________________________________________________________________\n",
      "average_pooling1d_1 (Average (None, 1, 6)              0         \n",
      "_________________________________________________________________\n",
      "conv1d_2 (Conv1D)            (None, 1, 16)             112       \n",
      "_________________________________________________________________\n",
      "average_pooling1d_2 (Average (None, 1, 16)             0         \n",
      "_________________________________________________________________\n",
      "conv1d_3 (Conv1D)            (None, 1, 120)            2040      \n",
      "_________________________________________________________________\n",
      "flatten_1 (Flatten)          (None, 120)               0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 84)                10164     \n",
      "_________________________________________________________________\n",
      "preds (Dense)                (None, 6)                 510       \n",
      "=================================================================\n",
      "Total params: 12,838\n",
      "Trainable params: 12,838\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Train on 12490 samples, validate on 1388 samples\n",
      "Epoch 1/80\n",
      "12490/12490 [==============================] - 1s 59us/step - loss: 0.8804 - accuracy: 0.6958 - val_loss: 0.4885 - val_accuracy: 0.8062\n",
      "Epoch 2/80\n",
      "12490/12490 [==============================] - 1s 44us/step - loss: 0.4388 - accuracy: 0.8106 - val_loss: 0.3961 - val_accuracy: 0.8235\n",
      "Epoch 3/80\n",
      "12490/12490 [==============================] - 1s 41us/step - loss: 0.3731 - accuracy: 0.8401 - val_loss: 0.3218 - val_accuracy: 0.8746\n",
      "Epoch 4/80\n",
      "12490/12490 [==============================] - 0s 40us/step - loss: 0.3099 - accuracy: 0.8757 - val_loss: 0.2652 - val_accuracy: 0.8934\n",
      "Epoch 5/80\n",
      "12490/12490 [==============================] - 1s 42us/step - loss: 0.2545 - accuracy: 0.8966 - val_loss: 0.2285 - val_accuracy: 0.9056\n",
      "Epoch 6/80\n",
      "12490/12490 [==============================] - 0s 38us/step - loss: 0.2238 - accuracy: 0.9054 - val_loss: 0.2079 - val_accuracy: 0.9092\n",
      "Epoch 7/80\n",
      "12490/12490 [==============================] - 0s 38us/step - loss: 0.2120 - accuracy: 0.9091 - val_loss: 0.2010 - val_accuracy: 0.9085\n",
      "Epoch 8/80\n",
      "12490/12490 [==============================] - 0s 38us/step - loss: 0.2078 - accuracy: 0.9072 - val_loss: 0.1970 - val_accuracy: 0.9020\n",
      "Epoch 9/80\n",
      "12490/12490 [==============================] - 1s 42us/step - loss: 0.1985 - accuracy: 0.9090 - val_loss: 0.1895 - val_accuracy: 0.9063\n",
      "Epoch 10/80\n",
      "12490/12490 [==============================] - 1s 42us/step - loss: 0.1942 - accuracy: 0.9110 - val_loss: 0.1898 - val_accuracy: 0.9171\n",
      "Epoch 11/80\n",
      "12490/12490 [==============================] - 0s 38us/step - loss: 0.1949 - accuracy: 0.9095 - val_loss: 0.1837 - val_accuracy: 0.9085\n",
      "Epoch 12/80\n",
      "12490/12490 [==============================] - 0s 39us/step - loss: 0.1947 - accuracy: 0.9098 - val_loss: 0.1898 - val_accuracy: 0.9135\n",
      "Epoch 13/80\n",
      "12490/12490 [==============================] - 0s 39us/step - loss: 0.1906 - accuracy: 0.9109 - val_loss: 0.1890 - val_accuracy: 0.9143\n",
      "Epoch 14/80\n",
      "12490/12490 [==============================] - 0s 39us/step - loss: 0.1875 - accuracy: 0.9098 - val_loss: 0.1790 - val_accuracy: 0.9143\n",
      "Epoch 15/80\n",
      "12490/12490 [==============================] - 0s 40us/step - loss: 0.1855 - accuracy: 0.9132 - val_loss: 0.1781 - val_accuracy: 0.9179\n",
      "Epoch 16/80\n",
      "12490/12490 [==============================] - 0s 38us/step - loss: 0.1828 - accuracy: 0.9133 - val_loss: 0.1799 - val_accuracy: 0.9092\n",
      "Epoch 17/80\n",
      "12490/12490 [==============================] - 0s 36us/step - loss: 0.1811 - accuracy: 0.9147 - val_loss: 0.1918 - val_accuracy: 0.9063\n",
      "Epoch 18/80\n",
      "12490/12490 [==============================] - 0s 39us/step - loss: 0.1858 - accuracy: 0.9112 - val_loss: 0.1748 - val_accuracy: 0.9157\n",
      "Epoch 19/80\n",
      "12490/12490 [==============================] - 0s 39us/step - loss: 0.1780 - accuracy: 0.9146 - val_loss: 0.1783 - val_accuracy: 0.9099\n",
      "Epoch 20/80\n",
      "12490/12490 [==============================] - 0s 37us/step - loss: 0.1799 - accuracy: 0.9138 - val_loss: 0.1774 - val_accuracy: 0.9164\n",
      "Epoch 21/80\n",
      "12490/12490 [==============================] - 0s 39us/step - loss: 0.1779 - accuracy: 0.9150 - val_loss: 0.1774 - val_accuracy: 0.9135\n",
      "Epoch 22/80\n",
      "12490/12490 [==============================] - 0s 40us/step - loss: 0.1759 - accuracy: 0.9143 - val_loss: 0.1864 - val_accuracy: 0.9049\n",
      "Epoch 23/80\n",
      "12490/12490 [==============================] - 0s 38us/step - loss: 0.1779 - accuracy: 0.9148 - val_loss: 0.1827 - val_accuracy: 0.9114\n",
      "Epoch 24/80\n",
      "12490/12490 [==============================] - 0s 39us/step - loss: 0.1745 - accuracy: 0.9139 - val_loss: 0.1852 - val_accuracy: 0.9200\n",
      "Epoch 25/80\n",
      "12490/12490 [==============================] - 0s 38us/step - loss: 0.1766 - accuracy: 0.9154 - val_loss: 0.1776 - val_accuracy: 0.9056\n",
      "Epoch 26/80\n",
      "12490/12490 [==============================] - 0s 37us/step - loss: 0.1722 - accuracy: 0.9175 - val_loss: 0.1762 - val_accuracy: 0.9085\n",
      "Epoch 27/80\n",
      "12490/12490 [==============================] - 0s 39us/step - loss: 0.1751 - accuracy: 0.9163 - val_loss: 0.1688 - val_accuracy: 0.9193\n",
      "Epoch 28/80\n",
      "12490/12490 [==============================] - 0s 38us/step - loss: 0.1730 - accuracy: 0.9152 - val_loss: 0.1694 - val_accuracy: 0.9128\n",
      "Epoch 29/80\n",
      "12490/12490 [==============================] - 1s 40us/step - loss: 0.1753 - accuracy: 0.9124 - val_loss: 0.1737 - val_accuracy: 0.9200\n",
      "Epoch 30/80\n",
      "12490/12490 [==============================] - 0s 40us/step - loss: 0.1797 - accuracy: 0.9133 - val_loss: 0.1954 - val_accuracy: 0.9056\n",
      "Epoch 31/80\n",
      "12490/12490 [==============================] - 1s 41us/step - loss: 0.1727 - accuracy: 0.9165 - val_loss: 0.1649 - val_accuracy: 0.9193\n",
      "Epoch 32/80\n",
      "12490/12490 [==============================] - 0s 38us/step - loss: 0.1680 - accuracy: 0.9171 - val_loss: 0.1637 - val_accuracy: 0.9186\n",
      "Epoch 33/80\n",
      "12490/12490 [==============================] - 1s 40us/step - loss: 0.1662 - accuracy: 0.9179 - val_loss: 0.1664 - val_accuracy: 0.9121\n",
      "Epoch 34/80\n",
      "12490/12490 [==============================] - 0s 39us/step - loss: 0.1680 - accuracy: 0.9170 - val_loss: 0.1618 - val_accuracy: 0.9207\n",
      "Epoch 35/80\n",
      "12490/12490 [==============================] - 0s 39us/step - loss: 0.1677 - accuracy: 0.9176 - val_loss: 0.1641 - val_accuracy: 0.9171\n",
      "Epoch 36/80\n",
      "12490/12490 [==============================] - 0s 39us/step - loss: 0.1679 - accuracy: 0.9184 - val_loss: 0.1898 - val_accuracy: 0.9287\n",
      "Epoch 37/80\n",
      "12490/12490 [==============================] - 0s 37us/step - loss: 0.1705 - accuracy: 0.9196 - val_loss: 0.1700 - val_accuracy: 0.9193\n",
      "Epoch 38/80\n",
      "12490/12490 [==============================] - 0s 36us/step - loss: 0.1683 - accuracy: 0.9196 - val_loss: 0.1633 - val_accuracy: 0.9222\n",
      "Epoch 39/80\n",
      "12490/12490 [==============================] - 0s 38us/step - loss: 0.1663 - accuracy: 0.9194 - val_loss: 0.1694 - val_accuracy: 0.9207\n",
      "Epoch 40/80\n",
      "12490/12490 [==============================] - 0s 40us/step - loss: 0.1653 - accuracy: 0.9200 - val_loss: 0.1676 - val_accuracy: 0.9207\n",
      "Epoch 41/80\n",
      "12490/12490 [==============================] - 1s 41us/step - loss: 0.1654 - accuracy: 0.9215 - val_loss: 0.1722 - val_accuracy: 0.9229\n",
      "Epoch 42/80\n",
      "12490/12490 [==============================] - 1s 45us/step - loss: 0.1634 - accuracy: 0.9223 - val_loss: 0.1674 - val_accuracy: 0.9179\n",
      "Epoch 43/80\n",
      "12490/12490 [==============================] - 0s 40us/step - loss: 0.1604 - accuracy: 0.9224 - val_loss: 0.1630 - val_accuracy: 0.9272\n",
      "Epoch 44/80\n",
      "12490/12490 [==============================] - 0s 39us/step - loss: 0.1625 - accuracy: 0.9219 - val_loss: 0.1568 - val_accuracy: 0.9251\n",
      "Epoch 45/80\n",
      "12490/12490 [==============================] - 0s 40us/step - loss: 0.1628 - accuracy: 0.9215 - val_loss: 0.1618 - val_accuracy: 0.9222\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 46/80\n",
      "12490/12490 [==============================] - 1s 40us/step - loss: 0.1608 - accuracy: 0.9231 - val_loss: 0.1585 - val_accuracy: 0.9215\n",
      "Epoch 47/80\n",
      "12490/12490 [==============================] - 0s 40us/step - loss: 0.1591 - accuracy: 0.9251 - val_loss: 0.1669 - val_accuracy: 0.9244\n",
      "Epoch 48/80\n",
      "12490/12490 [==============================] - 0s 38us/step - loss: 0.1603 - accuracy: 0.9229 - val_loss: 0.1620 - val_accuracy: 0.9150\n",
      "Epoch 49/80\n",
      "12490/12490 [==============================] - 1s 40us/step - loss: 0.1628 - accuracy: 0.9231 - val_loss: 0.1863 - val_accuracy: 0.9258\n",
      "Epoch 50/80\n",
      "12490/12490 [==============================] - 0s 38us/step - loss: 0.1617 - accuracy: 0.9251 - val_loss: 0.1649 - val_accuracy: 0.9222\n",
      "Epoch 51/80\n",
      "12490/12490 [==============================] - 0s 40us/step - loss: 0.1605 - accuracy: 0.9245 - val_loss: 0.1698 - val_accuracy: 0.9193\n",
      "Epoch 52/80\n",
      "12490/12490 [==============================] - 1s 41us/step - loss: 0.1621 - accuracy: 0.9244 - val_loss: 0.1545 - val_accuracy: 0.9323\n",
      "Epoch 53/80\n",
      "12490/12490 [==============================] - 0s 39us/step - loss: 0.1600 - accuracy: 0.9237 - val_loss: 0.1601 - val_accuracy: 0.9222\n",
      "Epoch 54/80\n",
      "12490/12490 [==============================] - 0s 37us/step - loss: 0.1591 - accuracy: 0.9257 - val_loss: 0.1573 - val_accuracy: 0.9258\n",
      "Epoch 55/80\n",
      "12490/12490 [==============================] - 1s 41us/step - loss: 0.1585 - accuracy: 0.9246 - val_loss: 0.1598 - val_accuracy: 0.9294\n",
      "Epoch 56/80\n",
      "12490/12490 [==============================] - 0s 39us/step - loss: 0.1590 - accuracy: 0.9265 - val_loss: 0.1882 - val_accuracy: 0.9179\n",
      "Epoch 57/80\n",
      "12490/12490 [==============================] - 0s 35us/step - loss: 0.1606 - accuracy: 0.9251 - val_loss: 0.1518 - val_accuracy: 0.9330\n",
      "Epoch 58/80\n",
      "12490/12490 [==============================] - 0s 38us/step - loss: 0.1621 - accuracy: 0.9240 - val_loss: 0.1596 - val_accuracy: 0.9251\n",
      "Epoch 59/80\n",
      "12490/12490 [==============================] - 0s 35us/step - loss: 0.1577 - accuracy: 0.9268 - val_loss: 0.1582 - val_accuracy: 0.9236\n",
      "Epoch 60/80\n",
      "12490/12490 [==============================] - 1s 40us/step - loss: 0.1563 - accuracy: 0.9287 - val_loss: 0.1541 - val_accuracy: 0.9301\n",
      "Epoch 61/80\n",
      "12490/12490 [==============================] - 0s 38us/step - loss: 0.1570 - accuracy: 0.9275 - val_loss: 0.1612 - val_accuracy: 0.9236\n",
      "Epoch 62/80\n",
      "12490/12490 [==============================] - 0s 39us/step - loss: 0.1564 - accuracy: 0.9273 - val_loss: 0.1594 - val_accuracy: 0.9251\n",
      "Epoch 63/80\n",
      "12490/12490 [==============================] - 0s 39us/step - loss: 0.1562 - accuracy: 0.9271 - val_loss: 0.1581 - val_accuracy: 0.9244\n",
      "Epoch 64/80\n",
      "12490/12490 [==============================] - 0s 38us/step - loss: 0.1564 - accuracy: 0.9268 - val_loss: 0.1592 - val_accuracy: 0.9287\n",
      "Epoch 65/80\n",
      "12490/12490 [==============================] - 0s 38us/step - loss: 0.1572 - accuracy: 0.9283 - val_loss: 0.1531 - val_accuracy: 0.9272\n",
      "Epoch 66/80\n",
      "12490/12490 [==============================] - 0s 37us/step - loss: 0.1584 - accuracy: 0.9281 - val_loss: 0.1506 - val_accuracy: 0.9337\n",
      "Epoch 67/80\n",
      "12490/12490 [==============================] - 0s 39us/step - loss: 0.1539 - accuracy: 0.9279 - val_loss: 0.1630 - val_accuracy: 0.9244\n",
      "Epoch 68/80\n",
      "12490/12490 [==============================] - 0s 38us/step - loss: 0.1553 - accuracy: 0.9290 - val_loss: 0.1621 - val_accuracy: 0.9150\n",
      "Epoch 69/80\n",
      "12490/12490 [==============================] - 0s 39us/step - loss: 0.1527 - accuracy: 0.9295 - val_loss: 0.1562 - val_accuracy: 0.9244\n",
      "Epoch 70/80\n",
      "12490/12490 [==============================] - 1s 40us/step - loss: 0.1560 - accuracy: 0.9256 - val_loss: 0.1499 - val_accuracy: 0.9366\n",
      "Epoch 71/80\n",
      "12490/12490 [==============================] - 0s 36us/step - loss: 0.1560 - accuracy: 0.9267 - val_loss: 0.1598 - val_accuracy: 0.9308\n",
      "Epoch 72/80\n",
      "12490/12490 [==============================] - 1s 41us/step - loss: 0.1545 - accuracy: 0.9286 - val_loss: 0.1601 - val_accuracy: 0.9294\n",
      "Epoch 73/80\n",
      "12490/12490 [==============================] - 0s 40us/step - loss: 0.1553 - accuracy: 0.9279 - val_loss: 0.1666 - val_accuracy: 0.9207\n",
      "Epoch 74/80\n",
      "12490/12490 [==============================] - 0s 40us/step - loss: 0.1530 - accuracy: 0.9286 - val_loss: 0.1585 - val_accuracy: 0.9308\n",
      "Epoch 75/80\n",
      "12490/12490 [==============================] - 0s 38us/step - loss: 0.1534 - accuracy: 0.9275 - val_loss: 0.1469 - val_accuracy: 0.9380\n",
      "Epoch 76/80\n",
      "12490/12490 [==============================] - 0s 39us/step - loss: 0.1551 - accuracy: 0.9271 - val_loss: 0.1539 - val_accuracy: 0.9352\n",
      "Epoch 77/80\n",
      "12490/12490 [==============================] - 0s 39us/step - loss: 0.1566 - accuracy: 0.9275 - val_loss: 0.1483 - val_accuracy: 0.9323\n",
      "Epoch 78/80\n",
      "12490/12490 [==============================] - 0s 40us/step - loss: 0.1540 - accuracy: 0.9283 - val_loss: 0.1570 - val_accuracy: 0.9258\n",
      "Epoch 79/80\n",
      "12490/12490 [==============================] - 1s 41us/step - loss: 0.1499 - accuracy: 0.9280 - val_loss: 0.1513 - val_accuracy: 0.9272\n",
      "Epoch 80/80\n",
      "12490/12490 [==============================] - 0s 37us/step - loss: 0.1537 - accuracy: 0.9285 - val_loss: 0.1553 - val_accuracy: 0.9258\n",
      "[[1.00000000e+00 3.80746421e-08 2.85192259e-10 5.49539967e-14\n",
      "  2.93924121e-08 1.26171937e-11]\n",
      " [1.24253260e-04 4.46606707e-03 6.39556732e-04 1.30223846e-10\n",
      "  1.23198214e-03 9.93538082e-01]\n",
      " [1.20860794e-04 4.39835945e-03 6.29089365e-04 1.27961572e-10\n",
      "  1.22084399e-03 9.93630826e-01]\n",
      " ...\n",
      " [1.23041488e-09 2.18536513e-07 9.77935433e-01 2.20609624e-02\n",
      "  1.85248800e-12 3.39224562e-06]\n",
      " [1.26160103e-05 1.62607332e-08 9.60032463e-01 1.51819011e-04\n",
      "  3.86814214e-02 1.12169702e-03]\n",
      " [2.45469925e-03 8.75983091e-08 2.79042342e-05 1.00896250e-10\n",
      "  9.95677173e-01 1.84016174e-03]]\n",
      "[0 5 5 ... 2 2 4]\n",
      "<class 'numpy.ndarray'>\n",
      "One CNN, r:  3\n",
      "Computing Time:  0:02:36.854220\n",
      "Model: \"sequential_1\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv1d_1 (Conv1D)            (None, 3, 6)              12        \n",
      "_________________________________________________________________\n",
      "average_pooling1d_1 (Average (None, 1, 6)              0         \n",
      "_________________________________________________________________\n",
      "conv1d_2 (Conv1D)            (None, 1, 16)             112       \n",
      "_________________________________________________________________\n",
      "average_pooling1d_2 (Average (None, 1, 16)             0         \n",
      "_________________________________________________________________\n",
      "conv1d_3 (Conv1D)            (None, 1, 120)            2040      \n",
      "_________________________________________________________________\n",
      "flatten_1 (Flatten)          (None, 120)               0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 84)                10164     \n",
      "_________________________________________________________________\n",
      "preds (Dense)                (None, 6)                 510       \n",
      "=================================================================\n",
      "Total params: 12,838\n",
      "Trainable params: 12,838\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Train on 12490 samples, validate on 1388 samples\n",
      "Epoch 1/80\n",
      "12490/12490 [==============================] - 1s 60us/step - loss: 0.7245 - accuracy: 0.7334 - val_loss: 0.4598 - val_accuracy: 0.7947\n",
      "Epoch 2/80\n",
      "12490/12490 [==============================] - 1s 41us/step - loss: 0.4319 - accuracy: 0.8118 - val_loss: 0.3961 - val_accuracy: 0.8148\n",
      "Epoch 3/80\n",
      "12490/12490 [==============================] - 0s 39us/step - loss: 0.3723 - accuracy: 0.8430 - val_loss: 0.3325 - val_accuracy: 0.8739\n",
      "Epoch 4/80\n",
      "12490/12490 [==============================] - 1s 40us/step - loss: 0.3101 - accuracy: 0.8774 - val_loss: 0.2783 - val_accuracy: 0.8927\n",
      "Epoch 5/80\n",
      "12490/12490 [==============================] - 0s 39us/step - loss: 0.2615 - accuracy: 0.8976 - val_loss: 0.2491 - val_accuracy: 0.9006\n",
      "Epoch 6/80\n",
      "12490/12490 [==============================] - 0s 37us/step - loss: 0.2340 - accuracy: 0.9024 - val_loss: 0.2141 - val_accuracy: 0.9135\n",
      "Epoch 7/80\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "12490/12490 [==============================] - 1s 41us/step - loss: 0.2225 - accuracy: 0.9050 - val_loss: 0.2046 - val_accuracy: 0.9229\n",
      "Epoch 8/80\n",
      "12490/12490 [==============================] - 1s 41us/step - loss: 0.2101 - accuracy: 0.9082 - val_loss: 0.2003 - val_accuracy: 0.9171\n",
      "Epoch 9/80\n",
      "12490/12490 [==============================] - 0s 40us/step - loss: 0.2028 - accuracy: 0.9078 - val_loss: 0.2014 - val_accuracy: 0.9135\n",
      "Epoch 10/80\n",
      "12490/12490 [==============================] - 0s 40us/step - loss: 0.1990 - accuracy: 0.9110 - val_loss: 0.1977 - val_accuracy: 0.9164\n",
      "Epoch 11/80\n",
      "12490/12490 [==============================] - 0s 39us/step - loss: 0.1933 - accuracy: 0.9121 - val_loss: 0.1912 - val_accuracy: 0.9236\n",
      "Epoch 12/80\n",
      "12490/12490 [==============================] - 0s 38us/step - loss: 0.1946 - accuracy: 0.9109 - val_loss: 0.1751 - val_accuracy: 0.9215\n",
      "Epoch 13/80\n",
      "12490/12490 [==============================] - 0s 40us/step - loss: 0.1962 - accuracy: 0.9101 - val_loss: 0.1917 - val_accuracy: 0.9215\n",
      "Epoch 14/80\n",
      "12490/12490 [==============================] - 1s 40us/step - loss: 0.1879 - accuracy: 0.9131 - val_loss: 0.1726 - val_accuracy: 0.9222\n",
      "Epoch 15/80\n",
      "12490/12490 [==============================] - 1s 40us/step - loss: 0.1832 - accuracy: 0.9111 - val_loss: 0.1801 - val_accuracy: 0.9150\n",
      "Epoch 16/80\n",
      "12490/12490 [==============================] - 0s 38us/step - loss: 0.1904 - accuracy: 0.9111 - val_loss: 0.1809 - val_accuracy: 0.9071\n",
      "Epoch 17/80\n",
      "12490/12490 [==============================] - 0s 37us/step - loss: 0.1824 - accuracy: 0.9122 - val_loss: 0.1715 - val_accuracy: 0.9186\n",
      "Epoch 18/80\n",
      "12490/12490 [==============================] - 1s 40us/step - loss: 0.1804 - accuracy: 0.9130 - val_loss: 0.1938 - val_accuracy: 0.9265\n",
      "Epoch 19/80\n",
      "12490/12490 [==============================] - 1s 41us/step - loss: 0.1831 - accuracy: 0.9139 - val_loss: 0.1709 - val_accuracy: 0.9193\n",
      "Epoch 20/80\n",
      "12490/12490 [==============================] - 0s 38us/step - loss: 0.1776 - accuracy: 0.9163 - val_loss: 0.1624 - val_accuracy: 0.9236\n",
      "Epoch 21/80\n",
      "12490/12490 [==============================] - 0s 40us/step - loss: 0.1754 - accuracy: 0.9164 - val_loss: 0.1577 - val_accuracy: 0.9308\n",
      "Epoch 22/80\n",
      "12490/12490 [==============================] - 0s 39us/step - loss: 0.1745 - accuracy: 0.9180 - val_loss: 0.1570 - val_accuracy: 0.9373\n",
      "Epoch 23/80\n",
      "12490/12490 [==============================] - 0s 38us/step - loss: 0.1702 - accuracy: 0.9214 - val_loss: 0.1610 - val_accuracy: 0.9251\n",
      "Epoch 24/80\n",
      "12490/12490 [==============================] - 0s 38us/step - loss: 0.1737 - accuracy: 0.9206 - val_loss: 0.1569 - val_accuracy: 0.9294\n",
      "Epoch 25/80\n",
      "12490/12490 [==============================] - 0s 38us/step - loss: 0.1708 - accuracy: 0.9207 - val_loss: 0.1547 - val_accuracy: 0.9323\n",
      "Epoch 26/80\n",
      "12490/12490 [==============================] - 0s 38us/step - loss: 0.1688 - accuracy: 0.9224 - val_loss: 0.1622 - val_accuracy: 0.9244\n",
      "Epoch 27/80\n",
      "12490/12490 [==============================] - 1s 41us/step - loss: 0.1657 - accuracy: 0.9230 - val_loss: 0.1518 - val_accuracy: 0.9287\n",
      "Epoch 28/80\n",
      "12490/12490 [==============================] - 0s 40us/step - loss: 0.1670 - accuracy: 0.9245 - val_loss: 0.1505 - val_accuracy: 0.9316\n",
      "Epoch 29/80\n",
      "12490/12490 [==============================] - 0s 40us/step - loss: 0.1658 - accuracy: 0.9246 - val_loss: 0.1526 - val_accuracy: 0.9280\n",
      "Epoch 30/80\n",
      "12490/12490 [==============================] - 0s 40us/step - loss: 0.1627 - accuracy: 0.9242 - val_loss: 0.1460 - val_accuracy: 0.9330\n",
      "Epoch 31/80\n",
      "12490/12490 [==============================] - 0s 36us/step - loss: 0.1626 - accuracy: 0.9244 - val_loss: 0.1518 - val_accuracy: 0.9316\n",
      "Epoch 32/80\n",
      "12490/12490 [==============================] - 0s 35us/step - loss: 0.1684 - accuracy: 0.9223 - val_loss: 0.1586 - val_accuracy: 0.9244\n",
      "Epoch 33/80\n",
      "12490/12490 [==============================] - 0s 37us/step - loss: 0.1612 - accuracy: 0.9251 - val_loss: 0.1484 - val_accuracy: 0.9323\n",
      "Epoch 34/80\n",
      "12490/12490 [==============================] - 0s 38us/step - loss: 0.1616 - accuracy: 0.9247 - val_loss: 0.1494 - val_accuracy: 0.9330\n",
      "Epoch 35/80\n",
      "12490/12490 [==============================] - 0s 38us/step - loss: 0.1605 - accuracy: 0.9241 - val_loss: 0.1422 - val_accuracy: 0.9373\n",
      "Epoch 36/80\n",
      "12490/12490 [==============================] - 0s 37us/step - loss: 0.1617 - accuracy: 0.9244 - val_loss: 0.1471 - val_accuracy: 0.9308\n",
      "Epoch 37/80\n",
      "12490/12490 [==============================] - 0s 39us/step - loss: 0.1592 - accuracy: 0.9268 - val_loss: 0.1467 - val_accuracy: 0.9344\n",
      "Epoch 38/80\n",
      "12490/12490 [==============================] - 0s 38us/step - loss: 0.1623 - accuracy: 0.9254 - val_loss: 0.1477 - val_accuracy: 0.9344\n",
      "Epoch 39/80\n",
      "12490/12490 [==============================] - 0s 40us/step - loss: 0.1588 - accuracy: 0.9267 - val_loss: 0.1473 - val_accuracy: 0.9316\n",
      "Epoch 40/80\n",
      "12490/12490 [==============================] - 1s 43us/step - loss: 0.1579 - accuracy: 0.9279 - val_loss: 0.1465 - val_accuracy: 0.9359\n",
      "Epoch 41/80\n",
      "12490/12490 [==============================] - 0s 37us/step - loss: 0.1598 - accuracy: 0.9266 - val_loss: 0.1510 - val_accuracy: 0.9316\n",
      "Epoch 42/80\n",
      "12490/12490 [==============================] - 0s 39us/step - loss: 0.1574 - accuracy: 0.9271 - val_loss: 0.1509 - val_accuracy: 0.9352\n",
      "Epoch 43/80\n",
      "12490/12490 [==============================] - 0s 38us/step - loss: 0.1590 - accuracy: 0.9263 - val_loss: 0.1444 - val_accuracy: 0.9352\n",
      "Epoch 44/80\n",
      "12490/12490 [==============================] - 0s 39us/step - loss: 0.1557 - accuracy: 0.9295 - val_loss: 0.1430 - val_accuracy: 0.9359\n",
      "Epoch 45/80\n",
      "12490/12490 [==============================] - 0s 37us/step - loss: 0.1577 - accuracy: 0.9289 - val_loss: 0.1455 - val_accuracy: 0.9373\n",
      "Epoch 00045: early stopping\n",
      "[[9.99997497e-01 3.66290863e-07 1.14915533e-09 1.72300099e-06\n",
      "  4.32762903e-07 6.65194904e-08]\n",
      " [9.90890476e-05 7.08989380e-03 5.68490577e-07 1.02265090e-04\n",
      "  1.71916516e-04 9.92536306e-01]\n",
      " [9.65754225e-05 6.97854906e-03 5.63882168e-07 1.00816935e-04\n",
      "  1.70672429e-04 9.92652893e-01]\n",
      " ...\n",
      " [1.92545375e-08 2.83317913e-05 9.89990234e-01 9.95482784e-03\n",
      "  6.92464280e-11 2.66805164e-05]\n",
      " [4.12325026e-05 3.19794663e-06 9.78378236e-01 3.52809299e-03\n",
      "  1.13466419e-02 6.70256140e-03]\n",
      " [1.04233979e-04 5.16900256e-09 1.74433569e-06 7.95487892e-07\n",
      "  9.98737633e-01 1.15555723e-03]]\n",
      "[0 5 5 ... 2 2 4]\n",
      "<class 'numpy.ndarray'>\n",
      "One CNN, r:  4\n",
      "Computing Time:  0:03:03.463559\n",
      "true region_label= [6, 6, 2, 4, 3, 5]\n",
      "dist_table_truth\n",
      " [[1304  846    0 1448   19  308 1540   10  507]\n",
      " [ 621   56    3  192  270    5 2172 3250   49]\n",
      " [ 180  495 2203   31 1398  556   16  419 1023]\n",
      " [ 165 1266 2235    0 1471  215   28    0  186]\n",
      " [2230  537   17 2457   39 1374   58   23 2094]\n",
      " [ 174  578   26  113  233 1883  840  413  241]]\n",
      "num of merged_region_image 0 2216\n",
      "num of merged_region_image 1 2572\n",
      "num of merged_region_image 2 3233\n",
      "num of merged_region_image 3 2609\n",
      "num of merged_region_image 4 1344\n",
      "num of merged_region_image 5 1904\n",
      "Counter({-1: 29339, 2: 3233, 3: 2609, 1: 2572, 0: 2216, 5: 1904, 4: 1344})\n",
      "\n",
      "\n",
      "==== merged_and_expand(PATH5,ITE) ====\n",
      "===========  ITE = 0   ===========\n",
      "used_img 13878 13878\n",
      "working_img(=other images=unclean images) 29339 29339\n",
      "merged regions 58 58\n",
      "other_regions 142 142\n",
      "All other regions\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>other index</th>\n",
       "      <th>pred label</th>\n",
       "      <th>truth</th>\n",
       "      <th>rate</th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2</td>\n",
       "      <td>5</td>\n",
       "      <td>6</td>\n",
       "      <td>0.98</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>1.00</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>183</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1.00</td>\n",
       "      <td>161</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>6</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>0.87</td>\n",
       "      <td>4</td>\n",
       "      <td>62</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>7</td>\n",
       "      <td>3</td>\n",
       "      <td>5</td>\n",
       "      <td>0.85</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>239</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>137</th>\n",
       "      <td>194</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1.00</td>\n",
       "      <td>1</td>\n",
       "      <td>111</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>138</th>\n",
       "      <td>195</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>0.62</td>\n",
       "      <td>2</td>\n",
       "      <td>21</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>17</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>139</th>\n",
       "      <td>196</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>0.58</td>\n",
       "      <td>372</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>140</th>\n",
       "      <td>199</td>\n",
       "      <td>2</td>\n",
       "      <td>8</td>\n",
       "      <td>0.86</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>141</th>\n",
       "      <td>200</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>1.00</td>\n",
       "      <td>260</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>142 rows × 10 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     other index  pred label  truth  rate    0    1  2    3  4    5\n",
       "0              2           5      6  0.98    0    0  0    0  0    0\n",
       "1              3           4      3  1.00    1    0  0  183  2    0\n",
       "2              4           1      0  1.00  161    0  2    3  0    2\n",
       "3              6           5      1  0.87    4   62  0    0  1    2\n",
       "4              7           3      5  0.85    1    0  0    0  3  239\n",
       "..           ...         ...    ...   ...  ...  ... ..  ... ..  ...\n",
       "137          194           0      1  1.00    1  111  0    0  0    2\n",
       "138          195           4      1  0.62    2   21  0    0  0   17\n",
       "139          196           4      0  0.58  372    2  1    1  4    1\n",
       "140          199           2      8  0.86    0    0  2    0  0    0\n",
       "141          200           4      0  1.00  260    0  0    0  1    0\n",
       "\n",
       "[142 rows x 10 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "added label, regions, img amount: {0} [132, 100, 185, 162, 159] 938\n",
      "added label, regions, img amount: {1} [4, 74, 119, 103, 193] 804\n",
      "added label, regions, img amount: {2} [124, 47, 65, 77, 80] 320\n",
      "added label, regions, img amount: {3} [54, 108, 110, 114, 148] 821\n",
      "added label, regions, img amount: {4} [3, 76, 167, 165, 151] 1088\n",
      "added label, regions, img amount: {5} [107, 140, 2, 62, 90] 648\n",
      "Not getting into residuals\n",
      "NUM_region 6\n",
      "number of clean images 18497\n",
      "n, p1, p2 0 0 0\n",
      "NUM_CLASSES 6\n",
      "current_train_label:  [0, 1, 2, 3, 4, 5]\n",
      "Model: \"sequential_1\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv1d_1 (Conv1D)            (None, 3, 6)              12        \n",
      "_________________________________________________________________\n",
      "average_pooling1d_1 (Average (None, 1, 6)              0         \n",
      "_________________________________________________________________\n",
      "conv1d_2 (Conv1D)            (None, 1, 16)             112       \n",
      "_________________________________________________________________\n",
      "average_pooling1d_2 (Average (None, 1, 16)             0         \n",
      "_________________________________________________________________\n",
      "conv1d_3 (Conv1D)            (None, 1, 120)            2040      \n",
      "_________________________________________________________________\n",
      "flatten_1 (Flatten)          (None, 120)               0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 84)                10164     \n",
      "_________________________________________________________________\n",
      "preds (Dense)                (None, 6)                 510       \n",
      "=================================================================\n",
      "Total params: 12,838\n",
      "Trainable params: 12,838\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Train on 16647 samples, validate on 1850 samples\n",
      "Epoch 1/80\n",
      "16647/16647 [==============================] - 1s 72us/step - loss: 0.8437 - accuracy: 0.6786 - val_loss: 0.4584 - val_accuracy: 0.8508\n",
      "Epoch 2/80\n",
      "16647/16647 [==============================] - 1s 41us/step - loss: 0.3326 - accuracy: 0.8851 - val_loss: 0.2555 - val_accuracy: 0.8973\n",
      "Epoch 3/80\n",
      "16647/16647 [==============================] - 1s 41us/step - loss: 0.2338 - accuracy: 0.9117 - val_loss: 0.2048 - val_accuracy: 0.9168\n",
      "Epoch 4/80\n",
      "16647/16647 [==============================] - 1s 42us/step - loss: 0.2027 - accuracy: 0.9215 - val_loss: 0.2201 - val_accuracy: 0.9151\n",
      "Epoch 5/80\n",
      "16647/16647 [==============================] - 1s 38us/step - loss: 0.1885 - accuracy: 0.9244 - val_loss: 0.2206 - val_accuracy: 0.9092\n",
      "Epoch 6/80\n",
      "16647/16647 [==============================] - 1s 39us/step - loss: 0.1818 - accuracy: 0.9246 - val_loss: 0.1814 - val_accuracy: 0.9281\n",
      "Epoch 7/80\n",
      "16647/16647 [==============================] - 1s 38us/step - loss: 0.1670 - accuracy: 0.9316 - val_loss: 0.2280 - val_accuracy: 0.9178\n",
      "Epoch 8/80\n",
      "16647/16647 [==============================] - 1s 39us/step - loss: 0.1705 - accuracy: 0.9313 - val_loss: 0.4878 - val_accuracy: 0.7989\n",
      "Epoch 9/80\n",
      "16647/16647 [==============================] - 1s 38us/step - loss: 0.1725 - accuracy: 0.9280 - val_loss: 0.1807 - val_accuracy: 0.9259\n",
      "Epoch 10/80\n",
      "16647/16647 [==============================] - 1s 37us/step - loss: 0.1544 - accuracy: 0.9340 - val_loss: 0.1626 - val_accuracy: 0.9303\n",
      "Epoch 11/80\n",
      "16647/16647 [==============================] - 1s 38us/step - loss: 0.1492 - accuracy: 0.9362 - val_loss: 0.1660 - val_accuracy: 0.9270\n",
      "Epoch 12/80\n",
      "16647/16647 [==============================] - 1s 42us/step - loss: 0.1507 - accuracy: 0.9343 - val_loss: 0.1634 - val_accuracy: 0.9281\n",
      "Epoch 13/80\n",
      "16647/16647 [==============================] - 1s 38us/step - loss: 0.1429 - accuracy: 0.9360 - val_loss: 0.1634 - val_accuracy: 0.9308\n",
      "Epoch 14/80\n",
      "16647/16647 [==============================] - 1s 40us/step - loss: 0.1430 - accuracy: 0.9391 - val_loss: 0.1525 - val_accuracy: 0.9324\n",
      "Epoch 15/80\n",
      "16647/16647 [==============================] - 1s 39us/step - loss: 0.1386 - accuracy: 0.9407 - val_loss: 0.1438 - val_accuracy: 0.9330\n",
      "Epoch 16/80\n",
      "16647/16647 [==============================] - 1s 39us/step - loss: 0.1373 - accuracy: 0.9397 - val_loss: 0.1596 - val_accuracy: 0.9314\n",
      "Epoch 17/80\n",
      "16647/16647 [==============================] - 1s 40us/step - loss: 0.1394 - accuracy: 0.9403 - val_loss: 0.1553 - val_accuracy: 0.9351\n",
      "Epoch 18/80\n",
      "16647/16647 [==============================] - 1s 40us/step - loss: 0.1356 - accuracy: 0.9419 - val_loss: 0.1644 - val_accuracy: 0.9308\n",
      "Epoch 19/80\n",
      "16647/16647 [==============================] - 1s 41us/step - loss: 0.1436 - accuracy: 0.9381 - val_loss: 0.1450 - val_accuracy: 0.9395\n",
      "Epoch 20/80\n",
      "16647/16647 [==============================] - 1s 43us/step - loss: 0.1327 - accuracy: 0.9425 - val_loss: 0.1507 - val_accuracy: 0.9368\n",
      "Epoch 21/80\n",
      "16647/16647 [==============================] - 1s 39us/step - loss: 0.1356 - accuracy: 0.9419 - val_loss: 0.1729 - val_accuracy: 0.9249\n",
      "Epoch 22/80\n",
      "16647/16647 [==============================] - 1s 40us/step - loss: 0.1327 - accuracy: 0.9432 - val_loss: 0.1397 - val_accuracy: 0.9335\n",
      "Epoch 23/80\n",
      "16647/16647 [==============================] - 1s 39us/step - loss: 0.1315 - accuracy: 0.9449 - val_loss: 0.1602 - val_accuracy: 0.9286\n",
      "Epoch 24/80\n",
      "16647/16647 [==============================] - 1s 39us/step - loss: 0.1321 - accuracy: 0.9432 - val_loss: 0.1565 - val_accuracy: 0.9384\n",
      "Epoch 25/80\n",
      "16647/16647 [==============================] - 1s 37us/step - loss: 0.1329 - accuracy: 0.9408 - val_loss: 0.1425 - val_accuracy: 0.9281\n",
      "Epoch 26/80\n",
      "16647/16647 [==============================] - 1s 42us/step - loss: 0.1278 - accuracy: 0.9455 - val_loss: 0.1441 - val_accuracy: 0.9389\n",
      "Epoch 27/80\n",
      "16647/16647 [==============================] - 1s 39us/step - loss: 0.1305 - accuracy: 0.9447 - val_loss: 0.1346 - val_accuracy: 0.9373\n",
      "Epoch 28/80\n",
      "16647/16647 [==============================] - 1s 39us/step - loss: 0.1275 - accuracy: 0.9456 - val_loss: 0.1452 - val_accuracy: 0.9411\n",
      "Epoch 29/80\n",
      "16647/16647 [==============================] - 1s 40us/step - loss: 0.1288 - accuracy: 0.9452 - val_loss: 0.2289 - val_accuracy: 0.8951\n",
      "Epoch 30/80\n",
      "16647/16647 [==============================] - 1s 38us/step - loss: 0.1314 - accuracy: 0.9424 - val_loss: 0.1597 - val_accuracy: 0.9384\n",
      "Epoch 31/80\n",
      "16647/16647 [==============================] - 1s 39us/step - loss: 0.1280 - accuracy: 0.9447 - val_loss: 0.1480 - val_accuracy: 0.9314\n",
      "Epoch 32/80\n",
      "16647/16647 [==============================] - 1s 37us/step - loss: 0.1328 - accuracy: 0.9431 - val_loss: 0.1373 - val_accuracy: 0.9362\n",
      "Epoch 33/80\n",
      "16647/16647 [==============================] - 1s 36us/step - loss: 0.1236 - accuracy: 0.9468 - val_loss: 0.1376 - val_accuracy: 0.9432\n",
      "Epoch 34/80\n",
      "16647/16647 [==============================] - 1s 40us/step - loss: 0.1264 - accuracy: 0.9443 - val_loss: 0.1363 - val_accuracy: 0.9454\n",
      "Epoch 35/80\n",
      "16647/16647 [==============================] - 1s 42us/step - loss: 0.1293 - accuracy: 0.9440 - val_loss: 0.1408 - val_accuracy: 0.9432\n",
      "Epoch 36/80\n",
      "16647/16647 [==============================] - 1s 36us/step - loss: 0.1244 - accuracy: 0.9449 - val_loss: 0.1509 - val_accuracy: 0.9395\n",
      "Epoch 37/80\n",
      "16647/16647 [==============================] - 1s 36us/step - loss: 0.1298 - accuracy: 0.9432 - val_loss: 0.1319 - val_accuracy: 0.9411\n",
      "Epoch 38/80\n",
      "16647/16647 [==============================] - 1s 36us/step - loss: 0.1245 - accuracy: 0.9450 - val_loss: 0.1585 - val_accuracy: 0.9416\n",
      "Epoch 39/80\n",
      "16647/16647 [==============================] - 1s 38us/step - loss: 0.1283 - accuracy: 0.9441 - val_loss: 0.1266 - val_accuracy: 0.9405\n",
      "Epoch 40/80\n",
      "16647/16647 [==============================] - 1s 40us/step - loss: 0.1234 - accuracy: 0.9463 - val_loss: 0.1262 - val_accuracy: 0.9427\n",
      "Epoch 41/80\n",
      "16647/16647 [==============================] - 1s 38us/step - loss: 0.1238 - accuracy: 0.9448 - val_loss: 0.1276 - val_accuracy: 0.9346\n",
      "Epoch 42/80\n",
      "16647/16647 [==============================] - 1s 36us/step - loss: 0.1216 - accuracy: 0.9468 - val_loss: 0.1337 - val_accuracy: 0.9427\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 43/80\n",
      "16647/16647 [==============================] - 1s 36us/step - loss: 0.1202 - accuracy: 0.9468 - val_loss: 0.1263 - val_accuracy: 0.9449\n",
      "Epoch 44/80\n",
      "16647/16647 [==============================] - 1s 39us/step - loss: 0.1233 - accuracy: 0.9450 - val_loss: 0.1344 - val_accuracy: 0.9427\n",
      "Epoch 45/80\n",
      "16647/16647 [==============================] - 1s 42us/step - loss: 0.1199 - accuracy: 0.9460 - val_loss: 0.1488 - val_accuracy: 0.9292\n",
      "Epoch 46/80\n",
      "16647/16647 [==============================] - 1s 36us/step - loss: 0.1214 - accuracy: 0.9463 - val_loss: 0.1293 - val_accuracy: 0.9449\n",
      "Epoch 47/80\n",
      "16647/16647 [==============================] - 1s 36us/step - loss: 0.1224 - accuracy: 0.9468 - val_loss: 0.1478 - val_accuracy: 0.9292\n",
      "Epoch 48/80\n",
      "16647/16647 [==============================] - 1s 37us/step - loss: 0.1229 - accuracy: 0.9453 - val_loss: 0.1304 - val_accuracy: 0.9314\n",
      "Epoch 49/80\n",
      "16647/16647 [==============================] - 1s 36us/step - loss: 0.1221 - accuracy: 0.9462 - val_loss: 0.1323 - val_accuracy: 0.9405\n",
      "Epoch 50/80\n",
      "16647/16647 [==============================] - 1s 39us/step - loss: 0.1183 - accuracy: 0.9473 - val_loss: 0.1223 - val_accuracy: 0.9405\n",
      "Epoch 51/80\n",
      "16647/16647 [==============================] - 1s 36us/step - loss: 0.1160 - accuracy: 0.9479 - val_loss: 0.1252 - val_accuracy: 0.9427\n",
      "Epoch 52/80\n",
      "16647/16647 [==============================] - 1s 37us/step - loss: 0.1182 - accuracy: 0.9460 - val_loss: 0.1798 - val_accuracy: 0.9292\n",
      "Epoch 53/80\n",
      "16647/16647 [==============================] - 1s 39us/step - loss: 0.1228 - accuracy: 0.9440 - val_loss: 0.1212 - val_accuracy: 0.9341\n",
      "Epoch 54/80\n",
      "16647/16647 [==============================] - 1s 38us/step - loss: 0.1178 - accuracy: 0.9473 - val_loss: 0.1299 - val_accuracy: 0.9416\n",
      "Epoch 55/80\n",
      "16647/16647 [==============================] - 1s 37us/step - loss: 0.1147 - accuracy: 0.9485 - val_loss: 0.1210 - val_accuracy: 0.9476\n",
      "Epoch 56/80\n",
      "16647/16647 [==============================] - 1s 39us/step - loss: 0.1184 - accuracy: 0.9477 - val_loss: 0.1353 - val_accuracy: 0.9373\n",
      "Epoch 57/80\n",
      "16647/16647 [==============================] - 1s 38us/step - loss: 0.1154 - accuracy: 0.9467 - val_loss: 0.1298 - val_accuracy: 0.9449\n",
      "Epoch 58/80\n",
      "16647/16647 [==============================] - 1s 36us/step - loss: 0.1151 - accuracy: 0.9469 - val_loss: 0.1230 - val_accuracy: 0.9362\n",
      "Epoch 59/80\n",
      "16647/16647 [==============================] - 1s 38us/step - loss: 0.1193 - accuracy: 0.9462 - val_loss: 0.1254 - val_accuracy: 0.9432\n",
      "Epoch 60/80\n",
      "16647/16647 [==============================] - 1s 39us/step - loss: 0.1161 - accuracy: 0.9468 - val_loss: 0.1281 - val_accuracy: 0.9405\n",
      "Epoch 61/80\n",
      "16647/16647 [==============================] - 1s 36us/step - loss: 0.1129 - accuracy: 0.9471 - val_loss: 0.1390 - val_accuracy: 0.9362\n",
      "Epoch 62/80\n",
      "16647/16647 [==============================] - 1s 38us/step - loss: 0.1183 - accuracy: 0.9462 - val_loss: 0.1370 - val_accuracy: 0.9357\n",
      "Epoch 63/80\n",
      "16647/16647 [==============================] - 1s 38us/step - loss: 0.1173 - accuracy: 0.9475 - val_loss: 0.1244 - val_accuracy: 0.9432\n",
      "Epoch 64/80\n",
      "16647/16647 [==============================] - 1s 38us/step - loss: 0.1155 - accuracy: 0.9485 - val_loss: 0.1259 - val_accuracy: 0.9427\n",
      "Epoch 65/80\n",
      "16647/16647 [==============================] - 1s 37us/step - loss: 0.1156 - accuracy: 0.9461 - val_loss: 0.1219 - val_accuracy: 0.9438\n",
      "Epoch 00065: early stopping\n",
      "[[1.0000000e+00 1.5148828e-12 3.5018410e-10 5.5880415e-11 1.6705179e-08\n",
      "  2.3347421e-13]\n",
      " [1.3156440e-04 3.7696492e-03 3.0895671e-07 5.4183191e-10 1.2331745e-03\n",
      "  9.9486536e-01]\n",
      " [1.2902731e-04 3.6859165e-03 3.1035759e-07 5.3591676e-10 1.2381122e-03\n",
      "  9.9494666e-01]\n",
      " ...\n",
      " [1.2099963e-07 4.7870975e-11 9.9880719e-01 1.1813286e-03 4.2279687e-11\n",
      "  1.1364772e-05]\n",
      " [2.1036390e-04 4.3060126e-12 9.4247508e-01 3.4781953e-03 5.0933201e-02\n",
      "  2.9032282e-03]\n",
      " [6.0052276e-05 4.2758255e-11 2.6578885e-08 1.3635745e-10 9.9989593e-01\n",
      "  4.3935648e-05]]\n",
      "[0 5 5 ... 2 2 4]\n",
      "<class 'numpy.ndarray'>\n",
      "One CNN, r:  0\n",
      "Computing Time:  0:00:46.621800\n",
      "Model: \"sequential_1\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv1d_1 (Conv1D)            (None, 3, 6)              12        \n",
      "_________________________________________________________________\n",
      "average_pooling1d_1 (Average (None, 1, 6)              0         \n",
      "_________________________________________________________________\n",
      "conv1d_2 (Conv1D)            (None, 1, 16)             112       \n",
      "_________________________________________________________________\n",
      "average_pooling1d_2 (Average (None, 1, 16)             0         \n",
      "_________________________________________________________________\n",
      "conv1d_3 (Conv1D)            (None, 1, 120)            2040      \n",
      "_________________________________________________________________\n",
      "flatten_1 (Flatten)          (None, 120)               0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 84)                10164     \n",
      "_________________________________________________________________\n",
      "preds (Dense)                (None, 6)                 510       \n",
      "=================================================================\n",
      "Total params: 12,838\n",
      "Trainable params: 12,838\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Train on 16647 samples, validate on 1850 samples\n",
      "Epoch 1/80\n",
      "16647/16647 [==============================] - 1s 53us/step - loss: 0.7582 - accuracy: 0.7189 - val_loss: 0.4102 - val_accuracy: 0.8470\n",
      "Epoch 2/80\n",
      "16647/16647 [==============================] - 1s 39us/step - loss: 0.3468 - accuracy: 0.8775 - val_loss: 0.2761 - val_accuracy: 0.8962\n",
      "Epoch 3/80\n",
      "16647/16647 [==============================] - 1s 37us/step - loss: 0.2461 - accuracy: 0.9107 - val_loss: 0.2530 - val_accuracy: 0.9043\n",
      "Epoch 4/80\n",
      "16647/16647 [==============================] - 1s 38us/step - loss: 0.2041 - accuracy: 0.9216 - val_loss: 0.2120 - val_accuracy: 0.9238\n",
      "Epoch 5/80\n",
      "16647/16647 [==============================] - 1s 38us/step - loss: 0.1831 - accuracy: 0.9270 - val_loss: 0.1879 - val_accuracy: 0.9222\n",
      "Epoch 6/80\n",
      "16647/16647 [==============================] - 1s 39us/step - loss: 0.1659 - accuracy: 0.9322 - val_loss: 0.1537 - val_accuracy: 0.9303\n",
      "Epoch 7/80\n",
      "16647/16647 [==============================] - 1s 39us/step - loss: 0.1590 - accuracy: 0.9345 - val_loss: 0.1458 - val_accuracy: 0.9405\n",
      "Epoch 8/80\n",
      "16647/16647 [==============================] - 1s 39us/step - loss: 0.1568 - accuracy: 0.9335 - val_loss: 0.1396 - val_accuracy: 0.9341\n",
      "Epoch 9/80\n",
      "16647/16647 [==============================] - 1s 41us/step - loss: 0.1501 - accuracy: 0.9342 - val_loss: 0.1428 - val_accuracy: 0.9357\n",
      "Epoch 10/80\n",
      "16647/16647 [==============================] - 1s 39us/step - loss: 0.1426 - accuracy: 0.9374 - val_loss: 0.1287 - val_accuracy: 0.9422\n",
      "Epoch 11/80\n",
      "16647/16647 [==============================] - 1s 38us/step - loss: 0.1400 - accuracy: 0.9387 - val_loss: 0.1331 - val_accuracy: 0.9400\n",
      "Epoch 12/80\n",
      "16647/16647 [==============================] - 1s 38us/step - loss: 0.1412 - accuracy: 0.9380 - val_loss: 0.1310 - val_accuracy: 0.9389\n",
      "Epoch 13/80\n",
      "16647/16647 [==============================] - 1s 40us/step - loss: 0.1377 - accuracy: 0.9398 - val_loss: 0.1442 - val_accuracy: 0.9324\n",
      "Epoch 14/80\n",
      "16647/16647 [==============================] - 1s 40us/step - loss: 0.1360 - accuracy: 0.9386 - val_loss: 0.1245 - val_accuracy: 0.9438\n",
      "Epoch 15/80\n",
      "16647/16647 [==============================] - 1s 44us/step - loss: 0.1326 - accuracy: 0.9399 - val_loss: 0.1233 - val_accuracy: 0.9400\n",
      "Epoch 16/80\n",
      "16647/16647 [==============================] - 1s 39us/step - loss: 0.1312 - accuracy: 0.9420 - val_loss: 0.1230 - val_accuracy: 0.9357\n",
      "Epoch 17/80\n",
      "16647/16647 [==============================] - 1s 40us/step - loss: 0.1295 - accuracy: 0.9413 - val_loss: 0.1220 - val_accuracy: 0.9357\n",
      "Epoch 18/80\n",
      "16647/16647 [==============================] - 1s 39us/step - loss: 0.1288 - accuracy: 0.9412 - val_loss: 0.1253 - val_accuracy: 0.9368\n",
      "Epoch 19/80\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "16647/16647 [==============================] - 1s 37us/step - loss: 0.1276 - accuracy: 0.9417 - val_loss: 0.1130 - val_accuracy: 0.9470\n",
      "Epoch 20/80\n",
      "16647/16647 [==============================] - 1s 39us/step - loss: 0.1256 - accuracy: 0.9420 - val_loss: 0.1383 - val_accuracy: 0.9416\n",
      "Epoch 21/80\n",
      "16647/16647 [==============================] - 1s 37us/step - loss: 0.1275 - accuracy: 0.9427 - val_loss: 0.1108 - val_accuracy: 0.9454\n",
      "Epoch 22/80\n",
      "16647/16647 [==============================] - 1s 37us/step - loss: 0.1259 - accuracy: 0.9421 - val_loss: 0.1142 - val_accuracy: 0.9395\n",
      "Epoch 23/80\n",
      "16647/16647 [==============================] - 1s 37us/step - loss: 0.1205 - accuracy: 0.9451 - val_loss: 0.1368 - val_accuracy: 0.9476\n",
      "Epoch 24/80\n",
      "16647/16647 [==============================] - 1s 36us/step - loss: 0.1199 - accuracy: 0.9455 - val_loss: 0.1194 - val_accuracy: 0.9449\n",
      "Epoch 25/80\n",
      "16647/16647 [==============================] - 1s 38us/step - loss: 0.1223 - accuracy: 0.9432 - val_loss: 0.1138 - val_accuracy: 0.9432\n",
      "Epoch 26/80\n",
      "16647/16647 [==============================] - 1s 39us/step - loss: 0.1193 - accuracy: 0.9447 - val_loss: 0.1191 - val_accuracy: 0.9432\n",
      "Epoch 27/80\n",
      "16647/16647 [==============================] - 1s 40us/step - loss: 0.1196 - accuracy: 0.9444 - val_loss: 0.1184 - val_accuracy: 0.9416\n",
      "Epoch 28/80\n",
      "16647/16647 [==============================] - 1s 39us/step - loss: 0.1240 - accuracy: 0.9417 - val_loss: 0.1120 - val_accuracy: 0.9476\n",
      "Epoch 29/80\n",
      "16647/16647 [==============================] - 1s 39us/step - loss: 0.1214 - accuracy: 0.9437 - val_loss: 0.1319 - val_accuracy: 0.9454\n",
      "Epoch 30/80\n",
      "16647/16647 [==============================] - 1s 41us/step - loss: 0.1186 - accuracy: 0.9456 - val_loss: 0.1094 - val_accuracy: 0.9497\n",
      "Epoch 31/80\n",
      "16647/16647 [==============================] - 1s 41us/step - loss: 0.1181 - accuracy: 0.9437 - val_loss: 0.1219 - val_accuracy: 0.9486\n",
      "Epoch 32/80\n",
      "16647/16647 [==============================] - 1s 38us/step - loss: 0.1173 - accuracy: 0.9440 - val_loss: 0.1061 - val_accuracy: 0.9443\n",
      "Epoch 33/80\n",
      "16647/16647 [==============================] - 1s 39us/step - loss: 0.1155 - accuracy: 0.9454 - val_loss: 0.1101 - val_accuracy: 0.9454\n",
      "Epoch 34/80\n",
      "16647/16647 [==============================] - 1s 39us/step - loss: 0.1198 - accuracy: 0.9436 - val_loss: 0.1103 - val_accuracy: 0.9519\n",
      "Epoch 35/80\n",
      "16647/16647 [==============================] - 1s 41us/step - loss: 0.1173 - accuracy: 0.9438 - val_loss: 0.1131 - val_accuracy: 0.9476\n",
      "Epoch 36/80\n",
      "16647/16647 [==============================] - 1s 38us/step - loss: 0.1204 - accuracy: 0.9443 - val_loss: 0.1068 - val_accuracy: 0.9476\n",
      "Epoch 37/80\n",
      "16647/16647 [==============================] - 1s 41us/step - loss: 0.1166 - accuracy: 0.9456 - val_loss: 0.1161 - val_accuracy: 0.9524\n",
      "Epoch 38/80\n",
      "16647/16647 [==============================] - 1s 41us/step - loss: 0.1154 - accuracy: 0.9465 - val_loss: 0.1098 - val_accuracy: 0.9443\n",
      "Epoch 39/80\n",
      "16647/16647 [==============================] - 1s 36us/step - loss: 0.1146 - accuracy: 0.9483 - val_loss: 0.1155 - val_accuracy: 0.9411\n",
      "Epoch 40/80\n",
      "16647/16647 [==============================] - 1s 32us/step - loss: 0.1168 - accuracy: 0.9449 - val_loss: 0.1084 - val_accuracy: 0.9443\n",
      "Epoch 41/80\n",
      "16647/16647 [==============================] - 1s 34us/step - loss: 0.1123 - accuracy: 0.9459 - val_loss: 0.1087 - val_accuracy: 0.9405\n",
      "Epoch 42/80\n",
      "16647/16647 [==============================] - 1s 35us/step - loss: 0.1129 - accuracy: 0.9458 - val_loss: 0.1065 - val_accuracy: 0.9486\n",
      "Epoch 00042: early stopping\n",
      "[[9.99998450e-01 1.00037454e-07 5.02048927e-08 1.35947357e-06\n",
      "  2.95816740e-08 8.59615668e-09]\n",
      " [4.18499185e-05 7.21931399e-04 3.46159104e-05 2.01370014e-08\n",
      "  4.57583694e-04 9.98744011e-01]\n",
      " [4.12521586e-05 7.09176064e-04 3.44859145e-05 1.98766372e-08\n",
      "  4.56053764e-04 9.98759031e-01]\n",
      " ...\n",
      " [6.03464798e-07 4.45257298e-09 9.98188198e-01 1.77878654e-03\n",
      "  4.70056549e-10 3.23450731e-05]\n",
      " [1.10621069e-04 2.79525967e-08 9.26584363e-01 1.47866865e-03\n",
      "  6.58680797e-02 5.95824746e-03]\n",
      " [3.07043535e-07 9.90636392e-13 6.44143529e-06 2.74442941e-10\n",
      "  9.99978662e-01 1.45668791e-05]]\n",
      "[0 5 5 ... 2 2 4]\n",
      "<class 'numpy.ndarray'>\n",
      "One CNN, r:  1\n",
      "Computing Time:  0:01:18.153013\n",
      "Model: \"sequential_1\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv1d_1 (Conv1D)            (None, 3, 6)              12        \n",
      "_________________________________________________________________\n",
      "average_pooling1d_1 (Average (None, 1, 6)              0         \n",
      "_________________________________________________________________\n",
      "conv1d_2 (Conv1D)            (None, 1, 16)             112       \n",
      "_________________________________________________________________\n",
      "average_pooling1d_2 (Average (None, 1, 16)             0         \n",
      "_________________________________________________________________\n",
      "conv1d_3 (Conv1D)            (None, 1, 120)            2040      \n",
      "_________________________________________________________________\n",
      "flatten_1 (Flatten)          (None, 120)               0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 84)                10164     \n",
      "_________________________________________________________________\n",
      "preds (Dense)                (None, 6)                 510       \n",
      "=================================================================\n",
      "Total params: 12,838\n",
      "Trainable params: 12,838\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Train on 16647 samples, validate on 1850 samples\n",
      "Epoch 1/80\n",
      "16647/16647 [==============================] - 1s 54us/step - loss: 0.7108 - accuracy: 0.7104 - val_loss: 0.4356 - val_accuracy: 0.8270\n",
      "Epoch 2/80\n",
      "16647/16647 [==============================] - 1s 40us/step - loss: 0.3392 - accuracy: 0.8771 - val_loss: 0.2785 - val_accuracy: 0.8816\n",
      "Epoch 3/80\n",
      "16647/16647 [==============================] - 1s 40us/step - loss: 0.2329 - accuracy: 0.9094 - val_loss: 0.2080 - val_accuracy: 0.9157\n",
      "Epoch 4/80\n",
      "16647/16647 [==============================] - 1s 38us/step - loss: 0.1920 - accuracy: 0.9238 - val_loss: 0.2263 - val_accuracy: 0.9189\n",
      "Epoch 5/80\n",
      "16647/16647 [==============================] - 1s 39us/step - loss: 0.1881 - accuracy: 0.9226 - val_loss: 0.1793 - val_accuracy: 0.9249\n",
      "Epoch 6/80\n",
      "16647/16647 [==============================] - 1s 41us/step - loss: 0.1703 - accuracy: 0.9268 - val_loss: 0.1580 - val_accuracy: 0.9335\n",
      "Epoch 7/80\n",
      "16647/16647 [==============================] - 1s 44us/step - loss: 0.1622 - accuracy: 0.9307 - val_loss: 0.1514 - val_accuracy: 0.9357\n",
      "Epoch 8/80\n",
      "16647/16647 [==============================] - 1s 39us/step - loss: 0.1613 - accuracy: 0.9311 - val_loss: 0.1615 - val_accuracy: 0.9227\n",
      "Epoch 9/80\n",
      "16647/16647 [==============================] - 1s 39us/step - loss: 0.1580 - accuracy: 0.9334 - val_loss: 0.1451 - val_accuracy: 0.9351\n",
      "Epoch 10/80\n",
      "16647/16647 [==============================] - 1s 39us/step - loss: 0.1555 - accuracy: 0.9341 - val_loss: 0.1442 - val_accuracy: 0.9416\n",
      "Epoch 11/80\n",
      "16647/16647 [==============================] - 1s 39us/step - loss: 0.1579 - accuracy: 0.9312 - val_loss: 0.1644 - val_accuracy: 0.9422\n",
      "Epoch 12/80\n",
      "16647/16647 [==============================] - 1s 39us/step - loss: 0.1488 - accuracy: 0.9361 - val_loss: 0.1342 - val_accuracy: 0.9459\n",
      "Epoch 13/80\n",
      "16647/16647 [==============================] - 1s 39us/step - loss: 0.1464 - accuracy: 0.9386 - val_loss: 0.1412 - val_accuracy: 0.9357\n",
      "Epoch 14/80\n",
      "16647/16647 [==============================] - 1s 42us/step - loss: 0.1398 - accuracy: 0.9400 - val_loss: 0.1346 - val_accuracy: 0.9411\n",
      "Epoch 15/80\n",
      "16647/16647 [==============================] - 1s 38us/step - loss: 0.1396 - accuracy: 0.9409 - val_loss: 0.1290 - val_accuracy: 0.9508\n",
      "Epoch 16/80\n",
      "16647/16647 [==============================] - 1s 40us/step - loss: 0.1367 - accuracy: 0.9385 - val_loss: 0.1403 - val_accuracy: 0.9395\n",
      "Epoch 17/80\n",
      "16647/16647 [==============================] - 1s 38us/step - loss: 0.1339 - accuracy: 0.9421 - val_loss: 0.1391 - val_accuracy: 0.9411\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 18/80\n",
      "16647/16647 [==============================] - 1s 40us/step - loss: 0.1351 - accuracy: 0.9413 - val_loss: 0.1292 - val_accuracy: 0.9519\n",
      "Epoch 19/80\n",
      "16647/16647 [==============================] - 1s 38us/step - loss: 0.1331 - accuracy: 0.9428 - val_loss: 0.1274 - val_accuracy: 0.9443\n",
      "Epoch 20/80\n",
      "16647/16647 [==============================] - 1s 40us/step - loss: 0.1354 - accuracy: 0.9420 - val_loss: 0.4306 - val_accuracy: 0.8216\n",
      "Epoch 21/80\n",
      "16647/16647 [==============================] - 1s 38us/step - loss: 0.1408 - accuracy: 0.9393 - val_loss: 0.1206 - val_accuracy: 0.9503\n",
      "Epoch 22/80\n",
      "16647/16647 [==============================] - 1s 38us/step - loss: 0.1282 - accuracy: 0.9440 - val_loss: 0.1329 - val_accuracy: 0.9378\n",
      "Epoch 23/80\n",
      "16647/16647 [==============================] - 1s 38us/step - loss: 0.1269 - accuracy: 0.9429 - val_loss: 0.1187 - val_accuracy: 0.9459\n",
      "Epoch 24/80\n",
      "16647/16647 [==============================] - 1s 43us/step - loss: 0.1256 - accuracy: 0.9435 - val_loss: 0.1263 - val_accuracy: 0.9465\n",
      "Epoch 25/80\n",
      "16647/16647 [==============================] - 1s 39us/step - loss: 0.1254 - accuracy: 0.9439 - val_loss: 0.1197 - val_accuracy: 0.9481\n",
      "Epoch 26/80\n",
      "16647/16647 [==============================] - 1s 38us/step - loss: 0.1234 - accuracy: 0.9458 - val_loss: 0.1422 - val_accuracy: 0.9362\n",
      "Epoch 27/80\n",
      "16647/16647 [==============================] - 1s 38us/step - loss: 0.1218 - accuracy: 0.9438 - val_loss: 0.1243 - val_accuracy: 0.9470\n",
      "Epoch 28/80\n",
      "16647/16647 [==============================] - 1s 39us/step - loss: 0.1226 - accuracy: 0.9427 - val_loss: 0.1288 - val_accuracy: 0.9497\n",
      "Epoch 29/80\n",
      "16647/16647 [==============================] - 1s 36us/step - loss: 0.1214 - accuracy: 0.9450 - val_loss: 0.1262 - val_accuracy: 0.9427\n",
      "Epoch 30/80\n",
      "16647/16647 [==============================] - 1s 36us/step - loss: 0.1216 - accuracy: 0.9443 - val_loss: 0.1167 - val_accuracy: 0.9470\n",
      "Epoch 31/80\n",
      "16647/16647 [==============================] - 1s 37us/step - loss: 0.1176 - accuracy: 0.9440 - val_loss: 0.1206 - val_accuracy: 0.9454\n",
      "Epoch 32/80\n",
      "16647/16647 [==============================] - 1s 39us/step - loss: 0.1160 - accuracy: 0.9453 - val_loss: 0.1207 - val_accuracy: 0.9476\n",
      "Epoch 33/80\n",
      "16647/16647 [==============================] - 1s 38us/step - loss: 0.1156 - accuracy: 0.9459 - val_loss: 0.1249 - val_accuracy: 0.9395\n",
      "Epoch 34/80\n",
      "16647/16647 [==============================] - 1s 38us/step - loss: 0.1146 - accuracy: 0.9458 - val_loss: 0.1159 - val_accuracy: 0.9541\n",
      "Epoch 35/80\n",
      "16647/16647 [==============================] - 1s 39us/step - loss: 0.1156 - accuracy: 0.9450 - val_loss: 0.1296 - val_accuracy: 0.9346\n",
      "Epoch 36/80\n",
      "16647/16647 [==============================] - 1s 37us/step - loss: 0.1143 - accuracy: 0.9447 - val_loss: 0.1159 - val_accuracy: 0.9508\n",
      "Epoch 37/80\n",
      "16647/16647 [==============================] - ETA: 0s - loss: 0.1170 - accuracy: 0.9425 ETA: 0s - loss: 0.1155 - accuracy:  - 1s 38us/step - loss: 0.1160 - accuracy: 0.9433 - val_loss: 0.1322 - val_accuracy: 0.9395\n",
      "Epoch 38/80\n",
      "16647/16647 [==============================] - 1s 39us/step - loss: 0.1144 - accuracy: 0.9435 - val_loss: 0.1199 - val_accuracy: 0.9432\n",
      "Epoch 39/80\n",
      "16647/16647 [==============================] - 1s 38us/step - loss: 0.1111 - accuracy: 0.9481 - val_loss: 0.1209 - val_accuracy: 0.9492\n",
      "Epoch 40/80\n",
      "16647/16647 [==============================] - 1s 39us/step - loss: 0.1146 - accuracy: 0.9452 - val_loss: 0.1219 - val_accuracy: 0.9400\n",
      "Epoch 41/80\n",
      "16647/16647 [==============================] - 1s 38us/step - loss: 0.1139 - accuracy: 0.9463 - val_loss: 0.1233 - val_accuracy: 0.9443\n",
      "Epoch 42/80\n",
      "16647/16647 [==============================] - 1s 34us/step - loss: 0.1169 - accuracy: 0.9426 - val_loss: 0.1183 - val_accuracy: 0.9449\n",
      "Epoch 43/80\n",
      "16647/16647 [==============================] - 1s 34us/step - loss: 0.1120 - accuracy: 0.9464 - val_loss: 0.1141 - val_accuracy: 0.9514\n",
      "Epoch 44/80\n",
      "16647/16647 [==============================] - 1s 37us/step - loss: 0.1106 - accuracy: 0.9461 - val_loss: 0.1186 - val_accuracy: 0.9459\n",
      "Epoch 45/80\n",
      "16647/16647 [==============================] - 1s 35us/step - loss: 0.1129 - accuracy: 0.9460 - val_loss: 0.1225 - val_accuracy: 0.9459\n",
      "Epoch 46/80\n",
      "16647/16647 [==============================] - 1s 38us/step - loss: 0.1164 - accuracy: 0.9443 - val_loss: 0.1150 - val_accuracy: 0.9519\n",
      "Epoch 47/80\n",
      "16647/16647 [==============================] - 1s 36us/step - loss: 0.1087 - accuracy: 0.9484 - val_loss: 0.1212 - val_accuracy: 0.9422\n",
      "Epoch 48/80\n",
      "16647/16647 [==============================] - 1s 35us/step - loss: 0.1155 - accuracy: 0.9444 - val_loss: 0.1168 - val_accuracy: 0.9530\n",
      "Epoch 49/80\n",
      "16647/16647 [==============================] - 1s 35us/step - loss: 0.1092 - accuracy: 0.9473 - val_loss: 0.1154 - val_accuracy: 0.9400\n",
      "Epoch 50/80\n",
      "16647/16647 [==============================] - 1s 33us/step - loss: 0.1128 - accuracy: 0.9450 - val_loss: 0.1307 - val_accuracy: 0.9308\n",
      "Epoch 51/80\n",
      "16647/16647 [==============================] - 1s 36us/step - loss: 0.1154 - accuracy: 0.9450 - val_loss: 0.1145 - val_accuracy: 0.9497\n",
      "Epoch 52/80\n",
      "16647/16647 [==============================] - 1s 37us/step - loss: 0.1103 - accuracy: 0.9454 - val_loss: 0.1240 - val_accuracy: 0.9476\n",
      "Epoch 53/80\n",
      "16647/16647 [==============================] - 1s 38us/step - loss: 0.1087 - accuracy: 0.9466 - val_loss: 0.1249 - val_accuracy: 0.9303\n",
      "Epoch 00053: early stopping\n",
      "[[9.9999785e-01 2.0992227e-08 4.4750923e-08 1.2790299e-06 1.7080487e-09\n",
      "  7.8710872e-07]\n",
      " [9.0660369e-06 2.2879266e-04 3.6425423e-05 4.8242271e-07 6.4703039e-05\n",
      "  9.9966049e-01]\n",
      " [8.9076857e-06 2.2575533e-04 3.6274505e-05 4.7614407e-07 6.4808111e-05\n",
      "  9.9966371e-01]\n",
      " ...\n",
      " [4.7977283e-10 3.1368363e-12 9.9959952e-01 3.9718204e-04 3.2435231e-12\n",
      "  3.3949689e-06]\n",
      " [4.0962086e-06 6.8208821e-11 9.9623066e-01 2.3928010e-03 9.5527741e-04\n",
      "  4.1717221e-04]\n",
      " [2.4730957e-09 3.8141348e-16 2.4490061e-09 2.3004154e-11 9.9999976e-01\n",
      "  2.0103904e-07]]\n",
      "[0 5 5 ... 2 2 4]\n",
      "<class 'numpy.ndarray'>\n",
      "One CNN, r:  2\n",
      "Computing Time:  0:01:56.449880\n",
      "Model: \"sequential_1\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv1d_1 (Conv1D)            (None, 3, 6)              12        \n",
      "_________________________________________________________________\n",
      "average_pooling1d_1 (Average (None, 1, 6)              0         \n",
      "_________________________________________________________________\n",
      "conv1d_2 (Conv1D)            (None, 1, 16)             112       \n",
      "_________________________________________________________________\n",
      "average_pooling1d_2 (Average (None, 1, 16)             0         \n",
      "_________________________________________________________________\n",
      "conv1d_3 (Conv1D)            (None, 1, 120)            2040      \n",
      "_________________________________________________________________\n",
      "flatten_1 (Flatten)          (None, 120)               0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 84)                10164     \n",
      "_________________________________________________________________\n",
      "preds (Dense)                (None, 6)                 510       \n",
      "=================================================================\n",
      "Total params: 12,838\n",
      "Trainable params: 12,838\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Train on 16647 samples, validate on 1850 samples\n",
      "Epoch 1/80\n",
      "16647/16647 [==============================] - 1s 54us/step - loss: 0.7234 - accuracy: 0.7376 - val_loss: 0.3831 - val_accuracy: 0.8827\n",
      "Epoch 2/80\n",
      "16647/16647 [==============================] - 1s 37us/step - loss: 0.2986 - accuracy: 0.8961 - val_loss: 0.2563 - val_accuracy: 0.8989\n",
      "Epoch 3/80\n",
      "16647/16647 [==============================] - 1s 37us/step - loss: 0.2195 - accuracy: 0.9171 - val_loss: 0.2219 - val_accuracy: 0.9076\n",
      "Epoch 4/80\n",
      "16647/16647 [==============================] - 1s 37us/step - loss: 0.1932 - accuracy: 0.9226 - val_loss: 0.1929 - val_accuracy: 0.9200\n",
      "Epoch 5/80\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "16647/16647 [==============================] - 1s 38us/step - loss: 0.1763 - accuracy: 0.9300 - val_loss: 0.1749 - val_accuracy: 0.9303\n",
      "Epoch 6/80\n",
      "16647/16647 [==============================] - 1s 41us/step - loss: 0.1724 - accuracy: 0.9304 - val_loss: 0.1667 - val_accuracy: 0.9249\n",
      "Epoch 7/80\n",
      "16647/16647 [==============================] - 1s 37us/step - loss: 0.1600 - accuracy: 0.9332 - val_loss: 0.1763 - val_accuracy: 0.9249\n",
      "Epoch 8/80\n",
      "16647/16647 [==============================] - 1s 37us/step - loss: 0.1541 - accuracy: 0.9357 - val_loss: 0.1755 - val_accuracy: 0.9324\n",
      "Epoch 9/80\n",
      "16647/16647 [==============================] - 1s 35us/step - loss: 0.1488 - accuracy: 0.9376 - val_loss: 0.1541 - val_accuracy: 0.9351\n",
      "Epoch 10/80\n",
      "16647/16647 [==============================] - 1s 37us/step - loss: 0.1496 - accuracy: 0.9367 - val_loss: 0.1570 - val_accuracy: 0.9254\n",
      "Epoch 11/80\n",
      "16647/16647 [==============================] - 1s 37us/step - loss: 0.1464 - accuracy: 0.9385 - val_loss: 0.1681 - val_accuracy: 0.9259\n",
      "Epoch 12/80\n",
      "16647/16647 [==============================] - 1s 36us/step - loss: 0.1423 - accuracy: 0.9399 - val_loss: 0.1546 - val_accuracy: 0.9281\n",
      "Epoch 13/80\n",
      "16647/16647 [==============================] - 1s 36us/step - loss: 0.1379 - accuracy: 0.9417 - val_loss: 0.1469 - val_accuracy: 0.9308\n",
      "Epoch 14/80\n",
      "16647/16647 [==============================] - 1s 36us/step - loss: 0.1391 - accuracy: 0.9422 - val_loss: 0.1459 - val_accuracy: 0.9400\n",
      "Epoch 15/80\n",
      "16647/16647 [==============================] - 1s 40us/step - loss: 0.1337 - accuracy: 0.9445 - val_loss: 0.1431 - val_accuracy: 0.9368\n",
      "Epoch 16/80\n",
      "16647/16647 [==============================] - 1s 38us/step - loss: 0.1365 - accuracy: 0.9423 - val_loss: 0.1423 - val_accuracy: 0.9395\n",
      "Epoch 17/80\n",
      "16647/16647 [==============================] - 1s 39us/step - loss: 0.1326 - accuracy: 0.9426 - val_loss: 0.1516 - val_accuracy: 0.9341\n",
      "Epoch 18/80\n",
      "16647/16647 [==============================] - 1s 37us/step - loss: 0.1336 - accuracy: 0.9438 - val_loss: 0.1439 - val_accuracy: 0.9405\n",
      "Epoch 19/80\n",
      "16647/16647 [==============================] - 1s 37us/step - loss: 0.1313 - accuracy: 0.9440 - val_loss: 0.1489 - val_accuracy: 0.9405\n",
      "Epoch 20/80\n",
      "16647/16647 [==============================] - 1s 38us/step - loss: 0.1316 - accuracy: 0.9438 - val_loss: 0.1472 - val_accuracy: 0.9416\n",
      "Epoch 21/80\n",
      "16647/16647 [==============================] - 1s 37us/step - loss: 0.1288 - accuracy: 0.9440 - val_loss: 0.1367 - val_accuracy: 0.9411\n",
      "Epoch 22/80\n",
      "16647/16647 [==============================] - 1s 38us/step - loss: 0.1261 - accuracy: 0.9460 - val_loss: 0.1359 - val_accuracy: 0.9438\n",
      "Epoch 23/80\n",
      "16647/16647 [==============================] - 1s 36us/step - loss: 0.1282 - accuracy: 0.9444 - val_loss: 0.1304 - val_accuracy: 0.9427\n",
      "Epoch 24/80\n",
      "16647/16647 [==============================] - 1s 37us/step - loss: 0.1268 - accuracy: 0.9436 - val_loss: 0.1342 - val_accuracy: 0.9449\n",
      "Epoch 25/80\n",
      "16647/16647 [==============================] - 1s 36us/step - loss: 0.1253 - accuracy: 0.9453 - val_loss: 0.1363 - val_accuracy: 0.9330\n",
      "Epoch 26/80\n",
      "16647/16647 [==============================] - 1s 37us/step - loss: 0.1234 - accuracy: 0.9434 - val_loss: 0.1406 - val_accuracy: 0.9303\n",
      "Epoch 27/80\n",
      "16647/16647 [==============================] - 1s 36us/step - loss: 0.1228 - accuracy: 0.9441 - val_loss: 0.1290 - val_accuracy: 0.9400\n",
      "Epoch 28/80\n",
      "16647/16647 [==============================] - 1s 36us/step - loss: 0.1219 - accuracy: 0.9426 - val_loss: 0.1376 - val_accuracy: 0.9303\n",
      "Epoch 29/80\n",
      "16647/16647 [==============================] - 1s 37us/step - loss: 0.1219 - accuracy: 0.9432 - val_loss: 0.1247 - val_accuracy: 0.9411\n",
      "Epoch 30/80\n",
      "16647/16647 [==============================] - 1s 37us/step - loss: 0.1176 - accuracy: 0.9456 - val_loss: 0.1331 - val_accuracy: 0.9438\n",
      "Epoch 31/80\n",
      "16647/16647 [==============================] - 1s 35us/step - loss: 0.1191 - accuracy: 0.9444 - val_loss: 0.1376 - val_accuracy: 0.9411\n",
      "Epoch 32/80\n",
      "16647/16647 [==============================] - 1s 36us/step - loss: 0.1201 - accuracy: 0.9443 - val_loss: 0.1300 - val_accuracy: 0.9389\n",
      "Epoch 33/80\n",
      "16647/16647 [==============================] - 1s 37us/step - loss: 0.1190 - accuracy: 0.9427 - val_loss: 0.1297 - val_accuracy: 0.9465\n",
      "Epoch 34/80\n",
      "16647/16647 [==============================] - 1s 36us/step - loss: 0.1170 - accuracy: 0.9450 - val_loss: 0.1260 - val_accuracy: 0.9432\n",
      "Epoch 35/80\n",
      "16647/16647 [==============================] - 1s 36us/step - loss: 0.1156 - accuracy: 0.9452 - val_loss: 0.1211 - val_accuracy: 0.9432\n",
      "Epoch 36/80\n",
      "16647/16647 [==============================] - 1s 37us/step - loss: 0.1171 - accuracy: 0.9452 - val_loss: 0.1243 - val_accuracy: 0.9443\n",
      "Epoch 37/80\n",
      "16647/16647 [==============================] - 1s 37us/step - loss: 0.1190 - accuracy: 0.9435 - val_loss: 0.1206 - val_accuracy: 0.9395\n",
      "Epoch 38/80\n",
      "16647/16647 [==============================] - 1s 35us/step - loss: 0.1154 - accuracy: 0.9442 - val_loss: 0.1278 - val_accuracy: 0.9384\n",
      "Epoch 39/80\n",
      "16647/16647 [==============================] - 1s 37us/step - loss: 0.1130 - accuracy: 0.9470 - val_loss: 0.1176 - val_accuracy: 0.9416\n",
      "Epoch 40/80\n",
      "16647/16647 [==============================] - 1s 35us/step - loss: 0.1157 - accuracy: 0.9450 - val_loss: 0.1205 - val_accuracy: 0.9400\n",
      "Epoch 41/80\n",
      "16647/16647 [==============================] - 1s 38us/step - loss: 0.1160 - accuracy: 0.9444 - val_loss: 0.1191 - val_accuracy: 0.9400\n",
      "Epoch 42/80\n",
      "16647/16647 [==============================] - 1s 38us/step - loss: 0.1128 - accuracy: 0.9460 - val_loss: 0.1176 - val_accuracy: 0.9432\n",
      "Epoch 43/80\n",
      "16647/16647 [==============================] - 1s 35us/step - loss: 0.1147 - accuracy: 0.9469 - val_loss: 0.1206 - val_accuracy: 0.9395\n",
      "Epoch 44/80\n",
      "16647/16647 [==============================] - 1s 35us/step - loss: 0.1125 - accuracy: 0.9461 - val_loss: 0.1152 - val_accuracy: 0.9443\n",
      "Epoch 45/80\n",
      "16647/16647 [==============================] - 1s 35us/step - loss: 0.1112 - accuracy: 0.9458 - val_loss: 0.1164 - val_accuracy: 0.9432\n",
      "Epoch 46/80\n",
      "16647/16647 [==============================] - 1s 37us/step - loss: 0.1120 - accuracy: 0.9473 - val_loss: 0.1251 - val_accuracy: 0.9373\n",
      "Epoch 47/80\n",
      "16647/16647 [==============================] - 1s 38us/step - loss: 0.1124 - accuracy: 0.9467 - val_loss: 0.1157 - val_accuracy: 0.9481\n",
      "Epoch 48/80\n",
      "16647/16647 [==============================] - 1s 38us/step - loss: 0.1131 - accuracy: 0.9459 - val_loss: 0.1127 - val_accuracy: 0.9427\n",
      "Epoch 49/80\n",
      "16647/16647 [==============================] - 1s 36us/step - loss: 0.1114 - accuracy: 0.9465 - val_loss: 0.1155 - val_accuracy: 0.9454\n",
      "Epoch 50/80\n",
      "16647/16647 [==============================] - 1s 36us/step - loss: 0.1118 - accuracy: 0.9456 - val_loss: 0.1284 - val_accuracy: 0.9389\n",
      "Epoch 51/80\n",
      "16647/16647 [==============================] - 1s 39us/step - loss: 0.1139 - accuracy: 0.9454 - val_loss: 0.1163 - val_accuracy: 0.9432\n",
      "Epoch 52/80\n",
      "16647/16647 [==============================] - 1s 38us/step - loss: 0.1101 - accuracy: 0.9479 - val_loss: 0.1122 - val_accuracy: 0.9459\n",
      "Epoch 53/80\n",
      "16647/16647 [==============================] - 1s 37us/step - loss: 0.1107 - accuracy: 0.9459 - val_loss: 0.1114 - val_accuracy: 0.9449\n",
      "Epoch 54/80\n",
      "16647/16647 [==============================] - 1s 38us/step - loss: 0.1088 - accuracy: 0.9477 - val_loss: 0.1159 - val_accuracy: 0.9373\n",
      "Epoch 55/80\n",
      "16647/16647 [==============================] - 1s 38us/step - loss: 0.1124 - accuracy: 0.9447 - val_loss: 0.1141 - val_accuracy: 0.9443\n",
      "Epoch 56/80\n",
      "16647/16647 [==============================] - 1s 36us/step - loss: 0.1108 - accuracy: 0.9473 - val_loss: 0.1187 - val_accuracy: 0.9405\n",
      "Epoch 57/80\n",
      "16647/16647 [==============================] - 1s 35us/step - loss: 0.1106 - accuracy: 0.9471 - val_loss: 0.1111 - val_accuracy: 0.9459\n",
      "Epoch 58/80\n",
      "16647/16647 [==============================] - 1s 37us/step - loss: 0.1087 - accuracy: 0.9477 - val_loss: 0.1106 - val_accuracy: 0.9519\n",
      "Epoch 59/80\n",
      "16647/16647 [==============================] - 1s 35us/step - loss: 0.1083 - accuracy: 0.9488 - val_loss: 0.1185 - val_accuracy: 0.9373\n",
      "Epoch 60/80\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "16647/16647 [==============================] - 1s 37us/step - loss: 0.1097 - accuracy: 0.9467 - val_loss: 0.1079 - val_accuracy: 0.9508\n",
      "Epoch 61/80\n",
      "16647/16647 [==============================] - 1s 36us/step - loss: 0.1089 - accuracy: 0.9479 - val_loss: 0.1124 - val_accuracy: 0.9438\n",
      "Epoch 62/80\n",
      "16647/16647 [==============================] - 1s 36us/step - loss: 0.1098 - accuracy: 0.9470 - val_loss: 0.1070 - val_accuracy: 0.9524\n",
      "Epoch 63/80\n",
      "16647/16647 [==============================] - 1s 37us/step - loss: 0.1109 - accuracy: 0.9467 - val_loss: 0.1156 - val_accuracy: 0.9470\n",
      "Epoch 64/80\n",
      "16647/16647 [==============================] - 1s 36us/step - loss: 0.1099 - accuracy: 0.9480 - val_loss: 0.1124 - val_accuracy: 0.9416\n",
      "Epoch 65/80\n",
      "16647/16647 [==============================] - 1s 36us/step - loss: 0.1073 - accuracy: 0.9471 - val_loss: 0.1152 - val_accuracy: 0.9481\n",
      "Epoch 66/80\n",
      "16647/16647 [==============================] - 1s 37us/step - loss: 0.1078 - accuracy: 0.9475 - val_loss: 0.1173 - val_accuracy: 0.9416\n",
      "Epoch 67/80\n",
      "16647/16647 [==============================] - 1s 35us/step - loss: 0.1083 - accuracy: 0.9469 - val_loss: 0.1167 - val_accuracy: 0.9503\n",
      "Epoch 68/80\n",
      "16647/16647 [==============================] - 1s 35us/step - loss: 0.1094 - accuracy: 0.9469 - val_loss: 0.1070 - val_accuracy: 0.9519\n",
      "Epoch 69/80\n",
      "16647/16647 [==============================] - 1s 36us/step - loss: 0.1069 - accuracy: 0.9473 - val_loss: 0.1088 - val_accuracy: 0.9481\n",
      "Epoch 70/80\n",
      "16647/16647 [==============================] - 1s 39us/step - loss: 0.1101 - accuracy: 0.9470 - val_loss: 0.1197 - val_accuracy: 0.9427\n",
      "Epoch 71/80\n",
      "16647/16647 [==============================] - 1s 38us/step - loss: 0.1085 - accuracy: 0.9474 - val_loss: 0.1064 - val_accuracy: 0.9535\n",
      "Epoch 72/80\n",
      "16647/16647 [==============================] - 1s 41us/step - loss: 0.1092 - accuracy: 0.9471 - val_loss: 0.1160 - val_accuracy: 0.9416\n",
      "Epoch 73/80\n",
      "16647/16647 [==============================] - 1s 35us/step - loss: 0.1111 - accuracy: 0.9461 - val_loss: 0.1188 - val_accuracy: 0.9449\n",
      "Epoch 74/80\n",
      "16647/16647 [==============================] - 1s 37us/step - loss: 0.1059 - accuracy: 0.9495 - val_loss: 0.1055 - val_accuracy: 0.9492\n",
      "Epoch 75/80\n",
      "16647/16647 [==============================] - 1s 40us/step - loss: 0.1077 - accuracy: 0.9465 - val_loss: 0.1179 - val_accuracy: 0.9416\n",
      "Epoch 76/80\n",
      "16647/16647 [==============================] - 1s 35us/step - loss: 0.1140 - accuracy: 0.9449 - val_loss: 0.1100 - val_accuracy: 0.9449\n",
      "Epoch 77/80\n",
      "16647/16647 [==============================] - 1s 38us/step - loss: 0.1060 - accuracy: 0.9480 - val_loss: 0.1082 - val_accuracy: 0.9524\n",
      "Epoch 78/80\n",
      "16647/16647 [==============================] - 1s 36us/step - loss: 0.1071 - accuracy: 0.9473 - val_loss: 0.1114 - val_accuracy: 0.9476\n",
      "Epoch 79/80\n",
      "16647/16647 [==============================] - 1s 38us/step - loss: 0.1078 - accuracy: 0.9467 - val_loss: 0.1071 - val_accuracy: 0.9508\n",
      "Epoch 80/80\n",
      "16647/16647 [==============================] - 1s 42us/step - loss: 0.1075 - accuracy: 0.9485 - val_loss: 0.1205 - val_accuracy: 0.9368\n",
      "[[9.99999762e-01 4.10885700e-11 2.22053886e-12 2.46840216e-07\n",
      "  7.18538467e-12 1.35288482e-13]\n",
      " [4.84719523e-04 9.34027787e-03 1.53437995e-05 9.92206495e-08\n",
      "  7.02956413e-07 9.90158856e-01]\n",
      " [4.72594373e-04 9.18948371e-03 1.52788725e-05 9.68601697e-08\n",
      "  7.09698838e-07 9.90321815e-01]\n",
      " ...\n",
      " [3.89127315e-12 1.67826940e-07 9.99623060e-01 3.69313813e-04\n",
      "  4.35663685e-13 7.50401750e-06]\n",
      " [1.52973644e-06 2.14122808e-09 9.95703518e-01 2.78897025e-03\n",
      "  1.21310807e-03 2.92834418e-04]\n",
      " [1.16380115e-05 7.06113905e-14 8.68852385e-06 1.70181473e-11\n",
      "  9.99966383e-01 1.32737732e-05]]\n",
      "[0 5 5 ... 2 2 4]\n",
      "<class 'numpy.ndarray'>\n",
      "One CNN, r:  3\n",
      "Computing Time:  0:02:50.192860\n",
      "Model: \"sequential_1\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv1d_1 (Conv1D)            (None, 3, 6)              12        \n",
      "_________________________________________________________________\n",
      "average_pooling1d_1 (Average (None, 1, 6)              0         \n",
      "_________________________________________________________________\n",
      "conv1d_2 (Conv1D)            (None, 1, 16)             112       \n",
      "_________________________________________________________________\n",
      "average_pooling1d_2 (Average (None, 1, 16)             0         \n",
      "_________________________________________________________________\n",
      "conv1d_3 (Conv1D)            (None, 1, 120)            2040      \n",
      "_________________________________________________________________\n",
      "flatten_1 (Flatten)          (None, 120)               0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 84)                10164     \n",
      "_________________________________________________________________\n",
      "preds (Dense)                (None, 6)                 510       \n",
      "=================================================================\n",
      "Total params: 12,838\n",
      "Trainable params: 12,838\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Train on 16647 samples, validate on 1850 samples\n",
      "Epoch 1/80\n",
      "16647/16647 [==============================] - 1s 54us/step - loss: 0.6562 - accuracy: 0.7382 - val_loss: 0.4168 - val_accuracy: 0.8578\n",
      "Epoch 2/80\n",
      "16647/16647 [==============================] - 1s 42us/step - loss: 0.3521 - accuracy: 0.8738 - val_loss: 0.2767 - val_accuracy: 0.8941\n",
      "Epoch 3/80\n",
      "16647/16647 [==============================] - 1s 40us/step - loss: 0.2572 - accuracy: 0.9050 - val_loss: 0.2291 - val_accuracy: 0.9151\n",
      "Epoch 4/80\n",
      "16647/16647 [==============================] - 1s 38us/step - loss: 0.2084 - accuracy: 0.9173 - val_loss: 0.1798 - val_accuracy: 0.9303\n",
      "Epoch 5/80\n",
      "16647/16647 [==============================] - 1s 39us/step - loss: 0.1907 - accuracy: 0.9239 - val_loss: 0.1709 - val_accuracy: 0.9308\n",
      "Epoch 6/80\n",
      "16647/16647 [==============================] - 1s 37us/step - loss: 0.1819 - accuracy: 0.9243 - val_loss: 0.1732 - val_accuracy: 0.9308\n",
      "Epoch 7/80\n",
      "16647/16647 [==============================] - 1s 38us/step - loss: 0.1771 - accuracy: 0.9249 - val_loss: 0.1686 - val_accuracy: 0.9270\n",
      "Epoch 8/80\n",
      "16647/16647 [==============================] - 1s 38us/step - loss: 0.1802 - accuracy: 0.9227 - val_loss: 0.1466 - val_accuracy: 0.9351\n",
      "Epoch 9/80\n",
      "16647/16647 [==============================] - 1s 38us/step - loss: 0.1649 - accuracy: 0.9273 - val_loss: 0.1517 - val_accuracy: 0.9335\n",
      "Epoch 10/80\n",
      "16647/16647 [==============================] - 1s 38us/step - loss: 0.1663 - accuracy: 0.9266 - val_loss: 0.1440 - val_accuracy: 0.9373\n",
      "Epoch 11/80\n",
      "16647/16647 [==============================] - 1s 38us/step - loss: 0.1595 - accuracy: 0.9307 - val_loss: 0.1578 - val_accuracy: 0.9265\n",
      "Epoch 12/80\n",
      "16647/16647 [==============================] - 1s 35us/step - loss: 0.1611 - accuracy: 0.9286 - val_loss: 0.1387 - val_accuracy: 0.9378\n",
      "Epoch 13/80\n",
      "16647/16647 [==============================] - 1s 38us/step - loss: 0.1568 - accuracy: 0.9304 - val_loss: 0.1565 - val_accuracy: 0.9362\n",
      "Epoch 14/80\n",
      "16647/16647 [==============================] - 1s 37us/step - loss: 0.1584 - accuracy: 0.9298 - val_loss: 0.1401 - val_accuracy: 0.9362\n",
      "Epoch 15/80\n",
      "16647/16647 [==============================] - 1s 38us/step - loss: 0.1565 - accuracy: 0.9315 - val_loss: 0.1436 - val_accuracy: 0.9395\n",
      "Epoch 16/80\n",
      "16647/16647 [==============================] - 1s 38us/step - loss: 0.1563 - accuracy: 0.9316 - val_loss: 0.1414 - val_accuracy: 0.9362\n",
      "Epoch 17/80\n",
      "16647/16647 [==============================] - 1s 38us/step - loss: 0.1572 - accuracy: 0.9302 - val_loss: 0.1354 - val_accuracy: 0.9378\n",
      "Epoch 18/80\n",
      "16647/16647 [==============================] - 1s 36us/step - loss: 0.1528 - accuracy: 0.9319 - val_loss: 0.1547 - val_accuracy: 0.9265\n",
      "Epoch 19/80\n",
      "16647/16647 [==============================] - 1s 37us/step - loss: 0.1529 - accuracy: 0.9321 - val_loss: 0.1650 - val_accuracy: 0.9205\n",
      "Epoch 20/80\n",
      "16647/16647 [==============================] - 1s 38us/step - loss: 0.1517 - accuracy: 0.9313 - val_loss: 0.1368 - val_accuracy: 0.9378\n",
      "Epoch 21/80\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "16647/16647 [==============================] - 1s 38us/step - loss: 0.1491 - accuracy: 0.9316 - val_loss: 0.1430 - val_accuracy: 0.9335\n",
      "Epoch 22/80\n",
      "16647/16647 [==============================] - 1s 37us/step - loss: 0.1520 - accuracy: 0.9334 - val_loss: 0.1330 - val_accuracy: 0.9341\n",
      "Epoch 23/80\n",
      "16647/16647 [==============================] - 1s 40us/step - loss: 0.1505 - accuracy: 0.9317 - val_loss: 0.1302 - val_accuracy: 0.9373\n",
      "Epoch 24/80\n",
      "16647/16647 [==============================] - 1s 38us/step - loss: 0.1475 - accuracy: 0.9334 - val_loss: 0.1435 - val_accuracy: 0.9400\n",
      "Epoch 25/80\n",
      "16647/16647 [==============================] - 1s 39us/step - loss: 0.1460 - accuracy: 0.9359 - val_loss: 0.1283 - val_accuracy: 0.9405\n",
      "Epoch 26/80\n",
      "16647/16647 [==============================] - 1s 38us/step - loss: 0.1416 - accuracy: 0.9354 - val_loss: 0.1356 - val_accuracy: 0.9384\n",
      "Epoch 27/80\n",
      "16647/16647 [==============================] - 1s 39us/step - loss: 0.1455 - accuracy: 0.9342 - val_loss: 0.1363 - val_accuracy: 0.9341\n",
      "Epoch 28/80\n",
      "16647/16647 [==============================] - 1s 38us/step - loss: 0.1432 - accuracy: 0.9345 - val_loss: 0.1589 - val_accuracy: 0.9195\n",
      "Epoch 29/80\n",
      "16647/16647 [==============================] - 1s 40us/step - loss: 0.1418 - accuracy: 0.9358 - val_loss: 0.1265 - val_accuracy: 0.9384\n",
      "Epoch 30/80\n",
      "16647/16647 [==============================] - 1s 37us/step - loss: 0.1463 - accuracy: 0.9344 - val_loss: 0.1422 - val_accuracy: 0.9432\n",
      "Epoch 31/80\n",
      "16647/16647 [==============================] - 1s 37us/step - loss: 0.1413 - accuracy: 0.9339 - val_loss: 0.1340 - val_accuracy: 0.9395\n",
      "Epoch 32/80\n",
      "16647/16647 [==============================] - 1s 36us/step - loss: 0.1439 - accuracy: 0.9342 - val_loss: 0.1332 - val_accuracy: 0.9411\n",
      "Epoch 33/80\n",
      "16647/16647 [==============================] - 1s 38us/step - loss: 0.1397 - accuracy: 0.9358 - val_loss: 0.1274 - val_accuracy: 0.9416\n",
      "Epoch 34/80\n",
      "16647/16647 [==============================] - 1s 37us/step - loss: 0.1404 - accuracy: 0.9344 - val_loss: 0.1264 - val_accuracy: 0.9389\n",
      "Epoch 35/80\n",
      "16647/16647 [==============================] - 1s 33us/step - loss: 0.1408 - accuracy: 0.9360 - val_loss: 0.1580 - val_accuracy: 0.9254\n",
      "Epoch 36/80\n",
      "16647/16647 [==============================] - 1s 36us/step - loss: 0.1359 - accuracy: 0.9375 - val_loss: 0.1238 - val_accuracy: 0.9405\n",
      "Epoch 37/80\n",
      "16647/16647 [==============================] - 1s 36us/step - loss: 0.1387 - accuracy: 0.9352 - val_loss: 0.1232 - val_accuracy: 0.9427\n",
      "Epoch 38/80\n",
      "16647/16647 [==============================] - 1s 37us/step - loss: 0.1368 - accuracy: 0.9370 - val_loss: 0.1265 - val_accuracy: 0.9405\n",
      "Epoch 39/80\n",
      "16647/16647 [==============================] - 1s 35us/step - loss: 0.1373 - accuracy: 0.9370 - val_loss: 0.1376 - val_accuracy: 0.9427\n",
      "Epoch 40/80\n",
      "16647/16647 [==============================] - 1s 40us/step - loss: 0.1360 - accuracy: 0.9379 - val_loss: 0.1339 - val_accuracy: 0.9416\n",
      "Epoch 41/80\n",
      "16647/16647 [==============================] - 1s 37us/step - loss: 0.1391 - accuracy: 0.9366 - val_loss: 0.1298 - val_accuracy: 0.9432\n",
      "Epoch 42/80\n",
      "16647/16647 [==============================] - 1s 37us/step - loss: 0.1346 - accuracy: 0.9379 - val_loss: 0.1297 - val_accuracy: 0.9411\n",
      "Epoch 43/80\n",
      "16647/16647 [==============================] - 1s 37us/step - loss: 0.1342 - accuracy: 0.9396 - val_loss: 0.1800 - val_accuracy: 0.9173\n",
      "Epoch 44/80\n",
      "16647/16647 [==============================] - 1s 38us/step - loss: 0.1434 - accuracy: 0.9370 - val_loss: 0.1165 - val_accuracy: 0.9443\n",
      "Epoch 45/80\n",
      "16647/16647 [==============================] - 1s 38us/step - loss: 0.1330 - accuracy: 0.9385 - val_loss: 0.1187 - val_accuracy: 0.9470\n",
      "Epoch 46/80\n",
      "16647/16647 [==============================] - 1s 39us/step - loss: 0.1343 - accuracy: 0.9406 - val_loss: 0.1232 - val_accuracy: 0.9432\n",
      "Epoch 47/80\n",
      "16647/16647 [==============================] - 1s 37us/step - loss: 0.1291 - accuracy: 0.9403 - val_loss: 0.1132 - val_accuracy: 0.9438\n",
      "Epoch 48/80\n",
      "16647/16647 [==============================] - 1s 36us/step - loss: 0.1334 - accuracy: 0.9376 - val_loss: 0.1178 - val_accuracy: 0.9449\n",
      "Epoch 49/80\n",
      "16647/16647 [==============================] - 1s 35us/step - loss: 0.1313 - accuracy: 0.9400 - val_loss: 0.1170 - val_accuracy: 0.9432\n",
      "Epoch 50/80\n",
      "16647/16647 [==============================] - 1s 38us/step - loss: 0.1317 - accuracy: 0.9405 - val_loss: 0.1157 - val_accuracy: 0.9443\n",
      "Epoch 51/80\n",
      "16647/16647 [==============================] - 1s 38us/step - loss: 0.1313 - accuracy: 0.9413 - val_loss: 0.1153 - val_accuracy: 0.9476\n",
      "Epoch 52/80\n",
      "16647/16647 [==============================] - 1s 34us/step - loss: 0.1303 - accuracy: 0.9409 - val_loss: 0.1192 - val_accuracy: 0.9465\n",
      "Epoch 53/80\n",
      "16647/16647 [==============================] - 1s 34us/step - loss: 0.1274 - accuracy: 0.9422 - val_loss: 0.1401 - val_accuracy: 0.9286\n",
      "Epoch 54/80\n",
      "16647/16647 [==============================] - 1s 35us/step - loss: 0.1306 - accuracy: 0.9396 - val_loss: 0.1156 - val_accuracy: 0.9470\n",
      "Epoch 55/80\n",
      "16647/16647 [==============================] - 1s 34us/step - loss: 0.1257 - accuracy: 0.9428 - val_loss: 0.1125 - val_accuracy: 0.9492\n",
      "Epoch 56/80\n",
      "16647/16647 [==============================] - 1s 34us/step - loss: 0.1245 - accuracy: 0.9438 - val_loss: 0.1166 - val_accuracy: 0.9492\n",
      "Epoch 57/80\n",
      "16647/16647 [==============================] - 1s 34us/step - loss: 0.1253 - accuracy: 0.9432 - val_loss: 0.1414 - val_accuracy: 0.9249\n",
      "Epoch 58/80\n",
      "16647/16647 [==============================] - 1s 36us/step - loss: 0.1298 - accuracy: 0.9394 - val_loss: 0.1103 - val_accuracy: 0.9470\n",
      "Epoch 59/80\n",
      "16647/16647 [==============================] - 1s 37us/step - loss: 0.1281 - accuracy: 0.9441 - val_loss: 0.1168 - val_accuracy: 0.9465\n",
      "Epoch 60/80\n",
      "16647/16647 [==============================] - 1s 35us/step - loss: 0.1287 - accuracy: 0.9432 - val_loss: 0.1221 - val_accuracy: 0.9486\n",
      "Epoch 61/80\n",
      "16647/16647 [==============================] - 1s 37us/step - loss: 0.1279 - accuracy: 0.9414 - val_loss: 0.1101 - val_accuracy: 0.9524\n",
      "Epoch 62/80\n",
      "16647/16647 [==============================] - 1s 34us/step - loss: 0.1260 - accuracy: 0.9431 - val_loss: 0.1120 - val_accuracy: 0.9541\n",
      "Epoch 63/80\n",
      "16647/16647 [==============================] - 1s 38us/step - loss: 0.1286 - accuracy: 0.9424 - val_loss: 0.1139 - val_accuracy: 0.9476\n",
      "Epoch 64/80\n",
      "16647/16647 [==============================] - 1s 37us/step - loss: 0.1233 - accuracy: 0.9438 - val_loss: 0.1051 - val_accuracy: 0.9508\n",
      "Epoch 65/80\n",
      "16647/16647 [==============================] - 1s 36us/step - loss: 0.1240 - accuracy: 0.9452 - val_loss: 0.1053 - val_accuracy: 0.9519\n",
      "Epoch 66/80\n",
      "16647/16647 [==============================] - 1s 36us/step - loss: 0.1206 - accuracy: 0.9480 - val_loss: 0.1180 - val_accuracy: 0.9465\n",
      "Epoch 67/80\n",
      "16647/16647 [==============================] - 1s 39us/step - loss: 0.1239 - accuracy: 0.9427 - val_loss: 0.1081 - val_accuracy: 0.9486\n",
      "Epoch 68/80\n",
      "16647/16647 [==============================] - 1s 36us/step - loss: 0.1226 - accuracy: 0.9447 - val_loss: 0.1093 - val_accuracy: 0.9524\n",
      "Epoch 69/80\n",
      "16647/16647 [==============================] - 1s 37us/step - loss: 0.1255 - accuracy: 0.9429 - val_loss: 0.1118 - val_accuracy: 0.9476\n",
      "Epoch 70/80\n",
      "16647/16647 [==============================] - 1s 35us/step - loss: 0.1210 - accuracy: 0.9465 - val_loss: 0.1152 - val_accuracy: 0.9443\n",
      "Epoch 71/80\n",
      "16647/16647 [==============================] - 1s 36us/step - loss: 0.1235 - accuracy: 0.9448 - val_loss: 0.1115 - val_accuracy: 0.9476\n",
      "Epoch 72/80\n",
      "16647/16647 [==============================] - 1s 37us/step - loss: 0.1282 - accuracy: 0.9432 - val_loss: 0.1105 - val_accuracy: 0.9497\n",
      "Epoch 73/80\n",
      "16647/16647 [==============================] - 1s 37us/step - loss: 0.1189 - accuracy: 0.9465 - val_loss: 0.1066 - val_accuracy: 0.9497\n",
      "Epoch 74/80\n",
      "16647/16647 [==============================] - 1s 37us/step - loss: 0.1211 - accuracy: 0.9447 - val_loss: 0.1052 - val_accuracy: 0.9508\n",
      "Epoch 00074: early stopping\n",
      "[[9.9995112e-01 4.5117209e-05 2.0609360e-08 3.7774191e-06 3.3116142e-12\n",
      "  2.0588133e-09]\n",
      " [2.5783798e-05 9.8666723e-04 4.8057234e-05 1.2676092e-07 7.6635051e-06\n",
      "  9.9893171e-01]\n",
      " [2.5126063e-05 9.6663862e-04 4.7687434e-05 1.2331564e-07 7.6671458e-06\n",
      "  9.9895275e-01]\n",
      " ...\n",
      " [3.1793158e-07 5.2760271e-08 9.9799168e-01 2.0042195e-03 1.5755646e-13\n",
      "  3.7899449e-06]\n",
      " [2.7440547e-06 6.4706802e-11 9.8994595e-01 5.9784134e-03 3.4028790e-03\n",
      "  6.6998356e-04]\n",
      " [9.9830196e-08 2.7530515e-12 3.9540890e-05 7.9708213e-09 9.9992919e-01\n",
      "  3.1120115e-05]]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0 5 5 ... 2 2 4]\n",
      "<class 'numpy.ndarray'>\n",
      "One CNN, r:  4\n",
      "Computing Time:  0:03:40.246825\n",
      "true region_label= [6, 6, 2, 4, 3, 5]\n",
      "dist_table_truth\n",
      " [[1320  800    0 1377   24  292 1532   46  481]\n",
      " [ 620   29    3  215  276    3 2150 3070   49]\n",
      " [ 181  608 2307   29 1345  582   18  406 1008]\n",
      " [ 192 1131 1892    0 1519  258  106    0  354]\n",
      " [2197  445   18 2365   46 1335   59   23 2083]\n",
      " [ 243  577   42  203  238 2027  785  405  271]]\n",
      "num of merged_region_image 0 3154\n",
      "num of merged_region_image 1 3376\n",
      "num of merged_region_image 2 3553\n",
      "num of merged_region_image 3 3430\n",
      "num of merged_region_image 4 2432\n",
      "num of merged_region_image 5 2552\n",
      "Counter({-1: 24720, 2: 3553, 3: 3430, 1: 3376, 0: 3154, 5: 2552, 4: 2432})\n",
      "\n",
      "\n",
      "==== merged_and_expand(PATH5,ITE) ====\n",
      "===========  ITE = 1   ===========\n",
      "used_img 18497 18497\n",
      "working_img(=other images=unclean images) 24720 24720\n",
      "merged regions 88 88\n",
      "other_regions 112 112\n",
      "All other regions\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>other index</th>\n",
       "      <th>pred label</th>\n",
       "      <th>truth</th>\n",
       "      <th>rate</th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>6</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>0.90</td>\n",
       "      <td>4</td>\n",
       "      <td>62</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>7</td>\n",
       "      <td>3</td>\n",
       "      <td>5</td>\n",
       "      <td>1.00</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>239</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>8</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>0.54</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>361</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>9</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>0.55</td>\n",
       "      <td>245</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>11</td>\n",
       "      <td>1</td>\n",
       "      <td>7</td>\n",
       "      <td>0.91</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>107</th>\n",
       "      <td>194</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1.00</td>\n",
       "      <td>1</td>\n",
       "      <td>111</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>108</th>\n",
       "      <td>195</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>0.45</td>\n",
       "      <td>2</td>\n",
       "      <td>21</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>17</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>109</th>\n",
       "      <td>196</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>0.63</td>\n",
       "      <td>372</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>110</th>\n",
       "      <td>199</td>\n",
       "      <td>2</td>\n",
       "      <td>8</td>\n",
       "      <td>0.87</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>111</th>\n",
       "      <td>200</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>1.00</td>\n",
       "      <td>260</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>112 rows × 10 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     other index  pred label  truth  rate    0    1  2  3  4    5\n",
       "0              6           5      1  0.90    4   62  0  0  1    2\n",
       "1              7           3      5  1.00    1    0  0  0  3  239\n",
       "2              8           5      5  0.54    0    3  0  0  0  361\n",
       "3              9           5      0  0.55  245    0  1  0  1    0\n",
       "4             11           1      7  0.91    2    0  0  0  0    0\n",
       "..           ...         ...    ...   ...  ...  ... .. .. ..  ...\n",
       "107          194           0      1  1.00    1  111  0  0  0    2\n",
       "108          195           4      1  0.45    2   21  0  0  0   17\n",
       "109          196           4      0  0.63  372    2  1  1  4    1\n",
       "110          199           2      8  0.87    0    0  2  0  0    0\n",
       "111          200           4      0  1.00  260    0  0  0  1    0\n",
       "\n",
       "[112 rows x 10 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "added label, regions, img amount: {0} [35, 139, 158, 194, 38] 1068\n",
      "added label, regions, img amount: {1} [23, 49, 45, 104, 11] 1182\n",
      "added label, regions, img amount: {2} [141, 181, 168, 163, 92] 658\n",
      "added label, regions, img amount: {3} [7, 29, 43, 52, 111] 701\n",
      "added label, regions, img amount: {4} [200, 98, 145, 135, 59] 995\n",
      "added label, regions, img amount: {5} [6, 14, 40, 137] 654\n",
      "Not getting into residuals\n",
      "NUM_region 6\n",
      "number of clean images 23755\n",
      "n, p1, p2 0 0 0\n",
      "NUM_CLASSES 6\n",
      "current_train_label:  [0, 1, 2, 3, 4, 5]\n",
      "Model: \"sequential_1\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv1d_1 (Conv1D)            (None, 3, 6)              12        \n",
      "_________________________________________________________________\n",
      "average_pooling1d_1 (Average (None, 1, 6)              0         \n",
      "_________________________________________________________________\n",
      "conv1d_2 (Conv1D)            (None, 1, 16)             112       \n",
      "_________________________________________________________________\n",
      "average_pooling1d_2 (Average (None, 1, 16)             0         \n",
      "_________________________________________________________________\n",
      "conv1d_3 (Conv1D)            (None, 1, 120)            2040      \n",
      "_________________________________________________________________\n",
      "flatten_1 (Flatten)          (None, 120)               0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 84)                10164     \n",
      "_________________________________________________________________\n",
      "preds (Dense)                (None, 6)                 510       \n",
      "=================================================================\n",
      "Total params: 12,838\n",
      "Trainable params: 12,838\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Train on 21379 samples, validate on 2376 samples\n",
      "Epoch 1/80\n",
      "21379/21379 [==============================] - 1s 61us/step - loss: 0.6408 - accuracy: 0.7712 - val_loss: 0.3750 - val_accuracy: 0.8813\n",
      "Epoch 2/80\n",
      "21379/21379 [==============================] - 1s 38us/step - loss: 0.2900 - accuracy: 0.9039 - val_loss: 0.2474 - val_accuracy: 0.9251\n",
      "Epoch 3/80\n",
      "21379/21379 [==============================] - 1s 36us/step - loss: 0.2089 - accuracy: 0.9252 - val_loss: 0.1801 - val_accuracy: 0.9419\n",
      "Epoch 4/80\n",
      "21379/21379 [==============================] - 1s 39us/step - loss: 0.1768 - accuracy: 0.9362 - val_loss: 0.1632 - val_accuracy: 0.9465\n",
      "Epoch 5/80\n",
      "21379/21379 [==============================] - 1s 37us/step - loss: 0.1610 - accuracy: 0.9398 - val_loss: 0.1602 - val_accuracy: 0.9444\n",
      "Epoch 6/80\n",
      "21379/21379 [==============================] - 1s 37us/step - loss: 0.1523 - accuracy: 0.9421 - val_loss: 0.1422 - val_accuracy: 0.9508\n",
      "Epoch 7/80\n",
      "21379/21379 [==============================] - 1s 37us/step - loss: 0.1442 - accuracy: 0.9440 - val_loss: 0.1320 - val_accuracy: 0.9503\n",
      "Epoch 8/80\n",
      "21379/21379 [==============================] - 1s 33us/step - loss: 0.1323 - accuracy: 0.9484 - val_loss: 0.1191 - val_accuracy: 0.9558\n",
      "Epoch 9/80\n",
      "21379/21379 [==============================] - 1s 36us/step - loss: 0.1273 - accuracy: 0.9507 - val_loss: 0.1184 - val_accuracy: 0.9541\n",
      "Epoch 10/80\n",
      "21379/21379 [==============================] - 1s 36us/step - loss: 0.1151 - accuracy: 0.9527 - val_loss: 0.1080 - val_accuracy: 0.9583\n",
      "Epoch 11/80\n",
      "21379/21379 [==============================] - 1s 34us/step - loss: 0.1096 - accuracy: 0.9542 - val_loss: 0.1088 - val_accuracy: 0.9537\n",
      "Epoch 12/80\n",
      "21379/21379 [==============================] - 1s 36us/step - loss: 0.1090 - accuracy: 0.9530 - val_loss: 0.1009 - val_accuracy: 0.9571\n",
      "Epoch 13/80\n",
      "21379/21379 [==============================] - 1s 37us/step - loss: 0.1056 - accuracy: 0.9535 - val_loss: 0.0991 - val_accuracy: 0.9592\n",
      "Epoch 14/80\n",
      "21379/21379 [==============================] - 1s 37us/step - loss: 0.1034 - accuracy: 0.9535 - val_loss: 0.0937 - val_accuracy: 0.9625\n",
      "Epoch 15/80\n",
      "21379/21379 [==============================] - 1s 34us/step - loss: 0.1024 - accuracy: 0.9545 - val_loss: 0.0991 - val_accuracy: 0.9621\n",
      "Epoch 16/80\n",
      "21379/21379 [==============================] - 1s 37us/step - loss: 0.0991 - accuracy: 0.9552 - val_loss: 0.0938 - val_accuracy: 0.9617\n",
      "Epoch 17/80\n",
      "21379/21379 [==============================] - 1s 37us/step - loss: 0.0992 - accuracy: 0.9555 - val_loss: 0.1098 - val_accuracy: 0.9545\n",
      "Epoch 18/80\n",
      "21379/21379 [==============================] - 1s 38us/step - loss: 0.1005 - accuracy: 0.9543 - val_loss: 0.0952 - val_accuracy: 0.9592\n",
      "Epoch 19/80\n",
      "21379/21379 [==============================] - 1s 36us/step - loss: 0.0985 - accuracy: 0.9563 - val_loss: 0.0971 - val_accuracy: 0.9646\n",
      "Epoch 20/80\n",
      "21379/21379 [==============================] - 1s 37us/step - loss: 0.0974 - accuracy: 0.9570 - val_loss: 0.0898 - val_accuracy: 0.9609\n",
      "Epoch 21/80\n",
      "21379/21379 [==============================] - 1s 37us/step - loss: 0.0961 - accuracy: 0.9564 - val_loss: 0.0924 - val_accuracy: 0.9609\n",
      "Epoch 22/80\n",
      "21379/21379 [==============================] - 1s 37us/step - loss: 0.1052 - accuracy: 0.9540 - val_loss: 0.0916 - val_accuracy: 0.9613\n",
      "Epoch 23/80\n",
      "21379/21379 [==============================] - 1s 38us/step - loss: 0.0947 - accuracy: 0.9576 - val_loss: 0.0940 - val_accuracy: 0.9562\n",
      "Epoch 24/80\n",
      "21379/21379 [==============================] - 1s 36us/step - loss: 0.0969 - accuracy: 0.9547 - val_loss: 0.0911 - val_accuracy: 0.9604\n",
      "Epoch 25/80\n",
      "21379/21379 [==============================] - 1s 36us/step - loss: 0.0998 - accuracy: 0.9559 - val_loss: 0.0905 - val_accuracy: 0.9617\n",
      "Epoch 26/80\n",
      "21379/21379 [==============================] - 1s 36us/step - loss: 0.0943 - accuracy: 0.9575 - val_loss: 0.1050 - val_accuracy: 0.9550\n",
      "Epoch 27/80\n",
      "21379/21379 [==============================] - 1s 37us/step - loss: 0.0951 - accuracy: 0.9570 - val_loss: 0.0869 - val_accuracy: 0.9604\n",
      "Epoch 28/80\n",
      "21379/21379 [==============================] - 1s 35us/step - loss: 0.0922 - accuracy: 0.9587 - val_loss: 0.1037 - val_accuracy: 0.9566\n",
      "Epoch 29/80\n",
      "21379/21379 [==============================] - 1s 35us/step - loss: 0.0962 - accuracy: 0.9579 - val_loss: 0.0979 - val_accuracy: 0.9583\n",
      "Epoch 30/80\n",
      "21379/21379 [==============================] - 1s 35us/step - loss: 0.1067 - accuracy: 0.9528 - val_loss: 0.0895 - val_accuracy: 0.9621\n",
      "Epoch 31/80\n",
      "21379/21379 [==============================] - 1s 36us/step - loss: 0.0974 - accuracy: 0.9545 - val_loss: 0.0856 - val_accuracy: 0.9613\n",
      "Epoch 32/80\n",
      "21379/21379 [==============================] - 1s 36us/step - loss: 0.0919 - accuracy: 0.9576 - val_loss: 0.0843 - val_accuracy: 0.9625\n",
      "Epoch 33/80\n",
      "21379/21379 [==============================] - 1s 37us/step - loss: 0.0896 - accuracy: 0.9580 - val_loss: 0.0860 - val_accuracy: 0.9638\n",
      "Epoch 34/80\n",
      "21379/21379 [==============================] - 1s 35us/step - loss: 0.0900 - accuracy: 0.9577 - val_loss: 0.0862 - val_accuracy: 0.9646\n",
      "Epoch 35/80\n",
      "21379/21379 [==============================] - 1s 37us/step - loss: 0.0896 - accuracy: 0.9588 - val_loss: 0.0839 - val_accuracy: 0.9638\n",
      "Epoch 36/80\n",
      "21379/21379 [==============================] - 1s 36us/step - loss: 0.0902 - accuracy: 0.9590 - val_loss: 0.0892 - val_accuracy: 0.9600\n",
      "Epoch 37/80\n",
      "21379/21379 [==============================] - 1s 37us/step - loss: 0.0928 - accuracy: 0.9572 - val_loss: 0.0861 - val_accuracy: 0.9646\n",
      "Epoch 38/80\n",
      "21379/21379 [==============================] - 1s 36us/step - loss: 0.0894 - accuracy: 0.9571 - val_loss: 0.0994 - val_accuracy: 0.9579\n",
      "Epoch 39/80\n",
      "21379/21379 [==============================] - 1s 36us/step - loss: 0.0910 - accuracy: 0.9583 - val_loss: 0.0869 - val_accuracy: 0.9617\n",
      "Epoch 40/80\n",
      "21379/21379 [==============================] - 1s 36us/step - loss: 0.0910 - accuracy: 0.9579 - val_loss: 0.0875 - val_accuracy: 0.9630\n",
      "Epoch 41/80\n",
      "21379/21379 [==============================] - 1s 35us/step - loss: 0.0921 - accuracy: 0.9581 - val_loss: 0.0980 - val_accuracy: 0.9562\n",
      "Epoch 42/80\n",
      "21379/21379 [==============================] - 1s 35us/step - loss: 0.0985 - accuracy: 0.9552 - val_loss: 0.1126 - val_accuracy: 0.9520\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 43/80\n",
      "21379/21379 [==============================] - 1s 34us/step - loss: 0.0926 - accuracy: 0.9574 - val_loss: 0.0913 - val_accuracy: 0.9613\n",
      "Epoch 44/80\n",
      "21379/21379 [==============================] - 1s 37us/step - loss: 0.0925 - accuracy: 0.9575 - val_loss: 0.0852 - val_accuracy: 0.9630\n",
      "Epoch 45/80\n",
      "21379/21379 [==============================] - 1s 37us/step - loss: 0.0894 - accuracy: 0.9580 - val_loss: 0.0825 - val_accuracy: 0.9617\n",
      "Epoch 46/80\n",
      "21379/21379 [==============================] - 1s 37us/step - loss: 0.0885 - accuracy: 0.9586 - val_loss: 0.0930 - val_accuracy: 0.9604\n",
      "Epoch 47/80\n",
      "21379/21379 [==============================] - 1s 36us/step - loss: 0.0904 - accuracy: 0.9581 - val_loss: 0.0900 - val_accuracy: 0.9571\n",
      "Epoch 48/80\n",
      "21379/21379 [==============================] - 1s 36us/step - loss: 0.0887 - accuracy: 0.9588 - val_loss: 0.0860 - val_accuracy: 0.9609\n",
      "Epoch 49/80\n",
      "21379/21379 [==============================] - 1s 36us/step - loss: 0.0882 - accuracy: 0.9581 - val_loss: 0.0821 - val_accuracy: 0.9625\n",
      "Epoch 50/80\n",
      "21379/21379 [==============================] - 1s 37us/step - loss: 0.0889 - accuracy: 0.9592 - val_loss: 0.0832 - val_accuracy: 0.9630\n",
      "Epoch 51/80\n",
      "21379/21379 [==============================] - 1s 39us/step - loss: 0.0886 - accuracy: 0.9588 - val_loss: 0.0918 - val_accuracy: 0.9621\n",
      "Epoch 52/80\n",
      "21379/21379 [==============================] - 1s 37us/step - loss: 0.0887 - accuracy: 0.9589 - val_loss: 0.0826 - val_accuracy: 0.9638\n",
      "Epoch 53/80\n",
      "21379/21379 [==============================] - 1s 36us/step - loss: 0.0960 - accuracy: 0.9566 - val_loss: 0.0975 - val_accuracy: 0.9533\n",
      "Epoch 54/80\n",
      "21379/21379 [==============================] - 1s 37us/step - loss: 0.0909 - accuracy: 0.9577 - val_loss: 0.0829 - val_accuracy: 0.9617\n",
      "Epoch 55/80\n",
      "21379/21379 [==============================] - 1s 37us/step - loss: 0.0870 - accuracy: 0.9590 - val_loss: 0.0813 - val_accuracy: 0.9625\n",
      "Epoch 56/80\n",
      "21379/21379 [==============================] - 1s 36us/step - loss: 0.0873 - accuracy: 0.9594 - val_loss: 0.0834 - val_accuracy: 0.9638\n",
      "Epoch 57/80\n",
      "21379/21379 [==============================] - 1s 35us/step - loss: 0.0892 - accuracy: 0.9572 - val_loss: 0.0794 - val_accuracy: 0.9604\n",
      "Epoch 58/80\n",
      "21379/21379 [==============================] - 1s 36us/step - loss: 0.0852 - accuracy: 0.9600 - val_loss: 0.0783 - val_accuracy: 0.9642\n",
      "Epoch 59/80\n",
      "21379/21379 [==============================] - 1s 37us/step - loss: 0.0859 - accuracy: 0.9589 - val_loss: 0.0838 - val_accuracy: 0.9621\n",
      "Epoch 60/80\n",
      "21379/21379 [==============================] - 1s 35us/step - loss: 0.0887 - accuracy: 0.9587 - val_loss: 0.0862 - val_accuracy: 0.9625\n",
      "Epoch 61/80\n",
      "21379/21379 [==============================] - 1s 37us/step - loss: 0.0869 - accuracy: 0.9595 - val_loss: 0.0957 - val_accuracy: 0.9524\n",
      "Epoch 62/80\n",
      "21379/21379 [==============================] - 1s 37us/step - loss: 0.0908 - accuracy: 0.9577 - val_loss: 0.0888 - val_accuracy: 0.9613\n",
      "Epoch 63/80\n",
      "21379/21379 [==============================] - 1s 37us/step - loss: 0.0857 - accuracy: 0.9599 - val_loss: 0.0889 - val_accuracy: 0.9583\n",
      "Epoch 64/80\n",
      "21379/21379 [==============================] - 1s 37us/step - loss: 0.0909 - accuracy: 0.9567 - val_loss: 0.0811 - val_accuracy: 0.9625\n",
      "Epoch 65/80\n",
      "21379/21379 [==============================] - 1s 38us/step - loss: 0.0856 - accuracy: 0.9586 - val_loss: 0.0875 - val_accuracy: 0.9625\n",
      "Epoch 66/80\n",
      "21379/21379 [==============================] - 1s 36us/step - loss: 0.0859 - accuracy: 0.9577 - val_loss: 0.0814 - val_accuracy: 0.9638\n",
      "Epoch 67/80\n",
      "21379/21379 [==============================] - 1s 35us/step - loss: 0.0864 - accuracy: 0.9590 - val_loss: 0.0934 - val_accuracy: 0.9575\n",
      "Epoch 68/80\n",
      "21379/21379 [==============================] - 1s 36us/step - loss: 0.0932 - accuracy: 0.9567 - val_loss: 0.0886 - val_accuracy: 0.9621\n",
      "Epoch 00068: early stopping\n",
      "[[1.0000000e+00 3.1014720e-17 4.8799985e-21 2.6969652e-10 9.9577291e-12\n",
      "  1.7621012e-12]\n",
      " [8.4119572e-05 9.9520630e-06 5.8353759e-08 2.3174705e-07 6.6818047e-06\n",
      "  9.9989891e-01]\n",
      " [8.1875085e-05 9.7122711e-06 5.8522765e-08 2.2813796e-07 6.6943612e-06\n",
      "  9.9990141e-01]\n",
      " ...\n",
      " [8.9712309e-14 1.5544235e-10 9.9995160e-01 1.6983544e-05 3.0891004e-10\n",
      "  3.1495161e-05]\n",
      " [1.3897312e-07 4.9129784e-10 9.8030007e-01 3.6356831e-04 1.8774506e-02\n",
      "  5.6171138e-04]\n",
      " [1.5389724e-05 1.8922168e-15 1.6742888e-08 3.1298878e-06 9.9991643e-01\n",
      "  6.5019711e-05]]\n",
      "[0 5 5 ... 2 2 4]\n",
      "<class 'numpy.ndarray'>\n",
      "One CNN, r:  0\n",
      "Computing Time:  0:00:58.390642\n",
      "Model: \"sequential_1\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv1d_1 (Conv1D)            (None, 3, 6)              12        \n",
      "_________________________________________________________________\n",
      "average_pooling1d_1 (Average (None, 1, 6)              0         \n",
      "_________________________________________________________________\n",
      "conv1d_2 (Conv1D)            (None, 1, 16)             112       \n",
      "_________________________________________________________________\n",
      "average_pooling1d_2 (Average (None, 1, 16)             0         \n",
      "_________________________________________________________________\n",
      "conv1d_3 (Conv1D)            (None, 1, 120)            2040      \n",
      "_________________________________________________________________\n",
      "flatten_1 (Flatten)          (None, 120)               0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 84)                10164     \n",
      "_________________________________________________________________\n",
      "preds (Dense)                (None, 6)                 510       \n",
      "=================================================================\n",
      "Total params: 12,838\n",
      "Trainable params: 12,838\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Train on 21379 samples, validate on 2376 samples\n",
      "Epoch 1/80\n",
      "21379/21379 [==============================] - 1s 55us/step - loss: 0.6881 - accuracy: 0.7470 - val_loss: 0.3672 - val_accuracy: 0.8796\n",
      "Epoch 2/80\n",
      "21379/21379 [==============================] - 1s 38us/step - loss: 0.2888 - accuracy: 0.9005 - val_loss: 0.2371 - val_accuracy: 0.9019\n",
      "Epoch 3/80\n",
      "21379/21379 [==============================] - 1s 38us/step - loss: 0.2001 - accuracy: 0.9280 - val_loss: 0.1684 - val_accuracy: 0.9415\n",
      "Epoch 4/80\n",
      "21379/21379 [==============================] - 1s 38us/step - loss: 0.1730 - accuracy: 0.9343 - val_loss: 0.1771 - val_accuracy: 0.9205\n",
      "Epoch 5/80\n",
      "21379/21379 [==============================] - 1s 37us/step - loss: 0.1528 - accuracy: 0.9391 - val_loss: 0.1448 - val_accuracy: 0.9482\n",
      "Epoch 6/80\n",
      "21379/21379 [==============================] - 1s 38us/step - loss: 0.1460 - accuracy: 0.9414 - val_loss: 0.1940 - val_accuracy: 0.8885\n",
      "Epoch 7/80\n",
      "21379/21379 [==============================] - 1s 37us/step - loss: 0.1451 - accuracy: 0.9408 - val_loss: 0.1755 - val_accuracy: 0.9386\n",
      "Epoch 8/80\n",
      "21379/21379 [==============================] - 1s 37us/step - loss: 0.1436 - accuracy: 0.9438 - val_loss: 0.1326 - val_accuracy: 0.9533\n",
      "Epoch 9/80\n",
      "21379/21379 [==============================] - 1s 37us/step - loss: 0.1323 - accuracy: 0.9485 - val_loss: 0.1330 - val_accuracy: 0.9482\n",
      "Epoch 10/80\n",
      "21379/21379 [==============================] - 1s 37us/step - loss: 0.1294 - accuracy: 0.9476 - val_loss: 0.1240 - val_accuracy: 0.9545\n",
      "Epoch 11/80\n",
      "21379/21379 [==============================] - 1s 37us/step - loss: 0.1293 - accuracy: 0.9488 - val_loss: 0.1185 - val_accuracy: 0.9516\n",
      "Epoch 12/80\n",
      "21379/21379 [==============================] - 1s 38us/step - loss: 0.1315 - accuracy: 0.9475 - val_loss: 0.1350 - val_accuracy: 0.9495\n",
      "Epoch 13/80\n",
      "21379/21379 [==============================] - 1s 37us/step - loss: 0.1280 - accuracy: 0.9493 - val_loss: 0.1220 - val_accuracy: 0.9516\n",
      "Epoch 14/80\n",
      "21379/21379 [==============================] - 1s 34us/step - loss: 0.1279 - accuracy: 0.9495 - val_loss: 0.1054 - val_accuracy: 0.9613\n",
      "Epoch 15/80\n",
      "21379/21379 [==============================] - 1s 37us/step - loss: 0.1228 - accuracy: 0.9524 - val_loss: 0.1028 - val_accuracy: 0.9630\n",
      "Epoch 16/80\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "21379/21379 [==============================] - 1s 37us/step - loss: 0.1193 - accuracy: 0.9540 - val_loss: 0.1014 - val_accuracy: 0.9621\n",
      "Epoch 17/80\n",
      "21379/21379 [==============================] - 1s 37us/step - loss: 0.1156 - accuracy: 0.9548 - val_loss: 0.1085 - val_accuracy: 0.9558\n",
      "Epoch 18/80\n",
      "21379/21379 [==============================] - 1s 34us/step - loss: 0.1169 - accuracy: 0.9533 - val_loss: 0.1056 - val_accuracy: 0.9575\n",
      "Epoch 19/80\n",
      "21379/21379 [==============================] - 1s 34us/step - loss: 0.1125 - accuracy: 0.9551 - val_loss: 0.0974 - val_accuracy: 0.9634\n",
      "Epoch 20/80\n",
      "21379/21379 [==============================] - 1s 37us/step - loss: 0.1135 - accuracy: 0.9550 - val_loss: 0.1041 - val_accuracy: 0.9621\n",
      "Epoch 21/80\n",
      "21379/21379 [==============================] - 1s 35us/step - loss: 0.1116 - accuracy: 0.9559 - val_loss: 0.1320 - val_accuracy: 0.9474\n",
      "Epoch 22/80\n",
      "21379/21379 [==============================] - 1s 37us/step - loss: 0.1166 - accuracy: 0.9545 - val_loss: 0.1057 - val_accuracy: 0.9625\n",
      "Epoch 23/80\n",
      "21379/21379 [==============================] - 1s 39us/step - loss: 0.1062 - accuracy: 0.9559 - val_loss: 0.0955 - val_accuracy: 0.9638\n",
      "Epoch 24/80\n",
      "21379/21379 [==============================] - 1s 37us/step - loss: 0.1092 - accuracy: 0.9547 - val_loss: 0.0995 - val_accuracy: 0.9617\n",
      "Epoch 25/80\n",
      "21379/21379 [==============================] - 1s 39us/step - loss: 0.1034 - accuracy: 0.9560 - val_loss: 0.0959 - val_accuracy: 0.9663\n",
      "Epoch 26/80\n",
      "21379/21379 [==============================] - 1s 36us/step - loss: 0.1024 - accuracy: 0.9569 - val_loss: 0.0955 - val_accuracy: 0.9596\n",
      "Epoch 27/80\n",
      "21379/21379 [==============================] - 1s 35us/step - loss: 0.1021 - accuracy: 0.9577 - val_loss: 0.1190 - val_accuracy: 0.9609\n",
      "Epoch 28/80\n",
      "21379/21379 [==============================] - 1s 35us/step - loss: 0.1017 - accuracy: 0.9590 - val_loss: 0.0973 - val_accuracy: 0.9592\n",
      "Epoch 29/80\n",
      "21379/21379 [==============================] - 1s 34us/step - loss: 0.1004 - accuracy: 0.9588 - val_loss: 0.0984 - val_accuracy: 0.9583\n",
      "Epoch 30/80\n",
      "21379/21379 [==============================] - 1s 34us/step - loss: 0.0986 - accuracy: 0.9571 - val_loss: 0.0937 - val_accuracy: 0.9613\n",
      "Epoch 31/80\n",
      "21379/21379 [==============================] - 1s 35us/step - loss: 0.0964 - accuracy: 0.9589 - val_loss: 0.0969 - val_accuracy: 0.9625\n",
      "Epoch 32/80\n",
      "21379/21379 [==============================] - 1s 34us/step - loss: 0.1026 - accuracy: 0.9565 - val_loss: 0.0900 - val_accuracy: 0.9625\n",
      "Epoch 33/80\n",
      "21379/21379 [==============================] - 1s 34us/step - loss: 0.0971 - accuracy: 0.9574 - val_loss: 0.0939 - val_accuracy: 0.9600\n",
      "Epoch 34/80\n",
      "21379/21379 [==============================] - 1s 34us/step - loss: 0.0954 - accuracy: 0.9595 - val_loss: 0.0940 - val_accuracy: 0.9617\n",
      "Epoch 35/80\n",
      "21379/21379 [==============================] - 1s 35us/step - loss: 0.0958 - accuracy: 0.9582 - val_loss: 0.0936 - val_accuracy: 0.9562\n",
      "Epoch 36/80\n",
      "21379/21379 [==============================] - 1s 36us/step - loss: 0.0924 - accuracy: 0.9589 - val_loss: 0.0888 - val_accuracy: 0.9596\n",
      "Epoch 37/80\n",
      "21379/21379 [==============================] - 1s 34us/step - loss: 0.0930 - accuracy: 0.9582 - val_loss: 0.0888 - val_accuracy: 0.9583\n",
      "Epoch 38/80\n",
      "21379/21379 [==============================] - 1s 35us/step - loss: 0.0933 - accuracy: 0.9581 - val_loss: 0.0876 - val_accuracy: 0.9592\n",
      "Epoch 39/80\n",
      "21379/21379 [==============================] - 1s 34us/step - loss: 0.0929 - accuracy: 0.9583 - val_loss: 0.0867 - val_accuracy: 0.9600\n",
      "Epoch 40/80\n",
      "21379/21379 [==============================] - 1s 34us/step - loss: 0.0903 - accuracy: 0.9587 - val_loss: 0.0975 - val_accuracy: 0.9558\n",
      "Epoch 41/80\n",
      "21379/21379 [==============================] - 1s 34us/step - loss: 0.0935 - accuracy: 0.9574 - val_loss: 0.1347 - val_accuracy: 0.9550\n",
      "Epoch 42/80\n",
      "21379/21379 [==============================] - 1s 36us/step - loss: 0.0993 - accuracy: 0.9555 - val_loss: 0.0944 - val_accuracy: 0.9609\n",
      "Epoch 43/80\n",
      "21379/21379 [==============================] - 1s 35us/step - loss: 0.0915 - accuracy: 0.9592 - val_loss: 0.0965 - val_accuracy: 0.9554\n",
      "Epoch 44/80\n",
      "21379/21379 [==============================] - 1s 34us/step - loss: 0.1009 - accuracy: 0.9564 - val_loss: 0.1061 - val_accuracy: 0.9571\n",
      "Epoch 45/80\n",
      "21379/21379 [==============================] - 1s 35us/step - loss: 0.0926 - accuracy: 0.9572 - val_loss: 0.0926 - val_accuracy: 0.9592\n",
      "Epoch 46/80\n",
      "21379/21379 [==============================] - 1s 35us/step - loss: 0.0914 - accuracy: 0.9572 - val_loss: 0.0847 - val_accuracy: 0.9659\n",
      "Epoch 47/80\n",
      "21379/21379 [==============================] - 1s 36us/step - loss: 0.0887 - accuracy: 0.9597 - val_loss: 0.1169 - val_accuracy: 0.9554\n",
      "Epoch 48/80\n",
      "21379/21379 [==============================] - 1s 33us/step - loss: 0.0989 - accuracy: 0.9553 - val_loss: 0.0838 - val_accuracy: 0.9672\n",
      "Epoch 49/80\n",
      "21379/21379 [==============================] - 1s 36us/step - loss: 0.0882 - accuracy: 0.9590 - val_loss: 0.0822 - val_accuracy: 0.9634\n",
      "Epoch 50/80\n",
      "21379/21379 [==============================] - 1s 35us/step - loss: 0.0903 - accuracy: 0.9590 - val_loss: 0.0862 - val_accuracy: 0.9588\n",
      "Epoch 51/80\n",
      "21379/21379 [==============================] - 1s 34us/step - loss: 0.0890 - accuracy: 0.9582 - val_loss: 0.0921 - val_accuracy: 0.9651\n",
      "Epoch 52/80\n",
      "21379/21379 [==============================] - 1s 34us/step - loss: 0.0885 - accuracy: 0.9585 - val_loss: 0.1213 - val_accuracy: 0.9491\n",
      "Epoch 53/80\n",
      "21379/21379 [==============================] - 1s 35us/step - loss: 0.1020 - accuracy: 0.9542 - val_loss: 0.0829 - val_accuracy: 0.9588\n",
      "Epoch 54/80\n",
      "21379/21379 [==============================] - 1s 37us/step - loss: 0.0870 - accuracy: 0.9584 - val_loss: 0.0788 - val_accuracy: 0.9630\n",
      "Epoch 55/80\n",
      "21379/21379 [==============================] - 1s 35us/step - loss: 0.0864 - accuracy: 0.9587 - val_loss: 0.0797 - val_accuracy: 0.9609\n",
      "Epoch 56/80\n",
      "21379/21379 [==============================] - 1s 36us/step - loss: 0.0872 - accuracy: 0.9576 - val_loss: 0.0817 - val_accuracy: 0.9638\n",
      "Epoch 57/80\n",
      "21379/21379 [==============================] - 1s 36us/step - loss: 0.0877 - accuracy: 0.9582 - val_loss: 0.0828 - val_accuracy: 0.9617\n",
      "Epoch 58/80\n",
      "21379/21379 [==============================] - 1s 36us/step - loss: 0.0880 - accuracy: 0.9580 - val_loss: 0.0938 - val_accuracy: 0.9630\n",
      "Epoch 59/80\n",
      "21379/21379 [==============================] - 1s 36us/step - loss: 0.0873 - accuracy: 0.9589 - val_loss: 0.0837 - val_accuracy: 0.9659\n",
      "Epoch 60/80\n",
      "21379/21379 [==============================] - 1s 37us/step - loss: 0.0919 - accuracy: 0.9573 - val_loss: 0.0905 - val_accuracy: 0.9588\n",
      "Epoch 61/80\n",
      "21379/21379 [==============================] - 1s 36us/step - loss: 0.0873 - accuracy: 0.9577 - val_loss: 0.0917 - val_accuracy: 0.9621\n",
      "Epoch 62/80\n",
      "21379/21379 [==============================] - 1s 37us/step - loss: 0.0913 - accuracy: 0.9565 - val_loss: 0.0793 - val_accuracy: 0.9609\n",
      "Epoch 63/80\n",
      "21379/21379 [==============================] - 1s 37us/step - loss: 0.0862 - accuracy: 0.9586 - val_loss: 0.0837 - val_accuracy: 0.9596\n",
      "Epoch 64/80\n",
      "21379/21379 [==============================] - 1s 38us/step - loss: 0.0855 - accuracy: 0.9593 - val_loss: 0.0801 - val_accuracy: 0.9613\n",
      "Epoch 00064: early stopping\n",
      "[[1.00000000e+00 8.50760781e-11 4.20185664e-10 8.86289875e-14\n",
      "  2.29895963e-11 8.75280404e-12]\n",
      " [2.97342136e-04 2.02468858e-04 8.20528712e-09 1.24785622e-08\n",
      "  7.96282984e-06 9.99492168e-01]\n",
      " [2.96352839e-04 2.02197654e-04 8.22399038e-09 1.25202515e-08\n",
      "  7.98101792e-06 9.99493480e-01]\n",
      " ...\n",
      " [5.49074116e-15 1.35174694e-09 9.99720871e-01 2.78978318e-04\n",
      "  4.41700740e-13 9.24924350e-08]\n",
      " [7.20970775e-07 6.15830553e-10 9.86233592e-01 3.31866951e-03\n",
      "  1.04173180e-02 2.96869439e-05]\n",
      " [1.39124792e-08 6.47033154e-14 3.44568457e-06 2.88556956e-11\n",
      "  9.99970675e-01 2.58287637e-05]]\n",
      "[0 5 5 ... 2 2 4]\n",
      "<class 'numpy.ndarray'>\n",
      "One CNN, r:  1\n",
      "Computing Time:  0:01:52.394954\n",
      "Model: \"sequential_1\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv1d_1 (Conv1D)            (None, 3, 6)              12        \n",
      "_________________________________________________________________\n",
      "average_pooling1d_1 (Average (None, 1, 6)              0         \n",
      "_________________________________________________________________\n",
      "conv1d_2 (Conv1D)            (None, 1, 16)             112       \n",
      "_________________________________________________________________\n",
      "average_pooling1d_2 (Average (None, 1, 16)             0         \n",
      "_________________________________________________________________\n",
      "conv1d_3 (Conv1D)            (None, 1, 120)            2040      \n",
      "_________________________________________________________________\n",
      "flatten_1 (Flatten)          (None, 120)               0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 84)                10164     \n",
      "_________________________________________________________________\n",
      "preds (Dense)                (None, 6)                 510       \n",
      "=================================================================\n",
      "Total params: 12,838\n",
      "Trainable params: 12,838\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 21379 samples, validate on 2376 samples\n",
      "Epoch 1/80\n",
      "21379/21379 [==============================] - 1s 55us/step - loss: 0.6383 - accuracy: 0.7503 - val_loss: 0.3814 - val_accuracy: 0.8712\n",
      "Epoch 2/80\n",
      "21379/21379 [==============================] - 1s 37us/step - loss: 0.2853 - accuracy: 0.9042 - val_loss: 0.2216 - val_accuracy: 0.9230\n",
      "Epoch 3/80\n",
      "21379/21379 [==============================] - 1s 38us/step - loss: 0.1966 - accuracy: 0.9299 - val_loss: 0.1703 - val_accuracy: 0.9369\n",
      "Epoch 4/80\n",
      "21379/21379 [==============================] - 1s 37us/step - loss: 0.1667 - accuracy: 0.9365 - val_loss: 0.1720 - val_accuracy: 0.9293\n",
      "Epoch 5/80\n",
      "21379/21379 [==============================] - 1s 38us/step - loss: 0.1575 - accuracy: 0.9381 - val_loss: 0.1928 - val_accuracy: 0.9272\n",
      "Epoch 6/80\n",
      "21379/21379 [==============================] - 1s 38us/step - loss: 0.1539 - accuracy: 0.9405 - val_loss: 0.1444 - val_accuracy: 0.9411\n",
      "Epoch 7/80\n",
      "21379/21379 [==============================] - 1s 39us/step - loss: 0.1482 - accuracy: 0.9418 - val_loss: 0.1577 - val_accuracy: 0.9449\n",
      "Epoch 8/80\n",
      "21379/21379 [==============================] - 1s 38us/step - loss: 0.1374 - accuracy: 0.9456 - val_loss: 0.1352 - val_accuracy: 0.9487\n",
      "Epoch 9/80\n",
      "21379/21379 [==============================] - 1s 38us/step - loss: 0.1346 - accuracy: 0.9478 - val_loss: 0.1281 - val_accuracy: 0.9487\n",
      "Epoch 10/80\n",
      "21379/21379 [==============================] - 1s 39us/step - loss: 0.1326 - accuracy: 0.9485 - val_loss: 0.1288 - val_accuracy: 0.9499\n",
      "Epoch 11/80\n",
      "21379/21379 [==============================] - 1s 39us/step - loss: 0.1307 - accuracy: 0.9480 - val_loss: 0.1295 - val_accuracy: 0.9482\n",
      "Epoch 12/80\n",
      "21379/21379 [==============================] - 1s 40us/step - loss: 0.1260 - accuracy: 0.9507 - val_loss: 0.1250 - val_accuracy: 0.9524\n",
      "Epoch 13/80\n",
      "21379/21379 [==============================] - 1s 39us/step - loss: 0.1223 - accuracy: 0.9517 - val_loss: 0.1157 - val_accuracy: 0.9508\n",
      "Epoch 14/80\n",
      "21379/21379 [==============================] - 1s 40us/step - loss: 0.1201 - accuracy: 0.9519 - val_loss: 0.1175 - val_accuracy: 0.9520\n",
      "Epoch 15/80\n",
      "21379/21379 [==============================] - 1s 40us/step - loss: 0.1179 - accuracy: 0.9528 - val_loss: 0.1243 - val_accuracy: 0.9482\n",
      "Epoch 16/80\n",
      "21379/21379 [==============================] - 1s 38us/step - loss: 0.1176 - accuracy: 0.9531 - val_loss: 0.1108 - val_accuracy: 0.9512\n",
      "Epoch 17/80\n",
      "21379/21379 [==============================] - 1s 38us/step - loss: 0.1090 - accuracy: 0.9551 - val_loss: 0.1042 - val_accuracy: 0.9550\n",
      "Epoch 18/80\n",
      "21379/21379 [==============================] - 1s 38us/step - loss: 0.1009 - accuracy: 0.9571 - val_loss: 0.1007 - val_accuracy: 0.9545\n",
      "Epoch 19/80\n",
      "21379/21379 [==============================] - 1s 37us/step - loss: 0.1008 - accuracy: 0.9568 - val_loss: 0.1131 - val_accuracy: 0.9508\n",
      "Epoch 20/80\n",
      "21379/21379 [==============================] - 1s 38us/step - loss: 0.0989 - accuracy: 0.9558 - val_loss: 0.0997 - val_accuracy: 0.9512\n",
      "Epoch 21/80\n",
      "21379/21379 [==============================] - 1s 39us/step - loss: 0.0972 - accuracy: 0.9561 - val_loss: 0.1000 - val_accuracy: 0.9575\n",
      "Epoch 22/80\n",
      "21379/21379 [==============================] - 1s 38us/step - loss: 0.0978 - accuracy: 0.9558 - val_loss: 0.1100 - val_accuracy: 0.9545\n",
      "Epoch 23/80\n",
      "21379/21379 [==============================] - 1s 39us/step - loss: 0.0958 - accuracy: 0.9572 - val_loss: 0.1033 - val_accuracy: 0.9529\n",
      "Epoch 24/80\n",
      "21379/21379 [==============================] - 1s 39us/step - loss: 0.0974 - accuracy: 0.9562 - val_loss: 0.1060 - val_accuracy: 0.9566\n",
      "Epoch 25/80\n",
      "21379/21379 [==============================] - 1s 38us/step - loss: 0.0951 - accuracy: 0.9570 - val_loss: 0.0882 - val_accuracy: 0.9600\n",
      "Epoch 26/80\n",
      "21379/21379 [==============================] - 1s 38us/step - loss: 0.0920 - accuracy: 0.9580 - val_loss: 0.0975 - val_accuracy: 0.9579\n",
      "Epoch 27/80\n",
      "21379/21379 [==============================] - 1s 41us/step - loss: 0.0924 - accuracy: 0.9570 - val_loss: 0.1122 - val_accuracy: 0.9533\n",
      "Epoch 28/80\n",
      "21379/21379 [==============================] - 1s 39us/step - loss: 0.1000 - accuracy: 0.9558 - val_loss: 0.0977 - val_accuracy: 0.9566\n",
      "Epoch 29/80\n",
      "21379/21379 [==============================] - 1s 39us/step - loss: 0.0943 - accuracy: 0.9575 - val_loss: 0.0984 - val_accuracy: 0.9524\n",
      "Epoch 30/80\n",
      "21379/21379 [==============================] - 1s 37us/step - loss: 0.0948 - accuracy: 0.9576 - val_loss: 0.0928 - val_accuracy: 0.9600\n",
      "Epoch 31/80\n",
      "21379/21379 [==============================] - 1s 40us/step - loss: 0.0916 - accuracy: 0.9575 - val_loss: 0.0878 - val_accuracy: 0.9588\n",
      "Epoch 32/80\n",
      "21379/21379 [==============================] - 1s 38us/step - loss: 0.0916 - accuracy: 0.9577 - val_loss: 0.0870 - val_accuracy: 0.9588\n",
      "Epoch 33/80\n",
      "21379/21379 [==============================] - 1s 38us/step - loss: 0.0926 - accuracy: 0.9587 - val_loss: 0.0860 - val_accuracy: 0.9596\n",
      "Epoch 34/80\n",
      "21379/21379 [==============================] - 1s 38us/step - loss: 0.0924 - accuracy: 0.9575 - val_loss: 0.0943 - val_accuracy: 0.9550\n",
      "Epoch 35/80\n",
      "21379/21379 [==============================] - 1s 38us/step - loss: 0.0900 - accuracy: 0.9581 - val_loss: 0.0881 - val_accuracy: 0.9579\n",
      "Epoch 36/80\n",
      "21379/21379 [==============================] - 1s 39us/step - loss: 0.0898 - accuracy: 0.9573 - val_loss: 0.0952 - val_accuracy: 0.9541\n",
      "Epoch 37/80\n",
      "21379/21379 [==============================] - 1s 40us/step - loss: 0.0905 - accuracy: 0.9574 - val_loss: 0.0839 - val_accuracy: 0.9596\n",
      "Epoch 38/80\n",
      "21379/21379 [==============================] - 1s 39us/step - loss: 0.0909 - accuracy: 0.9578 - val_loss: 0.0932 - val_accuracy: 0.9571\n",
      "Epoch 39/80\n",
      "21379/21379 [==============================] - 1s 39us/step - loss: 0.0903 - accuracy: 0.9587 - val_loss: 0.0857 - val_accuracy: 0.9571\n",
      "Epoch 40/80\n",
      "21379/21379 [==============================] - 1s 41us/step - loss: 0.0887 - accuracy: 0.9577 - val_loss: 0.0858 - val_accuracy: 0.9588\n",
      "Epoch 41/80\n",
      "21379/21379 [==============================] - 1s 38us/step - loss: 0.0974 - accuracy: 0.9560 - val_loss: 0.0893 - val_accuracy: 0.9583\n",
      "Epoch 42/80\n",
      "21379/21379 [==============================] - 1s 39us/step - loss: 0.0889 - accuracy: 0.9577 - val_loss: 0.0868 - val_accuracy: 0.9596\n",
      "Epoch 43/80\n",
      "21379/21379 [==============================] - 1s 39us/step - loss: 0.0869 - accuracy: 0.9597 - val_loss: 0.0887 - val_accuracy: 0.9566\n",
      "Epoch 44/80\n",
      "21379/21379 [==============================] - 1s 37us/step - loss: 0.0868 - accuracy: 0.9578 - val_loss: 0.0818 - val_accuracy: 0.9609\n",
      "Epoch 45/80\n",
      "21379/21379 [==============================] - 1s 37us/step - loss: 0.0876 - accuracy: 0.9599 - val_loss: 0.0859 - val_accuracy: 0.9575\n",
      "Epoch 46/80\n",
      "21379/21379 [==============================] - 1s 36us/step - loss: 0.0860 - accuracy: 0.9588 - val_loss: 0.0814 - val_accuracy: 0.9604\n",
      "Epoch 47/80\n",
      "21379/21379 [==============================] - 1s 38us/step - loss: 0.0897 - accuracy: 0.9585 - val_loss: 0.1038 - val_accuracy: 0.9554\n",
      "Epoch 48/80\n",
      "21379/21379 [==============================] - 1s 39us/step - loss: 0.0897 - accuracy: 0.9581 - val_loss: 0.0856 - val_accuracy: 0.9575\n",
      "Epoch 49/80\n",
      "21379/21379 [==============================] - 1s 35us/step - loss: 0.0852 - accuracy: 0.9595 - val_loss: 0.0912 - val_accuracy: 0.9583\n",
      "Epoch 50/80\n",
      "21379/21379 [==============================] - 1s 36us/step - loss: 0.0885 - accuracy: 0.9579 - val_loss: 0.0879 - val_accuracy: 0.9566\n",
      "Epoch 51/80\n",
      "21379/21379 [==============================] - 1s 38us/step - loss: 0.0971 - accuracy: 0.9562 - val_loss: 0.0823 - val_accuracy: 0.9596\n",
      "Epoch 52/80\n",
      "21379/21379 [==============================] - 1s 36us/step - loss: 0.0858 - accuracy: 0.9589 - val_loss: 0.0834 - val_accuracy: 0.9604\n",
      "Epoch 53/80\n",
      "21379/21379 [==============================] - 1s 38us/step - loss: 0.0871 - accuracy: 0.9578 - val_loss: 0.0944 - val_accuracy: 0.9588\n",
      "Epoch 54/80\n",
      "21379/21379 [==============================] - 1s 36us/step - loss: 0.0904 - accuracy: 0.9581 - val_loss: 0.0869 - val_accuracy: 0.9562\n",
      "Epoch 55/80\n",
      "21379/21379 [==============================] - 1s 37us/step - loss: 0.0855 - accuracy: 0.9592 - val_loss: 0.0847 - val_accuracy: 0.9579\n",
      "Epoch 56/80\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "21379/21379 [==============================] - 1s 37us/step - loss: 0.0881 - accuracy: 0.9583 - val_loss: 0.1122 - val_accuracy: 0.9491\n",
      "Epoch 00056: early stopping\n",
      "[[1.0000000e+00 3.2345373e-14 1.7695327e-10 2.0023075e-10 3.8561473e-11\n",
      "  1.9019867e-14]\n",
      " [2.7344049e-05 5.2142335e-04 8.0753116e-06 6.6948914e-08 2.9326329e-06\n",
      "  9.9944013e-01]\n",
      " [2.6637821e-05 5.1546725e-04 7.9981701e-06 6.6026416e-08 2.9276057e-06\n",
      "  9.9944681e-01]\n",
      " ...\n",
      " [9.4920187e-09 6.7788875e-07 9.9192280e-01 8.0748452e-03 6.6030202e-12\n",
      "  1.7143054e-06]\n",
      " [1.9125969e-04 5.9879217e-09 9.7997928e-01 8.2147820e-03 1.0136872e-02\n",
      "  1.4778213e-03]\n",
      " [1.2814168e-07 8.5217084e-20 2.4941207e-07 1.4065631e-12 9.9999928e-01\n",
      "  3.0327965e-07]]\n",
      "[0 5 5 ... 2 2 4]\n",
      "<class 'numpy.ndarray'>\n",
      "One CNN, r:  2\n",
      "Computing Time:  0:02:42.609397\n",
      "Model: \"sequential_1\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv1d_1 (Conv1D)            (None, 3, 6)              12        \n",
      "_________________________________________________________________\n",
      "average_pooling1d_1 (Average (None, 1, 6)              0         \n",
      "_________________________________________________________________\n",
      "conv1d_2 (Conv1D)            (None, 1, 16)             112       \n",
      "_________________________________________________________________\n",
      "average_pooling1d_2 (Average (None, 1, 16)             0         \n",
      "_________________________________________________________________\n",
      "conv1d_3 (Conv1D)            (None, 1, 120)            2040      \n",
      "_________________________________________________________________\n",
      "flatten_1 (Flatten)          (None, 120)               0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 84)                10164     \n",
      "_________________________________________________________________\n",
      "preds (Dense)                (None, 6)                 510       \n",
      "=================================================================\n",
      "Total params: 12,838\n",
      "Trainable params: 12,838\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Train on 21379 samples, validate on 2376 samples\n",
      "Epoch 1/80\n",
      "21379/21379 [==============================] - 1s 53us/step - loss: 0.6294 - accuracy: 0.7705 - val_loss: 0.3925 - val_accuracy: 0.9108\n",
      "Epoch 2/80\n",
      "21379/21379 [==============================] - 1s 38us/step - loss: 0.2777 - accuracy: 0.9077 - val_loss: 0.2103 - val_accuracy: 0.9238\n",
      "Epoch 3/80\n",
      "21379/21379 [==============================] - 1s 37us/step - loss: 0.2011 - accuracy: 0.9300 - val_loss: 0.3158 - val_accuracy: 0.7992\n",
      "Epoch 4/80\n",
      "21379/21379 [==============================] - 1s 37us/step - loss: 0.1825 - accuracy: 0.9351 - val_loss: 0.1460 - val_accuracy: 0.9449\n",
      "Epoch 5/80\n",
      "21379/21379 [==============================] - 1s 38us/step - loss: 0.1449 - accuracy: 0.9441 - val_loss: 0.1328 - val_accuracy: 0.9474\n",
      "Epoch 6/80\n",
      "21379/21379 [==============================] - 1s 35us/step - loss: 0.1279 - accuracy: 0.9487 - val_loss: 0.1835 - val_accuracy: 0.9221\n",
      "Epoch 7/80\n",
      "21379/21379 [==============================] - 1s 36us/step - loss: 0.1383 - accuracy: 0.9453 - val_loss: 0.1153 - val_accuracy: 0.9516\n",
      "Epoch 8/80\n",
      "21379/21379 [==============================] - 1s 36us/step - loss: 0.1165 - accuracy: 0.9508 - val_loss: 0.1127 - val_accuracy: 0.9533\n",
      "Epoch 9/80\n",
      "21379/21379 [==============================] - 1s 37us/step - loss: 0.1120 - accuracy: 0.9521 - val_loss: 0.1091 - val_accuracy: 0.9537\n",
      "Epoch 10/80\n",
      "21379/21379 [==============================] - 1s 37us/step - loss: 0.1091 - accuracy: 0.9539 - val_loss: 0.1177 - val_accuracy: 0.9512\n",
      "Epoch 11/80\n",
      "21379/21379 [==============================] - 1s 37us/step - loss: 0.1124 - accuracy: 0.9539 - val_loss: 0.1136 - val_accuracy: 0.9512\n",
      "Epoch 12/80\n",
      "21379/21379 [==============================] - 1s 37us/step - loss: 0.1106 - accuracy: 0.9528 - val_loss: 0.1078 - val_accuracy: 0.9533\n",
      "Epoch 13/80\n",
      "21379/21379 [==============================] - 1s 37us/step - loss: 0.1083 - accuracy: 0.9544 - val_loss: 0.1053 - val_accuracy: 0.9541\n",
      "Epoch 14/80\n",
      "21379/21379 [==============================] - 1s 37us/step - loss: 0.1057 - accuracy: 0.9560 - val_loss: 0.2367 - val_accuracy: 0.9162\n",
      "Epoch 15/80\n",
      "21379/21379 [==============================] - 1s 36us/step - loss: 0.1147 - accuracy: 0.9506 - val_loss: 0.1011 - val_accuracy: 0.9533\n",
      "Epoch 16/80\n",
      "21379/21379 [==============================] - 1s 36us/step - loss: 0.1032 - accuracy: 0.9547 - val_loss: 0.1030 - val_accuracy: 0.9541\n",
      "Epoch 17/80\n",
      "21379/21379 [==============================] - 1s 37us/step - loss: 0.1051 - accuracy: 0.9543 - val_loss: 0.1412 - val_accuracy: 0.9449\n",
      "Epoch 18/80\n",
      "21379/21379 [==============================] - 1s 38us/step - loss: 0.1043 - accuracy: 0.9547 - val_loss: 0.1213 - val_accuracy: 0.9474\n",
      "Epoch 19/80\n",
      "21379/21379 [==============================] - 1s 38us/step - loss: 0.1100 - accuracy: 0.9534 - val_loss: 0.1254 - val_accuracy: 0.9449\n",
      "Epoch 20/80\n",
      "21379/21379 [==============================] - 1s 35us/step - loss: 0.1104 - accuracy: 0.9532 - val_loss: 0.0981 - val_accuracy: 0.9545\n",
      "Epoch 21/80\n",
      "21379/21379 [==============================] - 1s 38us/step - loss: 0.0980 - accuracy: 0.9561 - val_loss: 0.0989 - val_accuracy: 0.9562\n",
      "Epoch 22/80\n",
      "21379/21379 [==============================] - 1s 38us/step - loss: 0.0997 - accuracy: 0.9548 - val_loss: 0.1002 - val_accuracy: 0.9524\n",
      "Epoch 23/80\n",
      "21379/21379 [==============================] - 1s 36us/step - loss: 0.0998 - accuracy: 0.9557 - val_loss: 0.1144 - val_accuracy: 0.9512\n",
      "Epoch 24/80\n",
      "21379/21379 [==============================] - 1s 38us/step - loss: 0.0982 - accuracy: 0.9566 - val_loss: 0.0972 - val_accuracy: 0.9558\n",
      "Epoch 25/80\n",
      "21379/21379 [==============================] - 1s 38us/step - loss: 0.0972 - accuracy: 0.9569 - val_loss: 0.1099 - val_accuracy: 0.9537\n",
      "Epoch 26/80\n",
      "21379/21379 [==============================] - 1s 37us/step - loss: 0.0976 - accuracy: 0.9570 - val_loss: 0.1017 - val_accuracy: 0.9545\n",
      "Epoch 27/80\n",
      "21379/21379 [==============================] - 1s 37us/step - loss: 0.0940 - accuracy: 0.9582 - val_loss: 0.0991 - val_accuracy: 0.9537\n",
      "Epoch 28/80\n",
      "21379/21379 [==============================] - 1s 36us/step - loss: 0.0954 - accuracy: 0.9570 - val_loss: 0.0956 - val_accuracy: 0.9537\n",
      "Epoch 29/80\n",
      "21379/21379 [==============================] - 1s 38us/step - loss: 0.0942 - accuracy: 0.9559 - val_loss: 0.1642 - val_accuracy: 0.9369\n",
      "Epoch 30/80\n",
      "21379/21379 [==============================] - 1s 37us/step - loss: 0.1094 - accuracy: 0.9529 - val_loss: 0.0966 - val_accuracy: 0.9558\n",
      "Epoch 31/80\n",
      "21379/21379 [==============================] - 1s 37us/step - loss: 0.0955 - accuracy: 0.9565 - val_loss: 0.0961 - val_accuracy: 0.9520\n",
      "Epoch 32/80\n",
      "21379/21379 [==============================] - 1s 38us/step - loss: 0.0940 - accuracy: 0.9591 - val_loss: 0.1058 - val_accuracy: 0.9508\n",
      "Epoch 33/80\n",
      "21379/21379 [==============================] - 1s 37us/step - loss: 0.1054 - accuracy: 0.9539 - val_loss: 0.0921 - val_accuracy: 0.9550\n",
      "Epoch 34/80\n",
      "21379/21379 [==============================] - 1s 36us/step - loss: 0.0932 - accuracy: 0.9574 - val_loss: 0.0924 - val_accuracy: 0.9545\n",
      "Epoch 35/80\n",
      "21379/21379 [==============================] - 1s 36us/step - loss: 0.0919 - accuracy: 0.9588 - val_loss: 0.0916 - val_accuracy: 0.9545\n",
      "Epoch 36/80\n",
      "21379/21379 [==============================] - 1s 36us/step - loss: 0.0926 - accuracy: 0.9592 - val_loss: 0.0902 - val_accuracy: 0.9558\n",
      "Epoch 37/80\n",
      "21379/21379 [==============================] - 1s 37us/step - loss: 0.0942 - accuracy: 0.9579 - val_loss: 0.1057 - val_accuracy: 0.9545\n",
      "Epoch 38/80\n",
      "21379/21379 [==============================] - 1s 38us/step - loss: 0.0915 - accuracy: 0.9577 - val_loss: 0.0912 - val_accuracy: 0.9583\n",
      "Epoch 39/80\n",
      "21379/21379 [==============================] - 1s 39us/step - loss: 0.0907 - accuracy: 0.9582 - val_loss: 0.0950 - val_accuracy: 0.9566\n",
      "Epoch 40/80\n",
      "21379/21379 [==============================] - 1s 37us/step - loss: 0.0935 - accuracy: 0.9580 - val_loss: 0.0977 - val_accuracy: 0.9524\n",
      "Epoch 41/80\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "21379/21379 [==============================] - 1s 36us/step - loss: 0.0934 - accuracy: 0.9569 - val_loss: 0.0946 - val_accuracy: 0.9554\n",
      "Epoch 42/80\n",
      "21379/21379 [==============================] - 1s 39us/step - loss: 0.0930 - accuracy: 0.9575 - val_loss: 0.0889 - val_accuracy: 0.9588\n",
      "Epoch 43/80\n",
      "21379/21379 [==============================] - 1s 36us/step - loss: 0.0907 - accuracy: 0.9584 - val_loss: 0.0939 - val_accuracy: 0.9566\n",
      "Epoch 44/80\n",
      "21379/21379 [==============================] - 1s 36us/step - loss: 0.0914 - accuracy: 0.9582 - val_loss: 0.1053 - val_accuracy: 0.9545\n",
      "Epoch 45/80\n",
      "21379/21379 [==============================] - 1s 39us/step - loss: 0.0966 - accuracy: 0.9566 - val_loss: 0.0993 - val_accuracy: 0.9545\n",
      "Epoch 46/80\n",
      "21379/21379 [==============================] - 1s 37us/step - loss: 0.1083 - accuracy: 0.9549 - val_loss: 0.0919 - val_accuracy: 0.9562\n",
      "Epoch 47/80\n",
      "21379/21379 [==============================] - 1s 39us/step - loss: 0.0905 - accuracy: 0.9576 - val_loss: 0.1010 - val_accuracy: 0.9533\n",
      "Epoch 48/80\n",
      "21379/21379 [==============================] - 1s 36us/step - loss: 0.0948 - accuracy: 0.9567 - val_loss: 0.0882 - val_accuracy: 0.9554\n",
      "Epoch 49/80\n",
      "21379/21379 [==============================] - 1s 37us/step - loss: 0.0884 - accuracy: 0.9597 - val_loss: 0.0889 - val_accuracy: 0.9583\n",
      "Epoch 50/80\n",
      "21379/21379 [==============================] - 1s 36us/step - loss: 0.0921 - accuracy: 0.9573 - val_loss: 0.0954 - val_accuracy: 0.9533\n",
      "Epoch 51/80\n",
      "21379/21379 [==============================] - 1s 36us/step - loss: 0.0909 - accuracy: 0.9581 - val_loss: 0.0884 - val_accuracy: 0.9596\n",
      "Epoch 52/80\n",
      "21379/21379 [==============================] - 1s 38us/step - loss: 0.0877 - accuracy: 0.9599 - val_loss: 0.0874 - val_accuracy: 0.9541\n",
      "Epoch 53/80\n",
      "21379/21379 [==============================] - 1s 38us/step - loss: 0.0888 - accuracy: 0.9591 - val_loss: 0.0920 - val_accuracy: 0.9541\n",
      "Epoch 54/80\n",
      "21379/21379 [==============================] - 1s 37us/step - loss: 0.0900 - accuracy: 0.9587 - val_loss: 0.0867 - val_accuracy: 0.9575\n",
      "Epoch 55/80\n",
      "21379/21379 [==============================] - 1s 38us/step - loss: 0.0889 - accuracy: 0.9579 - val_loss: 0.0884 - val_accuracy: 0.9529\n",
      "Epoch 56/80\n",
      "21379/21379 [==============================] - 1s 37us/step - loss: 0.0896 - accuracy: 0.9589 - val_loss: 0.0953 - val_accuracy: 0.9558\n",
      "Epoch 57/80\n",
      "21379/21379 [==============================] - 1s 35us/step - loss: 0.0923 - accuracy: 0.9582 - val_loss: 0.0927 - val_accuracy: 0.9545\n",
      "Epoch 58/80\n",
      "21379/21379 [==============================] - 1s 37us/step - loss: 0.0869 - accuracy: 0.9598 - val_loss: 0.0864 - val_accuracy: 0.9583\n",
      "Epoch 59/80\n",
      "21379/21379 [==============================] - 1s 36us/step - loss: 0.0889 - accuracy: 0.9587 - val_loss: 0.0895 - val_accuracy: 0.9533\n",
      "Epoch 60/80\n",
      "21379/21379 [==============================] - 1s 37us/step - loss: 0.0874 - accuracy: 0.9583 - val_loss: 0.0944 - val_accuracy: 0.9571\n",
      "Epoch 61/80\n",
      "21379/21379 [==============================] - 1s 38us/step - loss: 0.0883 - accuracy: 0.9588 - val_loss: 0.0893 - val_accuracy: 0.9541\n",
      "Epoch 62/80\n",
      "21379/21379 [==============================] - 1s 37us/step - loss: 0.0895 - accuracy: 0.9579 - val_loss: 0.0992 - val_accuracy: 0.9550\n",
      "Epoch 63/80\n",
      "21379/21379 [==============================] - 1s 37us/step - loss: 0.0876 - accuracy: 0.9587 - val_loss: 0.0895 - val_accuracy: 0.9583\n",
      "Epoch 64/80\n",
      "21379/21379 [==============================] - 1s 36us/step - loss: 0.0869 - accuracy: 0.9594 - val_loss: 0.0858 - val_accuracy: 0.9592\n",
      "Epoch 65/80\n",
      "21379/21379 [==============================] - 1s 39us/step - loss: 0.0858 - accuracy: 0.9601 - val_loss: 0.0936 - val_accuracy: 0.9562\n",
      "Epoch 66/80\n",
      "21379/21379 [==============================] - 1s 37us/step - loss: 0.0865 - accuracy: 0.9587 - val_loss: 0.0839 - val_accuracy: 0.9588\n",
      "Epoch 67/80\n",
      "21379/21379 [==============================] - 1s 37us/step - loss: 0.0860 - accuracy: 0.9597 - val_loss: 0.0888 - val_accuracy: 0.9566\n",
      "Epoch 68/80\n",
      "21379/21379 [==============================] - 1s 38us/step - loss: 0.0854 - accuracy: 0.9596 - val_loss: 0.0816 - val_accuracy: 0.9562\n",
      "Epoch 69/80\n",
      "21379/21379 [==============================] - 1s 37us/step - loss: 0.0870 - accuracy: 0.9584 - val_loss: 0.1077 - val_accuracy: 0.9470\n",
      "Epoch 70/80\n",
      "21379/21379 [==============================] - 1s 37us/step - loss: 0.0884 - accuracy: 0.9585 - val_loss: 0.0915 - val_accuracy: 0.9566\n",
      "Epoch 71/80\n",
      "21379/21379 [==============================] - 1s 36us/step - loss: 0.0862 - accuracy: 0.9594 - val_loss: 0.0911 - val_accuracy: 0.9520\n",
      "Epoch 72/80\n",
      "21379/21379 [==============================] - 1s 36us/step - loss: 0.0869 - accuracy: 0.9584 - val_loss: 0.0878 - val_accuracy: 0.9550\n",
      "Epoch 73/80\n",
      "21379/21379 [==============================] - 1s 37us/step - loss: 0.0864 - accuracy: 0.9589 - val_loss: 0.0925 - val_accuracy: 0.9541\n",
      "Epoch 74/80\n",
      "21379/21379 [==============================] - 1s 37us/step - loss: 0.0866 - accuracy: 0.9584 - val_loss: 0.0857 - val_accuracy: 0.9554\n",
      "Epoch 75/80\n",
      "21379/21379 [==============================] - 1s 36us/step - loss: 0.0866 - accuracy: 0.9591 - val_loss: 0.0914 - val_accuracy: 0.9566\n",
      "Epoch 76/80\n",
      "21379/21379 [==============================] - 1s 37us/step - loss: 0.0857 - accuracy: 0.9598 - val_loss: 0.0839 - val_accuracy: 0.9566\n",
      "Epoch 77/80\n",
      "21379/21379 [==============================] - 1s 37us/step - loss: 0.0845 - accuracy: 0.9596 - val_loss: 0.0829 - val_accuracy: 0.9604\n",
      "Epoch 78/80\n",
      "21379/21379 [==============================] - 1s 37us/step - loss: 0.0863 - accuracy: 0.9586 - val_loss: 0.0899 - val_accuracy: 0.9562\n",
      "Epoch 00078: early stopping\n",
      "[[1.0000000e+00 4.3868861e-13 5.3989003e-15 5.3526566e-08 4.1557872e-14\n",
      "  4.4992002e-13]\n",
      " [3.7983264e-05 3.5088701e-04 2.9612600e-08 4.7677936e-08 1.2128839e-07\n",
      "  9.9961096e-01]\n",
      " [3.7278969e-05 3.4842044e-04 2.9612638e-08 4.6821683e-08 1.2240993e-07\n",
      "  9.9961412e-01]\n",
      " ...\n",
      " [3.5165301e-14 9.0613035e-08 9.9991930e-01 8.0282043e-05 1.2228028e-13\n",
      "  1.8584592e-07]\n",
      " [1.9684305e-06 9.7498845e-09 9.8837435e-01 7.7567919e-04 1.0404175e-02\n",
      "  4.4384194e-04]\n",
      " [1.1229458e-07 2.3003930e-15 5.0229097e-08 9.9713449e-10 9.9999976e-01\n",
      "  1.4016877e-07]]\n",
      "[0 5 5 ... 2 2 4]\n",
      "<class 'numpy.ndarray'>\n",
      "One CNN, r:  3\n",
      "Computing Time:  0:03:48.937609\n",
      "Model: \"sequential_1\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv1d_1 (Conv1D)            (None, 3, 6)              12        \n",
      "_________________________________________________________________\n",
      "average_pooling1d_1 (Average (None, 1, 6)              0         \n",
      "_________________________________________________________________\n",
      "conv1d_2 (Conv1D)            (None, 1, 16)             112       \n",
      "_________________________________________________________________\n",
      "average_pooling1d_2 (Average (None, 1, 16)             0         \n",
      "_________________________________________________________________\n",
      "conv1d_3 (Conv1D)            (None, 1, 120)            2040      \n",
      "_________________________________________________________________\n",
      "flatten_1 (Flatten)          (None, 120)               0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 84)                10164     \n",
      "_________________________________________________________________\n",
      "preds (Dense)                (None, 6)                 510       \n",
      "=================================================================\n",
      "Total params: 12,838\n",
      "Trainable params: 12,838\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Train on 21379 samples, validate on 2376 samples\n",
      "Epoch 1/80\n",
      "21379/21379 [==============================] - 1s 49us/step - loss: 0.6774 - accuracy: 0.7339 - val_loss: 0.3403 - val_accuracy: 0.9003\n",
      "Epoch 2/80\n",
      "21379/21379 [==============================] - 1s 39us/step - loss: 0.2583 - accuracy: 0.9117 - val_loss: 0.2100 - val_accuracy: 0.9226\n",
      "Epoch 3/80\n",
      "21379/21379 [==============================] - 1s 37us/step - loss: 0.1835 - accuracy: 0.9333 - val_loss: 0.1849 - val_accuracy: 0.9381\n",
      "Epoch 4/80\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "21379/21379 [==============================] - 1s 37us/step - loss: 0.1578 - accuracy: 0.9397 - val_loss: 0.2186 - val_accuracy: 0.8902\n",
      "Epoch 5/80\n",
      "21379/21379 [==============================] - 1s 38us/step - loss: 0.1457 - accuracy: 0.9424 - val_loss: 0.1547 - val_accuracy: 0.9491\n",
      "Epoch 6/80\n",
      "21379/21379 [==============================] - 1s 37us/step - loss: 0.1331 - accuracy: 0.9466 - val_loss: 0.1188 - val_accuracy: 0.9554\n",
      "Epoch 7/80\n",
      "21379/21379 [==============================] - 1s 38us/step - loss: 0.1202 - accuracy: 0.9487 - val_loss: 0.1097 - val_accuracy: 0.9508\n",
      "Epoch 8/80\n",
      "21379/21379 [==============================] - 1s 37us/step - loss: 0.1133 - accuracy: 0.9517 - val_loss: 0.1160 - val_accuracy: 0.9516\n",
      "Epoch 9/80\n",
      "21379/21379 [==============================] - 1s 39us/step - loss: 0.1081 - accuracy: 0.9544 - val_loss: 0.1072 - val_accuracy: 0.9533\n",
      "Epoch 10/80\n",
      "21379/21379 [==============================] - 1s 39us/step - loss: 0.1073 - accuracy: 0.9535 - val_loss: 0.1083 - val_accuracy: 0.9566\n",
      "Epoch 11/80\n",
      "21379/21379 [==============================] - 1s 38us/step - loss: 0.1041 - accuracy: 0.9537 - val_loss: 0.0991 - val_accuracy: 0.9554\n",
      "Epoch 12/80\n",
      "21379/21379 [==============================] - 1s 38us/step - loss: 0.1048 - accuracy: 0.9549 - val_loss: 0.1008 - val_accuracy: 0.9583\n",
      "Epoch 13/80\n",
      "21379/21379 [==============================] - 1s 36us/step - loss: 0.0994 - accuracy: 0.9568 - val_loss: 0.0958 - val_accuracy: 0.9579\n",
      "Epoch 14/80\n",
      "21379/21379 [==============================] - 1s 37us/step - loss: 0.0980 - accuracy: 0.9568 - val_loss: 0.0935 - val_accuracy: 0.9588\n",
      "Epoch 15/80\n",
      "21379/21379 [==============================] - 1s 39us/step - loss: 0.0984 - accuracy: 0.9558 - val_loss: 0.0964 - val_accuracy: 0.9579\n",
      "Epoch 16/80\n",
      "21379/21379 [==============================] - 1s 38us/step - loss: 0.1013 - accuracy: 0.9551 - val_loss: 0.0928 - val_accuracy: 0.9533\n",
      "Epoch 17/80\n",
      "21379/21379 [==============================] - 1s 36us/step - loss: 0.0974 - accuracy: 0.9562 - val_loss: 0.0994 - val_accuracy: 0.9621\n",
      "Epoch 18/80\n",
      "21379/21379 [==============================] - 1s 37us/step - loss: 0.0948 - accuracy: 0.9561 - val_loss: 0.0965 - val_accuracy: 0.9533\n",
      "Epoch 19/80\n",
      "21379/21379 [==============================] - 1s 37us/step - loss: 0.0937 - accuracy: 0.9562 - val_loss: 0.0910 - val_accuracy: 0.9592\n",
      "Epoch 20/80\n",
      "21379/21379 [==============================] - 1s 38us/step - loss: 0.0938 - accuracy: 0.9581 - val_loss: 0.0877 - val_accuracy: 0.9558\n",
      "Epoch 21/80\n",
      "21379/21379 [==============================] - 1s 36us/step - loss: 0.0932 - accuracy: 0.9569 - val_loss: 0.0919 - val_accuracy: 0.9541\n",
      "Epoch 22/80\n",
      "21379/21379 [==============================] - 1s 38us/step - loss: 0.0962 - accuracy: 0.9564 - val_loss: 0.0884 - val_accuracy: 0.9600\n",
      "Epoch 23/80\n",
      "21379/21379 [==============================] - 1s 38us/step - loss: 0.0924 - accuracy: 0.9580 - val_loss: 0.0884 - val_accuracy: 0.9617\n",
      "Epoch 24/80\n",
      "21379/21379 [==============================] - 1s 38us/step - loss: 0.0916 - accuracy: 0.9576 - val_loss: 0.0864 - val_accuracy: 0.9609\n",
      "Epoch 25/80\n",
      "21379/21379 [==============================] - 1s 37us/step - loss: 0.0931 - accuracy: 0.9573 - val_loss: 0.1554 - val_accuracy: 0.9449\n",
      "Epoch 26/80\n",
      "21379/21379 [==============================] - 1s 37us/step - loss: 0.0930 - accuracy: 0.9574 - val_loss: 0.0864 - val_accuracy: 0.9600\n",
      "Epoch 27/80\n",
      "21379/21379 [==============================] - 1s 38us/step - loss: 0.0914 - accuracy: 0.9568 - val_loss: 0.1021 - val_accuracy: 0.9566\n",
      "Epoch 28/80\n",
      "21379/21379 [==============================] - 1s 38us/step - loss: 0.0910 - accuracy: 0.9587 - val_loss: 0.1070 - val_accuracy: 0.9558\n",
      "Epoch 29/80\n",
      "21379/21379 [==============================] - 1s 39us/step - loss: 0.0896 - accuracy: 0.9575 - val_loss: 0.0884 - val_accuracy: 0.9630\n",
      "Epoch 30/80\n",
      "21379/21379 [==============================] - 1s 39us/step - loss: 0.0919 - accuracy: 0.9572 - val_loss: 0.0850 - val_accuracy: 0.9588\n",
      "Epoch 31/80\n",
      "21379/21379 [==============================] - 1s 37us/step - loss: 0.0892 - accuracy: 0.9584 - val_loss: 0.0936 - val_accuracy: 0.9558\n",
      "Epoch 32/80\n",
      "21379/21379 [==============================] - 1s 37us/step - loss: 0.0927 - accuracy: 0.9568 - val_loss: 0.0913 - val_accuracy: 0.9545\n",
      "Epoch 33/80\n",
      "21379/21379 [==============================] - 1s 38us/step - loss: 0.0958 - accuracy: 0.9565 - val_loss: 0.0929 - val_accuracy: 0.9596\n",
      "Epoch 34/80\n",
      "21379/21379 [==============================] - 1s 37us/step - loss: 0.0900 - accuracy: 0.9576 - val_loss: 0.0908 - val_accuracy: 0.9571\n",
      "Epoch 35/80\n",
      "21379/21379 [==============================] - 1s 39us/step - loss: 0.0876 - accuracy: 0.9576 - val_loss: 0.0861 - val_accuracy: 0.9583\n",
      "Epoch 36/80\n",
      "21379/21379 [==============================] - 1s 39us/step - loss: 0.0920 - accuracy: 0.9572 - val_loss: 0.0866 - val_accuracy: 0.9638\n",
      "Epoch 37/80\n",
      "21379/21379 [==============================] - 1s 39us/step - loss: 0.0889 - accuracy: 0.9582 - val_loss: 0.0986 - val_accuracy: 0.9550\n",
      "Epoch 38/80\n",
      "21379/21379 [==============================] - 1s 38us/step - loss: 0.0969 - accuracy: 0.9563 - val_loss: 0.0855 - val_accuracy: 0.9592\n",
      "Epoch 39/80\n",
      "21379/21379 [==============================] - 1s 36us/step - loss: 0.0874 - accuracy: 0.9590 - val_loss: 0.0853 - val_accuracy: 0.9600\n",
      "Epoch 40/80\n",
      "21379/21379 [==============================] - 1s 37us/step - loss: 0.0870 - accuracy: 0.9585 - val_loss: 0.0877 - val_accuracy: 0.9583\n",
      "Epoch 00040: early stopping\n",
      "[[9.9999905e-01 9.5064775e-07 1.5312314e-11 2.2285608e-08 8.1091450e-10\n",
      "  1.6111019e-11]\n",
      " [1.8194166e-08 5.1902159e-04 8.2317655e-09 1.9465099e-06 1.5123226e-05\n",
      "  9.9946386e-01]\n",
      " [1.7577785e-08 5.1074021e-04 8.1777367e-09 1.9210013e-06 1.5068446e-05\n",
      "  9.9947232e-01]\n",
      " ...\n",
      " [2.5277291e-12 1.3766835e-10 9.9998033e-01 1.9604211e-05 7.4769080e-11\n",
      "  1.2412210e-07]\n",
      " [1.3064273e-07 5.1610265e-11 9.3422335e-01 3.3064233e-03 6.2075995e-02\n",
      "  3.9413784e-04]\n",
      " [1.2955019e-06 2.3982799e-13 9.5402959e-07 1.1371679e-07 9.9999487e-01\n",
      "  2.7160909e-06]]\n",
      "[0 5 5 ... 2 2 4]\n",
      "<class 'numpy.ndarray'>\n",
      "One CNN, r:  4\n",
      "Computing Time:  0:04:25.765637\n",
      "true region_label= [6, 7, 2, 4, 3, 5]\n",
      "dist_table_truth\n",
      " [[1302  801    0 1305   13  293 1529   13  478]\n",
      " [ 621   18    3  186  285    3 2118 3118   46]\n",
      " [ 142  471 1982    0 1122  489    6  384  808]\n",
      " [ 209 1154 2016    0 1916  262  107    0  420]\n",
      " [2203  480   38 2454   88 1315   58   23 2280]\n",
      " [ 229  719   16  228  235 1907  890  427  251]]\n",
      "num of merged_region_image 0 4222\n",
      "num of merged_region_image 1 4558\n",
      "num of merged_region_image 2 4211\n",
      "num of merged_region_image 3 4131\n",
      "num of merged_region_image 4 3427\n",
      "num of merged_region_image 5 3206\n",
      "Counter({-1: 19462, 1: 4558, 0: 4222, 2: 4211, 3: 4131, 4: 3427, 5: 3206})\n",
      "\n",
      "\n",
      "==== merged_and_expand(PATH5,ITE) ====\n",
      "===========  ITE = 2   ===========\n",
      "used_img 23755 23755\n",
      "working_img(=other images=unclean images) 19462 19462\n",
      "merged regions 117 117\n",
      "other_regions 83 83\n",
      "All other regions\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>other index</th>\n",
       "      <th>pred label</th>\n",
       "      <th>truth</th>\n",
       "      <th>rate</th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>8</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>0.61</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>361</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>9</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>0.64</td>\n",
       "      <td>245</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>12</td>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "      <td>0.85</td>\n",
       "      <td>13</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>77</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>13</td>\n",
       "      <td>-1</td>\n",
       "      <td>1</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0</td>\n",
       "      <td>26</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>16</td>\n",
       "      <td>4</td>\n",
       "      <td>8</td>\n",
       "      <td>0.99</td>\n",
       "      <td>8</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>78</th>\n",
       "      <td>190</td>\n",
       "      <td>4</td>\n",
       "      <td>8</td>\n",
       "      <td>0.62</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>79</th>\n",
       "      <td>191</td>\n",
       "      <td>-1</td>\n",
       "      <td>3</td>\n",
       "      <td>0.00</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>227</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>80</th>\n",
       "      <td>195</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>0.70</td>\n",
       "      <td>2</td>\n",
       "      <td>21</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>17</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>81</th>\n",
       "      <td>196</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>0.58</td>\n",
       "      <td>372</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>82</th>\n",
       "      <td>199</td>\n",
       "      <td>2</td>\n",
       "      <td>8</td>\n",
       "      <td>0.74</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>83 rows × 10 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    other index  pred label  truth  rate    0   1  2    3   4    5\n",
       "0             8           5      5  0.61    0   3  0    0   0  361\n",
       "1             9           5      0  0.64  245   0  1    0   1    0\n",
       "2            12           2      4  0.85   13   0  0    0  77    2\n",
       "3            13          -1      1  0.00    0  26  0    0   0    0\n",
       "4            16           4      8  0.99    8   0  0    3   0    1\n",
       "..          ...         ...    ...   ...  ...  .. ..  ...  ..  ...\n",
       "78          190           4      8  0.62    1   0  0    0   0    4\n",
       "79          191          -1      3  0.00    5   0  0  227   1    0\n",
       "80          195           4      1  0.70    2  21  0    0   0   17\n",
       "81          196           4      0  0.58  372   2  1    1   4    1\n",
       "82          199           2      8  0.74    0   0  2    0   0    0\n",
       "\n",
       "[83 rows x 10 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "added label, regions, img amount: {0} [30, 129, 81, 166] 658\n",
      "added label, regions, img amount: {1} [21, 136, 142, 106, 31] 976\n",
      "added label, regions, img amount: {2} [93, 12, 19, 99, 83] 552\n",
      "added label, regions, img amount: {3} [51, 177, 189, 18, 122] 827\n",
      "added label, regions, img amount: {4} [117, 133, 101, 16, 173] 1121\n",
      "added label, regions, img amount: {5} [150] 114\n",
      "Not getting into residuals\n",
      "NUM_region 6\n",
      "number of clean images 28003\n",
      "n, p1, p2 0 0 0\n",
      "NUM_CLASSES 6\n",
      "current_train_label:  [0, 1, 2, 3, 4, 5]\n",
      "Model: \"sequential_1\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv1d_1 (Conv1D)            (None, 3, 6)              12        \n",
      "_________________________________________________________________\n",
      "average_pooling1d_1 (Average (None, 1, 6)              0         \n",
      "_________________________________________________________________\n",
      "conv1d_2 (Conv1D)            (None, 1, 16)             112       \n",
      "_________________________________________________________________\n",
      "average_pooling1d_2 (Average (None, 1, 16)             0         \n",
      "_________________________________________________________________\n",
      "conv1d_3 (Conv1D)            (None, 1, 120)            2040      \n",
      "_________________________________________________________________\n",
      "flatten_1 (Flatten)          (None, 120)               0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 84)                10164     \n",
      "_________________________________________________________________\n",
      "preds (Dense)                (None, 6)                 510       \n",
      "=================================================================\n",
      "Total params: 12,838\n",
      "Trainable params: 12,838\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Train on 25202 samples, validate on 2801 samples\n",
      "Epoch 1/80\n",
      "25202/25202 [==============================] - 1s 57us/step - loss: 0.6352 - accuracy: 0.7602 - val_loss: 0.3732 - val_accuracy: 0.8897\n",
      "Epoch 2/80\n",
      "25202/25202 [==============================] - 1s 38us/step - loss: 0.3057 - accuracy: 0.8922 - val_loss: 0.2619 - val_accuracy: 0.9007\n",
      "Epoch 3/80\n",
      "25202/25202 [==============================] - 1s 36us/step - loss: 0.2468 - accuracy: 0.9117 - val_loss: 0.2216 - val_accuracy: 0.9261\n",
      "Epoch 4/80\n",
      "25202/25202 [==============================] - 1s 37us/step - loss: 0.2008 - accuracy: 0.9280 - val_loss: 0.1733 - val_accuracy: 0.9361\n",
      "Epoch 5/80\n",
      "25202/25202 [==============================] - 1s 36us/step - loss: 0.1726 - accuracy: 0.9360 - val_loss: 0.1545 - val_accuracy: 0.9414\n",
      "Epoch 6/80\n",
      "25202/25202 [==============================] - 1s 37us/step - loss: 0.1580 - accuracy: 0.9423 - val_loss: 0.1351 - val_accuracy: 0.9497\n",
      "Epoch 7/80\n",
      "25202/25202 [==============================] - 1s 35us/step - loss: 0.1403 - accuracy: 0.9490 - val_loss: 0.1265 - val_accuracy: 0.9536\n",
      "Epoch 8/80\n",
      "25202/25202 [==============================] - 1s 37us/step - loss: 0.1295 - accuracy: 0.9512 - val_loss: 0.1243 - val_accuracy: 0.9589\n",
      "Epoch 9/80\n",
      "25202/25202 [==============================] - 1s 36us/step - loss: 0.1285 - accuracy: 0.9522 - val_loss: 0.1215 - val_accuracy: 0.9575\n",
      "Epoch 10/80\n",
      "25202/25202 [==============================] - 1s 37us/step - loss: 0.1172 - accuracy: 0.9551 - val_loss: 0.1025 - val_accuracy: 0.9625\n",
      "Epoch 11/80\n",
      "25202/25202 [==============================] - 1s 37us/step - loss: 0.1055 - accuracy: 0.9580 - val_loss: 0.0994 - val_accuracy: 0.9632\n",
      "Epoch 12/80\n",
      "25202/25202 [==============================] - 1s 35us/step - loss: 0.0993 - accuracy: 0.9602 - val_loss: 0.0979 - val_accuracy: 0.9668\n",
      "Epoch 13/80\n",
      "25202/25202 [==============================] - 1s 37us/step - loss: 0.0974 - accuracy: 0.9602 - val_loss: 0.0909 - val_accuracy: 0.9639\n",
      "Epoch 14/80\n",
      "25202/25202 [==============================] - 1s 37us/step - loss: 0.0910 - accuracy: 0.9615 - val_loss: 0.0951 - val_accuracy: 0.9632\n",
      "Epoch 15/80\n",
      "25202/25202 [==============================] - 1s 37us/step - loss: 0.0947 - accuracy: 0.9608 - val_loss: 0.1055 - val_accuracy: 0.9568\n",
      "Epoch 16/80\n",
      "25202/25202 [==============================] - 1s 37us/step - loss: 0.0884 - accuracy: 0.9623 - val_loss: 0.0798 - val_accuracy: 0.9654\n",
      "Epoch 17/80\n",
      "25202/25202 [==============================] - 1s 37us/step - loss: 0.0848 - accuracy: 0.9643 - val_loss: 0.0890 - val_accuracy: 0.9639\n",
      "Epoch 18/80\n",
      "25202/25202 [==============================] - 1s 37us/step - loss: 0.0874 - accuracy: 0.9622 - val_loss: 0.0817 - val_accuracy: 0.9675\n",
      "Epoch 19/80\n",
      "25202/25202 [==============================] - 1s 38us/step - loss: 0.0933 - accuracy: 0.9605 - val_loss: 0.0787 - val_accuracy: 0.9682\n",
      "Epoch 20/80\n",
      "25202/25202 [==============================] - 1s 37us/step - loss: 0.0872 - accuracy: 0.9640 - val_loss: 0.1080 - val_accuracy: 0.9564\n",
      "Epoch 21/80\n",
      "25202/25202 [==============================] - 1s 36us/step - loss: 0.0848 - accuracy: 0.9626 - val_loss: 0.0802 - val_accuracy: 0.9675\n",
      "Epoch 22/80\n",
      "25202/25202 [==============================] - 1s 36us/step - loss: 0.0841 - accuracy: 0.9629 - val_loss: 0.0796 - val_accuracy: 0.9661\n",
      "Epoch 23/80\n",
      "25202/25202 [==============================] - 1s 38us/step - loss: 0.0844 - accuracy: 0.9630 - val_loss: 0.0870 - val_accuracy: 0.9657\n",
      "Epoch 24/80\n",
      "25202/25202 [==============================] - 1s 38us/step - loss: 0.0880 - accuracy: 0.9625 - val_loss: 0.0785 - val_accuracy: 0.9693\n",
      "Epoch 25/80\n",
      "25202/25202 [==============================] - 1s 37us/step - loss: 0.0826 - accuracy: 0.9646 - val_loss: 0.0909 - val_accuracy: 0.9639\n",
      "Epoch 26/80\n",
      "25202/25202 [==============================] - 1s 37us/step - loss: 0.0823 - accuracy: 0.9639 - val_loss: 0.0770 - val_accuracy: 0.9661\n",
      "Epoch 27/80\n",
      "25202/25202 [==============================] - 1s 37us/step - loss: 0.0812 - accuracy: 0.9636 - val_loss: 0.0799 - val_accuracy: 0.9664\n",
      "Epoch 28/80\n",
      "25202/25202 [==============================] - 1s 37us/step - loss: 0.0829 - accuracy: 0.9635 - val_loss: 0.0751 - val_accuracy: 0.9672\n",
      "Epoch 29/80\n",
      "25202/25202 [==============================] - 1s 38us/step - loss: 0.0818 - accuracy: 0.9637 - val_loss: 0.0771 - val_accuracy: 0.9675\n",
      "Epoch 30/80\n",
      "25202/25202 [==============================] - 1s 39us/step - loss: 0.0847 - accuracy: 0.9635 - val_loss: 0.0958 - val_accuracy: 0.9582\n",
      "Epoch 31/80\n",
      "25202/25202 [==============================] - 1s 36us/step - loss: 0.0828 - accuracy: 0.9642 - val_loss: 0.0751 - val_accuracy: 0.9689\n",
      "Epoch 32/80\n",
      "25202/25202 [==============================] - 1s 36us/step - loss: 0.0803 - accuracy: 0.9632 - val_loss: 0.0753 - val_accuracy: 0.9697\n",
      "Epoch 33/80\n",
      "25202/25202 [==============================] - 1s 37us/step - loss: 0.0777 - accuracy: 0.9644 - val_loss: 0.0744 - val_accuracy: 0.9686\n",
      "Epoch 34/80\n",
      "25202/25202 [==============================] - 1s 36us/step - loss: 0.0799 - accuracy: 0.9639 - val_loss: 0.0882 - val_accuracy: 0.9618\n",
      "Epoch 35/80\n",
      "25202/25202 [==============================] - 1s 38us/step - loss: 0.0794 - accuracy: 0.9646 - val_loss: 0.0789 - val_accuracy: 0.9668\n",
      "Epoch 36/80\n",
      "25202/25202 [==============================] - 1s 38us/step - loss: 0.0799 - accuracy: 0.9646 - val_loss: 0.0849 - val_accuracy: 0.9618\n",
      "Epoch 37/80\n",
      "25202/25202 [==============================] - 1s 37us/step - loss: 0.0828 - accuracy: 0.9639 - val_loss: 0.0825 - val_accuracy: 0.9636\n",
      "Epoch 38/80\n",
      "25202/25202 [==============================] - 1s 36us/step - loss: 0.0784 - accuracy: 0.9650 - val_loss: 0.0863 - val_accuracy: 0.9632\n",
      "Epoch 39/80\n",
      "25202/25202 [==============================] - 1s 38us/step - loss: 0.0789 - accuracy: 0.9646 - val_loss: 0.0801 - val_accuracy: 0.9639\n",
      "Epoch 40/80\n",
      "25202/25202 [==============================] - 1s 37us/step - loss: 0.0778 - accuracy: 0.9651 - val_loss: 0.0754 - val_accuracy: 0.9686\n",
      "Epoch 41/80\n",
      "25202/25202 [==============================] - 1s 38us/step - loss: 0.0795 - accuracy: 0.9644 - val_loss: 0.0736 - val_accuracy: 0.9686\n",
      "Epoch 42/80\n",
      "25202/25202 [==============================] - 1s 37us/step - loss: 0.0760 - accuracy: 0.9645 - val_loss: 0.0730 - val_accuracy: 0.9650\n",
      "Epoch 43/80\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "25202/25202 [==============================] - 1s 36us/step - loss: 0.0810 - accuracy: 0.9642 - val_loss: 0.0746 - val_accuracy: 0.9675\n",
      "Epoch 44/80\n",
      "25202/25202 [==============================] - 1s 38us/step - loss: 0.0774 - accuracy: 0.9642 - val_loss: 0.0728 - val_accuracy: 0.9689\n",
      "Epoch 45/80\n",
      "25202/25202 [==============================] - 1s 36us/step - loss: 0.0774 - accuracy: 0.9647 - val_loss: 0.1289 - val_accuracy: 0.9404\n",
      "Epoch 46/80\n",
      "25202/25202 [==============================] - 1s 36us/step - loss: 0.0829 - accuracy: 0.9640 - val_loss: 0.0724 - val_accuracy: 0.9661\n",
      "Epoch 47/80\n",
      "25202/25202 [==============================] - 1s 38us/step - loss: 0.0755 - accuracy: 0.9646 - val_loss: 0.0760 - val_accuracy: 0.9675\n",
      "Epoch 48/80\n",
      "25202/25202 [==============================] - 1s 37us/step - loss: 0.0773 - accuracy: 0.9643 - val_loss: 0.0714 - val_accuracy: 0.9711\n",
      "Epoch 49/80\n",
      "25202/25202 [==============================] - 1s 37us/step - loss: 0.0781 - accuracy: 0.9642 - val_loss: 0.0727 - val_accuracy: 0.9693\n",
      "Epoch 50/80\n",
      "25202/25202 [==============================] - 1s 37us/step - loss: 0.0782 - accuracy: 0.9637 - val_loss: 0.0724 - val_accuracy: 0.9657\n",
      "Epoch 51/80\n",
      "25202/25202 [==============================] - 1s 37us/step - loss: 0.0773 - accuracy: 0.9652 - val_loss: 0.0729 - val_accuracy: 0.9668\n",
      "Epoch 52/80\n",
      "25202/25202 [==============================] - 1s 36us/step - loss: 0.0759 - accuracy: 0.9662 - val_loss: 0.0752 - val_accuracy: 0.9664\n",
      "Epoch 53/80\n",
      "25202/25202 [==============================] - 1s 39us/step - loss: 0.0746 - accuracy: 0.9652 - val_loss: 0.0770 - val_accuracy: 0.9636\n",
      "Epoch 54/80\n",
      "25202/25202 [==============================] - 1s 37us/step - loss: 0.0757 - accuracy: 0.9655 - val_loss: 0.0699 - val_accuracy: 0.9693\n",
      "Epoch 55/80\n",
      "25202/25202 [==============================] - 1s 37us/step - loss: 0.0743 - accuracy: 0.9653 - val_loss: 0.0712 - val_accuracy: 0.9697\n",
      "Epoch 56/80\n",
      "25202/25202 [==============================] - 1s 35us/step - loss: 0.0743 - accuracy: 0.9658 - val_loss: 0.0796 - val_accuracy: 0.9600\n",
      "Epoch 57/80\n",
      "25202/25202 [==============================] - 1s 37us/step - loss: 0.0785 - accuracy: 0.9639 - val_loss: 0.0728 - val_accuracy: 0.9693\n",
      "Epoch 58/80\n",
      "25202/25202 [==============================] - 1s 37us/step - loss: 0.0751 - accuracy: 0.9653 - val_loss: 0.0682 - val_accuracy: 0.9686\n",
      "Epoch 59/80\n",
      "25202/25202 [==============================] - 1s 37us/step - loss: 0.0737 - accuracy: 0.9644 - val_loss: 0.0742 - val_accuracy: 0.9661\n",
      "Epoch 60/80\n",
      "25202/25202 [==============================] - 1s 36us/step - loss: 0.0730 - accuracy: 0.9654 - val_loss: 0.0744 - val_accuracy: 0.9668\n",
      "Epoch 61/80\n",
      "25202/25202 [==============================] - 1s 38us/step - loss: 0.0759 - accuracy: 0.9642 - val_loss: 0.0688 - val_accuracy: 0.9693\n",
      "Epoch 62/80\n",
      "25202/25202 [==============================] - 1s 37us/step - loss: 0.0751 - accuracy: 0.9646 - val_loss: 0.0809 - val_accuracy: 0.9668\n",
      "Epoch 63/80\n",
      "25202/25202 [==============================] - 1s 38us/step - loss: 0.0754 - accuracy: 0.9644 - val_loss: 0.0692 - val_accuracy: 0.9714\n",
      "Epoch 64/80\n",
      "25202/25202 [==============================] - 1s 37us/step - loss: 0.0735 - accuracy: 0.9651 - val_loss: 0.0694 - val_accuracy: 0.9682\n",
      "Epoch 65/80\n",
      "25202/25202 [==============================] - 1s 37us/step - loss: 0.0746 - accuracy: 0.9647 - val_loss: 0.0684 - val_accuracy: 0.9729\n",
      "Epoch 66/80\n",
      "25202/25202 [==============================] - 1s 37us/step - loss: 0.0729 - accuracy: 0.9652 - val_loss: 0.0690 - val_accuracy: 0.9682\n",
      "Epoch 67/80\n",
      "25202/25202 [==============================] - 1s 35us/step - loss: 0.0736 - accuracy: 0.9659 - val_loss: 0.0698 - val_accuracy: 0.9697\n",
      "Epoch 68/80\n",
      "25202/25202 [==============================] - 1s 34us/step - loss: 0.0744 - accuracy: 0.9651 - val_loss: 0.0680 - val_accuracy: 0.9707\n",
      "Epoch 69/80\n",
      "25202/25202 [==============================] - 1s 35us/step - loss: 0.0741 - accuracy: 0.9650 - val_loss: 0.0751 - val_accuracy: 0.9700\n",
      "Epoch 70/80\n",
      "25202/25202 [==============================] - 1s 35us/step - loss: 0.0735 - accuracy: 0.9663 - val_loss: 0.0933 - val_accuracy: 0.9650\n",
      "Epoch 71/80\n",
      "25202/25202 [==============================] - 1s 37us/step - loss: 0.0752 - accuracy: 0.9644 - val_loss: 0.0797 - val_accuracy: 0.9672\n",
      "Epoch 72/80\n",
      "25202/25202 [==============================] - 1s 36us/step - loss: 0.0741 - accuracy: 0.9650 - val_loss: 0.0744 - val_accuracy: 0.9697\n",
      "Epoch 73/80\n",
      "25202/25202 [==============================] - 1s 36us/step - loss: 0.0730 - accuracy: 0.9649 - val_loss: 0.0678 - val_accuracy: 0.9700\n",
      "Epoch 74/80\n",
      "25202/25202 [==============================] - 1s 36us/step - loss: 0.0719 - accuracy: 0.9664 - val_loss: 0.0672 - val_accuracy: 0.9704\n",
      "Epoch 75/80\n",
      "25202/25202 [==============================] - 1s 36us/step - loss: 0.0726 - accuracy: 0.9659 - val_loss: 0.0787 - val_accuracy: 0.9639\n",
      "Epoch 76/80\n",
      "25202/25202 [==============================] - 1s 38us/step - loss: 0.0735 - accuracy: 0.9639 - val_loss: 0.0691 - val_accuracy: 0.9700\n",
      "Epoch 77/80\n",
      "25202/25202 [==============================] - 1s 38us/step - loss: 0.0730 - accuracy: 0.9653 - val_loss: 0.0697 - val_accuracy: 0.9700\n",
      "Epoch 78/80\n",
      "25202/25202 [==============================] - 1s 37us/step - loss: 0.0727 - accuracy: 0.9656 - val_loss: 0.0668 - val_accuracy: 0.9725\n",
      "Epoch 79/80\n",
      "25202/25202 [==============================] - 1s 34us/step - loss: 0.0726 - accuracy: 0.9654 - val_loss: 0.0770 - val_accuracy: 0.9632\n",
      "Epoch 80/80\n",
      "25202/25202 [==============================] - 1s 37us/step - loss: 0.0728 - accuracy: 0.9660 - val_loss: 0.0665 - val_accuracy: 0.9729\n",
      "[[1.0000000e+00 3.7816340e-19 1.4688123e-20 2.5521107e-10 5.9290200e-20\n",
      "  1.1460829e-20]\n",
      " [2.0976528e-05 7.6116344e-06 2.7600536e-11 1.2279975e-06 1.1512667e-10\n",
      "  9.9997020e-01]\n",
      " [2.0685582e-05 7.5005933e-06 2.7567450e-11 1.2163947e-06 1.1598696e-10\n",
      "  9.9997056e-01]\n",
      " ...\n",
      " [7.5857323e-14 1.0842190e-09 9.9984419e-01 1.5582895e-04 7.9289017e-24\n",
      "  2.7399004e-08]\n",
      " [4.4576176e-08 2.3406235e-11 9.9995148e-01 4.2866181e-05 7.8207484e-07\n",
      "  4.8463044e-06]\n",
      " [6.4637305e-08 6.5303664e-18 3.8944512e-10 3.6994113e-08 9.9999976e-01\n",
      "  9.3826884e-08]]\n",
      "[0 5 5 ... 2 2 4]\n",
      "<class 'numpy.ndarray'>\n",
      "One CNN, r:  0\n",
      "Computing Time:  0:01:19.351506\n",
      "Model: \"sequential_1\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv1d_1 (Conv1D)            (None, 3, 6)              12        \n",
      "_________________________________________________________________\n",
      "average_pooling1d_1 (Average (None, 1, 6)              0         \n",
      "_________________________________________________________________\n",
      "conv1d_2 (Conv1D)            (None, 1, 16)             112       \n",
      "_________________________________________________________________\n",
      "average_pooling1d_2 (Average (None, 1, 16)             0         \n",
      "_________________________________________________________________\n",
      "conv1d_3 (Conv1D)            (None, 1, 120)            2040      \n",
      "_________________________________________________________________\n",
      "flatten_1 (Flatten)          (None, 120)               0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 84)                10164     \n",
      "_________________________________________________________________\n",
      "preds (Dense)                (None, 6)                 510       \n",
      "=================================================================\n",
      "Total params: 12,838\n",
      "Trainable params: 12,838\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Train on 25202 samples, validate on 2801 samples\n",
      "Epoch 1/80\n",
      "25202/25202 [==============================] - 1s 45us/step - loss: 0.6895 - accuracy: 0.7350 - val_loss: 0.3911 - val_accuracy: 0.8658\n",
      "Epoch 2/80\n",
      "25202/25202 [==============================] - 1s 40us/step - loss: 0.2930 - accuracy: 0.9010 - val_loss: 0.2393 - val_accuracy: 0.9200\n",
      "Epoch 3/80\n",
      "25202/25202 [==============================] - 1s 36us/step - loss: 0.2095 - accuracy: 0.9297 - val_loss: 0.1914 - val_accuracy: 0.9304\n",
      "Epoch 4/80\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "25202/25202 [==============================] - 1s 37us/step - loss: 0.1703 - accuracy: 0.9435 - val_loss: 0.1542 - val_accuracy: 0.9475\n",
      "Epoch 5/80\n",
      "25202/25202 [==============================] - 1s 37us/step - loss: 0.1448 - accuracy: 0.9493 - val_loss: 0.1375 - val_accuracy: 0.9522\n",
      "Epoch 6/80\n",
      "25202/25202 [==============================] - 1s 37us/step - loss: 0.1282 - accuracy: 0.9550 - val_loss: 0.1267 - val_accuracy: 0.9564\n",
      "Epoch 7/80\n",
      "25202/25202 [==============================] - 1s 35us/step - loss: 0.1156 - accuracy: 0.9599 - val_loss: 0.1181 - val_accuracy: 0.9572\n",
      "Epoch 8/80\n",
      "25202/25202 [==============================] - 1s 39us/step - loss: 0.1137 - accuracy: 0.9602 - val_loss: 0.1244 - val_accuracy: 0.9561\n",
      "Epoch 9/80\n",
      "25202/25202 [==============================] - 1s 35us/step - loss: 0.1038 - accuracy: 0.9625 - val_loss: 0.1135 - val_accuracy: 0.9589\n",
      "Epoch 10/80\n",
      "25202/25202 [==============================] - 1s 36us/step - loss: 0.1031 - accuracy: 0.9621 - val_loss: 0.1116 - val_accuracy: 0.9589\n",
      "Epoch 11/80\n",
      "25202/25202 [==============================] - 1s 37us/step - loss: 0.1029 - accuracy: 0.9627 - val_loss: 0.1188 - val_accuracy: 0.9582\n",
      "Epoch 12/80\n",
      "25202/25202 [==============================] - 1s 37us/step - loss: 0.0979 - accuracy: 0.9633 - val_loss: 0.1092 - val_accuracy: 0.9543\n",
      "Epoch 13/80\n",
      "25202/25202 [==============================] - 1s 36us/step - loss: 0.0957 - accuracy: 0.9637 - val_loss: 0.1086 - val_accuracy: 0.9593\n",
      "Epoch 14/80\n",
      "25202/25202 [==============================] - 1s 38us/step - loss: 0.0986 - accuracy: 0.9632 - val_loss: 0.1131 - val_accuracy: 0.9575\n",
      "Epoch 15/80\n",
      "25202/25202 [==============================] - 1s 37us/step - loss: 0.0947 - accuracy: 0.9632 - val_loss: 0.1021 - val_accuracy: 0.9600\n",
      "Epoch 16/80\n",
      "25202/25202 [==============================] - 1s 38us/step - loss: 0.0932 - accuracy: 0.9636 - val_loss: 0.1134 - val_accuracy: 0.9564\n",
      "Epoch 17/80\n",
      "25202/25202 [==============================] - 1s 36us/step - loss: 0.0919 - accuracy: 0.9629 - val_loss: 0.1076 - val_accuracy: 0.9579\n",
      "Epoch 18/80\n",
      "25202/25202 [==============================] - 1s 36us/step - loss: 0.0887 - accuracy: 0.9642 - val_loss: 0.1046 - val_accuracy: 0.9579\n",
      "Epoch 19/80\n",
      "25202/25202 [==============================] - 1s 36us/step - loss: 0.0917 - accuracy: 0.9631 - val_loss: 0.1087 - val_accuracy: 0.9572\n",
      "Epoch 20/80\n",
      "25202/25202 [==============================] - 1s 37us/step - loss: 0.0895 - accuracy: 0.9633 - val_loss: 0.0989 - val_accuracy: 0.9579\n",
      "Epoch 21/80\n",
      "25202/25202 [==============================] - 1s 37us/step - loss: 0.0905 - accuracy: 0.9629 - val_loss: 0.1011 - val_accuracy: 0.9597\n",
      "Epoch 22/80\n",
      "25202/25202 [==============================] - 1s 37us/step - loss: 0.0888 - accuracy: 0.9640 - val_loss: 0.0966 - val_accuracy: 0.9564\n",
      "Epoch 23/80\n",
      "25202/25202 [==============================] - 1s 37us/step - loss: 0.0889 - accuracy: 0.9624 - val_loss: 0.0978 - val_accuracy: 0.9561\n",
      "Epoch 24/80\n",
      "25202/25202 [==============================] - 1s 36us/step - loss: 0.0851 - accuracy: 0.9646 - val_loss: 0.0910 - val_accuracy: 0.9589\n",
      "Epoch 25/80\n",
      "25202/25202 [==============================] - 1s 38us/step - loss: 0.0881 - accuracy: 0.9626 - val_loss: 0.1068 - val_accuracy: 0.9607\n",
      "Epoch 26/80\n",
      "25202/25202 [==============================] - 1s 36us/step - loss: 0.0860 - accuracy: 0.9640 - val_loss: 0.0884 - val_accuracy: 0.9604\n",
      "Epoch 27/80\n",
      "25202/25202 [==============================] - 1s 38us/step - loss: 0.0856 - accuracy: 0.9631 - val_loss: 0.0897 - val_accuracy: 0.9568\n",
      "Epoch 28/80\n",
      "25202/25202 [==============================] - 1s 35us/step - loss: 0.0835 - accuracy: 0.9647 - val_loss: 0.0999 - val_accuracy: 0.9597\n",
      "Epoch 29/80\n",
      "25202/25202 [==============================] - 1s 36us/step - loss: 0.0851 - accuracy: 0.9643 - val_loss: 0.0887 - val_accuracy: 0.9589\n",
      "Epoch 30/80\n",
      "25202/25202 [==============================] - 1s 37us/step - loss: 0.0841 - accuracy: 0.9639 - val_loss: 0.0928 - val_accuracy: 0.9593\n",
      "Epoch 31/80\n",
      "25202/25202 [==============================] - 1s 39us/step - loss: 0.0854 - accuracy: 0.9635 - val_loss: 0.0895 - val_accuracy: 0.9597\n",
      "Epoch 32/80\n",
      "25202/25202 [==============================] - 1s 37us/step - loss: 0.0822 - accuracy: 0.9640 - val_loss: 0.0881 - val_accuracy: 0.9604\n",
      "Epoch 33/80\n",
      "25202/25202 [==============================] - 1s 38us/step - loss: 0.0828 - accuracy: 0.9634 - val_loss: 0.1045 - val_accuracy: 0.9586\n",
      "Epoch 34/80\n",
      "25202/25202 [==============================] - 1s 37us/step - loss: 0.0808 - accuracy: 0.9650 - val_loss: 0.0896 - val_accuracy: 0.9572\n",
      "Epoch 35/80\n",
      "25202/25202 [==============================] - 1s 38us/step - loss: 0.0811 - accuracy: 0.9651 - val_loss: 0.0877 - val_accuracy: 0.9586\n",
      "Epoch 36/80\n",
      "25202/25202 [==============================] - 1s 37us/step - loss: 0.0823 - accuracy: 0.9640 - val_loss: 0.0911 - val_accuracy: 0.9618\n",
      "Epoch 37/80\n",
      "25202/25202 [==============================] - 1s 34us/step - loss: 0.0810 - accuracy: 0.9650 - val_loss: 0.0843 - val_accuracy: 0.9593\n",
      "Epoch 38/80\n",
      "25202/25202 [==============================] - 1s 34us/step - loss: 0.0820 - accuracy: 0.9641 - val_loss: 0.0819 - val_accuracy: 0.9597\n",
      "Epoch 39/80\n",
      "25202/25202 [==============================] - 1s 31us/step - loss: 0.0787 - accuracy: 0.9646 - val_loss: 0.0891 - val_accuracy: 0.9586\n",
      "Epoch 40/80\n",
      "25202/25202 [==============================] - 1s 34us/step - loss: 0.0809 - accuracy: 0.9646 - val_loss: 0.0987 - val_accuracy: 0.9582\n",
      "Epoch 41/80\n",
      "25202/25202 [==============================] - 1s 32us/step - loss: 0.0797 - accuracy: 0.9645 - val_loss: 0.1014 - val_accuracy: 0.9536\n",
      "Epoch 42/80\n",
      "25202/25202 [==============================] - 1s 37us/step - loss: 0.0794 - accuracy: 0.9649 - val_loss: 0.0924 - val_accuracy: 0.9582\n",
      "Epoch 43/80\n",
      "25202/25202 [==============================] - 1s 33us/step - loss: 0.0850 - accuracy: 0.9632 - val_loss: 0.0888 - val_accuracy: 0.9589\n",
      "Epoch 44/80\n",
      "25202/25202 [==============================] - 1s 36us/step - loss: 0.0797 - accuracy: 0.9643 - val_loss: 0.0915 - val_accuracy: 0.9586\n",
      "Epoch 45/80\n",
      "25202/25202 [==============================] - 1s 36us/step - loss: 0.0803 - accuracy: 0.9653 - val_loss: 0.0844 - val_accuracy: 0.9607\n",
      "Epoch 46/80\n",
      "25202/25202 [==============================] - 1s 37us/step - loss: 0.0812 - accuracy: 0.9643 - val_loss: 0.0875 - val_accuracy: 0.9604\n",
      "Epoch 47/80\n",
      "25202/25202 [==============================] - 1s 41us/step - loss: 0.0790 - accuracy: 0.9642 - val_loss: 0.0808 - val_accuracy: 0.9604\n",
      "Epoch 48/80\n",
      "25202/25202 [==============================] - 1s 37us/step - loss: 0.0798 - accuracy: 0.9647 - val_loss: 0.0831 - val_accuracy: 0.9607\n",
      "Epoch 49/80\n",
      "25202/25202 [==============================] - 1s 34us/step - loss: 0.0786 - accuracy: 0.9647 - val_loss: 0.0818 - val_accuracy: 0.9600\n",
      "Epoch 50/80\n",
      "25202/25202 [==============================] - 1s 34us/step - loss: 0.0763 - accuracy: 0.9656 - val_loss: 0.0891 - val_accuracy: 0.9607\n",
      "Epoch 51/80\n",
      "25202/25202 [==============================] - 1s 36us/step - loss: 0.0776 - accuracy: 0.9646 - val_loss: 0.0801 - val_accuracy: 0.9622\n",
      "Epoch 52/80\n",
      "25202/25202 [==============================] - 1s 37us/step - loss: 0.0807 - accuracy: 0.9628 - val_loss: 0.0879 - val_accuracy: 0.9597\n",
      "Epoch 53/80\n",
      "25202/25202 [==============================] - 1s 37us/step - loss: 0.0782 - accuracy: 0.9643 - val_loss: 0.0928 - val_accuracy: 0.9582\n",
      "Epoch 54/80\n",
      "25202/25202 [==============================] - 1s 36us/step - loss: 0.0781 - accuracy: 0.9641 - val_loss: 0.0817 - val_accuracy: 0.9600\n",
      "Epoch 55/80\n",
      "25202/25202 [==============================] - 1s 38us/step - loss: 0.0769 - accuracy: 0.9648 - val_loss: 0.0790 - val_accuracy: 0.9622\n",
      "Epoch 56/80\n",
      "25202/25202 [==============================] - 1s 35us/step - loss: 0.0786 - accuracy: 0.9646 - val_loss: 0.0938 - val_accuracy: 0.9597\n",
      "Epoch 57/80\n",
      "25202/25202 [==============================] - 1s 36us/step - loss: 0.0798 - accuracy: 0.9647 - val_loss: 0.0864 - val_accuracy: 0.9572\n",
      "Epoch 58/80\n",
      "25202/25202 [==============================] - 1s 37us/step - loss: 0.0786 - accuracy: 0.9642 - val_loss: 0.0825 - val_accuracy: 0.9611\n",
      "Epoch 59/80\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "25202/25202 [==============================] - 1s 35us/step - loss: 0.0772 - accuracy: 0.9649 - val_loss: 0.0952 - val_accuracy: 0.9604\n",
      "Epoch 60/80\n",
      "25202/25202 [==============================] - 1s 36us/step - loss: 0.0779 - accuracy: 0.9646 - val_loss: 0.0846 - val_accuracy: 0.9614\n",
      "Epoch 61/80\n",
      "25202/25202 [==============================] - 1s 36us/step - loss: 0.0777 - accuracy: 0.9640 - val_loss: 0.0891 - val_accuracy: 0.9568\n",
      "Epoch 62/80\n",
      "25202/25202 [==============================] - 1s 36us/step - loss: 0.0780 - accuracy: 0.9650 - val_loss: 0.0796 - val_accuracy: 0.9586\n",
      "Epoch 63/80\n",
      "25202/25202 [==============================] - 1s 36us/step - loss: 0.0798 - accuracy: 0.9646 - val_loss: 0.0820 - val_accuracy: 0.9618\n",
      "Epoch 64/80\n",
      "25202/25202 [==============================] - 1s 37us/step - loss: 0.0765 - accuracy: 0.9647 - val_loss: 0.0836 - val_accuracy: 0.9622\n",
      "Epoch 65/80\n",
      "25202/25202 [==============================] - 1s 36us/step - loss: 0.0768 - accuracy: 0.9657 - val_loss: 0.0860 - val_accuracy: 0.9611\n",
      "Epoch 00065: early stopping\n",
      "[[1.0000000e+00 1.6455787e-16 2.9768421e-21 7.3495217e-25 7.9543473e-12\n",
      "  1.1127239e-16]\n",
      " [1.3343641e-04 2.4352543e-05 2.6702375e-07 6.4255687e-20 2.4541238e-04\n",
      "  9.9959666e-01]\n",
      " [1.3108202e-04 2.4026021e-05 2.6827948e-07 6.4419967e-20 2.4657467e-04\n",
      "  9.9959809e-01]\n",
      " ...\n",
      " [2.6256807e-12 1.0932814e-17 9.8890483e-01 1.1095073e-02 1.2917604e-21\n",
      "  5.9026576e-08]\n",
      " [1.7935601e-08 1.7325781e-20 9.9788421e-01 1.2797783e-03 7.4758352e-04\n",
      "  8.8480840e-05]\n",
      " [4.4653223e-08 7.7405987e-21 8.5058072e-11 1.1185362e-18 1.0000000e+00\n",
      "  5.0742059e-08]]\n",
      "[0 5 5 ... 2 2 4]\n",
      "<class 'numpy.ndarray'>\n",
      "One CNN, r:  1\n",
      "Computing Time:  0:02:24.101446\n",
      "Model: \"sequential_1\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv1d_1 (Conv1D)            (None, 3, 6)              12        \n",
      "_________________________________________________________________\n",
      "average_pooling1d_1 (Average (None, 1, 6)              0         \n",
      "_________________________________________________________________\n",
      "conv1d_2 (Conv1D)            (None, 1, 16)             112       \n",
      "_________________________________________________________________\n",
      "average_pooling1d_2 (Average (None, 1, 16)             0         \n",
      "_________________________________________________________________\n",
      "conv1d_3 (Conv1D)            (None, 1, 120)            2040      \n",
      "_________________________________________________________________\n",
      "flatten_1 (Flatten)          (None, 120)               0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 84)                10164     \n",
      "_________________________________________________________________\n",
      "preds (Dense)                (None, 6)                 510       \n",
      "=================================================================\n",
      "Total params: 12,838\n",
      "Trainable params: 12,838\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Train on 25202 samples, validate on 2801 samples\n",
      "Epoch 1/80\n",
      "25202/25202 [==============================] - 1s 48us/step - loss: 0.6597 - accuracy: 0.7503 - val_loss: 0.3185 - val_accuracy: 0.8840\n",
      "Epoch 2/80\n",
      "25202/25202 [==============================] - 1s 37us/step - loss: 0.2479 - accuracy: 0.9110 - val_loss: 0.2273 - val_accuracy: 0.9122\n",
      "Epoch 3/80\n",
      "25202/25202 [==============================] - 1s 36us/step - loss: 0.1916 - accuracy: 0.9296 - val_loss: 0.1739 - val_accuracy: 0.9414\n",
      "Epoch 4/80\n",
      "25202/25202 [==============================] - 1s 37us/step - loss: 0.1395 - accuracy: 0.9490 - val_loss: 0.1209 - val_accuracy: 0.9543\n",
      "Epoch 5/80\n",
      "25202/25202 [==============================] - 1s 37us/step - loss: 0.1088 - accuracy: 0.9590 - val_loss: 0.0978 - val_accuracy: 0.9589\n",
      "Epoch 6/80\n",
      "25202/25202 [==============================] - 1s 38us/step - loss: 0.0947 - accuracy: 0.9629 - val_loss: 0.0908 - val_accuracy: 0.9614\n",
      "Epoch 7/80\n",
      "25202/25202 [==============================] - 1s 37us/step - loss: 0.0932 - accuracy: 0.9619 - val_loss: 0.0959 - val_accuracy: 0.9589\n",
      "Epoch 8/80\n",
      "25202/25202 [==============================] - 1s 35us/step - loss: 0.0920 - accuracy: 0.9622 - val_loss: 0.0998 - val_accuracy: 0.9586\n",
      "Epoch 9/80\n",
      "25202/25202 [==============================] - 1s 38us/step - loss: 0.0914 - accuracy: 0.9623 - val_loss: 0.1020 - val_accuracy: 0.9597\n",
      "Epoch 10/80\n",
      "25202/25202 [==============================] - 1s 37us/step - loss: 0.0879 - accuracy: 0.9638 - val_loss: 0.0993 - val_accuracy: 0.9568\n",
      "Epoch 11/80\n",
      "25202/25202 [==============================] - 1s 37us/step - loss: 0.0861 - accuracy: 0.9642 - val_loss: 0.0871 - val_accuracy: 0.9632\n",
      "Epoch 12/80\n",
      "25202/25202 [==============================] - 1s 38us/step - loss: 0.0843 - accuracy: 0.9639 - val_loss: 0.0948 - val_accuracy: 0.9572\n",
      "Epoch 13/80\n",
      "25202/25202 [==============================] - 1s 39us/step - loss: 0.0867 - accuracy: 0.9632 - val_loss: 0.0846 - val_accuracy: 0.9597\n",
      "Epoch 14/80\n",
      "25202/25202 [==============================] - 1s 37us/step - loss: 0.0845 - accuracy: 0.9635 - val_loss: 0.1018 - val_accuracy: 0.9586\n",
      "Epoch 15/80\n",
      "25202/25202 [==============================] - 1s 35us/step - loss: 0.0866 - accuracy: 0.9630 - val_loss: 0.0922 - val_accuracy: 0.9600\n",
      "Epoch 16/80\n",
      "25202/25202 [==============================] - 1s 37us/step - loss: 0.0851 - accuracy: 0.9641 - val_loss: 0.0832 - val_accuracy: 0.9597\n",
      "Epoch 17/80\n",
      "25202/25202 [==============================] - 1s 34us/step - loss: 0.0825 - accuracy: 0.9644 - val_loss: 0.0893 - val_accuracy: 0.9557\n",
      "Epoch 18/80\n",
      "25202/25202 [==============================] - 1s 38us/step - loss: 0.0874 - accuracy: 0.9632 - val_loss: 0.0823 - val_accuracy: 0.9636\n",
      "Epoch 19/80\n",
      "25202/25202 [==============================] - 1s 34us/step - loss: 0.0801 - accuracy: 0.9654 - val_loss: 0.0817 - val_accuracy: 0.9636\n",
      "Epoch 20/80\n",
      "25202/25202 [==============================] - 1s 34us/step - loss: 0.0812 - accuracy: 0.9649 - val_loss: 0.0814 - val_accuracy: 0.9607\n",
      "Epoch 21/80\n",
      "25202/25202 [==============================] - 1s 34us/step - loss: 0.0815 - accuracy: 0.9636 - val_loss: 0.0948 - val_accuracy: 0.9575\n",
      "Epoch 22/80\n",
      "25202/25202 [==============================] - 1s 35us/step - loss: 0.0803 - accuracy: 0.9640 - val_loss: 0.0846 - val_accuracy: 0.9618\n",
      "Epoch 23/80\n",
      "25202/25202 [==============================] - 1s 36us/step - loss: 0.0780 - accuracy: 0.9654 - val_loss: 0.0777 - val_accuracy: 0.9654\n",
      "Epoch 24/80\n",
      "25202/25202 [==============================] - 1s 33us/step - loss: 0.0823 - accuracy: 0.9641 - val_loss: 0.0880 - val_accuracy: 0.9582\n",
      "Epoch 25/80\n",
      "25202/25202 [==============================] - 1s 37us/step - loss: 0.0792 - accuracy: 0.9644 - val_loss: 0.0774 - val_accuracy: 0.9636\n",
      "Epoch 26/80\n",
      "25202/25202 [==============================] - 1s 38us/step - loss: 0.0788 - accuracy: 0.9642 - val_loss: 0.0775 - val_accuracy: 0.9639\n",
      "Epoch 27/80\n",
      "25202/25202 [==============================] - 1s 37us/step - loss: 0.0785 - accuracy: 0.9637 - val_loss: 0.0853 - val_accuracy: 0.9589\n",
      "Epoch 28/80\n",
      "25202/25202 [==============================] - 1s 38us/step - loss: 0.0810 - accuracy: 0.9649 - val_loss: 0.0913 - val_accuracy: 0.9557\n",
      "Epoch 29/80\n",
      "25202/25202 [==============================] - 1s 37us/step - loss: 0.0776 - accuracy: 0.9651 - val_loss: 0.0849 - val_accuracy: 0.9647\n",
      "Epoch 30/80\n",
      "25202/25202 [==============================] - 1s 34us/step - loss: 0.0784 - accuracy: 0.9645 - val_loss: 0.0800 - val_accuracy: 0.9629\n",
      "Epoch 31/80\n",
      "25202/25202 [==============================] - 1s 34us/step - loss: 0.0782 - accuracy: 0.9644 - val_loss: 0.0758 - val_accuracy: 0.9661\n",
      "Epoch 32/80\n",
      "25202/25202 [==============================] - 1s 35us/step - loss: 0.0759 - accuracy: 0.9650 - val_loss: 0.0850 - val_accuracy: 0.9593\n",
      "Epoch 33/80\n",
      "25202/25202 [==============================] - 1s 35us/step - loss: 0.0759 - accuracy: 0.9651 - val_loss: 0.1013 - val_accuracy: 0.9607\n",
      "Epoch 34/80\n",
      "25202/25202 [==============================] - 1s 34us/step - loss: 0.0769 - accuracy: 0.9644 - val_loss: 0.0826 - val_accuracy: 0.9639\n",
      "Epoch 35/80\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "25202/25202 [==============================] - 1s 34us/step - loss: 0.0769 - accuracy: 0.9642 - val_loss: 0.0804 - val_accuracy: 0.9611\n",
      "Epoch 36/80\n",
      "25202/25202 [==============================] - 1s 35us/step - loss: 0.0775 - accuracy: 0.9648 - val_loss: 0.0808 - val_accuracy: 0.9629\n",
      "Epoch 37/80\n",
      "25202/25202 [==============================] - 1s 35us/step - loss: 0.0767 - accuracy: 0.9659 - val_loss: 0.0841 - val_accuracy: 0.9604\n",
      "Epoch 38/80\n",
      "25202/25202 [==============================] - 1s 36us/step - loss: 0.0766 - accuracy: 0.9644 - val_loss: 0.0779 - val_accuracy: 0.9607\n",
      "Epoch 39/80\n",
      "25202/25202 [==============================] - 1s 35us/step - loss: 0.0783 - accuracy: 0.9640 - val_loss: 0.0786 - val_accuracy: 0.9629\n",
      "Epoch 40/80\n",
      "25202/25202 [==============================] - 1s 36us/step - loss: 0.0764 - accuracy: 0.9649 - val_loss: 0.0757 - val_accuracy: 0.9689\n",
      "Epoch 41/80\n",
      "25202/25202 [==============================] - 1s 35us/step - loss: 0.0753 - accuracy: 0.9654 - val_loss: 0.0797 - val_accuracy: 0.9636\n",
      "Epoch 42/80\n",
      "25202/25202 [==============================] - 1s 36us/step - loss: 0.0749 - accuracy: 0.9645 - val_loss: 0.0778 - val_accuracy: 0.9643\n",
      "Epoch 43/80\n",
      "25202/25202 [==============================] - 1s 37us/step - loss: 0.0748 - accuracy: 0.9653 - val_loss: 0.0792 - val_accuracy: 0.9611\n",
      "Epoch 44/80\n",
      "25202/25202 [==============================] - 1s 36us/step - loss: 0.0781 - accuracy: 0.9644 - val_loss: 0.0755 - val_accuracy: 0.9625\n",
      "Epoch 45/80\n",
      "25202/25202 [==============================] - 1s 37us/step - loss: 0.0728 - accuracy: 0.9662 - val_loss: 0.0748 - val_accuracy: 0.9643\n",
      "Epoch 46/80\n",
      "25202/25202 [==============================] - 1s 36us/step - loss: 0.0736 - accuracy: 0.9656 - val_loss: 0.0793 - val_accuracy: 0.9597\n",
      "Epoch 47/80\n",
      "25202/25202 [==============================] - 1s 37us/step - loss: 0.0740 - accuracy: 0.9655 - val_loss: 0.0743 - val_accuracy: 0.9654\n",
      "Epoch 48/80\n",
      "25202/25202 [==============================] - 1s 39us/step - loss: 0.0740 - accuracy: 0.9660 - val_loss: 0.0736 - val_accuracy: 0.9664\n",
      "Epoch 49/80\n",
      "25202/25202 [==============================] - 1s 37us/step - loss: 0.0749 - accuracy: 0.9650 - val_loss: 0.0737 - val_accuracy: 0.9636\n",
      "Epoch 50/80\n",
      "25202/25202 [==============================] - 1s 35us/step - loss: 0.0741 - accuracy: 0.9653 - val_loss: 0.0800 - val_accuracy: 0.9632\n",
      "Epoch 51/80\n",
      "25202/25202 [==============================] - 1s 34us/step - loss: 0.0744 - accuracy: 0.9651 - val_loss: 0.0773 - val_accuracy: 0.9629\n",
      "Epoch 52/80\n",
      "25202/25202 [==============================] - 1s 37us/step - loss: 0.0731 - accuracy: 0.9662 - val_loss: 0.0787 - val_accuracy: 0.9643\n",
      "Epoch 53/80\n",
      "25202/25202 [==============================] - 1s 35us/step - loss: 0.0725 - accuracy: 0.9659 - val_loss: 0.0746 - val_accuracy: 0.9643\n",
      "Epoch 54/80\n",
      "25202/25202 [==============================] - 1s 36us/step - loss: 0.0753 - accuracy: 0.9651 - val_loss: 0.0733 - val_accuracy: 0.9632\n",
      "Epoch 55/80\n",
      "25202/25202 [==============================] - 1s 35us/step - loss: 0.0742 - accuracy: 0.9668 - val_loss: 0.0778 - val_accuracy: 0.9618\n",
      "Epoch 56/80\n",
      "25202/25202 [==============================] - 1s 34us/step - loss: 0.0753 - accuracy: 0.9641 - val_loss: 0.0861 - val_accuracy: 0.9604\n",
      "Epoch 57/80\n",
      "25202/25202 [==============================] - 1s 34us/step - loss: 0.0734 - accuracy: 0.9650 - val_loss: 0.0759 - val_accuracy: 0.9625\n",
      "Epoch 58/80\n",
      "25202/25202 [==============================] - 1s 34us/step - loss: 0.0739 - accuracy: 0.9641 - val_loss: 0.0756 - val_accuracy: 0.9639\n",
      "Epoch 59/80\n",
      "25202/25202 [==============================] - 1s 34us/step - loss: 0.0723 - accuracy: 0.9660 - val_loss: 0.0746 - val_accuracy: 0.9643\n",
      "Epoch 60/80\n",
      "25202/25202 [==============================] - 1s 34us/step - loss: 0.0721 - accuracy: 0.9653 - val_loss: 0.0721 - val_accuracy: 0.9647\n",
      "Epoch 61/80\n",
      "25202/25202 [==============================] - 1s 35us/step - loss: 0.0721 - accuracy: 0.9657 - val_loss: 0.0751 - val_accuracy: 0.9650\n",
      "Epoch 62/80\n",
      "25202/25202 [==============================] - 1s 36us/step - loss: 0.0721 - accuracy: 0.9659 - val_loss: 0.0730 - val_accuracy: 0.9664\n",
      "Epoch 63/80\n",
      "25202/25202 [==============================] - 1s 35us/step - loss: 0.0724 - accuracy: 0.9660 - val_loss: 0.0803 - val_accuracy: 0.9625\n",
      "Epoch 64/80\n",
      "25202/25202 [==============================] - 1s 35us/step - loss: 0.0728 - accuracy: 0.9642 - val_loss: 0.0786 - val_accuracy: 0.9618\n",
      "Epoch 65/80\n",
      "25202/25202 [==============================] - 1s 35us/step - loss: 0.0725 - accuracy: 0.9658 - val_loss: 0.0786 - val_accuracy: 0.9604\n",
      "Epoch 66/80\n",
      "25202/25202 [==============================] - 1s 36us/step - loss: 0.0727 - accuracy: 0.9651 - val_loss: 0.0780 - val_accuracy: 0.9614\n",
      "Epoch 67/80\n",
      "25202/25202 [==============================] - 1s 37us/step - loss: 0.0727 - accuracy: 0.9650 - val_loss: 0.0754 - val_accuracy: 0.9618\n",
      "Epoch 68/80\n",
      "25202/25202 [==============================] - 1s 37us/step - loss: 0.0704 - accuracy: 0.9666 - val_loss: 0.0758 - val_accuracy: 0.9647\n",
      "Epoch 69/80\n",
      "25202/25202 [==============================] - 1s 37us/step - loss: 0.0728 - accuracy: 0.9653 - val_loss: 0.0884 - val_accuracy: 0.9589\n",
      "Epoch 70/80\n",
      "25202/25202 [==============================] - 1s 38us/step - loss: 0.0713 - accuracy: 0.9660 - val_loss: 0.0802 - val_accuracy: 0.9629\n",
      "Epoch 00070: early stopping\n",
      "[[1.0000000e+00 4.7182271e-16 6.8712516e-13 1.0532549e-12 2.4159401e-21\n",
      "  3.2928429e-19]\n",
      " [1.4558141e-05 2.6997429e-06 3.8912631e-07 1.2894475e-09 1.4368059e-07\n",
      "  9.9998224e-01]\n",
      " [1.4285745e-05 2.6657017e-06 3.8851792e-07 1.2776309e-09 1.4542992e-07\n",
      "  9.9998260e-01]\n",
      " ...\n",
      " [1.7660942e-13 2.5289137e-07 9.9978632e-01 2.1343402e-04 5.5121629e-18\n",
      "  1.2385026e-08]\n",
      " [6.1230730e-07 4.4259896e-10 9.9891698e-01 7.0281205e-04 3.7860463e-04\n",
      "  1.0342304e-06]\n",
      " [2.2541919e-08 3.3907289e-18 1.8382078e-08 1.4434094e-08 1.0000000e+00\n",
      "  4.4307253e-08]]\n",
      "[0 5 5 ... 2 2 4]\n",
      "<class 'numpy.ndarray'>\n",
      "One CNN, r:  2\n",
      "Computing Time:  0:03:32.054610\n",
      "Model: \"sequential_1\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv1d_1 (Conv1D)            (None, 3, 6)              12        \n",
      "_________________________________________________________________\n",
      "average_pooling1d_1 (Average (None, 1, 6)              0         \n",
      "_________________________________________________________________\n",
      "conv1d_2 (Conv1D)            (None, 1, 16)             112       \n",
      "_________________________________________________________________\n",
      "average_pooling1d_2 (Average (None, 1, 16)             0         \n",
      "_________________________________________________________________\n",
      "conv1d_3 (Conv1D)            (None, 1, 120)            2040      \n",
      "_________________________________________________________________\n",
      "flatten_1 (Flatten)          (None, 120)               0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 84)                10164     \n",
      "_________________________________________________________________\n",
      "preds (Dense)                (None, 6)                 510       \n",
      "=================================================================\n",
      "Total params: 12,838\n",
      "Trainable params: 12,838\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Train on 25202 samples, validate on 2801 samples\n",
      "Epoch 1/80\n",
      "25202/25202 [==============================] - 1s 47us/step - loss: 0.6178 - accuracy: 0.7787 - val_loss: 0.3332 - val_accuracy: 0.8922\n",
      "Epoch 2/80\n",
      "25202/25202 [==============================] - 1s 36us/step - loss: 0.2745 - accuracy: 0.9025 - val_loss: 0.2325 - val_accuracy: 0.9129\n",
      "Epoch 3/80\n",
      "25202/25202 [==============================] - 1s 37us/step - loss: 0.2155 - accuracy: 0.9219 - val_loss: 0.2510 - val_accuracy: 0.9186\n",
      "Epoch 4/80\n",
      "25202/25202 [==============================] - 1s 37us/step - loss: 0.1864 - accuracy: 0.9315 - val_loss: 0.1929 - val_accuracy: 0.9325\n",
      "Epoch 5/80\n",
      "25202/25202 [==============================] - 1s 36us/step - loss: 0.1619 - accuracy: 0.9396 - val_loss: 0.1582 - val_accuracy: 0.9386\n",
      "Epoch 6/80\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "25202/25202 [==============================] - 1s 34us/step - loss: 0.1485 - accuracy: 0.9455 - val_loss: 0.1461 - val_accuracy: 0.9454\n",
      "Epoch 7/80\n",
      "25202/25202 [==============================] - 1s 37us/step - loss: 0.1420 - accuracy: 0.9477 - val_loss: 0.1278 - val_accuracy: 0.9543\n",
      "Epoch 8/80\n",
      "25202/25202 [==============================] - 1s 37us/step - loss: 0.1282 - accuracy: 0.9524 - val_loss: 0.1183 - val_accuracy: 0.9554\n",
      "Epoch 9/80\n",
      "25202/25202 [==============================] - 1s 35us/step - loss: 0.1204 - accuracy: 0.9549 - val_loss: 0.1139 - val_accuracy: 0.9579\n",
      "Epoch 10/80\n",
      "25202/25202 [==============================] - 1s 37us/step - loss: 0.1114 - accuracy: 0.9588 - val_loss: 0.1014 - val_accuracy: 0.9611\n",
      "Epoch 11/80\n",
      "25202/25202 [==============================] - 1s 36us/step - loss: 0.1022 - accuracy: 0.9616 - val_loss: 0.0896 - val_accuracy: 0.9661\n",
      "Epoch 12/80\n",
      "25202/25202 [==============================] - 1s 36us/step - loss: 0.0951 - accuracy: 0.9621 - val_loss: 0.0870 - val_accuracy: 0.9661\n",
      "Epoch 13/80\n",
      "25202/25202 [==============================] - 1s 36us/step - loss: 0.0925 - accuracy: 0.9624 - val_loss: 0.0847 - val_accuracy: 0.9654\n",
      "Epoch 14/80\n",
      "25202/25202 [==============================] - 1s 38us/step - loss: 0.0909 - accuracy: 0.9624 - val_loss: 0.0834 - val_accuracy: 0.9672\n",
      "Epoch 15/80\n",
      "25202/25202 [==============================] - 1s 37us/step - loss: 0.0896 - accuracy: 0.9626 - val_loss: 0.0819 - val_accuracy: 0.9643\n",
      "Epoch 16/80\n",
      "25202/25202 [==============================] - 1s 37us/step - loss: 0.0863 - accuracy: 0.9641 - val_loss: 0.0859 - val_accuracy: 0.9664\n",
      "Epoch 17/80\n",
      "25202/25202 [==============================] - 1s 36us/step - loss: 0.0877 - accuracy: 0.9625 - val_loss: 0.0870 - val_accuracy: 0.9672\n",
      "Epoch 18/80\n",
      "25202/25202 [==============================] - 1s 36us/step - loss: 0.0851 - accuracy: 0.9632 - val_loss: 0.0928 - val_accuracy: 0.9604\n",
      "Epoch 19/80\n",
      "25202/25202 [==============================] - 1s 37us/step - loss: 0.0856 - accuracy: 0.9633 - val_loss: 0.0790 - val_accuracy: 0.9686\n",
      "Epoch 20/80\n",
      "25202/25202 [==============================] - 1s 37us/step - loss: 0.0835 - accuracy: 0.9636 - val_loss: 0.0808 - val_accuracy: 0.9647\n",
      "Epoch 21/80\n",
      "25202/25202 [==============================] - 1s 37us/step - loss: 0.0830 - accuracy: 0.9637 - val_loss: 0.0773 - val_accuracy: 0.9668\n",
      "Epoch 22/80\n",
      "25202/25202 [==============================] - 1s 37us/step - loss: 0.0847 - accuracy: 0.9627 - val_loss: 0.0785 - val_accuracy: 0.9647\n",
      "Epoch 23/80\n",
      "25202/25202 [==============================] - 1s 37us/step - loss: 0.0801 - accuracy: 0.9643 - val_loss: 0.0722 - val_accuracy: 0.9707\n",
      "Epoch 24/80\n",
      "25202/25202 [==============================] - 1s 37us/step - loss: 0.0816 - accuracy: 0.9647 - val_loss: 0.0789 - val_accuracy: 0.9675\n",
      "Epoch 25/80\n",
      "25202/25202 [==============================] - 1s 37us/step - loss: 0.0829 - accuracy: 0.9641 - val_loss: 0.0719 - val_accuracy: 0.9675\n",
      "Epoch 26/80\n",
      "25202/25202 [==============================] - 1s 38us/step - loss: 0.0808 - accuracy: 0.9647 - val_loss: 0.0727 - val_accuracy: 0.9697\n",
      "Epoch 27/80\n",
      "25202/25202 [==============================] - 1s 37us/step - loss: 0.0805 - accuracy: 0.9649 - val_loss: 0.0762 - val_accuracy: 0.9700\n",
      "Epoch 28/80\n",
      "25202/25202 [==============================] - 1s 36us/step - loss: 0.0819 - accuracy: 0.9639 - val_loss: 0.0759 - val_accuracy: 0.9657\n",
      "Epoch 29/80\n",
      "25202/25202 [==============================] - 1s 37us/step - loss: 0.0786 - accuracy: 0.9651 - val_loss: 0.0731 - val_accuracy: 0.9693\n",
      "Epoch 30/80\n",
      "25202/25202 [==============================] - 1s 37us/step - loss: 0.0804 - accuracy: 0.9648 - val_loss: 0.0768 - val_accuracy: 0.9657\n",
      "Epoch 31/80\n",
      "25202/25202 [==============================] - 1s 37us/step - loss: 0.0794 - accuracy: 0.9637 - val_loss: 0.0802 - val_accuracy: 0.9654\n",
      "Epoch 32/80\n",
      "25202/25202 [==============================] - 1s 38us/step - loss: 0.0809 - accuracy: 0.9624 - val_loss: 0.0829 - val_accuracy: 0.9629\n",
      "Epoch 33/80\n",
      "25202/25202 [==============================] - 1s 37us/step - loss: 0.0793 - accuracy: 0.9641 - val_loss: 0.0688 - val_accuracy: 0.9700\n",
      "Epoch 34/80\n",
      "25202/25202 [==============================] - 1s 35us/step - loss: 0.0773 - accuracy: 0.9648 - val_loss: 0.0728 - val_accuracy: 0.9668\n",
      "Epoch 35/80\n",
      "25202/25202 [==============================] - 1s 35us/step - loss: 0.0779 - accuracy: 0.9655 - val_loss: 0.0894 - val_accuracy: 0.9650\n",
      "Epoch 36/80\n",
      "25202/25202 [==============================] - 1s 35us/step - loss: 0.0804 - accuracy: 0.9641 - val_loss: 0.0828 - val_accuracy: 0.9632\n",
      "Epoch 37/80\n",
      "25202/25202 [==============================] - 1s 36us/step - loss: 0.0798 - accuracy: 0.9647 - val_loss: 0.0742 - val_accuracy: 0.9672\n",
      "Epoch 38/80\n",
      "25202/25202 [==============================] - 1s 39us/step - loss: 0.0808 - accuracy: 0.9639 - val_loss: 0.0732 - val_accuracy: 0.9700\n",
      "Epoch 39/80\n",
      "25202/25202 [==============================] - 1s 38us/step - loss: 0.0789 - accuracy: 0.9641 - val_loss: 0.0685 - val_accuracy: 0.9700\n",
      "Epoch 40/80\n",
      "25202/25202 [==============================] - 1s 37us/step - loss: 0.0798 - accuracy: 0.9646 - val_loss: 0.0703 - val_accuracy: 0.9693\n",
      "Epoch 41/80\n",
      "25202/25202 [==============================] - 1s 37us/step - loss: 0.0786 - accuracy: 0.9647 - val_loss: 0.0694 - val_accuracy: 0.9693\n",
      "Epoch 42/80\n",
      "25202/25202 [==============================] - 1s 37us/step - loss: 0.0771 - accuracy: 0.9650 - val_loss: 0.0713 - val_accuracy: 0.9700\n",
      "Epoch 43/80\n",
      "25202/25202 [==============================] - 1s 36us/step - loss: 0.0760 - accuracy: 0.9647 - val_loss: 0.0695 - val_accuracy: 0.9664\n",
      "Epoch 44/80\n",
      "25202/25202 [==============================] - 1s 39us/step - loss: 0.0753 - accuracy: 0.9648 - val_loss: 0.0719 - val_accuracy: 0.9697\n",
      "Epoch 45/80\n",
      "25202/25202 [==============================] - 1s 37us/step - loss: 0.0773 - accuracy: 0.9647 - val_loss: 0.0726 - val_accuracy: 0.9661\n",
      "Epoch 46/80\n",
      "25202/25202 [==============================] - 1s 37us/step - loss: 0.0773 - accuracy: 0.9646 - val_loss: 0.0712 - val_accuracy: 0.9697\n",
      "Epoch 47/80\n",
      "25202/25202 [==============================] - 1s 35us/step - loss: 0.0763 - accuracy: 0.9648 - val_loss: 0.0676 - val_accuracy: 0.9693\n",
      "Epoch 48/80\n",
      "25202/25202 [==============================] - 1s 37us/step - loss: 0.0766 - accuracy: 0.9646 - val_loss: 0.0683 - val_accuracy: 0.9693\n",
      "Epoch 49/80\n",
      "25202/25202 [==============================] - 1s 36us/step - loss: 0.0757 - accuracy: 0.9642 - val_loss: 0.0709 - val_accuracy: 0.9686\n",
      "Epoch 50/80\n",
      "25202/25202 [==============================] - 1s 37us/step - loss: 0.0773 - accuracy: 0.9642 - val_loss: 0.0661 - val_accuracy: 0.9704\n",
      "Epoch 51/80\n",
      "25202/25202 [==============================] - 1s 37us/step - loss: 0.0747 - accuracy: 0.9652 - val_loss: 0.0681 - val_accuracy: 0.9689\n",
      "Epoch 52/80\n",
      "25202/25202 [==============================] - 1s 35us/step - loss: 0.0753 - accuracy: 0.9662 - val_loss: 0.0731 - val_accuracy: 0.9672\n",
      "Epoch 53/80\n",
      "25202/25202 [==============================] - 1s 35us/step - loss: 0.0762 - accuracy: 0.9656 - val_loss: 0.0748 - val_accuracy: 0.9679\n",
      "Epoch 54/80\n",
      "25202/25202 [==============================] - 1s 38us/step - loss: 0.0761 - accuracy: 0.9651 - val_loss: 0.0676 - val_accuracy: 0.9700\n",
      "Epoch 55/80\n",
      "25202/25202 [==============================] - 1s 36us/step - loss: 0.0746 - accuracy: 0.9651 - val_loss: 0.0688 - val_accuracy: 0.9686\n",
      "Epoch 56/80\n",
      "25202/25202 [==============================] - 1s 34us/step - loss: 0.0738 - accuracy: 0.9662 - val_loss: 0.0642 - val_accuracy: 0.9700\n",
      "Epoch 57/80\n",
      "25202/25202 [==============================] - 1s 37us/step - loss: 0.0759 - accuracy: 0.9654 - val_loss: 0.0720 - val_accuracy: 0.9672\n",
      "Epoch 58/80\n",
      "25202/25202 [==============================] - 1s 36us/step - loss: 0.0763 - accuracy: 0.9648 - val_loss: 0.0677 - val_accuracy: 0.9707\n",
      "Epoch 59/80\n",
      "25202/25202 [==============================] - 1s 36us/step - loss: 0.0746 - accuracy: 0.9657 - val_loss: 0.0674 - val_accuracy: 0.9707\n",
      "Epoch 60/80\n",
      "25202/25202 [==============================] - 1s 37us/step - loss: 0.0747 - accuracy: 0.9660 - val_loss: 0.0684 - val_accuracy: 0.9700\n",
      "Epoch 61/80\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "25202/25202 [==============================] - 1s 40us/step - loss: 0.0749 - accuracy: 0.9650 - val_loss: 0.0686 - val_accuracy: 0.9675\n",
      "Epoch 62/80\n",
      "25202/25202 [==============================] - 1s 37us/step - loss: 0.0738 - accuracy: 0.9652 - val_loss: 0.0655 - val_accuracy: 0.9700\n",
      "Epoch 63/80\n",
      "25202/25202 [==============================] - 1s 36us/step - loss: 0.0739 - accuracy: 0.9651 - val_loss: 0.0708 - val_accuracy: 0.9672\n",
      "Epoch 64/80\n",
      "25202/25202 [==============================] - 1s 36us/step - loss: 0.0747 - accuracy: 0.9648 - val_loss: 0.0675 - val_accuracy: 0.9693\n",
      "Epoch 65/80\n",
      "25202/25202 [==============================] - 1s 35us/step - loss: 0.0733 - accuracy: 0.9653 - val_loss: 0.0642 - val_accuracy: 0.9714\n",
      "Epoch 66/80\n",
      "25202/25202 [==============================] - 1s 37us/step - loss: 0.0728 - accuracy: 0.9660 - val_loss: 0.0644 - val_accuracy: 0.9707\n",
      "Epoch 67/80\n",
      "25202/25202 [==============================] - 1s 38us/step - loss: 0.0728 - accuracy: 0.9667 - val_loss: 0.0664 - val_accuracy: 0.9697\n",
      "Epoch 68/80\n",
      "25202/25202 [==============================] - 1s 37us/step - loss: 0.0746 - accuracy: 0.9648 - val_loss: 0.0704 - val_accuracy: 0.9672\n",
      "Epoch 69/80\n",
      "25202/25202 [==============================] - 1s 37us/step - loss: 0.0742 - accuracy: 0.9646 - val_loss: 0.0664 - val_accuracy: 0.9689\n",
      "Epoch 70/80\n",
      "25202/25202 [==============================] - 1s 36us/step - loss: 0.0725 - accuracy: 0.9659 - val_loss: 0.0723 - val_accuracy: 0.9675\n",
      "Epoch 71/80\n",
      "25202/25202 [==============================] - 1s 37us/step - loss: 0.0734 - accuracy: 0.9647 - val_loss: 0.0711 - val_accuracy: 0.9664\n",
      "Epoch 72/80\n",
      "25202/25202 [==============================] - 1s 38us/step - loss: 0.0734 - accuracy: 0.9645 - val_loss: 0.0738 - val_accuracy: 0.9689\n",
      "Epoch 73/80\n",
      "25202/25202 [==============================] - 1s 38us/step - loss: 0.0731 - accuracy: 0.9654 - val_loss: 0.0649 - val_accuracy: 0.9704\n",
      "Epoch 74/80\n",
      "25202/25202 [==============================] - 1s 37us/step - loss: 0.0734 - accuracy: 0.9650 - val_loss: 0.0652 - val_accuracy: 0.9722\n",
      "Epoch 75/80\n",
      "25202/25202 [==============================] - 1s 37us/step - loss: 0.0722 - accuracy: 0.9655 - val_loss: 0.0660 - val_accuracy: 0.9697\n",
      "Epoch 00075: early stopping\n",
      "[[1.0000000e+00 8.8171101e-20 4.0140573e-12 3.7738568e-09 3.5563712e-13\n",
      "  1.5318316e-15]\n",
      " [8.9087353e-06 1.5744759e-05 3.0906290e-06 2.2303792e-09 1.1973445e-07\n",
      "  9.9997211e-01]\n",
      " [8.6836326e-06 1.5532036e-05 3.0657397e-06 2.1963291e-09 1.2081706e-07\n",
      "  9.9997258e-01]\n",
      " ...\n",
      " [1.0960609e-13 3.0214974e-07 9.9928814e-01 7.1144727e-04 1.1634678e-18\n",
      "  6.3641110e-08]\n",
      " [9.9063957e-09 4.6042026e-10 9.9947268e-01 4.1897647e-04 3.5733738e-05\n",
      "  7.2720250e-05]\n",
      " [1.2729914e-06 1.5707164e-17 6.5364583e-07 1.2796603e-10 9.9996054e-01\n",
      "  3.7595659e-05]]\n",
      "[0 5 5 ... 2 2 4]\n",
      "<class 'numpy.ndarray'>\n",
      "One CNN, r:  3\n",
      "Computing Time:  0:04:45.804576\n",
      "Model: \"sequential_1\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv1d_1 (Conv1D)            (None, 3, 6)              12        \n",
      "_________________________________________________________________\n",
      "average_pooling1d_1 (Average (None, 1, 6)              0         \n",
      "_________________________________________________________________\n",
      "conv1d_2 (Conv1D)            (None, 1, 16)             112       \n",
      "_________________________________________________________________\n",
      "average_pooling1d_2 (Average (None, 1, 16)             0         \n",
      "_________________________________________________________________\n",
      "conv1d_3 (Conv1D)            (None, 1, 120)            2040      \n",
      "_________________________________________________________________\n",
      "flatten_1 (Flatten)          (None, 120)               0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 84)                10164     \n",
      "_________________________________________________________________\n",
      "preds (Dense)                (None, 6)                 510       \n",
      "=================================================================\n",
      "Total params: 12,838\n",
      "Trainable params: 12,838\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Train on 25202 samples, validate on 2801 samples\n",
      "Epoch 1/80\n",
      "25202/25202 [==============================] - 1s 48us/step - loss: 0.7118 - accuracy: 0.7380 - val_loss: 0.3565 - val_accuracy: 0.8829\n",
      "Epoch 2/80\n",
      "25202/25202 [==============================] - 1s 40us/step - loss: 0.2814 - accuracy: 0.9006 - val_loss: 0.2254 - val_accuracy: 0.9243\n",
      "Epoch 3/80\n",
      "25202/25202 [==============================] - 1s 39us/step - loss: 0.2062 - accuracy: 0.9274 - val_loss: 0.1989 - val_accuracy: 0.9311\n",
      "Epoch 4/80\n",
      "25202/25202 [==============================] - 1s 39us/step - loss: 0.1701 - accuracy: 0.9391 - val_loss: 0.1600 - val_accuracy: 0.9393\n",
      "Epoch 5/80\n",
      "25202/25202 [==============================] - 1s 39us/step - loss: 0.1357 - accuracy: 0.9525 - val_loss: 0.1326 - val_accuracy: 0.9511\n",
      "Epoch 6/80\n",
      "25202/25202 [==============================] - 1s 38us/step - loss: 0.1229 - accuracy: 0.9576 - val_loss: 0.1237 - val_accuracy: 0.9539\n",
      "Epoch 7/80\n",
      "25202/25202 [==============================] - 1s 40us/step - loss: 0.1123 - accuracy: 0.9600 - val_loss: 0.1121 - val_accuracy: 0.9586\n",
      "Epoch 8/80\n",
      "25202/25202 [==============================] - 1s 39us/step - loss: 0.1105 - accuracy: 0.9616 - val_loss: 0.1101 - val_accuracy: 0.9589\n",
      "Epoch 9/80\n",
      "25202/25202 [==============================] - 1s 38us/step - loss: 0.1045 - accuracy: 0.9633 - val_loss: 0.1051 - val_accuracy: 0.9597\n",
      "Epoch 10/80\n",
      "25202/25202 [==============================] - 1s 40us/step - loss: 0.1019 - accuracy: 0.9629 - val_loss: 0.1099 - val_accuracy: 0.9618\n",
      "Epoch 11/80\n",
      "25202/25202 [==============================] - 1s 38us/step - loss: 0.0994 - accuracy: 0.9644 - val_loss: 0.1023 - val_accuracy: 0.9618\n",
      "Epoch 12/80\n",
      "25202/25202 [==============================] - 1s 38us/step - loss: 0.0970 - accuracy: 0.9635 - val_loss: 0.1166 - val_accuracy: 0.9618\n",
      "Epoch 13/80\n",
      "25202/25202 [==============================] - 1s 38us/step - loss: 0.0970 - accuracy: 0.9641 - val_loss: 0.1237 - val_accuracy: 0.9572\n",
      "Epoch 14/80\n",
      "25202/25202 [==============================] - 1s 37us/step - loss: 0.0914 - accuracy: 0.9641 - val_loss: 0.0931 - val_accuracy: 0.9629\n",
      "Epoch 15/80\n",
      "25202/25202 [==============================] - 1s 40us/step - loss: 0.0913 - accuracy: 0.9637 - val_loss: 0.0919 - val_accuracy: 0.9647\n",
      "Epoch 16/80\n",
      "25202/25202 [==============================] - 1s 38us/step - loss: 0.0900 - accuracy: 0.9642 - val_loss: 0.0912 - val_accuracy: 0.9622\n",
      "Epoch 17/80\n",
      "25202/25202 [==============================] - 1s 38us/step - loss: 0.0883 - accuracy: 0.9645 - val_loss: 0.1065 - val_accuracy: 0.9532\n",
      "Epoch 18/80\n",
      "25202/25202 [==============================] - 1s 37us/step - loss: 0.0882 - accuracy: 0.9637 - val_loss: 0.0880 - val_accuracy: 0.9632\n",
      "Epoch 19/80\n",
      "25202/25202 [==============================] - 1s 38us/step - loss: 0.0844 - accuracy: 0.9650 - val_loss: 0.1126 - val_accuracy: 0.9579\n",
      "Epoch 20/80\n",
      "25202/25202 [==============================] - 1s 39us/step - loss: 0.0860 - accuracy: 0.9638 - val_loss: 0.0939 - val_accuracy: 0.9614\n",
      "Epoch 21/80\n",
      "25202/25202 [==============================] - 1s 39us/step - loss: 0.0861 - accuracy: 0.9638 - val_loss: 0.1181 - val_accuracy: 0.9539\n",
      "Epoch 22/80\n",
      "25202/25202 [==============================] - 1s 39us/step - loss: 0.0863 - accuracy: 0.9633 - val_loss: 0.0967 - val_accuracy: 0.9625\n",
      "Epoch 23/80\n",
      "25202/25202 [==============================] - 1s 42us/step - loss: 0.0835 - accuracy: 0.9644 - val_loss: 0.0978 - val_accuracy: 0.9597\n",
      "Epoch 24/80\n",
      "25202/25202 [==============================] - 1s 38us/step - loss: 0.0854 - accuracy: 0.9637 - val_loss: 0.0842 - val_accuracy: 0.9657\n",
      "Epoch 25/80\n",
      "25202/25202 [==============================] - 1s 39us/step - loss: 0.0838 - accuracy: 0.9640 - val_loss: 0.1005 - val_accuracy: 0.9582\n",
      "Epoch 26/80\n",
      "25202/25202 [==============================] - 1s 42us/step - loss: 0.0831 - accuracy: 0.9644 - val_loss: 0.0939 - val_accuracy: 0.9632\n",
      "Epoch 27/80\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "25202/25202 [==============================] - 1s 39us/step - loss: 0.0823 - accuracy: 0.9644 - val_loss: 0.0909 - val_accuracy: 0.9579\n",
      "Epoch 28/80\n",
      "25202/25202 [==============================] - 1s 39us/step - loss: 0.0820 - accuracy: 0.9642 - val_loss: 0.0872 - val_accuracy: 0.9618\n",
      "Epoch 29/80\n",
      "25202/25202 [==============================] - 1s 39us/step - loss: 0.0823 - accuracy: 0.9642 - val_loss: 0.0934 - val_accuracy: 0.9600\n",
      "Epoch 30/80\n",
      "25202/25202 [==============================] - 1s 40us/step - loss: 0.0823 - accuracy: 0.9633 - val_loss: 0.0846 - val_accuracy: 0.9661\n",
      "Epoch 31/80\n",
      "25202/25202 [==============================] - 1s 40us/step - loss: 0.0856 - accuracy: 0.9633 - val_loss: 0.0789 - val_accuracy: 0.9664\n",
      "Epoch 32/80\n",
      "25202/25202 [==============================] - 1s 38us/step - loss: 0.0818 - accuracy: 0.9642 - val_loss: 0.0947 - val_accuracy: 0.9611\n",
      "Epoch 33/80\n",
      "25202/25202 [==============================] - 1s 40us/step - loss: 0.0793 - accuracy: 0.9648 - val_loss: 0.0795 - val_accuracy: 0.9643\n",
      "Epoch 34/80\n",
      "25202/25202 [==============================] - 1s 38us/step - loss: 0.0814 - accuracy: 0.9640 - val_loss: 0.0830 - val_accuracy: 0.9672\n",
      "Epoch 35/80\n",
      "25202/25202 [==============================] - 1s 38us/step - loss: 0.0807 - accuracy: 0.9646 - val_loss: 0.0837 - val_accuracy: 0.9611\n",
      "Epoch 36/80\n",
      "25202/25202 [==============================] - 1s 38us/step - loss: 0.0798 - accuracy: 0.9646 - val_loss: 0.0907 - val_accuracy: 0.9572\n",
      "Epoch 37/80\n",
      "25202/25202 [==============================] - 1s 40us/step - loss: 0.0792 - accuracy: 0.9650 - val_loss: 0.0844 - val_accuracy: 0.9636\n",
      "Epoch 38/80\n",
      "25202/25202 [==============================] - 1s 40us/step - loss: 0.0825 - accuracy: 0.9634 - val_loss: 0.0933 - val_accuracy: 0.9625\n",
      "Epoch 39/80\n",
      "25202/25202 [==============================] - 1s 38us/step - loss: 0.0817 - accuracy: 0.9633 - val_loss: 0.0897 - val_accuracy: 0.9575\n",
      "Epoch 40/80\n",
      "25202/25202 [==============================] - 1s 39us/step - loss: 0.0799 - accuracy: 0.9649 - val_loss: 0.0874 - val_accuracy: 0.9607\n",
      "Epoch 41/80\n",
      "25202/25202 [==============================] - 1s 40us/step - loss: 0.0812 - accuracy: 0.9645 - val_loss: 0.0851 - val_accuracy: 0.9618\n",
      "Epoch 00041: early stopping\n",
      "[[1.0000000e+00 1.7210769e-14 9.6536126e-11 8.9763082e-13 1.9056801e-10\n",
      "  1.7369798e-13]\n",
      " [8.0420632e-06 6.1140489e-04 3.7942941e-06 1.2811159e-10 9.2991995e-06\n",
      "  9.9936754e-01]\n",
      " [7.8395524e-06 6.0278602e-04 3.7621580e-06 1.2630490e-10 9.3060426e-06\n",
      "  9.9937636e-01]\n",
      " ...\n",
      " [5.1601455e-07 4.0023096e-07 9.9790418e-01 2.0935305e-03 2.5503724e-11\n",
      "  1.3381720e-06]\n",
      " [3.0288922e-05 8.9736205e-12 9.4445556e-01 3.8466204e-04 5.5118926e-02\n",
      "  1.0539634e-05]\n",
      " [1.6359401e-04 9.2038686e-12 1.6476370e-05 8.4167168e-10 9.9893123e-01\n",
      "  8.8875671e-04]]\n",
      "[0 5 5 ... 2 2 4]\n",
      "<class 'numpy.ndarray'>\n",
      "One CNN, r:  4\n",
      "Computing Time:  0:05:30.523377\n",
      "true region_label= [6, 7, 2, 4, 3, 5]\n",
      "dist_table_truth\n",
      " [[1347  856    0 1509   36  308 1552   37  529]\n",
      " [ 622    0    3  217  300    3 2070 3072   45]\n",
      " [ 179  710 2338   12 1245  553   14  365  934]\n",
      " [ 210 1207 2132    0 2114  262  107    0  480]\n",
      " [2205  440   15 2380   45 1337   58   23 2080]\n",
      " [ 204  711   21  194  237 1826  904  433  233]]\n",
      "num of merged_region_image 0 4880\n",
      "num of merged_region_image 1 5534\n",
      "num of merged_region_image 2 4763\n",
      "num of merged_region_image 3 4958\n",
      "num of merged_region_image 4 4548\n",
      "num of merged_region_image 5 3320\n",
      "Counter({-1: 15214, 1: 5534, 3: 4958, 0: 4880, 2: 4763, 4: 4548, 5: 3320})\n",
      "\n",
      "\n",
      "==== merged_and_expand(PATH5,ITE) ====\n",
      "===========  ITE = 3   ===========\n",
      "used_img 28003 28003\n",
      "working_img(=other images=unclean images) 15214 15214\n",
      "merged regions 142 142\n",
      "other_regions 58 58\n",
      "All other regions\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>other index</th>\n",
       "      <th>pred label</th>\n",
       "      <th>truth</th>\n",
       "      <th>rate</th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>128</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>0.92</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>213</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>131</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0.95</td>\n",
       "      <td>1</td>\n",
       "      <td>210</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>8</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>0.58</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>361</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>9</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>0.57</td>\n",
       "      <td>245</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>13</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.62</td>\n",
       "      <td>0</td>\n",
       "      <td>26</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>143</td>\n",
       "      <td>5</td>\n",
       "      <td>6</td>\n",
       "      <td>0.72</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>144</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>0.62</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>135</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>20</td>\n",
       "      <td>5</td>\n",
       "      <td>7</td>\n",
       "      <td>0.58</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>149</td>\n",
       "      <td>-1</td>\n",
       "      <td>8</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>22</td>\n",
       "      <td>2</td>\n",
       "      <td>8</td>\n",
       "      <td>0.86</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>152</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>0.48</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>399</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>153</td>\n",
       "      <td>-1</td>\n",
       "      <td>8</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>154</td>\n",
       "      <td>4</td>\n",
       "      <td>8</td>\n",
       "      <td>0.78</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>28</td>\n",
       "      <td>4</td>\n",
       "      <td>8</td>\n",
       "      <td>0.70</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>32</td>\n",
       "      <td>4</td>\n",
       "      <td>8</td>\n",
       "      <td>0.43</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>34</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>0.61</td>\n",
       "      <td>0</td>\n",
       "      <td>69</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>164</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0.76</td>\n",
       "      <td>2</td>\n",
       "      <td>268</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>37</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>0.92</td>\n",
       "      <td>382</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>39</td>\n",
       "      <td>-1</td>\n",
       "      <td>4</td>\n",
       "      <td>0.00</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>117</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>169</td>\n",
       "      <td>-1</td>\n",
       "      <td>5</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>112</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>170</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>0.66</td>\n",
       "      <td>6</td>\n",
       "      <td>601</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>171</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.46</td>\n",
       "      <td>120</td>\n",
       "      <td>12</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>44</td>\n",
       "      <td>4</td>\n",
       "      <td>8</td>\n",
       "      <td>0.74</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>172</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>0.96</td>\n",
       "      <td>0</td>\n",
       "      <td>44</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>46</td>\n",
       "      <td>-1</td>\n",
       "      <td>8</td>\n",
       "      <td>0.00</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>176</td>\n",
       "      <td>-1</td>\n",
       "      <td>4</td>\n",
       "      <td>0.00</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>96</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>53</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>0.88</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>476</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>182</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>0.72</td>\n",
       "      <td>1</td>\n",
       "      <td>233</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>183</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>0.47</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>202</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>184</td>\n",
       "      <td>-1</td>\n",
       "      <td>8</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>57</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0.59</td>\n",
       "      <td>0</td>\n",
       "      <td>128</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>186</td>\n",
       "      <td>2</td>\n",
       "      <td>8</td>\n",
       "      <td>0.98</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>187</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>0.59</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>223</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>188</td>\n",
       "      <td>-1</td>\n",
       "      <td>4</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>31</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>190</td>\n",
       "      <td>4</td>\n",
       "      <td>8</td>\n",
       "      <td>0.63</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35</th>\n",
       "      <td>191</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>0.36</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>227</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36</th>\n",
       "      <td>195</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>0.70</td>\n",
       "      <td>2</td>\n",
       "      <td>21</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>17</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37</th>\n",
       "      <td>196</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>0.66</td>\n",
       "      <td>372</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38</th>\n",
       "      <td>69</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>0.48</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>242</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39</th>\n",
       "      <td>70</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>0.50</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>183</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40</th>\n",
       "      <td>71</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>0.72</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>115</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41</th>\n",
       "      <td>72</td>\n",
       "      <td>4</td>\n",
       "      <td>5</td>\n",
       "      <td>0.60</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>238</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42</th>\n",
       "      <td>73</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>0.50</td>\n",
       "      <td>30</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>43</th>\n",
       "      <td>199</td>\n",
       "      <td>2</td>\n",
       "      <td>8</td>\n",
       "      <td>0.73</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>44</th>\n",
       "      <td>78</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>0.73</td>\n",
       "      <td>1</td>\n",
       "      <td>501</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>45</th>\n",
       "      <td>79</td>\n",
       "      <td>1</td>\n",
       "      <td>6</td>\n",
       "      <td>0.50</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>46</th>\n",
       "      <td>82</td>\n",
       "      <td>1</td>\n",
       "      <td>7</td>\n",
       "      <td>0.48</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>47</th>\n",
       "      <td>84</td>\n",
       "      <td>2</td>\n",
       "      <td>8</td>\n",
       "      <td>0.43</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>48</th>\n",
       "      <td>85</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>0.94</td>\n",
       "      <td>185</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49</th>\n",
       "      <td>94</td>\n",
       "      <td>4</td>\n",
       "      <td>5</td>\n",
       "      <td>0.89</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>169</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50</th>\n",
       "      <td>95</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>0.67</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>221</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>51</th>\n",
       "      <td>97</td>\n",
       "      <td>1</td>\n",
       "      <td>6</td>\n",
       "      <td>0.51</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>52</th>\n",
       "      <td>102</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>0.78</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>629</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>53</th>\n",
       "      <td>105</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>0.86</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>277</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>54</th>\n",
       "      <td>112</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0</td>\n",
       "      <td>22</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>55</th>\n",
       "      <td>113</td>\n",
       "      <td>2</td>\n",
       "      <td>7</td>\n",
       "      <td>0.50</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>56</th>\n",
       "      <td>118</td>\n",
       "      <td>4</td>\n",
       "      <td>8</td>\n",
       "      <td>0.85</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>57</th>\n",
       "      <td>123</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>0.23</td>\n",
       "      <td>54</td>\n",
       "      <td>244</td>\n",
       "      <td>98</td>\n",
       "      <td>62</td>\n",
       "      <td>18</td>\n",
       "      <td>457</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    other index  pred label  truth  rate    0    1    2    3    4    5\n",
       "0           128           3      4  0.92    5    0    0    0  213    0\n",
       "1           131           2      1  0.95    1  210    0    0    0    0\n",
       "2             8           5      5  0.58    0    3    0    0    0  361\n",
       "3             9           5      0  0.57  245    0    1    0    1    0\n",
       "4            13           0      1  0.62    0   26    0    0    0    0\n",
       "5           143           5      6  0.72    0    0    0    0    0    0\n",
       "6           144           4      3  0.62    0    0    0  135    0    0\n",
       "7            20           5      7  0.58    0    0    0    0    0    0\n",
       "8           149          -1      8  0.00    0    0    0    0    1    3\n",
       "9            22           2      8  0.86    0    0    0    0    0    0\n",
       "10          152           3      4  0.48    3    0    0    0  399    0\n",
       "11          153          -1      8  0.00    1    0    0    0    0    0\n",
       "12          154           4      8  0.78    0    0    0    0    0    1\n",
       "13           28           4      8  0.70    0    0    0    0    0    0\n",
       "14           32           4      8  0.43    2    0    0    0    0    1\n",
       "15           34           3      1  0.61    0   69    0    0    0    0\n",
       "16          164           2      1  0.76    2  268    0    0    1    1\n",
       "17           37           4      0  0.92  382    0    0    1    0    0\n",
       "18           39          -1      4  0.00    2    0    2    0  117    0\n",
       "19          169          -1      5  0.00    0    0    0    0    0  112\n",
       "20          170           4      1  0.66    6  601    0    0    0    2\n",
       "21          171           0      0  0.46  120   12    0    0    0    0\n",
       "22           44           4      8  0.74    1    0    0    0    1    0\n",
       "23          172           3      1  0.96    0   44    0    0    0    0\n",
       "24           46          -1      8  0.00    5    0    0    0    1    0\n",
       "25          176          -1      4  0.00    3    2    0    0   96    0\n",
       "26           53           4      3  0.88    0    0    0  476    0    0\n",
       "27          182           3      1  0.72    1  233    0    0    0    0\n",
       "28          183           0      3  0.47    0    0    0  202    0    0\n",
       "29          184          -1      8  0.00    0    0    0    0    0    0\n",
       "30           57           2      1  0.59    0  128    0    0    0    0\n",
       "31          186           2      8  0.98    0    0    0    0    0    0\n",
       "32          187           3      2  0.59    0    0  223    0    0    0\n",
       "33          188          -1      4  0.00    0    0    0    0   31    0\n",
       "34          190           4      8  0.63    1    0    0    0    0    4\n",
       "35          191           0      3  0.36    5    0    0  227    1    0\n",
       "36          195           4      1  0.70    2   21    0    0    0   17\n",
       "37          196           4      0  0.66  372    2    1    1    4    1\n",
       "38           69           0      3  0.48    0    0    0  242    0    0\n",
       "39           70           1      3  0.50    0    0    0  183    0    0\n",
       "40           71           0      3  0.72    0    0    0  115    0    0\n",
       "41           72           4      5  0.60    1    0    0    0    0  238\n",
       "42           73           4      0  0.50   30    0    0    0    0    0\n",
       "43          199           2      8  0.73    0    0    2    0    0    0\n",
       "44           78           5      1  0.73    1  501    0    0    0    0\n",
       "45           79           1      6  0.50    2    0    0    0    0    0\n",
       "46           82           1      7  0.48    0    0    0    0    0    0\n",
       "47           84           2      8  0.43    0    0    0    0    0    0\n",
       "48           85           4      0  0.94  185    0    0    0    0    3\n",
       "49           94           4      5  0.89    0    0    0    0    0  169\n",
       "50           95           0      3  0.67    0    0    0  221    0    0\n",
       "51           97           1      6  0.51    0    0    0    0    0    0\n",
       "52          102           3      2  0.78    0    1  629    0    1    0\n",
       "53          105           4      3  0.86    0    0    0  277    0    0\n",
       "54          112           2      1  1.00    0   22    0    0    0    0\n",
       "55          113           2      7  0.50    0    0    0    0    0    0\n",
       "56          118           4      8  0.85    3    4    0    1    1    3\n",
       "57          123           5      5  0.23   54  244   98   62   18  457"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "added label, regions, img amount: {0} [71] 83\n",
      "added label, regions, img amount: {2} [112, 186, 131, 22, 164] 706\n",
      "added label, regions, img amount: {3} [172, 128, 102, 182] 904\n",
      "added label, regions, img amount: {4} [85, 37, 94, 53, 105] 1342\n",
      "added label, regions, img amount: {5} [78, 143] 463\n",
      "Not getting into residuals\n",
      "NUM_region 6\n",
      "number of clean images 31501\n",
      "n, p1, p2 0 0 0\n",
      "NUM_CLASSES 6\n",
      "current_train_label:  [0, 1, 2, 3, 4, 5]\n",
      "Model: \"sequential_1\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv1d_1 (Conv1D)            (None, 3, 6)              12        \n",
      "_________________________________________________________________\n",
      "average_pooling1d_1 (Average (None, 1, 6)              0         \n",
      "_________________________________________________________________\n",
      "conv1d_2 (Conv1D)            (None, 1, 16)             112       \n",
      "_________________________________________________________________\n",
      "average_pooling1d_2 (Average (None, 1, 16)             0         \n",
      "_________________________________________________________________\n",
      "conv1d_3 (Conv1D)            (None, 1, 120)            2040      \n",
      "_________________________________________________________________\n",
      "flatten_1 (Flatten)          (None, 120)               0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 84)                10164     \n",
      "_________________________________________________________________\n",
      "preds (Dense)                (None, 6)                 510       \n",
      "=================================================================\n",
      "Total params: 12,838\n",
      "Trainable params: 12,838\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Train on 28350 samples, validate on 3151 samples\n",
      "Epoch 1/80\n",
      "28350/28350 [==============================] - 2s 53us/step - loss: 0.6383 - accuracy: 0.7505 - val_loss: 0.2984 - val_accuracy: 0.8953\n",
      "Epoch 2/80\n",
      "28350/28350 [==============================] - 1s 41us/step - loss: 0.2472 - accuracy: 0.9086 - val_loss: 0.1792 - val_accuracy: 0.9349\n",
      "Epoch 3/80\n",
      "28350/28350 [==============================] - 1s 37us/step - loss: 0.1574 - accuracy: 0.9422 - val_loss: 0.1166 - val_accuracy: 0.9635\n",
      "Epoch 4/80\n",
      "28350/28350 [==============================] - 1s 39us/step - loss: 0.1197 - accuracy: 0.9564 - val_loss: 0.0974 - val_accuracy: 0.9626\n",
      "Epoch 5/80\n",
      "28350/28350 [==============================] - 1s 40us/step - loss: 0.0987 - accuracy: 0.9639 - val_loss: 0.0890 - val_accuracy: 0.9648\n",
      "Epoch 6/80\n",
      "28350/28350 [==============================] - 1s 39us/step - loss: 0.0939 - accuracy: 0.9646 - val_loss: 0.0849 - val_accuracy: 0.9692\n",
      "Epoch 7/80\n",
      "28350/28350 [==============================] - 1s 38us/step - loss: 0.0900 - accuracy: 0.9656 - val_loss: 0.0915 - val_accuracy: 0.9641\n",
      "Epoch 8/80\n",
      "28350/28350 [==============================] - 1s 40us/step - loss: 0.0894 - accuracy: 0.9652 - val_loss: 0.0884 - val_accuracy: 0.9648\n",
      "Epoch 9/80\n",
      "28350/28350 [==============================] - 1s 37us/step - loss: 0.0873 - accuracy: 0.9661 - val_loss: 0.0923 - val_accuracy: 0.9635\n",
      "Epoch 10/80\n",
      "28350/28350 [==============================] - 1s 38us/step - loss: 0.0861 - accuracy: 0.9661 - val_loss: 0.0793 - val_accuracy: 0.9676\n",
      "Epoch 11/80\n",
      "28350/28350 [==============================] - 1s 39us/step - loss: 0.0830 - accuracy: 0.9669 - val_loss: 0.0972 - val_accuracy: 0.9600\n",
      "Epoch 12/80\n",
      "28350/28350 [==============================] - 1s 40us/step - loss: 0.0834 - accuracy: 0.9665 - val_loss: 0.0912 - val_accuracy: 0.9591\n",
      "Epoch 13/80\n",
      "28350/28350 [==============================] - 1s 40us/step - loss: 0.0829 - accuracy: 0.9663 - val_loss: 0.0764 - val_accuracy: 0.9699\n",
      "Epoch 14/80\n",
      "28350/28350 [==============================] - 1s 39us/step - loss: 0.0806 - accuracy: 0.9667 - val_loss: 0.0744 - val_accuracy: 0.9686\n",
      "Epoch 15/80\n",
      "28350/28350 [==============================] - 1s 39us/step - loss: 0.0794 - accuracy: 0.9673 - val_loss: 0.0897 - val_accuracy: 0.9616\n",
      "Epoch 16/80\n",
      "28350/28350 [==============================] - 1s 40us/step - loss: 0.0792 - accuracy: 0.9674 - val_loss: 0.0753 - val_accuracy: 0.9686\n",
      "Epoch 17/80\n",
      "28350/28350 [==============================] - 1s 38us/step - loss: 0.0807 - accuracy: 0.9670 - val_loss: 0.0760 - val_accuracy: 0.9676\n",
      "Epoch 18/80\n",
      "28350/28350 [==============================] - 1s 39us/step - loss: 0.0799 - accuracy: 0.9668 - val_loss: 0.0835 - val_accuracy: 0.9664\n",
      "Epoch 19/80\n",
      "28350/28350 [==============================] - 1s 37us/step - loss: 0.0778 - accuracy: 0.9680 - val_loss: 0.0739 - val_accuracy: 0.9670\n",
      "Epoch 20/80\n",
      "28350/28350 [==============================] - 1s 41us/step - loss: 0.0775 - accuracy: 0.9678 - val_loss: 0.0815 - val_accuracy: 0.9648\n",
      "Epoch 21/80\n",
      "28350/28350 [==============================] - 1s 40us/step - loss: 0.0793 - accuracy: 0.9669 - val_loss: 0.0935 - val_accuracy: 0.9597\n",
      "Epoch 22/80\n",
      "28350/28350 [==============================] - 1s 39us/step - loss: 0.0767 - accuracy: 0.9677 - val_loss: 0.0783 - val_accuracy: 0.9651\n",
      "Epoch 23/80\n",
      "28350/28350 [==============================] - 1s 40us/step - loss: 0.0756 - accuracy: 0.9681 - val_loss: 0.0729 - val_accuracy: 0.9654\n",
      "Epoch 24/80\n",
      "28350/28350 [==============================] - 1s 39us/step - loss: 0.0757 - accuracy: 0.9681 - val_loss: 0.0702 - val_accuracy: 0.9679\n",
      "Epoch 25/80\n",
      "28350/28350 [==============================] - 1s 41us/step - loss: 0.0756 - accuracy: 0.9675 - val_loss: 0.0749 - val_accuracy: 0.9689\n",
      "Epoch 26/80\n",
      "28350/28350 [==============================] - 1s 39us/step - loss: 0.0743 - accuracy: 0.9687 - val_loss: 0.1104 - val_accuracy: 0.9597\n",
      "Epoch 27/80\n",
      "28350/28350 [==============================] - 1s 39us/step - loss: 0.0748 - accuracy: 0.9680 - val_loss: 0.0802 - val_accuracy: 0.9660\n",
      "Epoch 28/80\n",
      "28350/28350 [==============================] - 1s 38us/step - loss: 0.0742 - accuracy: 0.9680 - val_loss: 0.0728 - val_accuracy: 0.9660\n",
      "Epoch 29/80\n",
      "28350/28350 [==============================] - 1s 37us/step - loss: 0.0724 - accuracy: 0.9684 - val_loss: 0.0701 - val_accuracy: 0.9683\n",
      "Epoch 30/80\n",
      "28350/28350 [==============================] - 1s 39us/step - loss: 0.0730 - accuracy: 0.9677 - val_loss: 0.0718 - val_accuracy: 0.9673\n",
      "Epoch 31/80\n",
      "28350/28350 [==============================] - 1s 39us/step - loss: 0.0734 - accuracy: 0.9675 - val_loss: 0.0666 - val_accuracy: 0.9721\n",
      "Epoch 32/80\n",
      "28350/28350 [==============================] - 1s 39us/step - loss: 0.0756 - accuracy: 0.9671 - val_loss: 0.0689 - val_accuracy: 0.9708\n",
      "Epoch 33/80\n",
      "28350/28350 [==============================] - 1s 41us/step - loss: 0.0721 - accuracy: 0.9681 - val_loss: 0.0693 - val_accuracy: 0.9702\n",
      "Epoch 34/80\n",
      "28350/28350 [==============================] - 1s 40us/step - loss: 0.0717 - accuracy: 0.9686 - val_loss: 0.0761 - val_accuracy: 0.9667\n",
      "Epoch 35/80\n",
      "28350/28350 [==============================] - 1s 40us/step - loss: 0.0727 - accuracy: 0.9675 - val_loss: 0.0711 - val_accuracy: 0.9638\n",
      "Epoch 36/80\n",
      "28350/28350 [==============================] - 1s 38us/step - loss: 0.0737 - accuracy: 0.9676 - val_loss: 0.0746 - val_accuracy: 0.9702\n",
      "Epoch 37/80\n",
      "28350/28350 [==============================] - 1s 39us/step - loss: 0.0708 - accuracy: 0.9696 - val_loss: 0.0754 - val_accuracy: 0.9673\n",
      "Epoch 38/80\n",
      "28350/28350 [==============================] - 1s 39us/step - loss: 0.0722 - accuracy: 0.9684 - val_loss: 0.0658 - val_accuracy: 0.9702\n",
      "Epoch 39/80\n",
      "28350/28350 [==============================] - 1s 39us/step - loss: 0.0709 - accuracy: 0.9689 - val_loss: 0.0765 - val_accuracy: 0.9705\n",
      "Epoch 40/80\n",
      "28350/28350 [==============================] - 1s 37us/step - loss: 0.0741 - accuracy: 0.9672 - val_loss: 0.0736 - val_accuracy: 0.9686\n",
      "Epoch 41/80\n",
      "28350/28350 [==============================] - 1s 39us/step - loss: 0.0725 - accuracy: 0.9674 - val_loss: 0.0688 - val_accuracy: 0.9724\n",
      "Epoch 42/80\n",
      "28350/28350 [==============================] - 1s 39us/step - loss: 0.0694 - accuracy: 0.9688 - val_loss: 0.0659 - val_accuracy: 0.9730\n",
      "Epoch 43/80\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "28350/28350 [==============================] - 1s 38us/step - loss: 0.0706 - accuracy: 0.9691 - val_loss: 0.0851 - val_accuracy: 0.9616\n",
      "Epoch 44/80\n",
      "28350/28350 [==============================] - 1s 38us/step - loss: 0.0695 - accuracy: 0.9685 - val_loss: 0.0666 - val_accuracy: 0.9721\n",
      "Epoch 45/80\n",
      "28350/28350 [==============================] - 1s 39us/step - loss: 0.0700 - accuracy: 0.9683 - val_loss: 0.0665 - val_accuracy: 0.9679\n",
      "Epoch 46/80\n",
      "28350/28350 [==============================] - 1s 38us/step - loss: 0.0719 - accuracy: 0.9678 - val_loss: 0.0703 - val_accuracy: 0.9695\n",
      "Epoch 47/80\n",
      "28350/28350 [==============================] - 1s 39us/step - loss: 0.0713 - accuracy: 0.9684 - val_loss: 0.0678 - val_accuracy: 0.9705\n",
      "Epoch 48/80\n",
      "28350/28350 [==============================] - 1s 40us/step - loss: 0.0683 - accuracy: 0.9688 - val_loss: 0.0703 - val_accuracy: 0.9673\n",
      "Epoch 00048: early stopping\n",
      "[[1.0000000e+00 8.0611643e-17 1.1961352e-16 1.2893496e-17 1.5949950e-20\n",
      "  3.8844807e-18]\n",
      " [1.8104506e-06 1.3259795e-06 7.6017832e-09 1.9099778e-07 3.6272012e-09\n",
      "  9.9999666e-01]\n",
      " [1.7608359e-06 1.3051086e-06 7.5937709e-09 1.8759711e-07 3.6608974e-09\n",
      "  9.9999678e-01]\n",
      " ...\n",
      " [3.7422038e-14 2.7050085e-14 9.9998736e-01 7.2342114e-06 9.6806125e-15\n",
      "  5.3998201e-06]\n",
      " [6.2120814e-10 3.1426816e-14 9.9936813e-01 3.2154148e-04 1.1497927e-04\n",
      "  1.9532371e-04]\n",
      " [2.6505202e-08 4.3421897e-21 5.8557870e-09 1.6072208e-07 9.9997890e-01\n",
      "  2.0822998e-05]]\n",
      "[0 5 5 ... 2 2 4]\n",
      "<class 'numpy.ndarray'>\n",
      "One CNN, r:  0\n",
      "Computing Time:  0:00:57.677255\n",
      "Model: \"sequential_1\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv1d_1 (Conv1D)            (None, 3, 6)              12        \n",
      "_________________________________________________________________\n",
      "average_pooling1d_1 (Average (None, 1, 6)              0         \n",
      "_________________________________________________________________\n",
      "conv1d_2 (Conv1D)            (None, 1, 16)             112       \n",
      "_________________________________________________________________\n",
      "average_pooling1d_2 (Average (None, 1, 16)             0         \n",
      "_________________________________________________________________\n",
      "conv1d_3 (Conv1D)            (None, 1, 120)            2040      \n",
      "_________________________________________________________________\n",
      "flatten_1 (Flatten)          (None, 120)               0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 84)                10164     \n",
      "_________________________________________________________________\n",
      "preds (Dense)                (None, 6)                 510       \n",
      "=================================================================\n",
      "Total params: 12,838\n",
      "Trainable params: 12,838\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Train on 28350 samples, validate on 3151 samples\n",
      "Epoch 1/80\n",
      "28350/28350 [==============================] - 1s 49us/step - loss: 0.6051 - accuracy: 0.7705 - val_loss: 0.3197 - val_accuracy: 0.8813\n",
      "Epoch 2/80\n",
      "28350/28350 [==============================] - 1s 43us/step - loss: 0.2548 - accuracy: 0.9075 - val_loss: 0.2129 - val_accuracy: 0.9229\n",
      "Epoch 3/80\n",
      "28350/28350 [==============================] - 1s 39us/step - loss: 0.1973 - accuracy: 0.9280 - val_loss: 0.1822 - val_accuracy: 0.9219\n",
      "Epoch 4/80\n",
      "28350/28350 [==============================] - 1s 40us/step - loss: 0.1603 - accuracy: 0.9431 - val_loss: 0.1431 - val_accuracy: 0.9483\n",
      "Epoch 5/80\n",
      "28350/28350 [==============================] - 1s 39us/step - loss: 0.1356 - accuracy: 0.9504 - val_loss: 0.1188 - val_accuracy: 0.9549\n",
      "Epoch 6/80\n",
      "28350/28350 [==============================] - 1s 38us/step - loss: 0.1085 - accuracy: 0.9580 - val_loss: 0.0946 - val_accuracy: 0.9648\n",
      "Epoch 7/80\n",
      "28350/28350 [==============================] - 1s 40us/step - loss: 0.0939 - accuracy: 0.9636 - val_loss: 0.0909 - val_accuracy: 0.9657\n",
      "Epoch 8/80\n",
      "28350/28350 [==============================] - 1s 39us/step - loss: 0.0879 - accuracy: 0.9654 - val_loss: 0.0914 - val_accuracy: 0.9638\n",
      "Epoch 9/80\n",
      "28350/28350 [==============================] - 1s 39us/step - loss: 0.0904 - accuracy: 0.9643 - val_loss: 0.0854 - val_accuracy: 0.9692\n",
      "Epoch 10/80\n",
      "28350/28350 [==============================] - 1s 39us/step - loss: 0.0844 - accuracy: 0.9662 - val_loss: 0.0807 - val_accuracy: 0.9667\n",
      "Epoch 11/80\n",
      "28350/28350 [==============================] - 1s 40us/step - loss: 0.0839 - accuracy: 0.9666 - val_loss: 0.0807 - val_accuracy: 0.9651\n",
      "Epoch 12/80\n",
      "28350/28350 [==============================] - 1s 40us/step - loss: 0.0839 - accuracy: 0.9662 - val_loss: 0.0849 - val_accuracy: 0.9667\n",
      "Epoch 13/80\n",
      "28350/28350 [==============================] - 1s 39us/step - loss: 0.0916 - accuracy: 0.9632 - val_loss: 0.0815 - val_accuracy: 0.9683\n",
      "Epoch 14/80\n",
      "28350/28350 [==============================] - 1s 39us/step - loss: 0.0803 - accuracy: 0.9672 - val_loss: 0.0867 - val_accuracy: 0.9648\n",
      "Epoch 15/80\n",
      "28350/28350 [==============================] - 1s 39us/step - loss: 0.0790 - accuracy: 0.9672 - val_loss: 0.0743 - val_accuracy: 0.9692\n",
      "Epoch 16/80\n",
      "28350/28350 [==============================] - 1s 40us/step - loss: 0.0803 - accuracy: 0.9671 - val_loss: 0.0745 - val_accuracy: 0.9692\n",
      "Epoch 17/80\n",
      "28350/28350 [==============================] - 1s 39us/step - loss: 0.0800 - accuracy: 0.9672 - val_loss: 0.0801 - val_accuracy: 0.9689\n",
      "Epoch 18/80\n",
      "28350/28350 [==============================] - 1s 40us/step - loss: 0.0778 - accuracy: 0.9658 - val_loss: 0.0729 - val_accuracy: 0.9705\n",
      "Epoch 19/80\n",
      "28350/28350 [==============================] - 1s 39us/step - loss: 0.0791 - accuracy: 0.9669 - val_loss: 0.0896 - val_accuracy: 0.9648\n",
      "Epoch 20/80\n",
      "28350/28350 [==============================] - 1s 38us/step - loss: 0.0808 - accuracy: 0.9657 - val_loss: 0.0814 - val_accuracy: 0.9660\n",
      "Epoch 21/80\n",
      "28350/28350 [==============================] - 1s 41us/step - loss: 0.0768 - accuracy: 0.9675 - val_loss: 0.0870 - val_accuracy: 0.9616\n",
      "Epoch 22/80\n",
      "28350/28350 [==============================] - 1s 40us/step - loss: 0.0856 - accuracy: 0.9653 - val_loss: 0.0742 - val_accuracy: 0.9708\n",
      "Epoch 23/80\n",
      "28350/28350 [==============================] - 1s 39us/step - loss: 0.0776 - accuracy: 0.9675 - val_loss: 0.0699 - val_accuracy: 0.9689\n",
      "Epoch 24/80\n",
      "28350/28350 [==============================] - 1s 39us/step - loss: 0.0734 - accuracy: 0.9686 - val_loss: 0.0762 - val_accuracy: 0.9670\n",
      "Epoch 25/80\n",
      "28350/28350 [==============================] - 1s 40us/step - loss: 0.0742 - accuracy: 0.9678 - val_loss: 0.0688 - val_accuracy: 0.9702\n",
      "Epoch 26/80\n",
      "28350/28350 [==============================] - 1s 40us/step - loss: 0.0780 - accuracy: 0.9662 - val_loss: 0.0679 - val_accuracy: 0.9683\n",
      "Epoch 27/80\n",
      "28350/28350 [==============================] - 1s 40us/step - loss: 0.0741 - accuracy: 0.9672 - val_loss: 0.0691 - val_accuracy: 0.9711\n",
      "Epoch 28/80\n",
      "28350/28350 [==============================] - 1s 41us/step - loss: 0.0732 - accuracy: 0.9678 - val_loss: 0.0758 - val_accuracy: 0.9648\n",
      "Epoch 29/80\n",
      "28350/28350 [==============================] - 1s 38us/step - loss: 0.0745 - accuracy: 0.9673 - val_loss: 0.0697 - val_accuracy: 0.9692\n",
      "Epoch 30/80\n",
      "28350/28350 [==============================] - 1s 41us/step - loss: 0.0724 - accuracy: 0.9682 - val_loss: 0.0775 - val_accuracy: 0.9657\n",
      "Epoch 31/80\n",
      "28350/28350 [==============================] - 1s 41us/step - loss: 0.0725 - accuracy: 0.9683 - val_loss: 0.0678 - val_accuracy: 0.9708\n",
      "Epoch 32/80\n",
      "28350/28350 [==============================] - 1s 39us/step - loss: 0.0713 - accuracy: 0.9687 - val_loss: 0.0730 - val_accuracy: 0.9699\n",
      "Epoch 33/80\n",
      "28350/28350 [==============================] - 1s 37us/step - loss: 0.0750 - accuracy: 0.9665 - val_loss: 0.0654 - val_accuracy: 0.9699\n",
      "Epoch 34/80\n",
      "28350/28350 [==============================] - 1s 38us/step - loss: 0.0761 - accuracy: 0.9668 - val_loss: 0.0652 - val_accuracy: 0.9727\n",
      "Epoch 35/80\n",
      "28350/28350 [==============================] - 1s 37us/step - loss: 0.0721 - accuracy: 0.9687 - val_loss: 0.0672 - val_accuracy: 0.9676\n",
      "Epoch 36/80\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "28350/28350 [==============================] - 1s 40us/step - loss: 0.0717 - accuracy: 0.9683 - val_loss: 0.0710 - val_accuracy: 0.9724\n",
      "Epoch 37/80\n",
      "28350/28350 [==============================] - 1s 39us/step - loss: 0.0720 - accuracy: 0.9682 - val_loss: 0.0693 - val_accuracy: 0.9705\n",
      "Epoch 38/80\n",
      "28350/28350 [==============================] - 1s 39us/step - loss: 0.0741 - accuracy: 0.9681 - val_loss: 0.0647 - val_accuracy: 0.9721\n",
      "Epoch 39/80\n",
      "28350/28350 [==============================] - 1s 39us/step - loss: 0.0706 - accuracy: 0.9685 - val_loss: 0.0653 - val_accuracy: 0.9718\n",
      "Epoch 40/80\n",
      "28350/28350 [==============================] - 1s 41us/step - loss: 0.0695 - accuracy: 0.9693 - val_loss: 0.0655 - val_accuracy: 0.9695\n",
      "Epoch 41/80\n",
      "28350/28350 [==============================] - 1s 40us/step - loss: 0.0734 - accuracy: 0.9672 - val_loss: 0.0672 - val_accuracy: 0.9721\n",
      "Epoch 42/80\n",
      "28350/28350 [==============================] - 1s 40us/step - loss: 0.0745 - accuracy: 0.9672 - val_loss: 0.0661 - val_accuracy: 0.9708\n",
      "Epoch 43/80\n",
      "28350/28350 [==============================] - 1s 39us/step - loss: 0.0726 - accuracy: 0.9684 - val_loss: 0.0638 - val_accuracy: 0.9730\n",
      "Epoch 44/80\n",
      "28350/28350 [==============================] - 1s 40us/step - loss: 0.0699 - accuracy: 0.9691 - val_loss: 0.0643 - val_accuracy: 0.9718\n",
      "Epoch 45/80\n",
      "28350/28350 [==============================] - 1s 39us/step - loss: 0.0699 - accuracy: 0.9683 - val_loss: 0.0763 - val_accuracy: 0.9667\n",
      "Epoch 46/80\n",
      "28350/28350 [==============================] - 1s 38us/step - loss: 0.0698 - accuracy: 0.9692 - val_loss: 0.0701 - val_accuracy: 0.9714\n",
      "Epoch 47/80\n",
      "28350/28350 [==============================] - 1s 40us/step - loss: 0.0708 - accuracy: 0.9682 - val_loss: 0.0686 - val_accuracy: 0.9714\n",
      "Epoch 48/80\n",
      "28350/28350 [==============================] - 1s 40us/step - loss: 0.0713 - accuracy: 0.9677 - val_loss: 0.0642 - val_accuracy: 0.9689\n",
      "Epoch 49/80\n",
      "28350/28350 [==============================] - 1s 38us/step - loss: 0.0718 - accuracy: 0.9675 - val_loss: 0.0682 - val_accuracy: 0.9676\n",
      "Epoch 50/80\n",
      "28350/28350 [==============================] - 1s 39us/step - loss: 0.0706 - accuracy: 0.9679 - val_loss: 0.0630 - val_accuracy: 0.9711\n",
      "Epoch 51/80\n",
      "28350/28350 [==============================] - 1s 37us/step - loss: 0.0697 - accuracy: 0.9687 - val_loss: 0.0686 - val_accuracy: 0.9695\n",
      "Epoch 52/80\n",
      "28350/28350 [==============================] - 1s 37us/step - loss: 0.0695 - accuracy: 0.9683 - val_loss: 0.0672 - val_accuracy: 0.9686\n",
      "Epoch 53/80\n",
      "28350/28350 [==============================] - 1s 39us/step - loss: 0.0679 - accuracy: 0.9688 - val_loss: 0.0634 - val_accuracy: 0.9711\n",
      "Epoch 54/80\n",
      "28350/28350 [==============================] - 1s 37us/step - loss: 0.0693 - accuracy: 0.9691 - val_loss: 0.0720 - val_accuracy: 0.9692\n",
      "Epoch 55/80\n",
      "28350/28350 [==============================] - 1s 41us/step - loss: 0.0680 - accuracy: 0.9691 - val_loss: 0.0648 - val_accuracy: 0.9708\n",
      "Epoch 56/80\n",
      "28350/28350 [==============================] - 1s 39us/step - loss: 0.0693 - accuracy: 0.9684 - val_loss: 0.0631 - val_accuracy: 0.9702\n",
      "Epoch 57/80\n",
      "28350/28350 [==============================] - 1s 42us/step - loss: 0.0690 - accuracy: 0.9689 - val_loss: 0.0637 - val_accuracy: 0.9714\n",
      "Epoch 58/80\n",
      "28350/28350 [==============================] - 1s 39us/step - loss: 0.0689 - accuracy: 0.9687 - val_loss: 0.0636 - val_accuracy: 0.9699\n",
      "Epoch 59/80\n",
      "28350/28350 [==============================] - 1s 39us/step - loss: 0.0700 - accuracy: 0.9690 - val_loss: 0.0658 - val_accuracy: 0.9705\n",
      "Epoch 60/80\n",
      "28350/28350 [==============================] - 1s 39us/step - loss: 0.0685 - accuracy: 0.9698 - val_loss: 0.0670 - val_accuracy: 0.9714\n",
      "Epoch 00060: early stopping\n",
      "[[1.0000000e+00 1.7084609e-19 8.6521082e-14 8.1718786e-18 2.1748928e-19\n",
      "  6.9598117e-20]\n",
      " [1.8833958e-05 7.1493105e-07 4.6810349e-08 9.0247330e-09 4.3927622e-09\n",
      "  9.9998045e-01]\n",
      " [1.8519560e-05 7.0661150e-07 4.6529692e-08 9.0191596e-09 4.4329704e-09\n",
      "  9.9998069e-01]\n",
      " ...\n",
      " [2.1933466e-12 4.7910363e-13 9.9999988e-01 1.4590093e-08 1.1190274e-17\n",
      "  1.0572829e-07]\n",
      " [1.3586294e-06 3.8055373e-15 9.9969590e-01 8.6577074e-06 2.7899636e-04\n",
      "  1.5130012e-05]\n",
      " [4.5793686e-07 2.6971988e-20 6.9982597e-08 1.0180063e-06 9.9999833e-01\n",
      "  9.3736951e-08]]\n",
      "[0 5 5 ... 2 2 4]\n",
      "<class 'numpy.ndarray'>\n",
      "One CNN, r:  1\n",
      "Computing Time:  0:02:09.433330\n",
      "Model: \"sequential_1\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv1d_1 (Conv1D)            (None, 3, 6)              12        \n",
      "_________________________________________________________________\n",
      "average_pooling1d_1 (Average (None, 1, 6)              0         \n",
      "_________________________________________________________________\n",
      "conv1d_2 (Conv1D)            (None, 1, 16)             112       \n",
      "_________________________________________________________________\n",
      "average_pooling1d_2 (Average (None, 1, 16)             0         \n",
      "_________________________________________________________________\n",
      "conv1d_3 (Conv1D)            (None, 1, 120)            2040      \n",
      "_________________________________________________________________\n",
      "flatten_1 (Flatten)          (None, 120)               0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 84)                10164     \n",
      "_________________________________________________________________\n",
      "preds (Dense)                (None, 6)                 510       \n",
      "=================================================================\n",
      "Total params: 12,838\n",
      "Trainable params: 12,838\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Train on 28350 samples, validate on 3151 samples\n",
      "Epoch 1/80\n",
      "28350/28350 [==============================] - 1s 47us/step - loss: 0.7012 - accuracy: 0.7221 - val_loss: 0.3349 - val_accuracy: 0.8788\n",
      "Epoch 2/80\n",
      "28350/28350 [==============================] - 1s 39us/step - loss: 0.2462 - accuracy: 0.9140 - val_loss: 0.2025 - val_accuracy: 0.9270\n",
      "Epoch 3/80\n",
      "28350/28350 [==============================] - 1s 40us/step - loss: 0.1787 - accuracy: 0.9366 - val_loss: 0.1685 - val_accuracy: 0.9397\n",
      "Epoch 4/80\n",
      "28350/28350 [==============================] - 1s 39us/step - loss: 0.1548 - accuracy: 0.9447 - val_loss: 0.1499 - val_accuracy: 0.9492\n",
      "Epoch 5/80\n",
      "28350/28350 [==============================] - 1s 39us/step - loss: 0.1357 - accuracy: 0.9501 - val_loss: 0.1340 - val_accuracy: 0.9502\n",
      "Epoch 6/80\n",
      "28350/28350 [==============================] - 1s 39us/step - loss: 0.1269 - accuracy: 0.9528 - val_loss: 0.1252 - val_accuracy: 0.9553\n",
      "Epoch 7/80\n",
      "28350/28350 [==============================] - 1s 40us/step - loss: 0.1171 - accuracy: 0.9560 - val_loss: 0.1171 - val_accuracy: 0.9591\n",
      "Epoch 8/80\n",
      "28350/28350 [==============================] - 1s 40us/step - loss: 0.1117 - accuracy: 0.9587 - val_loss: 0.1100 - val_accuracy: 0.9584\n",
      "Epoch 9/80\n",
      "28350/28350 [==============================] - 1s 39us/step - loss: 0.1056 - accuracy: 0.9611 - val_loss: 0.1003 - val_accuracy: 0.9619\n",
      "Epoch 10/80\n",
      "28350/28350 [==============================] - 1s 38us/step - loss: 0.1007 - accuracy: 0.9623 - val_loss: 0.1019 - val_accuracy: 0.9610\n",
      "Epoch 11/80\n",
      "28350/28350 [==============================] - 1s 39us/step - loss: 0.0984 - accuracy: 0.9642 - val_loss: 0.0988 - val_accuracy: 0.9603\n",
      "Epoch 12/80\n",
      "28350/28350 [==============================] - 1s 36us/step - loss: 0.0948 - accuracy: 0.9643 - val_loss: 0.0971 - val_accuracy: 0.9635\n",
      "Epoch 13/80\n",
      "28350/28350 [==============================] - 1s 39us/step - loss: 0.0981 - accuracy: 0.9641 - val_loss: 0.1097 - val_accuracy: 0.9597\n",
      "Epoch 14/80\n",
      "28350/28350 [==============================] - 1s 38us/step - loss: 0.0902 - accuracy: 0.9662 - val_loss: 0.0892 - val_accuracy: 0.9673\n",
      "Epoch 15/80\n",
      "28350/28350 [==============================] - 1s 40us/step - loss: 0.0872 - accuracy: 0.9671 - val_loss: 0.0895 - val_accuracy: 0.9657\n",
      "Epoch 16/80\n",
      "28350/28350 [==============================] - 1s 38us/step - loss: 0.0880 - accuracy: 0.9660 - val_loss: 0.0892 - val_accuracy: 0.9629\n",
      "Epoch 17/80\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "28350/28350 [==============================] - 1s 37us/step - loss: 0.0881 - accuracy: 0.9655 - val_loss: 0.0889 - val_accuracy: 0.9622\n",
      "Epoch 18/80\n",
      "28350/28350 [==============================] - 1s 39us/step - loss: 0.0820 - accuracy: 0.9671 - val_loss: 0.0879 - val_accuracy: 0.9670\n",
      "Epoch 19/80\n",
      "28350/28350 [==============================] - 1s 37us/step - loss: 0.0806 - accuracy: 0.9684 - val_loss: 0.0913 - val_accuracy: 0.9660\n",
      "Epoch 20/80\n",
      "28350/28350 [==============================] - 1s 39us/step - loss: 0.0811 - accuracy: 0.9678 - val_loss: 0.0792 - val_accuracy: 0.9673\n",
      "Epoch 21/80\n",
      "28350/28350 [==============================] - 1s 39us/step - loss: 0.0787 - accuracy: 0.9685 - val_loss: 0.0811 - val_accuracy: 0.9670\n",
      "Epoch 22/80\n",
      "28350/28350 [==============================] - 1s 37us/step - loss: 0.0805 - accuracy: 0.9678 - val_loss: 0.0809 - val_accuracy: 0.9660\n",
      "Epoch 23/80\n",
      "28350/28350 [==============================] - 1s 38us/step - loss: 0.0789 - accuracy: 0.9683 - val_loss: 0.0802 - val_accuracy: 0.9657\n",
      "Epoch 24/80\n",
      "28350/28350 [==============================] - 1s 40us/step - loss: 0.0877 - accuracy: 0.9647 - val_loss: 0.0793 - val_accuracy: 0.9683\n",
      "Epoch 25/80\n",
      "28350/28350 [==============================] - 1s 41us/step - loss: 0.0758 - accuracy: 0.9690 - val_loss: 0.0796 - val_accuracy: 0.9664\n",
      "Epoch 26/80\n",
      "28350/28350 [==============================] - 1s 39us/step - loss: 0.0757 - accuracy: 0.9685 - val_loss: 0.0768 - val_accuracy: 0.9689\n",
      "Epoch 27/80\n",
      "28350/28350 [==============================] - 1s 38us/step - loss: 0.0756 - accuracy: 0.9696 - val_loss: 0.0847 - val_accuracy: 0.9667\n",
      "Epoch 28/80\n",
      "28350/28350 [==============================] - 1s 40us/step - loss: 0.0734 - accuracy: 0.9698 - val_loss: 0.0775 - val_accuracy: 0.9683\n",
      "Epoch 29/80\n",
      "28350/28350 [==============================] - 1s 39us/step - loss: 0.0748 - accuracy: 0.9689 - val_loss: 0.0798 - val_accuracy: 0.9664\n",
      "Epoch 30/80\n",
      "28350/28350 [==============================] - 1s 37us/step - loss: 0.0735 - accuracy: 0.9694 - val_loss: 0.0763 - val_accuracy: 0.9645\n",
      "Epoch 31/80\n",
      "28350/28350 [==============================] - 1s 39us/step - loss: 0.0739 - accuracy: 0.9687 - val_loss: 0.0781 - val_accuracy: 0.9638\n",
      "Epoch 32/80\n",
      "28350/28350 [==============================] - 1s 40us/step - loss: 0.0728 - accuracy: 0.9693 - val_loss: 0.0866 - val_accuracy: 0.9622\n",
      "Epoch 33/80\n",
      "28350/28350 [==============================] - 1s 40us/step - loss: 0.0759 - accuracy: 0.9681 - val_loss: 0.0762 - val_accuracy: 0.9673\n",
      "Epoch 34/80\n",
      "28350/28350 [==============================] - 1s 37us/step - loss: 0.0753 - accuracy: 0.9678 - val_loss: 0.0766 - val_accuracy: 0.9686\n",
      "Epoch 35/80\n",
      "28350/28350 [==============================] - 1s 31us/step - loss: 0.0729 - accuracy: 0.9693 - val_loss: 0.0731 - val_accuracy: 0.9683\n",
      "Epoch 36/80\n",
      "28350/28350 [==============================] - 1s 39us/step - loss: 0.0727 - accuracy: 0.9687 - val_loss: 0.0745 - val_accuracy: 0.9648\n",
      "Epoch 37/80\n",
      "28350/28350 [==============================] - 1s 40us/step - loss: 0.0724 - accuracy: 0.9678 - val_loss: 0.0784 - val_accuracy: 0.9654\n",
      "Epoch 38/80\n",
      "28350/28350 [==============================] - 1s 40us/step - loss: 0.0711 - accuracy: 0.9690 - val_loss: 0.0755 - val_accuracy: 0.9651\n",
      "Epoch 39/80\n",
      "28350/28350 [==============================] - 1s 30us/step - loss: 0.0724 - accuracy: 0.9689 - val_loss: 0.0734 - val_accuracy: 0.9679\n",
      "Epoch 40/80\n",
      "28350/28350 [==============================] - 1s 31us/step - loss: 0.0705 - accuracy: 0.9696 - val_loss: 0.0799 - val_accuracy: 0.9645\n",
      "Epoch 41/80\n",
      "28350/28350 [==============================] - 1s 31us/step - loss: 0.0704 - accuracy: 0.9692 - val_loss: 0.0725 - val_accuracy: 0.9660\n",
      "Epoch 42/80\n",
      "28350/28350 [==============================] - 1s 32us/step - loss: 0.0737 - accuracy: 0.9676 - val_loss: 0.0741 - val_accuracy: 0.9721\n",
      "Epoch 43/80\n",
      "28350/28350 [==============================] - 1s 30us/step - loss: 0.0715 - accuracy: 0.9688 - val_loss: 0.0767 - val_accuracy: 0.9638\n",
      "Epoch 44/80\n",
      "28350/28350 [==============================] - 1s 33us/step - loss: 0.0701 - accuracy: 0.9685 - val_loss: 0.0796 - val_accuracy: 0.9660\n",
      "Epoch 45/80\n",
      "28350/28350 [==============================] - 1s 30us/step - loss: 0.0701 - accuracy: 0.9689 - val_loss: 0.0704 - val_accuracy: 0.9657\n",
      "Epoch 46/80\n",
      "28350/28350 [==============================] - 1s 36us/step - loss: 0.0695 - accuracy: 0.9699 - val_loss: 0.0742 - val_accuracy: 0.9641\n",
      "Epoch 47/80\n",
      "28350/28350 [==============================] - 1s 39us/step - loss: 0.0681 - accuracy: 0.9693 - val_loss: 0.0767 - val_accuracy: 0.9626\n",
      "Epoch 48/80\n",
      "28350/28350 [==============================] - 1s 38us/step - loss: 0.0698 - accuracy: 0.9696 - val_loss: 0.0760 - val_accuracy: 0.9645\n",
      "Epoch 49/80\n",
      "28350/28350 [==============================] - 1s 40us/step - loss: 0.0690 - accuracy: 0.9696 - val_loss: 0.0757 - val_accuracy: 0.9679\n",
      "Epoch 50/80\n",
      "28350/28350 [==============================] - 1s 39us/step - loss: 0.0679 - accuracy: 0.9690 - val_loss: 0.0688 - val_accuracy: 0.9676\n",
      "Epoch 51/80\n",
      "28350/28350 [==============================] - 1s 39us/step - loss: 0.0767 - accuracy: 0.9673 - val_loss: 0.0741 - val_accuracy: 0.9654\n",
      "Epoch 52/80\n",
      "28350/28350 [==============================] - 1s 38us/step - loss: 0.0687 - accuracy: 0.9687 - val_loss: 0.0698 - val_accuracy: 0.9660\n",
      "Epoch 53/80\n",
      "28350/28350 [==============================] - 1s 37us/step - loss: 0.0699 - accuracy: 0.9695 - val_loss: 0.0743 - val_accuracy: 0.9657\n",
      "Epoch 54/80\n",
      "28350/28350 [==============================] - 1s 39us/step - loss: 0.0699 - accuracy: 0.9689 - val_loss: 0.0785 - val_accuracy: 0.9660\n",
      "Epoch 55/80\n",
      "28350/28350 [==============================] - 1s 39us/step - loss: 0.0675 - accuracy: 0.9693 - val_loss: 0.0807 - val_accuracy: 0.9629\n",
      "Epoch 56/80\n",
      "28350/28350 [==============================] - 1s 40us/step - loss: 0.0673 - accuracy: 0.9692 - val_loss: 0.0732 - val_accuracy: 0.9648\n",
      "Epoch 57/80\n",
      "28350/28350 [==============================] - 1s 38us/step - loss: 0.0691 - accuracy: 0.9684 - val_loss: 0.0726 - val_accuracy: 0.9657\n",
      "Epoch 58/80\n",
      "28350/28350 [==============================] - 1s 39us/step - loss: 0.0697 - accuracy: 0.9684 - val_loss: 0.0724 - val_accuracy: 0.9676\n",
      "Epoch 59/80\n",
      "28350/28350 [==============================] - 1s 39us/step - loss: 0.0669 - accuracy: 0.9707 - val_loss: 0.0735 - val_accuracy: 0.9667\n",
      "Epoch 60/80\n",
      "28350/28350 [==============================] - 1s 39us/step - loss: 0.0681 - accuracy: 0.9689 - val_loss: 0.0822 - val_accuracy: 0.9626\n",
      "Epoch 00060: early stopping\n",
      "[[1.0000000e+00 2.3005453e-13 1.9614239e-17 2.3359386e-18 5.4383745e-25\n",
      "  1.0423875e-18]\n",
      " [1.9363148e-08 6.4338661e-07 2.3632487e-09 9.7845410e-10 6.8919204e-09\n",
      "  9.9999928e-01]\n",
      " [1.8749265e-08 6.3484936e-07 2.3656388e-09 9.7850072e-10 7.0097519e-09\n",
      "  9.9999928e-01]\n",
      " ...\n",
      " [4.9209853e-15 7.2036793e-10 9.9999917e-01 3.4160195e-07 6.1461180e-17\n",
      "  5.1597868e-07]\n",
      " [1.5144224e-07 3.9679338e-10 9.9880338e-01 1.5276276e-04 1.8358928e-04\n",
      "  8.6012564e-04]\n",
      " [1.6874759e-05 5.4829406e-18 3.0882918e-09 7.8835483e-10 9.9998295e-01\n",
      "  1.0188235e-07]]\n",
      "[0 5 5 ... 2 2 4]\n",
      "<class 'numpy.ndarray'>\n",
      "One CNN, r:  2\n",
      "Computing Time:  0:03:18.277088\n",
      "Model: \"sequential_1\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv1d_1 (Conv1D)            (None, 3, 6)              12        \n",
      "_________________________________________________________________\n",
      "average_pooling1d_1 (Average (None, 1, 6)              0         \n",
      "_________________________________________________________________\n",
      "conv1d_2 (Conv1D)            (None, 1, 16)             112       \n",
      "_________________________________________________________________\n",
      "average_pooling1d_2 (Average (None, 1, 16)             0         \n",
      "_________________________________________________________________\n",
      "conv1d_3 (Conv1D)            (None, 1, 120)            2040      \n",
      "_________________________________________________________________\n",
      "flatten_1 (Flatten)          (None, 120)               0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 84)                10164     \n",
      "_________________________________________________________________\n",
      "preds (Dense)                (None, 6)                 510       \n",
      "=================================================================\n",
      "Total params: 12,838\n",
      "Trainable params: 12,838\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 28350 samples, validate on 3151 samples\n",
      "Epoch 1/80\n",
      "28350/28350 [==============================] - 1s 49us/step - loss: 0.6287 - accuracy: 0.7519 - val_loss: 0.3254 - val_accuracy: 0.8705\n",
      "Epoch 2/80\n",
      "28350/28350 [==============================] - 1s 39us/step - loss: 0.2677 - accuracy: 0.8978 - val_loss: 0.2648 - val_accuracy: 0.9038\n",
      "Epoch 3/80\n",
      "28350/28350 [==============================] - 1s 38us/step - loss: 0.2099 - accuracy: 0.9248 - val_loss: 0.2254 - val_accuracy: 0.9188\n",
      "Epoch 4/80\n",
      "28350/28350 [==============================] - 1s 37us/step - loss: 0.1696 - accuracy: 0.9386 - val_loss: 0.1785 - val_accuracy: 0.9505\n",
      "Epoch 5/80\n",
      "28350/28350 [==============================] - 1s 39us/step - loss: 0.1411 - accuracy: 0.9503 - val_loss: 0.1632 - val_accuracy: 0.9359\n",
      "Epoch 6/80\n",
      "28350/28350 [==============================] - 1s 39us/step - loss: 0.1121 - accuracy: 0.9601 - val_loss: 0.1101 - val_accuracy: 0.9568\n",
      "Epoch 7/80\n",
      "28350/28350 [==============================] - 1s 37us/step - loss: 0.0981 - accuracy: 0.9646 - val_loss: 0.0937 - val_accuracy: 0.9638\n",
      "Epoch 8/80\n",
      "28350/28350 [==============================] - 1s 38us/step - loss: 0.0899 - accuracy: 0.9662 - val_loss: 0.1147 - val_accuracy: 0.9565\n",
      "Epoch 9/80\n",
      "28350/28350 [==============================] - 1s 38us/step - loss: 0.0862 - accuracy: 0.9671 - val_loss: 0.0880 - val_accuracy: 0.9660\n",
      "Epoch 10/80\n",
      "28350/28350 [==============================] - 1s 37us/step - loss: 0.0868 - accuracy: 0.9666 - val_loss: 0.0887 - val_accuracy: 0.9673\n",
      "Epoch 11/80\n",
      "28350/28350 [==============================] - 1s 40us/step - loss: 0.0878 - accuracy: 0.9654 - val_loss: 0.0883 - val_accuracy: 0.9657\n",
      "Epoch 12/80\n",
      "28350/28350 [==============================] - 1s 39us/step - loss: 0.0827 - accuracy: 0.9675 - val_loss: 0.0905 - val_accuracy: 0.9670\n",
      "Epoch 13/80\n",
      "28350/28350 [==============================] - 1s 39us/step - loss: 0.0812 - accuracy: 0.9681 - val_loss: 0.0833 - val_accuracy: 0.9651\n",
      "Epoch 14/80\n",
      "28350/28350 [==============================] - 1s 37us/step - loss: 0.0817 - accuracy: 0.9677 - val_loss: 0.0966 - val_accuracy: 0.9584\n",
      "Epoch 15/80\n",
      "28350/28350 [==============================] - 1s 37us/step - loss: 0.0817 - accuracy: 0.9671 - val_loss: 0.0812 - val_accuracy: 0.9667\n",
      "Epoch 16/80\n",
      "28350/28350 [==============================] - 1s 38us/step - loss: 0.0798 - accuracy: 0.9674 - val_loss: 0.0825 - val_accuracy: 0.9645\n",
      "Epoch 17/80\n",
      "28350/28350 [==============================] - 1s 36us/step - loss: 0.0822 - accuracy: 0.9667 - val_loss: 0.0840 - val_accuracy: 0.9654\n",
      "Epoch 18/80\n",
      "28350/28350 [==============================] - 1s 37us/step - loss: 0.0772 - accuracy: 0.9679 - val_loss: 0.1201 - val_accuracy: 0.9502\n",
      "Epoch 19/80\n",
      "28350/28350 [==============================] - 1s 38us/step - loss: 0.0798 - accuracy: 0.9676 - val_loss: 0.1034 - val_accuracy: 0.9578\n",
      "Epoch 20/80\n",
      "28350/28350 [==============================] - 1s 38us/step - loss: 0.0808 - accuracy: 0.9668 - val_loss: 0.0794 - val_accuracy: 0.9651\n",
      "Epoch 21/80\n",
      "28350/28350 [==============================] - 1s 38us/step - loss: 0.0759 - accuracy: 0.9693 - val_loss: 0.0795 - val_accuracy: 0.9657\n",
      "Epoch 22/80\n",
      "28350/28350 [==============================] - 1s 39us/step - loss: 0.0748 - accuracy: 0.9681 - val_loss: 0.0775 - val_accuracy: 0.9667\n",
      "Epoch 23/80\n",
      "28350/28350 [==============================] - 1s 38us/step - loss: 0.0742 - accuracy: 0.9691 - val_loss: 0.0871 - val_accuracy: 0.9629\n",
      "Epoch 24/80\n",
      "28350/28350 [==============================] - 1s 37us/step - loss: 0.0757 - accuracy: 0.9680 - val_loss: 0.0825 - val_accuracy: 0.9648\n",
      "Epoch 25/80\n",
      "28350/28350 [==============================] - 1s 37us/step - loss: 0.0754 - accuracy: 0.9680 - val_loss: 0.0964 - val_accuracy: 0.9622\n",
      "Epoch 26/80\n",
      "28350/28350 [==============================] - 1s 40us/step - loss: 0.0745 - accuracy: 0.9687 - val_loss: 0.0804 - val_accuracy: 0.9667\n",
      "Epoch 27/80\n",
      "28350/28350 [==============================] - 1s 39us/step - loss: 0.0748 - accuracy: 0.9690 - val_loss: 0.0814 - val_accuracy: 0.9632\n",
      "Epoch 28/80\n",
      "28350/28350 [==============================] - 1s 37us/step - loss: 0.0754 - accuracy: 0.9683 - val_loss: 0.0773 - val_accuracy: 0.9645\n",
      "Epoch 29/80\n",
      "28350/28350 [==============================] - 1s 37us/step - loss: 0.0747 - accuracy: 0.9685 - val_loss: 0.0812 - val_accuracy: 0.9679\n",
      "Epoch 30/80\n",
      "28350/28350 [==============================] - 1s 37us/step - loss: 0.0767 - accuracy: 0.9672 - val_loss: 0.0775 - val_accuracy: 0.9654\n",
      "Epoch 31/80\n",
      "28350/28350 [==============================] - 1s 38us/step - loss: 0.0748 - accuracy: 0.9679 - val_loss: 0.0795 - val_accuracy: 0.9664\n",
      "Epoch 32/80\n",
      "28350/28350 [==============================] - 1s 37us/step - loss: 0.0746 - accuracy: 0.9681 - val_loss: 0.0820 - val_accuracy: 0.9641\n",
      "Epoch 33/80\n",
      "28350/28350 [==============================] - 1s 38us/step - loss: 0.0758 - accuracy: 0.9677 - val_loss: 0.0758 - val_accuracy: 0.9657\n",
      "Epoch 34/80\n",
      "28350/28350 [==============================] - 1s 36us/step - loss: 0.0742 - accuracy: 0.9690 - val_loss: 0.0844 - val_accuracy: 0.9622\n",
      "Epoch 35/80\n",
      "28350/28350 [==============================] - 1s 37us/step - loss: 0.0739 - accuracy: 0.9687 - val_loss: 0.0779 - val_accuracy: 0.9679\n",
      "Epoch 36/80\n",
      "28350/28350 [==============================] - 1s 40us/step - loss: 0.0733 - accuracy: 0.9672 - val_loss: 0.0837 - val_accuracy: 0.9635\n",
      "Epoch 37/80\n",
      "28350/28350 [==============================] - 1s 40us/step - loss: 0.0729 - accuracy: 0.9690 - val_loss: 0.0819 - val_accuracy: 0.9632\n",
      "Epoch 38/80\n",
      "28350/28350 [==============================] - 1s 41us/step - loss: 0.0771 - accuracy: 0.9673 - val_loss: 0.0802 - val_accuracy: 0.9664\n",
      "Epoch 39/80\n",
      "28350/28350 [==============================] - 1s 39us/step - loss: 0.0714 - accuracy: 0.9695 - val_loss: 0.1083 - val_accuracy: 0.9543\n",
      "Epoch 40/80\n",
      "28350/28350 [==============================] - 1s 39us/step - loss: 0.0721 - accuracy: 0.9684 - val_loss: 0.0751 - val_accuracy: 0.9667\n",
      "Epoch 41/80\n",
      "28350/28350 [==============================] - 1s 39us/step - loss: 0.0710 - accuracy: 0.9695 - val_loss: 0.0758 - val_accuracy: 0.9657\n",
      "Epoch 42/80\n",
      "28350/28350 [==============================] - 1s 37us/step - loss: 0.0722 - accuracy: 0.9687 - val_loss: 0.0827 - val_accuracy: 0.9629\n",
      "Epoch 43/80\n",
      "28350/28350 [==============================] - 1s 39us/step - loss: 0.0715 - accuracy: 0.9691 - val_loss: 0.0760 - val_accuracy: 0.9660\n",
      "Epoch 44/80\n",
      "28350/28350 [==============================] - 1s 36us/step - loss: 0.0722 - accuracy: 0.9682 - val_loss: 0.0808 - val_accuracy: 0.9641\n",
      "Epoch 45/80\n",
      "28350/28350 [==============================] - 1s 37us/step - loss: 0.0708 - accuracy: 0.9690 - val_loss: 0.0811 - val_accuracy: 0.9622\n",
      "Epoch 46/80\n",
      "28350/28350 [==============================] - 1s 39us/step - loss: 0.0705 - accuracy: 0.9697 - val_loss: 0.0745 - val_accuracy: 0.9670\n",
      "Epoch 47/80\n",
      "28350/28350 [==============================] - 1s 38us/step - loss: 0.0695 - accuracy: 0.9679 - val_loss: 0.0775 - val_accuracy: 0.9654\n",
      "Epoch 48/80\n",
      "28350/28350 [==============================] - 1s 39us/step - loss: 0.0712 - accuracy: 0.9685 - val_loss: 0.0784 - val_accuracy: 0.9667\n",
      "Epoch 49/80\n",
      "28350/28350 [==============================] - 1s 36us/step - loss: 0.0719 - accuracy: 0.9676 - val_loss: 0.0787 - val_accuracy: 0.9648\n",
      "Epoch 50/80\n",
      "28350/28350 [==============================] - 1s 41us/step - loss: 0.0726 - accuracy: 0.9693 - val_loss: 0.0785 - val_accuracy: 0.9676\n",
      "Epoch 51/80\n",
      "28350/28350 [==============================] - 1s 39us/step - loss: 0.0697 - accuracy: 0.9691 - val_loss: 0.0761 - val_accuracy: 0.9660\n",
      "Epoch 52/80\n",
      "28350/28350 [==============================] - 1s 39us/step - loss: 0.0699 - accuracy: 0.9695 - val_loss: 0.0818 - val_accuracy: 0.9632\n",
      "Epoch 53/80\n",
      "28350/28350 [==============================] - 1s 40us/step - loss: 0.0712 - accuracy: 0.9679 - val_loss: 0.0762 - val_accuracy: 0.9673\n",
      "Epoch 54/80\n",
      "28350/28350 [==============================] - 1s 38us/step - loss: 0.0714 - accuracy: 0.9678 - val_loss: 0.0816 - val_accuracy: 0.9613\n",
      "Epoch 55/80\n",
      "28350/28350 [==============================] - 1s 40us/step - loss: 0.0720 - accuracy: 0.9673 - val_loss: 0.0760 - val_accuracy: 0.9648\n",
      "Epoch 56/80\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "28350/28350 [==============================] - 1s 37us/step - loss: 0.0704 - accuracy: 0.9689 - val_loss: 0.0747 - val_accuracy: 0.9695\n",
      "Epoch 00056: early stopping\n",
      "[[1.0000000e+00 1.7130478e-20 1.4938520e-18 1.0220634e-08 1.2586707e-16\n",
      "  5.7527547e-24]\n",
      " [4.2943799e-07 5.0853718e-08 1.9101007e-07 5.0912264e-11 2.8174082e-07\n",
      "  9.9999905e-01]\n",
      " [4.1992874e-07 5.0524136e-08 1.9073667e-07 5.0070004e-11 2.8481676e-07\n",
      "  9.9999905e-01]\n",
      " ...\n",
      " [7.7825399e-11 3.4439318e-10 9.9991119e-01 8.8728244e-05 1.1899205e-18\n",
      "  1.6642232e-07]\n",
      " [3.2839043e-07 4.5164119e-14 9.9932337e-01 1.5353191e-05 6.5142091e-04\n",
      "  9.4947054e-06]\n",
      " [2.3500363e-08 2.1443922e-21 2.5054492e-08 1.5851266e-12 9.9999988e-01\n",
      "  8.2415440e-08]]\n",
      "[0 5 5 ... 2 2 4]\n",
      "<class 'numpy.ndarray'>\n",
      "One CNN, r:  3\n",
      "Computing Time:  0:04:23.980199\n",
      "Model: \"sequential_1\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv1d_1 (Conv1D)            (None, 3, 6)              12        \n",
      "_________________________________________________________________\n",
      "average_pooling1d_1 (Average (None, 1, 6)              0         \n",
      "_________________________________________________________________\n",
      "conv1d_2 (Conv1D)            (None, 1, 16)             112       \n",
      "_________________________________________________________________\n",
      "average_pooling1d_2 (Average (None, 1, 16)             0         \n",
      "_________________________________________________________________\n",
      "conv1d_3 (Conv1D)            (None, 1, 120)            2040      \n",
      "_________________________________________________________________\n",
      "flatten_1 (Flatten)          (None, 120)               0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 84)                10164     \n",
      "_________________________________________________________________\n",
      "preds (Dense)                (None, 6)                 510       \n",
      "=================================================================\n",
      "Total params: 12,838\n",
      "Trainable params: 12,838\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Train on 28350 samples, validate on 3151 samples\n",
      "Epoch 1/80\n",
      "28350/28350 [==============================] - 1s 47us/step - loss: 0.8283 - accuracy: 0.6865 - val_loss: 0.3722 - val_accuracy: 0.8642\n",
      "Epoch 2/80\n",
      "28350/28350 [==============================] - 1s 40us/step - loss: 0.2861 - accuracy: 0.8979 - val_loss: 0.2326 - val_accuracy: 0.9197\n",
      "Epoch 3/80\n",
      "28350/28350 [==============================] - 1s 39us/step - loss: 0.2018 - accuracy: 0.9285 - val_loss: 0.1790 - val_accuracy: 0.9407\n",
      "Epoch 4/80\n",
      "28350/28350 [==============================] - 1s 39us/step - loss: 0.1539 - accuracy: 0.9467 - val_loss: 0.1495 - val_accuracy: 0.9429\n",
      "Epoch 5/80\n",
      "28350/28350 [==============================] - 1s 40us/step - loss: 0.1302 - accuracy: 0.9553 - val_loss: 0.1163 - val_accuracy: 0.9575\n",
      "Epoch 6/80\n",
      "28350/28350 [==============================] - 1s 38us/step - loss: 0.1117 - accuracy: 0.9615 - val_loss: 0.1014 - val_accuracy: 0.9626\n",
      "Epoch 7/80\n",
      "28350/28350 [==============================] - 1s 39us/step - loss: 0.1001 - accuracy: 0.9638 - val_loss: 0.0993 - val_accuracy: 0.9610\n",
      "Epoch 8/80\n",
      "28350/28350 [==============================] - 1s 38us/step - loss: 0.0921 - accuracy: 0.9662 - val_loss: 0.0966 - val_accuracy: 0.9626\n",
      "Epoch 9/80\n",
      "28350/28350 [==============================] - 1s 40us/step - loss: 0.0943 - accuracy: 0.9654 - val_loss: 0.1026 - val_accuracy: 0.9629\n",
      "Epoch 10/80\n",
      "28350/28350 [==============================] - 1s 38us/step - loss: 0.0913 - accuracy: 0.9646 - val_loss: 0.0968 - val_accuracy: 0.9648\n",
      "Epoch 11/80\n",
      "28350/28350 [==============================] - 1s 39us/step - loss: 0.0911 - accuracy: 0.9644 - val_loss: 0.0862 - val_accuracy: 0.9660\n",
      "Epoch 12/80\n",
      "28350/28350 [==============================] - 1s 38us/step - loss: 0.0851 - accuracy: 0.9665 - val_loss: 0.0847 - val_accuracy: 0.9667\n",
      "Epoch 13/80\n",
      "28350/28350 [==============================] - 1s 37us/step - loss: 0.0882 - accuracy: 0.9652 - val_loss: 0.1047 - val_accuracy: 0.9603\n",
      "Epoch 14/80\n",
      "28350/28350 [==============================] - 1s 41us/step - loss: 0.0844 - accuracy: 0.9659 - val_loss: 0.0825 - val_accuracy: 0.9683\n",
      "Epoch 15/80\n",
      "28350/28350 [==============================] - 1s 38us/step - loss: 0.0860 - accuracy: 0.9655 - val_loss: 0.0786 - val_accuracy: 0.9692\n",
      "Epoch 16/80\n",
      "28350/28350 [==============================] - 1s 39us/step - loss: 0.0859 - accuracy: 0.9645 - val_loss: 0.0989 - val_accuracy: 0.9575\n",
      "Epoch 17/80\n",
      "28350/28350 [==============================] - 1s 37us/step - loss: 0.0834 - accuracy: 0.9660 - val_loss: 0.0817 - val_accuracy: 0.9676\n",
      "Epoch 18/80\n",
      "28350/28350 [==============================] - 1s 39us/step - loss: 0.0845 - accuracy: 0.9662 - val_loss: 0.0737 - val_accuracy: 0.9708\n",
      "Epoch 19/80\n",
      "28350/28350 [==============================] - 1s 41us/step - loss: 0.0850 - accuracy: 0.9654 - val_loss: 0.0743 - val_accuracy: 0.9705\n",
      "Epoch 20/80\n",
      "28350/28350 [==============================] - 1s 40us/step - loss: 0.0792 - accuracy: 0.9676 - val_loss: 0.0736 - val_accuracy: 0.9708\n",
      "Epoch 21/80\n",
      "28350/28350 [==============================] - 1s 39us/step - loss: 0.0816 - accuracy: 0.9667 - val_loss: 0.0729 - val_accuracy: 0.9695\n",
      "Epoch 22/80\n",
      "28350/28350 [==============================] - 1s 40us/step - loss: 0.0830 - accuracy: 0.9656 - val_loss: 0.0783 - val_accuracy: 0.9679\n",
      "Epoch 23/80\n",
      "28350/28350 [==============================] - 1s 39us/step - loss: 0.0806 - accuracy: 0.9665 - val_loss: 0.0908 - val_accuracy: 0.9610\n",
      "Epoch 24/80\n",
      "28350/28350 [==============================] - 1s 39us/step - loss: 0.0798 - accuracy: 0.9664 - val_loss: 0.1071 - val_accuracy: 0.9581\n",
      "Epoch 25/80\n",
      "28350/28350 [==============================] - 1s 37us/step - loss: 0.0780 - accuracy: 0.9669 - val_loss: 0.0748 - val_accuracy: 0.9705\n",
      "Epoch 26/80\n",
      "28350/28350 [==============================] - 1s 38us/step - loss: 0.0780 - accuracy: 0.9674 - val_loss: 0.0735 - val_accuracy: 0.9695\n",
      "Epoch 27/80\n",
      "28350/28350 [==============================] - 1s 37us/step - loss: 0.0824 - accuracy: 0.9660 - val_loss: 0.0772 - val_accuracy: 0.9654\n",
      "Epoch 28/80\n",
      "28350/28350 [==============================] - 1s 39us/step - loss: 0.0789 - accuracy: 0.9674 - val_loss: 0.0720 - val_accuracy: 0.9705\n",
      "Epoch 29/80\n",
      "28350/28350 [==============================] - 1s 40us/step - loss: 0.0795 - accuracy: 0.9659 - val_loss: 0.0761 - val_accuracy: 0.9686\n",
      "Epoch 30/80\n",
      "28350/28350 [==============================] - 1s 36us/step - loss: 0.0797 - accuracy: 0.9669 - val_loss: 0.0785 - val_accuracy: 0.9679\n",
      "Epoch 31/80\n",
      "28350/28350 [==============================] - 1s 37us/step - loss: 0.0806 - accuracy: 0.9657 - val_loss: 0.0707 - val_accuracy: 0.9718\n",
      "Epoch 32/80\n",
      "28350/28350 [==============================] - 1s 37us/step - loss: 0.0785 - accuracy: 0.9676 - val_loss: 0.0795 - val_accuracy: 0.9654\n",
      "Epoch 33/80\n",
      "28350/28350 [==============================] - 1s 39us/step - loss: 0.0796 - accuracy: 0.9673 - val_loss: 0.0807 - val_accuracy: 0.9679\n",
      "Epoch 34/80\n",
      "28350/28350 [==============================] - 1s 41us/step - loss: 0.0777 - accuracy: 0.9670 - val_loss: 0.0723 - val_accuracy: 0.9683\n",
      "Epoch 35/80\n",
      "28350/28350 [==============================] - 1s 39us/step - loss: 0.0757 - accuracy: 0.9680 - val_loss: 0.0977 - val_accuracy: 0.9619\n",
      "Epoch 36/80\n",
      "28350/28350 [==============================] - 1s 38us/step - loss: 0.0750 - accuracy: 0.9685 - val_loss: 0.0802 - val_accuracy: 0.9657\n",
      "Epoch 37/80\n",
      "28350/28350 [==============================] - 1s 39us/step - loss: 0.0767 - accuracy: 0.9678 - val_loss: 0.0685 - val_accuracy: 0.9714\n",
      "Epoch 38/80\n",
      "28350/28350 [==============================] - 1s 40us/step - loss: 0.0740 - accuracy: 0.9690 - val_loss: 0.0732 - val_accuracy: 0.9699\n",
      "Epoch 39/80\n",
      "28350/28350 [==============================] - 1s 40us/step - loss: 0.0774 - accuracy: 0.9667 - val_loss: 0.0841 - val_accuracy: 0.9635\n",
      "Epoch 40/80\n",
      "28350/28350 [==============================] - 1s 40us/step - loss: 0.0735 - accuracy: 0.9685 - val_loss: 0.0735 - val_accuracy: 0.9683\n",
      "Epoch 41/80\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "28350/28350 [==============================] - 1s 37us/step - loss: 0.0753 - accuracy: 0.9673 - val_loss: 0.0786 - val_accuracy: 0.9660\n",
      "Epoch 42/80\n",
      "28350/28350 [==============================] - 1s 38us/step - loss: 0.0739 - accuracy: 0.9683 - val_loss: 0.0861 - val_accuracy: 0.9638\n",
      "Epoch 43/80\n",
      "28350/28350 [==============================] - 1s 38us/step - loss: 0.0752 - accuracy: 0.9677 - val_loss: 0.0771 - val_accuracy: 0.9664\n",
      "Epoch 44/80\n",
      "28350/28350 [==============================] - 1s 39us/step - loss: 0.0760 - accuracy: 0.9684 - val_loss: 0.0752 - val_accuracy: 0.9648\n",
      "Epoch 45/80\n",
      "28350/28350 [==============================] - 1s 38us/step - loss: 0.0738 - accuracy: 0.9680 - val_loss: 0.0734 - val_accuracy: 0.9699\n",
      "Epoch 46/80\n",
      "28350/28350 [==============================] - 1s 39us/step - loss: 0.0721 - accuracy: 0.9690 - val_loss: 0.0701 - val_accuracy: 0.9718\n",
      "Epoch 47/80\n",
      "28350/28350 [==============================] - 1s 38us/step - loss: 0.0726 - accuracy: 0.9684 - val_loss: 0.0725 - val_accuracy: 0.9683\n",
      "Epoch 00047: early stopping\n",
      "[[1.00000000e+00 1.16376876e-17 6.17663147e-13 2.12921319e-15\n",
      "  1.32102373e-17 6.83817856e-19]\n",
      " [6.45198770e-06 3.95380857e-06 2.26109563e-07 1.63480156e-12\n",
      "  4.69900442e-06 9.99984741e-01]\n",
      " [6.39226164e-06 3.93137725e-06 2.25704142e-07 1.61784041e-12\n",
      "  4.69938595e-06 9.99984860e-01]\n",
      " ...\n",
      " [5.41667544e-11 2.20654103e-11 9.99790609e-01 2.09158068e-04\n",
      "  4.15068084e-21 2.49629096e-07]\n",
      " [7.85189422e-06 4.55367322e-19 9.94626582e-01 3.25590489e-03\n",
      "  1.94704626e-03 1.62634300e-04]\n",
      " [1.05908248e-05 5.77331163e-18 5.98517772e-07 3.91176480e-10\n",
      "  9.99970555e-01 1.82801195e-05]]\n",
      "[0 5 5 ... 2 2 4]\n",
      "<class 'numpy.ndarray'>\n",
      "One CNN, r:  4\n",
      "Computing Time:  0:05:19.980276\n",
      "true region_label= [6, 7, 2, 4, 3, 5]\n",
      "dist_table_truth\n",
      " [[1342  873    0 1493   24  306 1544   17  527]\n",
      " [ 622    1    3  282  301    3 2121 3248   48]\n",
      " [ 182  708 2362   17 1341  584   15  413 1013]\n",
      " [ 210 1203 2054    0 1924  262  107    0  461]\n",
      " [2157  496   21 2422   43 1254   57   23 2122]\n",
      " [ 230  787   25  248  238 1937 1000  470  257]]\n",
      "num of merged_region_image 0 4963\n",
      "num of merged_region_image 1 5534\n",
      "num of merged_region_image 2 5469\n",
      "num of merged_region_image 3 5862\n",
      "num of merged_region_image 4 5890\n",
      "num of merged_region_image 5 3783\n",
      "Counter({-1: 11716, 4: 5890, 3: 5862, 1: 5534, 2: 5469, 0: 4963, 5: 3783})\n",
      "\n",
      "\n",
      "==== merged_and_expand(PATH5,ITE) ====\n",
      "===========  ITE = 4   ===========\n",
      "used_img 31501 31501\n",
      "working_img(=other images=unclean images) 11716 11716\n",
      "merged regions 159 159\n",
      "other_regions 41 41\n",
      "All other regions\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>other index</th>\n",
       "      <th>pred label</th>\n",
       "      <th>truth</th>\n",
       "      <th>rate</th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>8</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>0.60</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>361</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>9</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>0.63</td>\n",
       "      <td>245</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>13</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.62</td>\n",
       "      <td>0</td>\n",
       "      <td>26</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>144</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>0.70</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>135</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>20</td>\n",
       "      <td>5</td>\n",
       "      <td>7</td>\n",
       "      <td>0.64</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>149</td>\n",
       "      <td>-1</td>\n",
       "      <td>8</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>152</td>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "      <td>0.40</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>399</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>153</td>\n",
       "      <td>-1</td>\n",
       "      <td>8</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>154</td>\n",
       "      <td>4</td>\n",
       "      <td>8</td>\n",
       "      <td>0.88</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>28</td>\n",
       "      <td>4</td>\n",
       "      <td>8</td>\n",
       "      <td>0.69</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>32</td>\n",
       "      <td>4</td>\n",
       "      <td>8</td>\n",
       "      <td>0.53</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>34</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>0.61</td>\n",
       "      <td>0</td>\n",
       "      <td>69</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>39</td>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "      <td>0.50</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>117</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>169</td>\n",
       "      <td>-1</td>\n",
       "      <td>5</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>112</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>170</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>0.72</td>\n",
       "      <td>6</td>\n",
       "      <td>601</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>171</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.47</td>\n",
       "      <td>120</td>\n",
       "      <td>12</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>44</td>\n",
       "      <td>4</td>\n",
       "      <td>8</td>\n",
       "      <td>0.72</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>46</td>\n",
       "      <td>2</td>\n",
       "      <td>8</td>\n",
       "      <td>0.46</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>176</td>\n",
       "      <td>-1</td>\n",
       "      <td>4</td>\n",
       "      <td>0.00</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>96</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>183</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>0.46</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>202</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>184</td>\n",
       "      <td>2</td>\n",
       "      <td>8</td>\n",
       "      <td>0.38</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>57</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0.59</td>\n",
       "      <td>0</td>\n",
       "      <td>128</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>187</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>0.57</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>223</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>188</td>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "      <td>0.61</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>31</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>190</td>\n",
       "      <td>4</td>\n",
       "      <td>8</td>\n",
       "      <td>0.51</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>191</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>0.43</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>227</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>195</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>0.70</td>\n",
       "      <td>2</td>\n",
       "      <td>21</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>17</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>196</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>0.48</td>\n",
       "      <td>372</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>69</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>0.49</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>242</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>70</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>0.55</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>183</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>199</td>\n",
       "      <td>2</td>\n",
       "      <td>8</td>\n",
       "      <td>0.82</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>72</td>\n",
       "      <td>-1</td>\n",
       "      <td>5</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>238</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>73</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>0.50</td>\n",
       "      <td>30</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>79</td>\n",
       "      <td>1</td>\n",
       "      <td>6</td>\n",
       "      <td>0.54</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>82</td>\n",
       "      <td>1</td>\n",
       "      <td>7</td>\n",
       "      <td>0.64</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35</th>\n",
       "      <td>84</td>\n",
       "      <td>2</td>\n",
       "      <td>8</td>\n",
       "      <td>0.76</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36</th>\n",
       "      <td>95</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>0.73</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>221</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37</th>\n",
       "      <td>97</td>\n",
       "      <td>1</td>\n",
       "      <td>6</td>\n",
       "      <td>0.57</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38</th>\n",
       "      <td>113</td>\n",
       "      <td>2</td>\n",
       "      <td>7</td>\n",
       "      <td>0.65</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39</th>\n",
       "      <td>118</td>\n",
       "      <td>4</td>\n",
       "      <td>8</td>\n",
       "      <td>0.85</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40</th>\n",
       "      <td>123</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>0.25</td>\n",
       "      <td>54</td>\n",
       "      <td>244</td>\n",
       "      <td>98</td>\n",
       "      <td>62</td>\n",
       "      <td>18</td>\n",
       "      <td>457</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    other index  pred label  truth  rate    0    1    2    3    4    5\n",
       "0             8           5      5  0.60    0    3    0    0    0  361\n",
       "1             9           5      0  0.63  245    0    1    0    1    0\n",
       "2            13           0      1  0.62    0   26    0    0    0    0\n",
       "3           144           4      3  0.70    0    0    0  135    0    0\n",
       "4            20           5      7  0.64    0    0    0    0    0    0\n",
       "5           149          -1      8  0.00    0    0    0    0    1    3\n",
       "6           152           2      4  0.40    3    0    0    0  399    0\n",
       "7           153          -1      8  0.00    1    0    0    0    0    0\n",
       "8           154           4      8  0.88    0    0    0    0    0    1\n",
       "9            28           4      8  0.69    0    0    0    0    0    0\n",
       "10           32           4      8  0.53    2    0    0    0    0    1\n",
       "11           34           3      1  0.61    0   69    0    0    0    0\n",
       "12           39           2      4  0.50    2    0    2    0  117    0\n",
       "13          169          -1      5  0.00    0    0    0    0    0  112\n",
       "14          170           4      1  0.72    6  601    0    0    0    2\n",
       "15          171           0      0  0.47  120   12    0    0    0    0\n",
       "16           44           4      8  0.72    1    0    0    0    1    0\n",
       "17           46           2      8  0.46    5    0    0    0    1    0\n",
       "18          176          -1      4  0.00    3    2    0    0   96    0\n",
       "19          183           0      3  0.46    0    0    0  202    0    0\n",
       "20          184           2      8  0.38    0    0    0    0    0    0\n",
       "21           57           2      1  0.59    0  128    0    0    0    0\n",
       "22          187           3      2  0.57    0    0  223    0    0    0\n",
       "23          188           2      4  0.61    0    0    0    0   31    0\n",
       "24          190           4      8  0.51    1    0    0    0    0    4\n",
       "25          191           1      3  0.43    5    0    0  227    1    0\n",
       "26          195           4      1  0.70    2   21    0    0    0   17\n",
       "27          196           4      0  0.48  372    2    1    1    4    1\n",
       "28           69           0      3  0.49    0    0    0  242    0    0\n",
       "29           70           1      3  0.55    0    0    0  183    0    0\n",
       "30          199           2      8  0.82    0    0    2    0    0    0\n",
       "31           72          -1      5  0.00    1    0    0    0    0  238\n",
       "32           73           4      0  0.50   30    0    0    0    0    0\n",
       "33           79           1      6  0.54    2    0    0    0    0    0\n",
       "34           82           1      7  0.64    0    0    0    0    0    0\n",
       "35           84           2      8  0.76    0    0    0    0    0    0\n",
       "36           95           0      3  0.73    0    0    0  221    0    0\n",
       "37           97           1      6  0.57    0    0    0    0    0    0\n",
       "38          113           2      7  0.65    0    0    0    0    0    0\n",
       "39          118           4      8  0.85    3    4    0    1    1    3\n",
       "40          123           5      5  0.25   54  244   98   62   18  457"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "added label, regions, img amount: {0} [95] 161\n",
      "added label, regions, img amount: {2} [199, 84] 163\n",
      "added label, regions, img amount: {4} [154, 118, 170, 44] 1324\n",
      "Not getting into residuals\n"
     ]
    }
   ],
   "source": [
    "for case_i in range(NUM_CASE):\n",
    "\n",
    "    #===== create folder case1, case2, case3...\n",
    "    print(\"case=\",case_i+1)\n",
    "    newpath = './case' + str(case_i+1)\n",
    "    if (not INTE_bool):\n",
    "        if not os.path.exists(newpath):   #No necessary in Integration\n",
    "            os.makedirs(newpath)\n",
    "    \n",
    "    #==== open csv 1\n",
    "    csv_path1 = newpath+'/' + 'accu_history.csv'\n",
    "    with open(csv_path1, 'a', newline='') as f:\n",
    "        csv_file = csv.writer(f)\n",
    "        csv_file.writerow(['ITE', 'correct', 'denominator', 'accu', 'description'])\n",
    "\n",
    "# 1.\n",
    "    if (not INTE_bool):\n",
    "        create_image_0(PATH6, case_i)   #No necessary in Integration\n",
    "\n",
    "\n",
    "    for ITE in range(ITE_START, ITE_END):\n",
    "# 2. CNN\n",
    "        CNN_part(PATH5,ITE)\n",
    "\n",
    "# 3. statistic\n",
    "        statistic(PATH5,ITE)\n",
    "\n",
    "# 4. merged_and_expand \n",
    "        merged_and_expand(PATH5,ITE)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Interpret the accuracy results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(overall 5-consensus)\n",
      "criterion 1\n",
      "correct in 5-consensus\n",
      "------------------------------------\n",
      "5-consensus\n",
      "\n",
      "ITE ITE     correct / denominator = accu\n",
      "ITE 0     2625 / 29339 = 0.089\n",
      "ITE 0     2625 / 29339 = 0.089\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "criterion 2\n",
      "correct in 5-consensus\n",
      "------------------------------------\n",
      "all\n",
      "\n",
      "ITE ITE     correct / denominator = accu\n",
      "ITE 0     2625 / 43217 = 0.061\n",
      "ITE 0     2625 / 43217 = 0.061\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "(clean)\n",
      "criterion 3\n",
      "correct in train in 5-consensus\n",
      "------------------------------------\n",
      "train in 5-consensus\n",
      "\n",
      "ITE ITE     correct / denominator = accu\n",
      "ITE 0     9403 / 43217 = 0.218\n",
      "ITE 0     9403 / 43217 = 0.218\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "criterion 4\n",
      "correct in train in 5-consensus \n",
      "------------------------------------\n",
      "all\n",
      "\n",
      "ITE 0     8326 / 38182 = 0.218\n",
      "ITE 0     8326 / 38182 = 0.218\n",
      "ITE ITE     correct / denominator = accu\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "(unclean)\n",
      "criterion 5\n",
      "correct in test in 5-consensus\n",
      "------------------------------------\n",
      "test in 5-consensus\n",
      "\n",
      "ITE 0     8326 / 43217 = 0.193\n",
      "ITE 0     8326 / 43217 = 0.193\n",
      "ITE 0     7809 / 37255 = 0.21\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "criterion 6\n",
      "correct in test in 5-consensus\n",
      "------------------------------------\n",
      "all\n",
      "\n",
      "ITE 0     7243 / 13878 = 0.522\n",
      "ITE 0     7243 / 13878 = 0.522\n",
      "ITE 0     7809 / 43217 = 0.181\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "(majority)\n",
      "criterion 7\n",
      "correct\n",
      "------------------\n",
      "all\n",
      "\n",
      "ITE 0     7243 / 43217 = 0.168\n",
      "ITE 0     7243 / 43217 = 0.168\n",
      "ITE 0     7243 / 13878 = 0.522\n",
      "\n",
      "\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "interpret_accu_results(interpret_path, AMOUNT_ITE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "done\n"
     ]
    }
   ],
   "source": [
    "print(\"done\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
